2025-05-09 17:43:15,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-09 17:43:15,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-09 17:43:15,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-09 17:43:15,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-09 17:45:05,173:INFO:PyCaret ClassificationExperiment
2025-05-09 17:45:05,173:INFO:Logging name: clf-default-name
2025-05-09 17:45:05,173:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-09 17:45:05,173:INFO:version 3.3.2
2025-05-09 17:45:05,173:INFO:Initializing setup()
2025-05-09 17:45:05,173:INFO:self.USI: 57e5
2025-05-09 17:45:05,173:INFO:self._variable_keys: {'USI', 'html_param', 'exp_name_log', 'seed', 'logging_param', 'X', 'fix_imbalance', 'gpu_n_jobs_param', '_available_plots', 'exp_id', 'is_multiclass', 'X_test', 'y_test', 'memory', 'fold_shuffle_param', 'log_plots_param', 'n_jobs_param', 'target_param', 'fold_groups_param', '_ml_usecase', 'pipeline', 'data', 'gpu_param', 'y', 'idx', 'X_train', 'fold_generator', 'y_train'}
2025-05-09 17:45:05,173:INFO:Checking environment
2025-05-09 17:45:05,173:INFO:python_version: 3.11.0
2025-05-09 17:45:05,173:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-09 17:45:05,173:INFO:machine: arm64
2025-05-09 17:45:05,173:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-09 17:45:05,174:INFO:Memory: svmem(total=17179869184, available=3983212544, percent=76.8, used=6546800640, free=69681152, active=3933634560, inactive=3889430528, wired=2613166080)
2025-05-09 17:45:05,174:INFO:Physical Core: 12
2025-05-09 17:45:05,174:INFO:Logical Core: 12
2025-05-09 17:45:05,174:INFO:Checking libraries
2025-05-09 17:45:05,174:INFO:System:
2025-05-09 17:45:05,174:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-09 17:45:05,174:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-09 17:45:05,174:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-09 17:45:05,174:INFO:PyCaret required dependencies:
2025-05-09 17:45:05,425:INFO:                 pip: 22.3
2025-05-09 17:45:05,426:INFO:          setuptools: 65.5.0
2025-05-09 17:45:05,426:INFO:             pycaret: 3.3.2
2025-05-09 17:45:05,426:INFO:             IPython: 9.2.0
2025-05-09 17:45:05,426:INFO:          ipywidgets: 8.1.7
2025-05-09 17:45:05,426:INFO:                tqdm: 4.67.1
2025-05-09 17:45:05,426:INFO:               numpy: 1.26.4
2025-05-09 17:45:05,426:INFO:              pandas: 2.1.4
2025-05-09 17:45:05,426:INFO:              jinja2: 3.1.6
2025-05-09 17:45:05,426:INFO:               scipy: 1.11.4
2025-05-09 17:45:05,426:INFO:              joblib: 1.3.2
2025-05-09 17:45:05,426:INFO:             sklearn: 1.4.2
2025-05-09 17:45:05,426:INFO:                pyod: 2.0.5
2025-05-09 17:45:05,426:INFO:            imblearn: 0.13.0
2025-05-09 17:45:05,426:INFO:   category_encoders: 2.7.0
2025-05-09 17:45:05,426:INFO:            lightgbm: 4.6.0
2025-05-09 17:45:05,426:INFO:               numba: 0.61.2
2025-05-09 17:45:05,426:INFO:            requests: 2.32.3
2025-05-09 17:45:05,426:INFO:          matplotlib: 3.7.5
2025-05-09 17:45:05,426:INFO:          scikitplot: 0.3.7
2025-05-09 17:45:05,426:INFO:         yellowbrick: 1.5
2025-05-09 17:45:05,426:INFO:              plotly: 5.24.1
2025-05-09 17:45:05,426:INFO:    plotly-resampler: Not installed
2025-05-09 17:45:05,426:INFO:             kaleido: 0.2.1
2025-05-09 17:45:05,426:INFO:           schemdraw: 0.15
2025-05-09 17:45:05,426:INFO:         statsmodels: 0.14.4
2025-05-09 17:45:05,426:INFO:              sktime: 0.26.0
2025-05-09 17:45:05,426:INFO:               tbats: 1.1.3
2025-05-09 17:45:05,426:INFO:            pmdarima: 2.0.4
2025-05-09 17:45:05,426:INFO:              psutil: 7.0.0
2025-05-09 17:45:05,426:INFO:          markupsafe: 3.0.2
2025-05-09 17:45:05,426:INFO:             pickle5: Not installed
2025-05-09 17:45:05,426:INFO:         cloudpickle: 3.1.1
2025-05-09 17:45:05,426:INFO:         deprecation: 2.1.0
2025-05-09 17:45:05,426:INFO:              xxhash: 3.5.0
2025-05-09 17:45:05,426:INFO:           wurlitzer: 3.1.1
2025-05-09 17:45:05,426:INFO:PyCaret optional dependencies:
2025-05-09 17:45:05,436:INFO:                shap: Not installed
2025-05-09 17:45:05,436:INFO:           interpret: Not installed
2025-05-09 17:45:05,436:INFO:                umap: Not installed
2025-05-09 17:45:05,437:INFO:     ydata_profiling: Not installed
2025-05-09 17:45:05,437:INFO:  explainerdashboard: Not installed
2025-05-09 17:45:05,437:INFO:             autoviz: Not installed
2025-05-09 17:45:05,437:INFO:           fairlearn: Not installed
2025-05-09 17:45:05,437:INFO:          deepchecks: Not installed
2025-05-09 17:45:05,437:INFO:             xgboost: Not installed
2025-05-09 17:45:05,437:INFO:            catboost: Not installed
2025-05-09 17:45:05,437:INFO:              kmodes: Not installed
2025-05-09 17:45:05,437:INFO:             mlxtend: Not installed
2025-05-09 17:45:05,437:INFO:       statsforecast: Not installed
2025-05-09 17:45:05,437:INFO:        tune_sklearn: Not installed
2025-05-09 17:45:05,437:INFO:                 ray: Not installed
2025-05-09 17:45:05,437:INFO:            hyperopt: Not installed
2025-05-09 17:45:05,437:INFO:              optuna: Not installed
2025-05-09 17:45:05,437:INFO:               skopt: Not installed
2025-05-09 17:45:05,437:INFO:              mlflow: Not installed
2025-05-09 17:45:05,437:INFO:              gradio: Not installed
2025-05-09 17:45:05,437:INFO:             fastapi: Not installed
2025-05-09 17:45:05,437:INFO:             uvicorn: Not installed
2025-05-09 17:45:05,437:INFO:              m2cgen: Not installed
2025-05-09 17:45:05,437:INFO:           evidently: Not installed
2025-05-09 17:45:05,437:INFO:               fugue: Not installed
2025-05-09 17:45:05,437:INFO:           streamlit: Not installed
2025-05-09 17:45:05,437:INFO:             prophet: Not installed
2025-05-09 17:45:05,437:INFO:None
2025-05-09 17:45:05,437:INFO:Set up data.
2025-05-09 17:45:05,484:INFO:Set up folding strategy.
2025-05-09 17:45:05,484:INFO:Set up train/test split.
2025-05-09 17:45:05,627:INFO:Set up index.
2025-05-09 17:45:05,627:INFO:Assigning column types.
2025-05-09 17:45:05,633:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-09 17:45:05,652:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 17:45:05,654:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:45:05,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:05,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:05,689:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 17:45:05,689:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:45:05,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:05,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:05,702:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-09 17:45:05,720:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:45:05,732:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:05,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:05,752:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:45:05,763:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:05,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:05,763:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-09 17:45:05,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:05,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:05,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:05,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:05,829:INFO:Preparing preprocessing pipeline...
2025-05-09 17:45:05,830:INFO:Set up simple imputation.
2025-05-09 17:45:05,837:INFO:Set up encoding of ordinal features.
2025-05-09 17:45:05,848:INFO:Set up encoding of categorical features.
2025-05-09 17:45:05,849:INFO:Set up imbalanced handling.
2025-05-09 17:45:05,849:INFO:Set up column transformation.
2025-05-09 17:45:07,204:INFO:Finished creating preprocessing pipeline.
2025-05-09 17:45:07,223:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-09 17:45:07,223:INFO:Creating final display dataframe.
2025-05-09 17:45:07,702:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              57e5
2025-05-09 17:45:07,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:07,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:07,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:07,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:45:07,774:INFO:setup() successfully completed in 2.6s...............
2025-05-09 17:45:07,774:INFO:Initializing compare_models()
2025-05-09 17:45:07,774:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-09 17:45:07,774:INFO:Checking exceptions
2025-05-09 17:45:07,781:INFO:Preparing display monitor
2025-05-09 17:45:07,831:INFO:Initializing Logistic Regression
2025-05-09 17:45:07,831:INFO:Total runtime is 3.4968058268229165e-06 minutes
2025-05-09 17:45:07,832:INFO:SubProcess create_model() called ==================================
2025-05-09 17:45:07,832:INFO:Initializing create_model()
2025-05-09 17:45:07,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337afc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:45:07,833:INFO:Checking exceptions
2025-05-09 17:45:07,833:INFO:Importing libraries
2025-05-09 17:45:07,833:INFO:Copying training dataset
2025-05-09 17:45:07,845:INFO:Defining folds
2025-05-09 17:45:07,846:INFO:Declaring metric variables
2025-05-09 17:45:07,847:INFO:Importing untrained model
2025-05-09 17:45:07,848:INFO:Logistic Regression Imported successfully
2025-05-09 17:45:07,850:INFO:Starting cross validation
2025-05-09 17:45:07,853:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:45:13,577:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:45:13,592:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:45:13,596:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:45:13,614:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:45:13,668:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:45:13,731:INFO:Calculating mean and std
2025-05-09 17:45:13,733:INFO:Creating metrics dataframe
2025-05-09 17:45:13,734:INFO:Uploading results into container
2025-05-09 17:45:13,735:INFO:Uploading model into container now
2025-05-09 17:45:13,735:INFO:_master_model_container: 1
2025-05-09 17:45:13,735:INFO:_display_container: 2
2025-05-09 17:45:13,736:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-09 17:45:13,736:INFO:create_model() successfully completed......................................
2025-05-09 17:45:13,818:INFO:SubProcess create_model() end ==================================
2025-05-09 17:45:13,818:INFO:Creating metrics dataframe
2025-05-09 17:45:13,821:INFO:Initializing K Neighbors Classifier
2025-05-09 17:45:13,821:INFO:Total runtime is 0.09984771410624187 minutes
2025-05-09 17:45:13,823:INFO:SubProcess create_model() called ==================================
2025-05-09 17:45:13,823:INFO:Initializing create_model()
2025-05-09 17:45:13,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337afc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:45:13,823:INFO:Checking exceptions
2025-05-09 17:45:13,823:INFO:Importing libraries
2025-05-09 17:45:13,823:INFO:Copying training dataset
2025-05-09 17:45:13,834:INFO:Defining folds
2025-05-09 17:45:13,834:INFO:Declaring metric variables
2025-05-09 17:45:13,835:INFO:Importing untrained model
2025-05-09 17:45:13,837:INFO:K Neighbors Classifier Imported successfully
2025-05-09 17:45:13,839:INFO:Starting cross validation
2025-05-09 17:45:13,840:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:45:19,782:INFO:Calculating mean and std
2025-05-09 17:45:19,783:INFO:Creating metrics dataframe
2025-05-09 17:45:19,784:INFO:Uploading results into container
2025-05-09 17:45:19,785:INFO:Uploading model into container now
2025-05-09 17:45:19,785:INFO:_master_model_container: 2
2025-05-09 17:45:19,785:INFO:_display_container: 2
2025-05-09 17:45:19,785:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-09 17:45:19,785:INFO:create_model() successfully completed......................................
2025-05-09 17:45:19,843:INFO:SubProcess create_model() end ==================================
2025-05-09 17:45:19,844:INFO:Creating metrics dataframe
2025-05-09 17:45:19,847:INFO:Initializing Naive Bayes
2025-05-09 17:45:19,847:INFO:Total runtime is 0.200269615650177 minutes
2025-05-09 17:45:19,848:INFO:SubProcess create_model() called ==================================
2025-05-09 17:45:19,848:INFO:Initializing create_model()
2025-05-09 17:45:19,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337afc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:45:19,848:INFO:Checking exceptions
2025-05-09 17:45:19,848:INFO:Importing libraries
2025-05-09 17:45:19,848:INFO:Copying training dataset
2025-05-09 17:45:19,858:INFO:Defining folds
2025-05-09 17:45:19,859:INFO:Declaring metric variables
2025-05-09 17:45:19,860:INFO:Importing untrained model
2025-05-09 17:45:19,861:INFO:Naive Bayes Imported successfully
2025-05-09 17:45:19,863:INFO:Starting cross validation
2025-05-09 17:45:19,865:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:45:22,131:INFO:Calculating mean and std
2025-05-09 17:45:22,135:INFO:Creating metrics dataframe
2025-05-09 17:45:22,137:INFO:Uploading results into container
2025-05-09 17:45:22,138:INFO:Uploading model into container now
2025-05-09 17:45:22,138:INFO:_master_model_container: 3
2025-05-09 17:45:22,138:INFO:_display_container: 2
2025-05-09 17:45:22,138:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-09 17:45:22,138:INFO:create_model() successfully completed......................................
2025-05-09 17:45:22,189:INFO:SubProcess create_model() end ==================================
2025-05-09 17:45:22,189:INFO:Creating metrics dataframe
2025-05-09 17:45:22,193:INFO:Initializing Decision Tree Classifier
2025-05-09 17:45:22,193:INFO:Total runtime is 0.23937471707661948 minutes
2025-05-09 17:45:22,194:INFO:SubProcess create_model() called ==================================
2025-05-09 17:45:22,194:INFO:Initializing create_model()
2025-05-09 17:45:22,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337afc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:45:22,195:INFO:Checking exceptions
2025-05-09 17:45:22,195:INFO:Importing libraries
2025-05-09 17:45:22,195:INFO:Copying training dataset
2025-05-09 17:45:22,206:INFO:Defining folds
2025-05-09 17:45:22,206:INFO:Declaring metric variables
2025-05-09 17:45:22,207:INFO:Importing untrained model
2025-05-09 17:45:22,209:INFO:Decision Tree Classifier Imported successfully
2025-05-09 17:45:22,211:INFO:Starting cross validation
2025-05-09 17:45:22,212:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:45:23,873:INFO:Calculating mean and std
2025-05-09 17:45:23,873:INFO:Creating metrics dataframe
2025-05-09 17:45:23,874:INFO:Uploading results into container
2025-05-09 17:45:23,875:INFO:Uploading model into container now
2025-05-09 17:45:23,875:INFO:_master_model_container: 4
2025-05-09 17:45:23,875:INFO:_display_container: 2
2025-05-09 17:45:23,875:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-09 17:45:23,875:INFO:create_model() successfully completed......................................
2025-05-09 17:45:23,917:INFO:SubProcess create_model() end ==================================
2025-05-09 17:45:23,918:INFO:Creating metrics dataframe
2025-05-09 17:45:23,921:INFO:Initializing SVM - Linear Kernel
2025-05-09 17:45:23,921:INFO:Total runtime is 0.26817026535669963 minutes
2025-05-09 17:45:23,922:INFO:SubProcess create_model() called ==================================
2025-05-09 17:45:23,922:INFO:Initializing create_model()
2025-05-09 17:45:23,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337afc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:45:23,922:INFO:Checking exceptions
2025-05-09 17:45:23,922:INFO:Importing libraries
2025-05-09 17:45:23,922:INFO:Copying training dataset
2025-05-09 17:45:23,932:INFO:Defining folds
2025-05-09 17:45:23,932:INFO:Declaring metric variables
2025-05-09 17:45:23,934:INFO:Importing untrained model
2025-05-09 17:45:23,935:INFO:SVM - Linear Kernel Imported successfully
2025-05-09 17:45:23,937:INFO:Starting cross validation
2025-05-09 17:45:23,938:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:45:27,525:INFO:Calculating mean and std
2025-05-09 17:45:27,526:INFO:Creating metrics dataframe
2025-05-09 17:45:27,527:INFO:Uploading results into container
2025-05-09 17:45:27,527:INFO:Uploading model into container now
2025-05-09 17:45:27,528:INFO:_master_model_container: 5
2025-05-09 17:45:27,528:INFO:_display_container: 2
2025-05-09 17:45:27,528:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-09 17:45:27,528:INFO:create_model() successfully completed......................................
2025-05-09 17:45:27,583:INFO:SubProcess create_model() end ==================================
2025-05-09 17:45:27,583:INFO:Creating metrics dataframe
2025-05-09 17:45:27,586:INFO:Initializing Ridge Classifier
2025-05-09 17:45:27,586:INFO:Total runtime is 0.32925729751586913 minutes
2025-05-09 17:45:27,587:INFO:SubProcess create_model() called ==================================
2025-05-09 17:45:27,587:INFO:Initializing create_model()
2025-05-09 17:45:27,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337afc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:45:27,588:INFO:Checking exceptions
2025-05-09 17:45:27,588:INFO:Importing libraries
2025-05-09 17:45:27,588:INFO:Copying training dataset
2025-05-09 17:45:27,599:INFO:Defining folds
2025-05-09 17:45:27,599:INFO:Declaring metric variables
2025-05-09 17:45:27,600:INFO:Importing untrained model
2025-05-09 17:45:27,601:INFO:Ridge Classifier Imported successfully
2025-05-09 17:45:27,604:INFO:Starting cross validation
2025-05-09 17:45:27,606:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:45:28,712:INFO:Calculating mean and std
2025-05-09 17:45:28,712:INFO:Creating metrics dataframe
2025-05-09 17:45:28,713:INFO:Uploading results into container
2025-05-09 17:45:28,713:INFO:Uploading model into container now
2025-05-09 17:45:28,714:INFO:_master_model_container: 6
2025-05-09 17:45:28,714:INFO:_display_container: 2
2025-05-09 17:45:28,714:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-09 17:45:28,714:INFO:create_model() successfully completed......................................
2025-05-09 17:45:28,765:INFO:SubProcess create_model() end ==================================
2025-05-09 17:45:28,765:INFO:Creating metrics dataframe
2025-05-09 17:45:28,769:INFO:Initializing Random Forest Classifier
2025-05-09 17:45:28,769:INFO:Total runtime is 0.3489700635274251 minutes
2025-05-09 17:45:28,770:INFO:SubProcess create_model() called ==================================
2025-05-09 17:45:28,771:INFO:Initializing create_model()
2025-05-09 17:45:28,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337afc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:45:28,771:INFO:Checking exceptions
2025-05-09 17:45:28,771:INFO:Importing libraries
2025-05-09 17:45:28,771:INFO:Copying training dataset
2025-05-09 17:45:28,782:INFO:Defining folds
2025-05-09 17:45:28,782:INFO:Declaring metric variables
2025-05-09 17:45:28,783:INFO:Importing untrained model
2025-05-09 17:45:28,785:INFO:Random Forest Classifier Imported successfully
2025-05-09 17:45:28,787:INFO:Starting cross validation
2025-05-09 17:45:28,788:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:45:34,347:INFO:Calculating mean and std
2025-05-09 17:45:34,349:INFO:Creating metrics dataframe
2025-05-09 17:45:34,355:INFO:Uploading results into container
2025-05-09 17:45:34,355:INFO:Uploading model into container now
2025-05-09 17:45:34,356:INFO:_master_model_container: 7
2025-05-09 17:45:34,356:INFO:_display_container: 2
2025-05-09 17:45:34,356:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-09 17:45:34,356:INFO:create_model() successfully completed......................................
2025-05-09 17:45:34,416:INFO:SubProcess create_model() end ==================================
2025-05-09 17:45:34,416:INFO:Creating metrics dataframe
2025-05-09 17:45:34,419:INFO:Initializing Quadratic Discriminant Analysis
2025-05-09 17:45:34,419:INFO:Total runtime is 0.44314448038736975 minutes
2025-05-09 17:45:34,420:INFO:SubProcess create_model() called ==================================
2025-05-09 17:45:34,421:INFO:Initializing create_model()
2025-05-09 17:45:34,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337afc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:45:34,421:INFO:Checking exceptions
2025-05-09 17:45:34,421:INFO:Importing libraries
2025-05-09 17:45:34,421:INFO:Copying training dataset
2025-05-09 17:45:34,431:INFO:Defining folds
2025-05-09 17:45:34,431:INFO:Declaring metric variables
2025-05-09 17:45:34,432:INFO:Importing untrained model
2025-05-09 17:45:34,433:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-09 17:45:34,435:INFO:Starting cross validation
2025-05-09 17:45:34,437:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:45:35,444:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:45:35,462:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:45:35,479:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:45:35,495:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:45:35,525:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:45:35,533:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:45:35,545:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:45:35,553:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:45:35,569:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:45:35,601:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:45:35,615:INFO:Calculating mean and std
2025-05-09 17:45:35,615:INFO:Creating metrics dataframe
2025-05-09 17:45:35,616:INFO:Uploading results into container
2025-05-09 17:45:35,616:INFO:Uploading model into container now
2025-05-09 17:45:35,616:INFO:_master_model_container: 8
2025-05-09 17:45:35,616:INFO:_display_container: 2
2025-05-09 17:45:35,617:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-09 17:45:35,617:INFO:create_model() successfully completed......................................
2025-05-09 17:45:35,661:INFO:SubProcess create_model() end ==================================
2025-05-09 17:45:35,661:INFO:Creating metrics dataframe
2025-05-09 17:45:35,664:INFO:Initializing Ada Boost Classifier
2025-05-09 17:45:35,664:INFO:Total runtime is 0.46389154990514114 minutes
2025-05-09 17:45:35,665:INFO:SubProcess create_model() called ==================================
2025-05-09 17:45:35,665:INFO:Initializing create_model()
2025-05-09 17:45:35,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337afc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:45:35,665:INFO:Checking exceptions
2025-05-09 17:45:35,665:INFO:Importing libraries
2025-05-09 17:45:35,666:INFO:Copying training dataset
2025-05-09 17:45:35,676:INFO:Defining folds
2025-05-09 17:45:35,676:INFO:Declaring metric variables
2025-05-09 17:45:35,677:INFO:Importing untrained model
2025-05-09 17:45:35,678:INFO:Ada Boost Classifier Imported successfully
2025-05-09 17:45:35,680:INFO:Starting cross validation
2025-05-09 17:45:35,681:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:45:36,650:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:45:36,663:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:45:36,669:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:45:36,718:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:45:36,757:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:45:39,415:INFO:Calculating mean and std
2025-05-09 17:45:39,415:INFO:Creating metrics dataframe
2025-05-09 17:45:39,416:INFO:Uploading results into container
2025-05-09 17:45:39,416:INFO:Uploading model into container now
2025-05-09 17:45:39,417:INFO:_master_model_container: 9
2025-05-09 17:45:39,417:INFO:_display_container: 2
2025-05-09 17:45:39,417:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-09 17:45:39,417:INFO:create_model() successfully completed......................................
2025-05-09 17:45:39,469:INFO:SubProcess create_model() end ==================================
2025-05-09 17:45:39,470:INFO:Creating metrics dataframe
2025-05-09 17:45:39,473:INFO:Initializing Gradient Boosting Classifier
2025-05-09 17:45:39,473:INFO:Total runtime is 0.5273747483889262 minutes
2025-05-09 17:45:39,474:INFO:SubProcess create_model() called ==================================
2025-05-09 17:45:39,474:INFO:Initializing create_model()
2025-05-09 17:45:39,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337afc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:45:39,474:INFO:Checking exceptions
2025-05-09 17:45:39,474:INFO:Importing libraries
2025-05-09 17:45:39,475:INFO:Copying training dataset
2025-05-09 17:45:39,484:INFO:Defining folds
2025-05-09 17:45:39,484:INFO:Declaring metric variables
2025-05-09 17:45:39,485:INFO:Importing untrained model
2025-05-09 17:45:39,486:INFO:Gradient Boosting Classifier Imported successfully
2025-05-09 17:45:39,489:INFO:Starting cross validation
2025-05-09 17:45:39,490:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:45:52,996:INFO:Calculating mean and std
2025-05-09 17:45:52,996:INFO:Creating metrics dataframe
2025-05-09 17:45:52,997:INFO:Uploading results into container
2025-05-09 17:45:52,997:INFO:Uploading model into container now
2025-05-09 17:45:52,998:INFO:_master_model_container: 10
2025-05-09 17:45:52,998:INFO:_display_container: 2
2025-05-09 17:45:52,998:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-09 17:45:52,998:INFO:create_model() successfully completed......................................
2025-05-09 17:45:53,045:INFO:SubProcess create_model() end ==================================
2025-05-09 17:45:53,045:INFO:Creating metrics dataframe
2025-05-09 17:45:53,049:INFO:Initializing Linear Discriminant Analysis
2025-05-09 17:45:53,049:INFO:Total runtime is 0.7536363999048868 minutes
2025-05-09 17:45:53,050:INFO:SubProcess create_model() called ==================================
2025-05-09 17:45:53,050:INFO:Initializing create_model()
2025-05-09 17:45:53,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337afc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:45:53,050:INFO:Checking exceptions
2025-05-09 17:45:53,050:INFO:Importing libraries
2025-05-09 17:45:53,050:INFO:Copying training dataset
2025-05-09 17:45:53,060:INFO:Defining folds
2025-05-09 17:45:53,060:INFO:Declaring metric variables
2025-05-09 17:45:53,061:INFO:Importing untrained model
2025-05-09 17:45:53,062:INFO:Linear Discriminant Analysis Imported successfully
2025-05-09 17:45:53,064:INFO:Starting cross validation
2025-05-09 17:45:53,065:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:45:54,297:INFO:Calculating mean and std
2025-05-09 17:45:54,298:INFO:Creating metrics dataframe
2025-05-09 17:45:54,299:INFO:Uploading results into container
2025-05-09 17:45:54,299:INFO:Uploading model into container now
2025-05-09 17:45:54,299:INFO:_master_model_container: 11
2025-05-09 17:45:54,299:INFO:_display_container: 2
2025-05-09 17:45:54,300:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-09 17:45:54,300:INFO:create_model() successfully completed......................................
2025-05-09 17:45:54,349:INFO:SubProcess create_model() end ==================================
2025-05-09 17:45:54,349:INFO:Creating metrics dataframe
2025-05-09 17:45:54,353:INFO:Initializing Extra Trees Classifier
2025-05-09 17:45:54,353:INFO:Total runtime is 0.7753785967826843 minutes
2025-05-09 17:45:54,355:INFO:SubProcess create_model() called ==================================
2025-05-09 17:45:54,355:INFO:Initializing create_model()
2025-05-09 17:45:54,355:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337afc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:45:54,355:INFO:Checking exceptions
2025-05-09 17:45:54,355:INFO:Importing libraries
2025-05-09 17:45:54,355:INFO:Copying training dataset
2025-05-09 17:45:54,364:INFO:Defining folds
2025-05-09 17:45:54,364:INFO:Declaring metric variables
2025-05-09 17:45:54,365:INFO:Importing untrained model
2025-05-09 17:45:54,366:INFO:Extra Trees Classifier Imported successfully
2025-05-09 17:45:54,369:INFO:Starting cross validation
2025-05-09 17:45:54,370:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:45:58,712:INFO:Calculating mean and std
2025-05-09 17:45:58,715:INFO:Creating metrics dataframe
2025-05-09 17:45:58,718:INFO:Uploading results into container
2025-05-09 17:45:58,720:INFO:Uploading model into container now
2025-05-09 17:45:58,721:INFO:_master_model_container: 12
2025-05-09 17:45:58,721:INFO:_display_container: 2
2025-05-09 17:45:58,721:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-09 17:45:58,722:INFO:create_model() successfully completed......................................
2025-05-09 17:45:58,828:INFO:SubProcess create_model() end ==================================
2025-05-09 17:45:58,828:INFO:Creating metrics dataframe
2025-05-09 17:45:58,832:INFO:Initializing Light Gradient Boosting Machine
2025-05-09 17:45:58,832:INFO:Total runtime is 0.8500284155209858 minutes
2025-05-09 17:45:58,834:INFO:SubProcess create_model() called ==================================
2025-05-09 17:45:58,834:INFO:Initializing create_model()
2025-05-09 17:45:58,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337afc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:45:58,834:INFO:Checking exceptions
2025-05-09 17:45:58,834:INFO:Importing libraries
2025-05-09 17:45:58,834:INFO:Copying training dataset
2025-05-09 17:45:58,853:INFO:Defining folds
2025-05-09 17:45:58,853:INFO:Declaring metric variables
2025-05-09 17:45:58,855:INFO:Importing untrained model
2025-05-09 17:45:58,856:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:45:58,859:INFO:Starting cross validation
2025-05-09 17:45:58,861:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:46:03,116:INFO:Calculating mean and std
2025-05-09 17:46:03,116:INFO:Creating metrics dataframe
2025-05-09 17:46:03,117:INFO:Uploading results into container
2025-05-09 17:46:03,118:INFO:Uploading model into container now
2025-05-09 17:46:03,118:INFO:_master_model_container: 13
2025-05-09 17:46:03,118:INFO:_display_container: 2
2025-05-09 17:46:03,118:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:46:03,118:INFO:create_model() successfully completed......................................
2025-05-09 17:46:03,167:INFO:SubProcess create_model() end ==================================
2025-05-09 17:46:03,167:INFO:Creating metrics dataframe
2025-05-09 17:46:03,172:INFO:Initializing Dummy Classifier
2025-05-09 17:46:03,172:INFO:Total runtime is 0.9223521669705708 minutes
2025-05-09 17:46:03,173:INFO:SubProcess create_model() called ==================================
2025-05-09 17:46:03,173:INFO:Initializing create_model()
2025-05-09 17:46:03,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337afc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:46:03,173:INFO:Checking exceptions
2025-05-09 17:46:03,173:INFO:Importing libraries
2025-05-09 17:46:03,173:INFO:Copying training dataset
2025-05-09 17:46:03,183:INFO:Defining folds
2025-05-09 17:46:03,184:INFO:Declaring metric variables
2025-05-09 17:46:03,185:INFO:Importing untrained model
2025-05-09 17:46:03,186:INFO:Dummy Classifier Imported successfully
2025-05-09 17:46:03,188:INFO:Starting cross validation
2025-05-09 17:46:03,189:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:46:04,202:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:46:04,245:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:46:04,246:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:46:04,357:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:46:04,379:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:46:04,387:INFO:Calculating mean and std
2025-05-09 17:46:04,388:INFO:Creating metrics dataframe
2025-05-09 17:46:04,389:INFO:Uploading results into container
2025-05-09 17:46:04,389:INFO:Uploading model into container now
2025-05-09 17:46:04,389:INFO:_master_model_container: 14
2025-05-09 17:46:04,389:INFO:_display_container: 2
2025-05-09 17:46:04,389:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-09 17:46:04,389:INFO:create_model() successfully completed......................................
2025-05-09 17:46:04,436:INFO:SubProcess create_model() end ==================================
2025-05-09 17:46:04,436:INFO:Creating metrics dataframe
2025-05-09 17:46:04,444:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-09 17:46:04,447:INFO:Initializing create_model()
2025-05-09 17:46:04,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:46:04,447:INFO:Checking exceptions
2025-05-09 17:46:04,448:INFO:Importing libraries
2025-05-09 17:46:04,448:INFO:Copying training dataset
2025-05-09 17:46:04,458:INFO:Defining folds
2025-05-09 17:46:04,458:INFO:Declaring metric variables
2025-05-09 17:46:04,458:INFO:Importing untrained model
2025-05-09 17:46:04,458:INFO:Declaring custom model
2025-05-09 17:46:04,459:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:46:04,460:INFO:Cross validation set to False
2025-05-09 17:46:04,460:INFO:Fitting Model
2025-05-09 17:46:05,795:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-09 17:46:05,806:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005638 seconds.
2025-05-09 17:46:05,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-09 17:46:05,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-09 17:46:05,807:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-09 17:46:05,807:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-09 17:46:05,807:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-09 17:46:06,558:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:46:06,558:INFO:create_model() successfully completed......................................
2025-05-09 17:46:06,603:INFO:Initializing create_model()
2025-05-09 17:46:06,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:46:06,603:INFO:Checking exceptions
2025-05-09 17:46:06,603:INFO:Importing libraries
2025-05-09 17:46:06,604:INFO:Copying training dataset
2025-05-09 17:46:06,613:INFO:Defining folds
2025-05-09 17:46:06,613:INFO:Declaring metric variables
2025-05-09 17:46:06,613:INFO:Importing untrained model
2025-05-09 17:46:06,613:INFO:Declaring custom model
2025-05-09 17:46:06,614:INFO:Gradient Boosting Classifier Imported successfully
2025-05-09 17:46:06,614:INFO:Cross validation set to False
2025-05-09 17:46:06,614:INFO:Fitting Model
2025-05-09 17:46:22,710:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-09 17:46:22,711:INFO:create_model() successfully completed......................................
2025-05-09 17:46:22,766:INFO:Initializing create_model()
2025-05-09 17:46:22,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:46:22,766:INFO:Checking exceptions
2025-05-09 17:46:22,767:INFO:Importing libraries
2025-05-09 17:46:22,767:INFO:Copying training dataset
2025-05-09 17:46:22,777:INFO:Defining folds
2025-05-09 17:46:22,777:INFO:Declaring metric variables
2025-05-09 17:46:22,777:INFO:Importing untrained model
2025-05-09 17:46:22,777:INFO:Declaring custom model
2025-05-09 17:46:22,778:INFO:Random Forest Classifier Imported successfully
2025-05-09 17:46:22,779:INFO:Cross validation set to False
2025-05-09 17:46:22,779:INFO:Fitting Model
2025-05-09 17:46:25,054:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-09 17:46:25,054:INFO:create_model() successfully completed......................................
2025-05-09 17:46:25,104:INFO:_master_model_container: 14
2025-05-09 17:46:25,104:INFO:_display_container: 2
2025-05-09 17:46:25,105:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-09 17:46:25,105:INFO:compare_models() successfully completed......................................
2025-05-09 17:46:25,105:INFO:Initializing evaluate_model()
2025-05-09 17:46:25,105:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-09 17:46:25,113:INFO:Initializing plot_model()
2025-05-09 17:46:25,113:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-09 17:46:25,113:INFO:Checking exceptions
2025-05-09 17:46:25,117:INFO:Preloading libraries
2025-05-09 17:46:25,119:INFO:Copying training dataset
2025-05-09 17:46:25,119:INFO:Plot type: pipeline
2025-05-09 17:46:25,358:INFO:Visual Rendered Successfully
2025-05-09 17:46:25,403:INFO:plot_model() successfully completed......................................
2025-05-09 17:46:25,405:INFO:Initializing tune_model()
2025-05-09 17:46:25,405:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x107e17810>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-09 17:46:25,405:INFO:Checking exceptions
2025-05-09 17:46:25,405:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2025-05-09 17:46:48,188:INFO:PyCaret ClassificationExperiment
2025-05-09 17:46:48,188:INFO:Logging name: clf-default-name
2025-05-09 17:46:48,188:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-09 17:46:48,188:INFO:version 3.3.2
2025-05-09 17:46:48,188:INFO:Initializing setup()
2025-05-09 17:46:48,188:INFO:self.USI: 4897
2025-05-09 17:46:48,188:INFO:self._variable_keys: {'USI', 'html_param', 'exp_name_log', 'seed', 'logging_param', 'X', 'fix_imbalance', 'gpu_n_jobs_param', '_available_plots', 'exp_id', 'is_multiclass', 'X_test', 'y_test', 'memory', 'fold_shuffle_param', 'log_plots_param', 'n_jobs_param', 'target_param', 'fold_groups_param', '_ml_usecase', 'pipeline', 'data', 'gpu_param', 'y', 'idx', 'X_train', 'fold_generator', 'y_train'}
2025-05-09 17:46:48,188:INFO:Checking environment
2025-05-09 17:46:48,188:INFO:python_version: 3.11.0
2025-05-09 17:46:48,188:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-09 17:46:48,188:INFO:machine: arm64
2025-05-09 17:46:48,188:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-09 17:46:48,188:INFO:Memory: svmem(total=17179869184, available=3300016128, percent=80.8, used=5613666304, free=222576640, active=3105112064, inactive=3028402176, wired=2508554240)
2025-05-09 17:46:48,188:INFO:Physical Core: 12
2025-05-09 17:46:48,188:INFO:Logical Core: 12
2025-05-09 17:46:48,188:INFO:Checking libraries
2025-05-09 17:46:48,188:INFO:System:
2025-05-09 17:46:48,188:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-09 17:46:48,188:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-09 17:46:48,188:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-09 17:46:48,188:INFO:PyCaret required dependencies:
2025-05-09 17:46:48,188:INFO:                 pip: 22.3
2025-05-09 17:46:48,188:INFO:          setuptools: 65.5.0
2025-05-09 17:46:48,188:INFO:             pycaret: 3.3.2
2025-05-09 17:46:48,188:INFO:             IPython: 9.2.0
2025-05-09 17:46:48,188:INFO:          ipywidgets: 8.1.7
2025-05-09 17:46:48,188:INFO:                tqdm: 4.67.1
2025-05-09 17:46:48,188:INFO:               numpy: 1.26.4
2025-05-09 17:46:48,188:INFO:              pandas: 2.1.4
2025-05-09 17:46:48,188:INFO:              jinja2: 3.1.6
2025-05-09 17:46:48,188:INFO:               scipy: 1.11.4
2025-05-09 17:46:48,188:INFO:              joblib: 1.3.2
2025-05-09 17:46:48,188:INFO:             sklearn: 1.4.2
2025-05-09 17:46:48,188:INFO:                pyod: 2.0.5
2025-05-09 17:46:48,189:INFO:            imblearn: 0.13.0
2025-05-09 17:46:48,189:INFO:   category_encoders: 2.7.0
2025-05-09 17:46:48,189:INFO:            lightgbm: 4.6.0
2025-05-09 17:46:48,189:INFO:               numba: 0.61.2
2025-05-09 17:46:48,189:INFO:            requests: 2.32.3
2025-05-09 17:46:48,189:INFO:          matplotlib: 3.7.5
2025-05-09 17:46:48,189:INFO:          scikitplot: 0.3.7
2025-05-09 17:46:48,189:INFO:         yellowbrick: 1.5
2025-05-09 17:46:48,189:INFO:              plotly: 5.24.1
2025-05-09 17:46:48,189:INFO:    plotly-resampler: Not installed
2025-05-09 17:46:48,189:INFO:             kaleido: 0.2.1
2025-05-09 17:46:48,189:INFO:           schemdraw: 0.15
2025-05-09 17:46:48,189:INFO:         statsmodels: 0.14.4
2025-05-09 17:46:48,189:INFO:              sktime: 0.26.0
2025-05-09 17:46:48,189:INFO:               tbats: 1.1.3
2025-05-09 17:46:48,189:INFO:            pmdarima: 2.0.4
2025-05-09 17:46:48,189:INFO:              psutil: 7.0.0
2025-05-09 17:46:48,189:INFO:          markupsafe: 3.0.2
2025-05-09 17:46:48,189:INFO:             pickle5: Not installed
2025-05-09 17:46:48,189:INFO:         cloudpickle: 3.1.1
2025-05-09 17:46:48,189:INFO:         deprecation: 2.1.0
2025-05-09 17:46:48,189:INFO:              xxhash: 3.5.0
2025-05-09 17:46:48,189:INFO:           wurlitzer: 3.1.1
2025-05-09 17:46:48,189:INFO:PyCaret optional dependencies:
2025-05-09 17:46:48,189:INFO:                shap: Not installed
2025-05-09 17:46:48,189:INFO:           interpret: Not installed
2025-05-09 17:46:48,189:INFO:                umap: Not installed
2025-05-09 17:46:48,189:INFO:     ydata_profiling: Not installed
2025-05-09 17:46:48,189:INFO:  explainerdashboard: Not installed
2025-05-09 17:46:48,189:INFO:             autoviz: Not installed
2025-05-09 17:46:48,189:INFO:           fairlearn: Not installed
2025-05-09 17:46:48,189:INFO:          deepchecks: Not installed
2025-05-09 17:46:48,189:INFO:             xgboost: Not installed
2025-05-09 17:46:48,189:INFO:            catboost: Not installed
2025-05-09 17:46:48,189:INFO:              kmodes: Not installed
2025-05-09 17:46:48,189:INFO:             mlxtend: Not installed
2025-05-09 17:46:48,189:INFO:       statsforecast: Not installed
2025-05-09 17:46:48,189:INFO:        tune_sklearn: Not installed
2025-05-09 17:46:48,189:INFO:                 ray: Not installed
2025-05-09 17:46:48,189:INFO:            hyperopt: Not installed
2025-05-09 17:46:48,189:INFO:              optuna: Not installed
2025-05-09 17:46:48,189:INFO:               skopt: Not installed
2025-05-09 17:46:48,189:INFO:              mlflow: Not installed
2025-05-09 17:46:48,189:INFO:              gradio: Not installed
2025-05-09 17:46:48,189:INFO:             fastapi: Not installed
2025-05-09 17:46:48,189:INFO:             uvicorn: Not installed
2025-05-09 17:46:48,189:INFO:              m2cgen: Not installed
2025-05-09 17:46:48,189:INFO:           evidently: Not installed
2025-05-09 17:46:48,189:INFO:               fugue: Not installed
2025-05-09 17:46:48,189:INFO:           streamlit: Not installed
2025-05-09 17:46:48,189:INFO:             prophet: Not installed
2025-05-09 17:46:48,189:INFO:None
2025-05-09 17:46:48,189:INFO:Set up data.
2025-05-09 17:46:48,222:INFO:Set up folding strategy.
2025-05-09 17:46:48,222:INFO:Set up train/test split.
2025-05-09 17:46:48,235:INFO:Set up index.
2025-05-09 17:46:48,236:INFO:Assigning column types.
2025-05-09 17:46:48,239:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-09 17:46:48,258:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 17:46:48,258:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:46:48,269:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:48,270:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:48,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 17:46:48,288:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:46:48,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:48,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:48,300:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-09 17:46:48,318:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:46:48,329:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:48,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:48,348:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:46:48,359:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:48,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:48,360:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-09 17:46:48,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:48,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:48,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:48,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:48,419:INFO:Preparing preprocessing pipeline...
2025-05-09 17:46:48,420:INFO:Set up simple imputation.
2025-05-09 17:46:48,426:INFO:Set up encoding of ordinal features.
2025-05-09 17:46:48,436:INFO:Set up encoding of categorical features.
2025-05-09 17:46:48,436:INFO:Set up imbalanced handling.
2025-05-09 17:46:48,436:INFO:Set up column transformation.
2025-05-09 17:46:48,708:INFO:Finished creating preprocessing pipeline.
2025-05-09 17:46:48,727:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-09 17:46:48,727:INFO:Creating final display dataframe.
2025-05-09 17:46:49,130:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              4897
2025-05-09 17:46:49,162:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:49,162:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:49,194:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:49,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:46:49,196:INFO:setup() successfully completed in 1.01s...............
2025-05-09 17:46:49,196:INFO:Initializing compare_models()
2025-05-09 17:46:49,196:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-09 17:46:49,196:INFO:Checking exceptions
2025-05-09 17:46:49,201:INFO:Preparing display monitor
2025-05-09 17:46:49,210:INFO:Initializing Logistic Regression
2025-05-09 17:46:49,210:INFO:Total runtime is 1.5974044799804688e-06 minutes
2025-05-09 17:46:49,211:INFO:SubProcess create_model() called ==================================
2025-05-09 17:46:49,211:INFO:Initializing create_model()
2025-05-09 17:46:49,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335cad790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:46:49,211:INFO:Checking exceptions
2025-05-09 17:46:49,211:INFO:Importing libraries
2025-05-09 17:46:49,211:INFO:Copying training dataset
2025-05-09 17:46:49,222:INFO:Defining folds
2025-05-09 17:46:49,222:INFO:Declaring metric variables
2025-05-09 17:46:49,223:INFO:Importing untrained model
2025-05-09 17:46:49,225:INFO:Logistic Regression Imported successfully
2025-05-09 17:46:49,227:INFO:Starting cross validation
2025-05-09 17:46:49,228:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:46:52,859:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:46:52,877:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:46:52,956:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:46:53,167:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:46:54,425:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:46:54,485:INFO:Calculating mean and std
2025-05-09 17:46:54,486:INFO:Creating metrics dataframe
2025-05-09 17:46:54,487:INFO:Uploading results into container
2025-05-09 17:46:54,487:INFO:Uploading model into container now
2025-05-09 17:46:54,487:INFO:_master_model_container: 1
2025-05-09 17:46:54,488:INFO:_display_container: 2
2025-05-09 17:46:54,488:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-09 17:46:54,488:INFO:create_model() successfully completed......................................
2025-05-09 17:46:54,556:INFO:SubProcess create_model() end ==================================
2025-05-09 17:46:54,556:INFO:Creating metrics dataframe
2025-05-09 17:46:54,559:INFO:Initializing K Neighbors Classifier
2025-05-09 17:46:54,559:INFO:Total runtime is 0.0891599178314209 minutes
2025-05-09 17:46:54,560:INFO:SubProcess create_model() called ==================================
2025-05-09 17:46:54,561:INFO:Initializing create_model()
2025-05-09 17:46:54,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335cad790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:46:54,561:INFO:Checking exceptions
2025-05-09 17:46:54,561:INFO:Importing libraries
2025-05-09 17:46:54,561:INFO:Copying training dataset
2025-05-09 17:46:54,570:INFO:Defining folds
2025-05-09 17:46:54,570:INFO:Declaring metric variables
2025-05-09 17:46:54,571:INFO:Importing untrained model
2025-05-09 17:46:54,572:INFO:K Neighbors Classifier Imported successfully
2025-05-09 17:46:54,575:INFO:Starting cross validation
2025-05-09 17:46:54,576:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:46:59,354:INFO:Calculating mean and std
2025-05-09 17:46:59,355:INFO:Creating metrics dataframe
2025-05-09 17:46:59,357:INFO:Uploading results into container
2025-05-09 17:46:59,357:INFO:Uploading model into container now
2025-05-09 17:46:59,357:INFO:_master_model_container: 2
2025-05-09 17:46:59,357:INFO:_display_container: 2
2025-05-09 17:46:59,358:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-09 17:46:59,358:INFO:create_model() successfully completed......................................
2025-05-09 17:46:59,422:INFO:SubProcess create_model() end ==================================
2025-05-09 17:46:59,423:INFO:Creating metrics dataframe
2025-05-09 17:46:59,425:INFO:Initializing Naive Bayes
2025-05-09 17:46:59,425:INFO:Total runtime is 0.17026487986246744 minutes
2025-05-09 17:46:59,427:INFO:SubProcess create_model() called ==================================
2025-05-09 17:46:59,427:INFO:Initializing create_model()
2025-05-09 17:46:59,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335cad790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:46:59,427:INFO:Checking exceptions
2025-05-09 17:46:59,427:INFO:Importing libraries
2025-05-09 17:46:59,427:INFO:Copying training dataset
2025-05-09 17:46:59,436:INFO:Defining folds
2025-05-09 17:46:59,436:INFO:Declaring metric variables
2025-05-09 17:46:59,437:INFO:Importing untrained model
2025-05-09 17:46:59,439:INFO:Naive Bayes Imported successfully
2025-05-09 17:46:59,441:INFO:Starting cross validation
2025-05-09 17:46:59,442:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:47:00,600:INFO:Calculating mean and std
2025-05-09 17:47:00,601:INFO:Creating metrics dataframe
2025-05-09 17:47:00,602:INFO:Uploading results into container
2025-05-09 17:47:00,602:INFO:Uploading model into container now
2025-05-09 17:47:00,602:INFO:_master_model_container: 3
2025-05-09 17:47:00,602:INFO:_display_container: 2
2025-05-09 17:47:00,603:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-09 17:47:00,603:INFO:create_model() successfully completed......................................
2025-05-09 17:47:00,660:INFO:SubProcess create_model() end ==================================
2025-05-09 17:47:00,660:INFO:Creating metrics dataframe
2025-05-09 17:47:00,663:INFO:Initializing Decision Tree Classifier
2025-05-09 17:47:00,663:INFO:Total runtime is 0.19088799953460692 minutes
2025-05-09 17:47:00,664:INFO:SubProcess create_model() called ==================================
2025-05-09 17:47:00,664:INFO:Initializing create_model()
2025-05-09 17:47:00,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335cad790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:47:00,664:INFO:Checking exceptions
2025-05-09 17:47:00,664:INFO:Importing libraries
2025-05-09 17:47:00,664:INFO:Copying training dataset
2025-05-09 17:47:00,674:INFO:Defining folds
2025-05-09 17:47:00,674:INFO:Declaring metric variables
2025-05-09 17:47:00,675:INFO:Importing untrained model
2025-05-09 17:47:00,676:INFO:Decision Tree Classifier Imported successfully
2025-05-09 17:47:00,679:INFO:Starting cross validation
2025-05-09 17:47:00,680:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:47:02,356:INFO:Calculating mean and std
2025-05-09 17:47:02,357:INFO:Creating metrics dataframe
2025-05-09 17:47:02,358:INFO:Uploading results into container
2025-05-09 17:47:02,358:INFO:Uploading model into container now
2025-05-09 17:47:02,359:INFO:_master_model_container: 4
2025-05-09 17:47:02,359:INFO:_display_container: 2
2025-05-09 17:47:02,359:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-09 17:47:02,359:INFO:create_model() successfully completed......................................
2025-05-09 17:47:02,423:INFO:SubProcess create_model() end ==================================
2025-05-09 17:47:02,423:INFO:Creating metrics dataframe
2025-05-09 17:47:02,426:INFO:Initializing SVM - Linear Kernel
2025-05-09 17:47:02,426:INFO:Total runtime is 0.2202805479367574 minutes
2025-05-09 17:47:02,428:INFO:SubProcess create_model() called ==================================
2025-05-09 17:47:02,428:INFO:Initializing create_model()
2025-05-09 17:47:02,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335cad790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:47:02,428:INFO:Checking exceptions
2025-05-09 17:47:02,428:INFO:Importing libraries
2025-05-09 17:47:02,428:INFO:Copying training dataset
2025-05-09 17:47:02,442:INFO:Defining folds
2025-05-09 17:47:02,442:INFO:Declaring metric variables
2025-05-09 17:47:02,443:INFO:Importing untrained model
2025-05-09 17:47:02,444:INFO:SVM - Linear Kernel Imported successfully
2025-05-09 17:47:02,447:INFO:Starting cross validation
2025-05-09 17:47:02,448:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:47:05,753:INFO:Calculating mean and std
2025-05-09 17:47:05,754:INFO:Creating metrics dataframe
2025-05-09 17:47:05,755:INFO:Uploading results into container
2025-05-09 17:47:05,755:INFO:Uploading model into container now
2025-05-09 17:47:05,755:INFO:_master_model_container: 5
2025-05-09 17:47:05,755:INFO:_display_container: 2
2025-05-09 17:47:05,755:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-09 17:47:05,755:INFO:create_model() successfully completed......................................
2025-05-09 17:47:05,818:INFO:SubProcess create_model() end ==================================
2025-05-09 17:47:05,818:INFO:Creating metrics dataframe
2025-05-09 17:47:05,822:INFO:Initializing Ridge Classifier
2025-05-09 17:47:05,822:INFO:Total runtime is 0.27687162955602007 minutes
2025-05-09 17:47:05,823:INFO:SubProcess create_model() called ==================================
2025-05-09 17:47:05,823:INFO:Initializing create_model()
2025-05-09 17:47:05,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335cad790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:47:05,823:INFO:Checking exceptions
2025-05-09 17:47:05,823:INFO:Importing libraries
2025-05-09 17:47:05,823:INFO:Copying training dataset
2025-05-09 17:47:05,835:INFO:Defining folds
2025-05-09 17:47:05,835:INFO:Declaring metric variables
2025-05-09 17:47:05,837:INFO:Importing untrained model
2025-05-09 17:47:05,838:INFO:Ridge Classifier Imported successfully
2025-05-09 17:47:05,841:INFO:Starting cross validation
2025-05-09 17:47:05,842:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:47:06,974:INFO:Calculating mean and std
2025-05-09 17:47:06,974:INFO:Creating metrics dataframe
2025-05-09 17:47:06,975:INFO:Uploading results into container
2025-05-09 17:47:06,975:INFO:Uploading model into container now
2025-05-09 17:47:06,976:INFO:_master_model_container: 6
2025-05-09 17:47:06,976:INFO:_display_container: 2
2025-05-09 17:47:06,976:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-09 17:47:06,976:INFO:create_model() successfully completed......................................
2025-05-09 17:47:07,031:INFO:SubProcess create_model() end ==================================
2025-05-09 17:47:07,031:INFO:Creating metrics dataframe
2025-05-09 17:47:07,034:INFO:Initializing Random Forest Classifier
2025-05-09 17:47:07,034:INFO:Total runtime is 0.2970730980237325 minutes
2025-05-09 17:47:07,035:INFO:SubProcess create_model() called ==================================
2025-05-09 17:47:07,035:INFO:Initializing create_model()
2025-05-09 17:47:07,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335cad790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:47:07,036:INFO:Checking exceptions
2025-05-09 17:47:07,036:INFO:Importing libraries
2025-05-09 17:47:07,036:INFO:Copying training dataset
2025-05-09 17:47:07,046:INFO:Defining folds
2025-05-09 17:47:07,046:INFO:Declaring metric variables
2025-05-09 17:47:07,047:INFO:Importing untrained model
2025-05-09 17:47:07,048:INFO:Random Forest Classifier Imported successfully
2025-05-09 17:47:07,051:INFO:Starting cross validation
2025-05-09 17:47:07,052:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:47:12,733:INFO:Calculating mean and std
2025-05-09 17:47:12,735:INFO:Creating metrics dataframe
2025-05-09 17:47:12,738:INFO:Uploading results into container
2025-05-09 17:47:12,739:INFO:Uploading model into container now
2025-05-09 17:47:12,739:INFO:_master_model_container: 7
2025-05-09 17:47:12,739:INFO:_display_container: 2
2025-05-09 17:47:12,740:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-09 17:47:12,740:INFO:create_model() successfully completed......................................
2025-05-09 17:47:12,860:INFO:SubProcess create_model() end ==================================
2025-05-09 17:47:12,860:INFO:Creating metrics dataframe
2025-05-09 17:47:12,864:INFO:Initializing Quadratic Discriminant Analysis
2025-05-09 17:47:12,864:INFO:Total runtime is 0.3942468523979187 minutes
2025-05-09 17:47:12,866:INFO:SubProcess create_model() called ==================================
2025-05-09 17:47:12,866:INFO:Initializing create_model()
2025-05-09 17:47:12,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335cad790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:47:12,866:INFO:Checking exceptions
2025-05-09 17:47:12,866:INFO:Importing libraries
2025-05-09 17:47:12,866:INFO:Copying training dataset
2025-05-09 17:47:12,878:INFO:Defining folds
2025-05-09 17:47:12,878:INFO:Declaring metric variables
2025-05-09 17:47:12,880:INFO:Importing untrained model
2025-05-09 17:47:12,881:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-09 17:47:12,884:INFO:Starting cross validation
2025-05-09 17:47:12,885:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:47:13,911:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:47:13,929:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:47:13,943:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:47:13,960:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:47:13,978:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:47:13,999:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:47:14,010:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:47:14,021:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:47:14,037:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:47:14,055:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:47:14,063:INFO:Calculating mean and std
2025-05-09 17:47:14,064:INFO:Creating metrics dataframe
2025-05-09 17:47:14,065:INFO:Uploading results into container
2025-05-09 17:47:14,065:INFO:Uploading model into container now
2025-05-09 17:47:14,065:INFO:_master_model_container: 8
2025-05-09 17:47:14,065:INFO:_display_container: 2
2025-05-09 17:47:14,065:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-09 17:47:14,065:INFO:create_model() successfully completed......................................
2025-05-09 17:47:14,121:INFO:SubProcess create_model() end ==================================
2025-05-09 17:47:14,121:INFO:Creating metrics dataframe
2025-05-09 17:47:14,124:INFO:Initializing Ada Boost Classifier
2025-05-09 17:47:14,124:INFO:Total runtime is 0.4152458667755127 minutes
2025-05-09 17:47:14,126:INFO:SubProcess create_model() called ==================================
2025-05-09 17:47:14,126:INFO:Initializing create_model()
2025-05-09 17:47:14,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335cad790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:47:14,126:INFO:Checking exceptions
2025-05-09 17:47:14,126:INFO:Importing libraries
2025-05-09 17:47:14,126:INFO:Copying training dataset
2025-05-09 17:47:14,136:INFO:Defining folds
2025-05-09 17:47:14,136:INFO:Declaring metric variables
2025-05-09 17:47:14,137:INFO:Importing untrained model
2025-05-09 17:47:14,138:INFO:Ada Boost Classifier Imported successfully
2025-05-09 17:47:14,141:INFO:Starting cross validation
2025-05-09 17:47:14,142:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:47:15,131:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:47:15,154:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:47:15,177:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:47:15,201:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:47:15,201:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:47:17,883:INFO:Calculating mean and std
2025-05-09 17:47:17,883:INFO:Creating metrics dataframe
2025-05-09 17:47:17,884:INFO:Uploading results into container
2025-05-09 17:47:17,884:INFO:Uploading model into container now
2025-05-09 17:47:17,885:INFO:_master_model_container: 9
2025-05-09 17:47:17,885:INFO:_display_container: 2
2025-05-09 17:47:17,885:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-09 17:47:17,885:INFO:create_model() successfully completed......................................
2025-05-09 17:47:17,945:INFO:SubProcess create_model() end ==================================
2025-05-09 17:47:17,945:INFO:Creating metrics dataframe
2025-05-09 17:47:17,949:INFO:Initializing Gradient Boosting Classifier
2025-05-09 17:47:17,949:INFO:Total runtime is 0.47899408340454097 minutes
2025-05-09 17:47:17,950:INFO:SubProcess create_model() called ==================================
2025-05-09 17:47:17,951:INFO:Initializing create_model()
2025-05-09 17:47:17,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335cad790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:47:17,951:INFO:Checking exceptions
2025-05-09 17:47:17,951:INFO:Importing libraries
2025-05-09 17:47:17,951:INFO:Copying training dataset
2025-05-09 17:47:17,961:INFO:Defining folds
2025-05-09 17:47:17,961:INFO:Declaring metric variables
2025-05-09 17:47:17,962:INFO:Importing untrained model
2025-05-09 17:47:17,964:INFO:Gradient Boosting Classifier Imported successfully
2025-05-09 17:47:17,966:INFO:Starting cross validation
2025-05-09 17:47:17,967:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:47:31,669:INFO:Calculating mean and std
2025-05-09 17:47:31,671:INFO:Creating metrics dataframe
2025-05-09 17:47:31,675:INFO:Uploading results into container
2025-05-09 17:47:31,676:INFO:Uploading model into container now
2025-05-09 17:47:31,676:INFO:_master_model_container: 10
2025-05-09 17:47:31,676:INFO:_display_container: 2
2025-05-09 17:47:31,677:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-09 17:47:31,677:INFO:create_model() successfully completed......................................
2025-05-09 17:47:31,792:INFO:SubProcess create_model() end ==================================
2025-05-09 17:47:31,792:INFO:Creating metrics dataframe
2025-05-09 17:47:31,797:INFO:Initializing Linear Discriminant Analysis
2025-05-09 17:47:31,797:INFO:Total runtime is 0.7097887992858887 minutes
2025-05-09 17:47:31,799:INFO:SubProcess create_model() called ==================================
2025-05-09 17:47:31,799:INFO:Initializing create_model()
2025-05-09 17:47:31,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335cad790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:47:31,799:INFO:Checking exceptions
2025-05-09 17:47:31,799:INFO:Importing libraries
2025-05-09 17:47:31,799:INFO:Copying training dataset
2025-05-09 17:47:31,815:INFO:Defining folds
2025-05-09 17:47:31,815:INFO:Declaring metric variables
2025-05-09 17:47:31,816:INFO:Importing untrained model
2025-05-09 17:47:31,818:INFO:Linear Discriminant Analysis Imported successfully
2025-05-09 17:47:31,820:INFO:Starting cross validation
2025-05-09 17:47:31,821:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:47:33,085:INFO:Calculating mean and std
2025-05-09 17:47:33,085:INFO:Creating metrics dataframe
2025-05-09 17:47:33,086:INFO:Uploading results into container
2025-05-09 17:47:33,086:INFO:Uploading model into container now
2025-05-09 17:47:33,087:INFO:_master_model_container: 11
2025-05-09 17:47:33,087:INFO:_display_container: 2
2025-05-09 17:47:33,087:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-09 17:47:33,087:INFO:create_model() successfully completed......................................
2025-05-09 17:47:33,145:INFO:SubProcess create_model() end ==================================
2025-05-09 17:47:33,145:INFO:Creating metrics dataframe
2025-05-09 17:47:33,149:INFO:Initializing Extra Trees Classifier
2025-05-09 17:47:33,149:INFO:Total runtime is 0.7323194026947022 minutes
2025-05-09 17:47:33,150:INFO:SubProcess create_model() called ==================================
2025-05-09 17:47:33,150:INFO:Initializing create_model()
2025-05-09 17:47:33,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335cad790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:47:33,150:INFO:Checking exceptions
2025-05-09 17:47:33,150:INFO:Importing libraries
2025-05-09 17:47:33,150:INFO:Copying training dataset
2025-05-09 17:47:33,160:INFO:Defining folds
2025-05-09 17:47:33,160:INFO:Declaring metric variables
2025-05-09 17:47:33,162:INFO:Importing untrained model
2025-05-09 17:47:33,163:INFO:Extra Trees Classifier Imported successfully
2025-05-09 17:47:33,165:INFO:Starting cross validation
2025-05-09 17:47:33,166:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:47:37,574:INFO:Calculating mean and std
2025-05-09 17:47:37,577:INFO:Creating metrics dataframe
2025-05-09 17:47:37,586:INFO:Uploading results into container
2025-05-09 17:47:37,586:INFO:Uploading model into container now
2025-05-09 17:47:37,587:INFO:_master_model_container: 12
2025-05-09 17:47:37,587:INFO:_display_container: 2
2025-05-09 17:47:37,588:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-09 17:47:37,588:INFO:create_model() successfully completed......................................
2025-05-09 17:47:37,697:INFO:SubProcess create_model() end ==================================
2025-05-09 17:47:37,698:INFO:Creating metrics dataframe
2025-05-09 17:47:37,702:INFO:Initializing Light Gradient Boosting Machine
2025-05-09 17:47:37,702:INFO:Total runtime is 0.8082044323285421 minutes
2025-05-09 17:47:37,703:INFO:SubProcess create_model() called ==================================
2025-05-09 17:47:37,703:INFO:Initializing create_model()
2025-05-09 17:47:37,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335cad790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:47:37,703:INFO:Checking exceptions
2025-05-09 17:47:37,703:INFO:Importing libraries
2025-05-09 17:47:37,703:INFO:Copying training dataset
2025-05-09 17:47:37,723:INFO:Defining folds
2025-05-09 17:47:37,723:INFO:Declaring metric variables
2025-05-09 17:47:37,725:INFO:Importing untrained model
2025-05-09 17:47:37,726:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:47:37,729:INFO:Starting cross validation
2025-05-09 17:47:37,730:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:47:41,733:INFO:Calculating mean and std
2025-05-09 17:47:41,734:INFO:Creating metrics dataframe
2025-05-09 17:47:41,735:INFO:Uploading results into container
2025-05-09 17:47:41,735:INFO:Uploading model into container now
2025-05-09 17:47:41,735:INFO:_master_model_container: 13
2025-05-09 17:47:41,735:INFO:_display_container: 2
2025-05-09 17:47:41,736:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:47:41,736:INFO:create_model() successfully completed......................................
2025-05-09 17:47:41,796:INFO:SubProcess create_model() end ==================================
2025-05-09 17:47:41,796:INFO:Creating metrics dataframe
2025-05-09 17:47:41,800:INFO:Initializing Dummy Classifier
2025-05-09 17:47:41,800:INFO:Total runtime is 0.8765141010284424 minutes
2025-05-09 17:47:41,802:INFO:SubProcess create_model() called ==================================
2025-05-09 17:47:41,802:INFO:Initializing create_model()
2025-05-09 17:47:41,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335cad790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:47:41,802:INFO:Checking exceptions
2025-05-09 17:47:41,802:INFO:Importing libraries
2025-05-09 17:47:41,802:INFO:Copying training dataset
2025-05-09 17:47:41,812:INFO:Defining folds
2025-05-09 17:47:41,812:INFO:Declaring metric variables
2025-05-09 17:47:41,814:INFO:Importing untrained model
2025-05-09 17:47:41,815:INFO:Dummy Classifier Imported successfully
2025-05-09 17:47:41,818:INFO:Starting cross validation
2025-05-09 17:47:41,819:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:47:42,854:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:47:42,856:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:47:42,939:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:47:42,950:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:47:42,952:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:47:42,965:INFO:Calculating mean and std
2025-05-09 17:47:42,966:INFO:Creating metrics dataframe
2025-05-09 17:47:42,966:INFO:Uploading results into container
2025-05-09 17:47:42,967:INFO:Uploading model into container now
2025-05-09 17:47:42,967:INFO:_master_model_container: 14
2025-05-09 17:47:42,967:INFO:_display_container: 2
2025-05-09 17:47:42,967:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-09 17:47:42,967:INFO:create_model() successfully completed......................................
2025-05-09 17:47:43,022:INFO:SubProcess create_model() end ==================================
2025-05-09 17:47:43,022:INFO:Creating metrics dataframe
2025-05-09 17:47:43,027:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-09 17:47:43,030:INFO:Initializing create_model()
2025-05-09 17:47:43,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:47:43,030:INFO:Checking exceptions
2025-05-09 17:47:43,031:INFO:Importing libraries
2025-05-09 17:47:43,031:INFO:Copying training dataset
2025-05-09 17:47:43,040:INFO:Defining folds
2025-05-09 17:47:43,040:INFO:Declaring metric variables
2025-05-09 17:47:43,040:INFO:Importing untrained model
2025-05-09 17:47:43,040:INFO:Declaring custom model
2025-05-09 17:47:43,041:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:47:43,041:INFO:Cross validation set to False
2025-05-09 17:47:43,041:INFO:Fitting Model
2025-05-09 17:47:44,420:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-09 17:47:44,431:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005103 seconds.
2025-05-09 17:47:44,431:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-09 17:47:44,431:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-09 17:47:44,431:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-09 17:47:44,431:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-09 17:47:44,431:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-09 17:47:45,177:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:47:45,177:INFO:create_model() successfully completed......................................
2025-05-09 17:47:45,239:INFO:Initializing create_model()
2025-05-09 17:47:45,239:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:47:45,239:INFO:Checking exceptions
2025-05-09 17:47:45,240:INFO:Importing libraries
2025-05-09 17:47:45,240:INFO:Copying training dataset
2025-05-09 17:47:45,249:INFO:Defining folds
2025-05-09 17:47:45,249:INFO:Declaring metric variables
2025-05-09 17:47:45,249:INFO:Importing untrained model
2025-05-09 17:47:45,249:INFO:Declaring custom model
2025-05-09 17:47:45,250:INFO:Gradient Boosting Classifier Imported successfully
2025-05-09 17:47:45,250:INFO:Cross validation set to False
2025-05-09 17:47:45,250:INFO:Fitting Model
2025-05-09 17:48:01,677:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-09 17:48:01,677:INFO:create_model() successfully completed......................................
2025-05-09 17:48:01,744:INFO:Initializing create_model()
2025-05-09 17:48:01,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:48:01,745:INFO:Checking exceptions
2025-05-09 17:48:01,745:INFO:Importing libraries
2025-05-09 17:48:01,745:INFO:Copying training dataset
2025-05-09 17:48:01,755:INFO:Defining folds
2025-05-09 17:48:01,755:INFO:Declaring metric variables
2025-05-09 17:48:01,755:INFO:Importing untrained model
2025-05-09 17:48:01,755:INFO:Declaring custom model
2025-05-09 17:48:01,755:INFO:Random Forest Classifier Imported successfully
2025-05-09 17:48:01,756:INFO:Cross validation set to False
2025-05-09 17:48:01,756:INFO:Fitting Model
2025-05-09 17:48:04,014:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-09 17:48:04,014:INFO:create_model() successfully completed......................................
2025-05-09 17:48:04,100:INFO:_master_model_container: 14
2025-05-09 17:48:04,100:INFO:_display_container: 2
2025-05-09 17:48:04,101:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-09 17:48:04,101:INFO:compare_models() successfully completed......................................
2025-05-09 17:48:04,109:INFO:Initializing evaluate_model()
2025-05-09 17:48:04,109:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-09 17:48:04,117:INFO:Initializing plot_model()
2025-05-09 17:48:04,117:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-09 17:48:04,117:INFO:Checking exceptions
2025-05-09 17:48:04,121:INFO:Preloading libraries
2025-05-09 17:48:04,123:INFO:Copying training dataset
2025-05-09 17:48:04,123:INFO:Plot type: pipeline
2025-05-09 17:48:04,184:INFO:Visual Rendered Successfully
2025-05-09 17:48:04,248:INFO:plot_model() successfully completed......................................
2025-05-09 17:48:04,250:INFO:Initializing tune_model()
2025-05-09 17:48:04,250:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x337824e50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-09 17:48:04,250:INFO:Checking exceptions
2025-05-09 17:48:04,250:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2025-05-09 17:50:43,595:INFO:PyCaret ClassificationExperiment
2025-05-09 17:50:43,596:INFO:Logging name: clf-default-name
2025-05-09 17:50:43,596:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-09 17:50:43,596:INFO:version 3.3.2
2025-05-09 17:50:43,596:INFO:Initializing setup()
2025-05-09 17:50:43,596:INFO:self.USI: 4320
2025-05-09 17:50:43,596:INFO:self._variable_keys: {'USI', 'html_param', 'exp_name_log', 'seed', 'logging_param', 'X', 'fix_imbalance', 'gpu_n_jobs_param', '_available_plots', 'exp_id', 'is_multiclass', 'X_test', 'y_test', 'memory', 'fold_shuffle_param', 'log_plots_param', 'n_jobs_param', 'target_param', 'fold_groups_param', '_ml_usecase', 'pipeline', 'data', 'gpu_param', 'y', 'idx', 'X_train', 'fold_generator', 'y_train'}
2025-05-09 17:50:43,596:INFO:Checking environment
2025-05-09 17:50:43,596:INFO:python_version: 3.11.0
2025-05-09 17:50:43,596:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-09 17:50:43,596:INFO:machine: arm64
2025-05-09 17:50:43,596:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-09 17:50:43,596:INFO:Memory: svmem(total=17179869184, available=3254435840, percent=81.1, used=5595643904, free=64503808, active=3130294272, inactive=3175645184, wired=2465349632)
2025-05-09 17:50:43,596:INFO:Physical Core: 12
2025-05-09 17:50:43,596:INFO:Logical Core: 12
2025-05-09 17:50:43,596:INFO:Checking libraries
2025-05-09 17:50:43,596:INFO:System:
2025-05-09 17:50:43,596:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-09 17:50:43,596:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-09 17:50:43,596:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-09 17:50:43,596:INFO:PyCaret required dependencies:
2025-05-09 17:50:43,596:INFO:                 pip: 22.3
2025-05-09 17:50:43,596:INFO:          setuptools: 65.5.0
2025-05-09 17:50:43,596:INFO:             pycaret: 3.3.2
2025-05-09 17:50:43,596:INFO:             IPython: 9.2.0
2025-05-09 17:50:43,596:INFO:          ipywidgets: 8.1.7
2025-05-09 17:50:43,596:INFO:                tqdm: 4.67.1
2025-05-09 17:50:43,596:INFO:               numpy: 1.26.4
2025-05-09 17:50:43,596:INFO:              pandas: 2.1.4
2025-05-09 17:50:43,596:INFO:              jinja2: 3.1.6
2025-05-09 17:50:43,596:INFO:               scipy: 1.11.4
2025-05-09 17:50:43,596:INFO:              joblib: 1.3.2
2025-05-09 17:50:43,596:INFO:             sklearn: 1.4.2
2025-05-09 17:50:43,596:INFO:                pyod: 2.0.5
2025-05-09 17:50:43,596:INFO:            imblearn: 0.13.0
2025-05-09 17:50:43,596:INFO:   category_encoders: 2.7.0
2025-05-09 17:50:43,596:INFO:            lightgbm: 4.6.0
2025-05-09 17:50:43,596:INFO:               numba: 0.61.2
2025-05-09 17:50:43,596:INFO:            requests: 2.32.3
2025-05-09 17:50:43,596:INFO:          matplotlib: 3.7.5
2025-05-09 17:50:43,596:INFO:          scikitplot: 0.3.7
2025-05-09 17:50:43,596:INFO:         yellowbrick: 1.5
2025-05-09 17:50:43,596:INFO:              plotly: 5.24.1
2025-05-09 17:50:43,596:INFO:    plotly-resampler: Not installed
2025-05-09 17:50:43,596:INFO:             kaleido: 0.2.1
2025-05-09 17:50:43,596:INFO:           schemdraw: 0.15
2025-05-09 17:50:43,596:INFO:         statsmodels: 0.14.4
2025-05-09 17:50:43,596:INFO:              sktime: 0.26.0
2025-05-09 17:50:43,596:INFO:               tbats: 1.1.3
2025-05-09 17:50:43,596:INFO:            pmdarima: 2.0.4
2025-05-09 17:50:43,596:INFO:              psutil: 7.0.0
2025-05-09 17:50:43,596:INFO:          markupsafe: 3.0.2
2025-05-09 17:50:43,596:INFO:             pickle5: Not installed
2025-05-09 17:50:43,596:INFO:         cloudpickle: 3.1.1
2025-05-09 17:50:43,596:INFO:         deprecation: 2.1.0
2025-05-09 17:50:43,596:INFO:              xxhash: 3.5.0
2025-05-09 17:50:43,596:INFO:           wurlitzer: 3.1.1
2025-05-09 17:50:43,596:INFO:PyCaret optional dependencies:
2025-05-09 17:50:43,596:INFO:                shap: Not installed
2025-05-09 17:50:43,596:INFO:           interpret: Not installed
2025-05-09 17:50:43,597:INFO:                umap: Not installed
2025-05-09 17:50:43,597:INFO:     ydata_profiling: Not installed
2025-05-09 17:50:43,597:INFO:  explainerdashboard: Not installed
2025-05-09 17:50:43,597:INFO:             autoviz: Not installed
2025-05-09 17:50:43,597:INFO:           fairlearn: Not installed
2025-05-09 17:50:43,597:INFO:          deepchecks: Not installed
2025-05-09 17:50:43,597:INFO:             xgboost: Not installed
2025-05-09 17:50:43,597:INFO:            catboost: Not installed
2025-05-09 17:50:43,597:INFO:              kmodes: Not installed
2025-05-09 17:50:43,597:INFO:             mlxtend: Not installed
2025-05-09 17:50:43,597:INFO:       statsforecast: Not installed
2025-05-09 17:50:43,597:INFO:        tune_sklearn: Not installed
2025-05-09 17:50:43,597:INFO:                 ray: Not installed
2025-05-09 17:50:43,597:INFO:            hyperopt: Not installed
2025-05-09 17:50:43,597:INFO:              optuna: Not installed
2025-05-09 17:50:43,597:INFO:               skopt: Not installed
2025-05-09 17:50:43,597:INFO:              mlflow: Not installed
2025-05-09 17:50:43,597:INFO:              gradio: Not installed
2025-05-09 17:50:43,597:INFO:             fastapi: Not installed
2025-05-09 17:50:43,597:INFO:             uvicorn: Not installed
2025-05-09 17:50:43,597:INFO:              m2cgen: Not installed
2025-05-09 17:50:43,597:INFO:           evidently: Not installed
2025-05-09 17:50:43,597:INFO:               fugue: Not installed
2025-05-09 17:50:43,597:INFO:           streamlit: Not installed
2025-05-09 17:50:43,597:INFO:             prophet: Not installed
2025-05-09 17:50:43,597:INFO:None
2025-05-09 17:50:43,597:INFO:Set up data.
2025-05-09 17:50:43,635:INFO:Set up folding strategy.
2025-05-09 17:50:43,635:INFO:Set up train/test split.
2025-05-09 17:50:43,651:INFO:Set up index.
2025-05-09 17:50:43,652:INFO:Assigning column types.
2025-05-09 17:50:43,656:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-09 17:50:43,674:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 17:50:43,675:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:50:43,686:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:43,686:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:43,704:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 17:50:43,704:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:50:43,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:43,715:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:43,716:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-09 17:50:43,734:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:50:43,745:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:43,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:43,763:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:50:43,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:43,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:43,775:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-09 17:50:43,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:43,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:43,839:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:43,839:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:43,839:INFO:Preparing preprocessing pipeline...
2025-05-09 17:50:43,841:INFO:Set up simple imputation.
2025-05-09 17:50:43,847:INFO:Set up encoding of ordinal features.
2025-05-09 17:50:43,860:INFO:Set up encoding of categorical features.
2025-05-09 17:50:43,861:INFO:Set up imbalanced handling.
2025-05-09 17:50:43,862:INFO:Set up column transformation.
2025-05-09 17:50:44,161:INFO:Finished creating preprocessing pipeline.
2025-05-09 17:50:44,183:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-09 17:50:44,183:INFO:Creating final display dataframe.
2025-05-09 17:50:44,400:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              4320
2025-05-09 17:50:44,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:44,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:44,466:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:44,466:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:50:44,467:INFO:setup() successfully completed in 0.87s...............
2025-05-09 17:50:44,468:INFO:Initializing compare_models()
2025-05-09 17:50:44,468:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-09 17:50:44,468:INFO:Checking exceptions
2025-05-09 17:50:44,473:INFO:Preparing display monitor
2025-05-09 17:50:44,485:INFO:Initializing Logistic Regression
2025-05-09 17:50:44,485:INFO:Total runtime is 1.0689099629720052e-06 minutes
2025-05-09 17:50:44,486:INFO:SubProcess create_model() called ==================================
2025-05-09 17:50:44,486:INFO:Initializing create_model()
2025-05-09 17:50:44,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e2e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:50:44,487:INFO:Checking exceptions
2025-05-09 17:50:44,487:INFO:Importing libraries
2025-05-09 17:50:44,487:INFO:Copying training dataset
2025-05-09 17:50:44,498:INFO:Defining folds
2025-05-09 17:50:44,498:INFO:Declaring metric variables
2025-05-09 17:50:44,499:INFO:Importing untrained model
2025-05-09 17:50:44,501:INFO:Logistic Regression Imported successfully
2025-05-09 17:50:44,503:INFO:Starting cross validation
2025-05-09 17:50:44,504:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:50:48,330:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:50:48,385:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:50:48,409:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:50:48,504:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:50:48,553:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:50:48,612:INFO:Calculating mean and std
2025-05-09 17:50:48,613:INFO:Creating metrics dataframe
2025-05-09 17:50:48,613:INFO:Uploading results into container
2025-05-09 17:50:48,614:INFO:Uploading model into container now
2025-05-09 17:50:48,614:INFO:_master_model_container: 1
2025-05-09 17:50:48,614:INFO:_display_container: 2
2025-05-09 17:50:48,614:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-09 17:50:48,614:INFO:create_model() successfully completed......................................
2025-05-09 17:50:48,702:INFO:SubProcess create_model() end ==================================
2025-05-09 17:50:48,702:INFO:Creating metrics dataframe
2025-05-09 17:50:48,705:INFO:Initializing K Neighbors Classifier
2025-05-09 17:50:48,705:INFO:Total runtime is 0.07033531665802002 minutes
2025-05-09 17:50:48,706:INFO:SubProcess create_model() called ==================================
2025-05-09 17:50:48,706:INFO:Initializing create_model()
2025-05-09 17:50:48,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e2e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:50:48,706:INFO:Checking exceptions
2025-05-09 17:50:48,706:INFO:Importing libraries
2025-05-09 17:50:48,707:INFO:Copying training dataset
2025-05-09 17:50:48,715:INFO:Defining folds
2025-05-09 17:50:48,715:INFO:Declaring metric variables
2025-05-09 17:50:48,717:INFO:Importing untrained model
2025-05-09 17:50:48,718:INFO:K Neighbors Classifier Imported successfully
2025-05-09 17:50:48,720:INFO:Starting cross validation
2025-05-09 17:50:48,721:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:50:53,506:INFO:Calculating mean and std
2025-05-09 17:50:53,506:INFO:Creating metrics dataframe
2025-05-09 17:50:53,507:INFO:Uploading results into container
2025-05-09 17:50:53,508:INFO:Uploading model into container now
2025-05-09 17:50:53,508:INFO:_master_model_container: 2
2025-05-09 17:50:53,508:INFO:_display_container: 2
2025-05-09 17:50:53,509:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-09 17:50:53,509:INFO:create_model() successfully completed......................................
2025-05-09 17:50:53,570:INFO:SubProcess create_model() end ==================================
2025-05-09 17:50:53,570:INFO:Creating metrics dataframe
2025-05-09 17:50:53,573:INFO:Initializing Naive Bayes
2025-05-09 17:50:53,573:INFO:Total runtime is 0.15147770245869954 minutes
2025-05-09 17:50:53,575:INFO:SubProcess create_model() called ==================================
2025-05-09 17:50:53,575:INFO:Initializing create_model()
2025-05-09 17:50:53,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e2e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:50:53,575:INFO:Checking exceptions
2025-05-09 17:50:53,575:INFO:Importing libraries
2025-05-09 17:50:53,575:INFO:Copying training dataset
2025-05-09 17:50:53,585:INFO:Defining folds
2025-05-09 17:50:53,585:INFO:Declaring metric variables
2025-05-09 17:50:53,587:INFO:Importing untrained model
2025-05-09 17:50:53,588:INFO:Naive Bayes Imported successfully
2025-05-09 17:50:53,591:INFO:Starting cross validation
2025-05-09 17:50:53,592:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:50:54,737:INFO:Calculating mean and std
2025-05-09 17:50:54,738:INFO:Creating metrics dataframe
2025-05-09 17:50:54,739:INFO:Uploading results into container
2025-05-09 17:50:54,739:INFO:Uploading model into container now
2025-05-09 17:50:54,739:INFO:_master_model_container: 3
2025-05-09 17:50:54,739:INFO:_display_container: 2
2025-05-09 17:50:54,739:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-09 17:50:54,740:INFO:create_model() successfully completed......................................
2025-05-09 17:50:54,803:INFO:SubProcess create_model() end ==================================
2025-05-09 17:50:54,803:INFO:Creating metrics dataframe
2025-05-09 17:50:54,806:INFO:Initializing Decision Tree Classifier
2025-05-09 17:50:54,806:INFO:Total runtime is 0.17202838261922201 minutes
2025-05-09 17:50:54,808:INFO:SubProcess create_model() called ==================================
2025-05-09 17:50:54,808:INFO:Initializing create_model()
2025-05-09 17:50:54,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e2e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:50:54,808:INFO:Checking exceptions
2025-05-09 17:50:54,808:INFO:Importing libraries
2025-05-09 17:50:54,808:INFO:Copying training dataset
2025-05-09 17:50:54,817:INFO:Defining folds
2025-05-09 17:50:54,817:INFO:Declaring metric variables
2025-05-09 17:50:54,819:INFO:Importing untrained model
2025-05-09 17:50:54,820:INFO:Decision Tree Classifier Imported successfully
2025-05-09 17:50:54,823:INFO:Starting cross validation
2025-05-09 17:50:54,824:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:50:56,503:INFO:Calculating mean and std
2025-05-09 17:50:56,506:INFO:Creating metrics dataframe
2025-05-09 17:50:56,509:INFO:Uploading results into container
2025-05-09 17:50:56,509:INFO:Uploading model into container now
2025-05-09 17:50:56,510:INFO:_master_model_container: 4
2025-05-09 17:50:56,510:INFO:_display_container: 2
2025-05-09 17:50:56,510:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-09 17:50:56,510:INFO:create_model() successfully completed......................................
2025-05-09 17:50:56,571:INFO:SubProcess create_model() end ==================================
2025-05-09 17:50:56,571:INFO:Creating metrics dataframe
2025-05-09 17:50:56,575:INFO:Initializing SVM - Linear Kernel
2025-05-09 17:50:56,575:INFO:Total runtime is 0.20149986743927004 minutes
2025-05-09 17:50:56,576:INFO:SubProcess create_model() called ==================================
2025-05-09 17:50:56,576:INFO:Initializing create_model()
2025-05-09 17:50:56,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e2e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:50:56,576:INFO:Checking exceptions
2025-05-09 17:50:56,576:INFO:Importing libraries
2025-05-09 17:50:56,576:INFO:Copying training dataset
2025-05-09 17:50:56,586:INFO:Defining folds
2025-05-09 17:50:56,586:INFO:Declaring metric variables
2025-05-09 17:50:56,587:INFO:Importing untrained model
2025-05-09 17:50:56,588:INFO:SVM - Linear Kernel Imported successfully
2025-05-09 17:50:56,590:INFO:Starting cross validation
2025-05-09 17:50:56,592:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:50:59,917:INFO:Calculating mean and std
2025-05-09 17:50:59,917:INFO:Creating metrics dataframe
2025-05-09 17:50:59,918:INFO:Uploading results into container
2025-05-09 17:50:59,918:INFO:Uploading model into container now
2025-05-09 17:50:59,918:INFO:_master_model_container: 5
2025-05-09 17:50:59,918:INFO:_display_container: 2
2025-05-09 17:50:59,919:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-09 17:50:59,919:INFO:create_model() successfully completed......................................
2025-05-09 17:50:59,974:INFO:SubProcess create_model() end ==================================
2025-05-09 17:50:59,974:INFO:Creating metrics dataframe
2025-05-09 17:50:59,978:INFO:Initializing Ridge Classifier
2025-05-09 17:50:59,978:INFO:Total runtime is 0.2582145651181539 minutes
2025-05-09 17:50:59,979:INFO:SubProcess create_model() called ==================================
2025-05-09 17:50:59,979:INFO:Initializing create_model()
2025-05-09 17:50:59,979:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e2e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:50:59,979:INFO:Checking exceptions
2025-05-09 17:50:59,979:INFO:Importing libraries
2025-05-09 17:50:59,979:INFO:Copying training dataset
2025-05-09 17:50:59,988:INFO:Defining folds
2025-05-09 17:50:59,988:INFO:Declaring metric variables
2025-05-09 17:50:59,989:INFO:Importing untrained model
2025-05-09 17:50:59,991:INFO:Ridge Classifier Imported successfully
2025-05-09 17:50:59,993:INFO:Starting cross validation
2025-05-09 17:50:59,994:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:51:01,111:INFO:Calculating mean and std
2025-05-09 17:51:01,112:INFO:Creating metrics dataframe
2025-05-09 17:51:01,113:INFO:Uploading results into container
2025-05-09 17:51:01,113:INFO:Uploading model into container now
2025-05-09 17:51:01,113:INFO:_master_model_container: 6
2025-05-09 17:51:01,113:INFO:_display_container: 2
2025-05-09 17:51:01,114:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-09 17:51:01,114:INFO:create_model() successfully completed......................................
2025-05-09 17:51:01,177:INFO:SubProcess create_model() end ==================================
2025-05-09 17:51:01,177:INFO:Creating metrics dataframe
2025-05-09 17:51:01,181:INFO:Initializing Random Forest Classifier
2025-05-09 17:51:01,181:INFO:Total runtime is 0.2782693862915039 minutes
2025-05-09 17:51:01,182:INFO:SubProcess create_model() called ==================================
2025-05-09 17:51:01,183:INFO:Initializing create_model()
2025-05-09 17:51:01,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e2e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:51:01,183:INFO:Checking exceptions
2025-05-09 17:51:01,183:INFO:Importing libraries
2025-05-09 17:51:01,183:INFO:Copying training dataset
2025-05-09 17:51:01,192:INFO:Defining folds
2025-05-09 17:51:01,192:INFO:Declaring metric variables
2025-05-09 17:51:01,194:INFO:Importing untrained model
2025-05-09 17:51:01,195:INFO:Random Forest Classifier Imported successfully
2025-05-09 17:51:01,197:INFO:Starting cross validation
2025-05-09 17:51:01,198:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:51:06,772:INFO:Calculating mean and std
2025-05-09 17:51:06,773:INFO:Creating metrics dataframe
2025-05-09 17:51:06,774:INFO:Uploading results into container
2025-05-09 17:51:06,774:INFO:Uploading model into container now
2025-05-09 17:51:06,774:INFO:_master_model_container: 7
2025-05-09 17:51:06,774:INFO:_display_container: 2
2025-05-09 17:51:06,775:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-09 17:51:06,775:INFO:create_model() successfully completed......................................
2025-05-09 17:51:06,877:INFO:SubProcess create_model() end ==================================
2025-05-09 17:51:06,877:INFO:Creating metrics dataframe
2025-05-09 17:51:06,880:INFO:Initializing Quadratic Discriminant Analysis
2025-05-09 17:51:06,880:INFO:Total runtime is 0.3732594807942708 minutes
2025-05-09 17:51:06,882:INFO:SubProcess create_model() called ==================================
2025-05-09 17:51:06,882:INFO:Initializing create_model()
2025-05-09 17:51:06,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e2e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:51:06,882:INFO:Checking exceptions
2025-05-09 17:51:06,882:INFO:Importing libraries
2025-05-09 17:51:06,882:INFO:Copying training dataset
2025-05-09 17:51:06,892:INFO:Defining folds
2025-05-09 17:51:06,892:INFO:Declaring metric variables
2025-05-09 17:51:06,893:INFO:Importing untrained model
2025-05-09 17:51:06,894:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-09 17:51:06,896:INFO:Starting cross validation
2025-05-09 17:51:06,897:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:51:07,918:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:51:07,947:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:51:07,991:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:51:07,997:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:51:08,029:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:51:08,031:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:51:08,077:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:51:08,088:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:51:08,107:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:51:08,159:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:51:08,172:INFO:Calculating mean and std
2025-05-09 17:51:08,173:INFO:Creating metrics dataframe
2025-05-09 17:51:08,174:INFO:Uploading results into container
2025-05-09 17:51:08,174:INFO:Uploading model into container now
2025-05-09 17:51:08,174:INFO:_master_model_container: 8
2025-05-09 17:51:08,174:INFO:_display_container: 2
2025-05-09 17:51:08,174:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-09 17:51:08,174:INFO:create_model() successfully completed......................................
2025-05-09 17:51:08,232:INFO:SubProcess create_model() end ==================================
2025-05-09 17:51:08,232:INFO:Creating metrics dataframe
2025-05-09 17:51:08,235:INFO:Initializing Ada Boost Classifier
2025-05-09 17:51:08,235:INFO:Total runtime is 0.3958409508069356 minutes
2025-05-09 17:51:08,236:INFO:SubProcess create_model() called ==================================
2025-05-09 17:51:08,237:INFO:Initializing create_model()
2025-05-09 17:51:08,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e2e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:51:08,237:INFO:Checking exceptions
2025-05-09 17:51:08,237:INFO:Importing libraries
2025-05-09 17:51:08,237:INFO:Copying training dataset
2025-05-09 17:51:08,246:INFO:Defining folds
2025-05-09 17:51:08,246:INFO:Declaring metric variables
2025-05-09 17:51:08,247:INFO:Importing untrained model
2025-05-09 17:51:08,249:INFO:Ada Boost Classifier Imported successfully
2025-05-09 17:51:08,251:INFO:Starting cross validation
2025-05-09 17:51:08,252:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:51:09,266:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:51:09,266:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:51:09,273:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:51:09,280:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:51:09,386:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:51:12,041:INFO:Calculating mean and std
2025-05-09 17:51:12,042:INFO:Creating metrics dataframe
2025-05-09 17:51:12,044:INFO:Uploading results into container
2025-05-09 17:51:12,044:INFO:Uploading model into container now
2025-05-09 17:51:12,044:INFO:_master_model_container: 9
2025-05-09 17:51:12,044:INFO:_display_container: 2
2025-05-09 17:51:12,044:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-09 17:51:12,044:INFO:create_model() successfully completed......................................
2025-05-09 17:51:12,105:INFO:SubProcess create_model() end ==================================
2025-05-09 17:51:12,105:INFO:Creating metrics dataframe
2025-05-09 17:51:12,109:INFO:Initializing Gradient Boosting Classifier
2025-05-09 17:51:12,109:INFO:Total runtime is 0.4604007522265116 minutes
2025-05-09 17:51:12,110:INFO:SubProcess create_model() called ==================================
2025-05-09 17:51:12,110:INFO:Initializing create_model()
2025-05-09 17:51:12,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e2e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:51:12,110:INFO:Checking exceptions
2025-05-09 17:51:12,110:INFO:Importing libraries
2025-05-09 17:51:12,110:INFO:Copying training dataset
2025-05-09 17:51:12,120:INFO:Defining folds
2025-05-09 17:51:12,120:INFO:Declaring metric variables
2025-05-09 17:51:12,122:INFO:Importing untrained model
2025-05-09 17:51:12,123:INFO:Gradient Boosting Classifier Imported successfully
2025-05-09 17:51:12,125:INFO:Starting cross validation
2025-05-09 17:51:12,126:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:51:25,727:INFO:Calculating mean and std
2025-05-09 17:51:25,728:INFO:Creating metrics dataframe
2025-05-09 17:51:25,729:INFO:Uploading results into container
2025-05-09 17:51:25,729:INFO:Uploading model into container now
2025-05-09 17:51:25,730:INFO:_master_model_container: 10
2025-05-09 17:51:25,730:INFO:_display_container: 2
2025-05-09 17:51:25,730:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-09 17:51:25,730:INFO:create_model() successfully completed......................................
2025-05-09 17:51:25,789:INFO:SubProcess create_model() end ==================================
2025-05-09 17:51:25,789:INFO:Creating metrics dataframe
2025-05-09 17:51:25,793:INFO:Initializing Linear Discriminant Analysis
2025-05-09 17:51:25,793:INFO:Total runtime is 0.6884658336639404 minutes
2025-05-09 17:51:25,794:INFO:SubProcess create_model() called ==================================
2025-05-09 17:51:25,794:INFO:Initializing create_model()
2025-05-09 17:51:25,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e2e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:51:25,794:INFO:Checking exceptions
2025-05-09 17:51:25,794:INFO:Importing libraries
2025-05-09 17:51:25,794:INFO:Copying training dataset
2025-05-09 17:51:25,804:INFO:Defining folds
2025-05-09 17:51:25,804:INFO:Declaring metric variables
2025-05-09 17:51:25,805:INFO:Importing untrained model
2025-05-09 17:51:25,806:INFO:Linear Discriminant Analysis Imported successfully
2025-05-09 17:51:25,809:INFO:Starting cross validation
2025-05-09 17:51:25,810:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:51:27,063:INFO:Calculating mean and std
2025-05-09 17:51:27,063:INFO:Creating metrics dataframe
2025-05-09 17:51:27,064:INFO:Uploading results into container
2025-05-09 17:51:27,064:INFO:Uploading model into container now
2025-05-09 17:51:27,065:INFO:_master_model_container: 11
2025-05-09 17:51:27,065:INFO:_display_container: 2
2025-05-09 17:51:27,065:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-09 17:51:27,065:INFO:create_model() successfully completed......................................
2025-05-09 17:51:27,124:INFO:SubProcess create_model() end ==================================
2025-05-09 17:51:27,124:INFO:Creating metrics dataframe
2025-05-09 17:51:27,128:INFO:Initializing Extra Trees Classifier
2025-05-09 17:51:27,128:INFO:Total runtime is 0.710722017288208 minutes
2025-05-09 17:51:27,129:INFO:SubProcess create_model() called ==================================
2025-05-09 17:51:27,129:INFO:Initializing create_model()
2025-05-09 17:51:27,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e2e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:51:27,130:INFO:Checking exceptions
2025-05-09 17:51:27,130:INFO:Importing libraries
2025-05-09 17:51:27,130:INFO:Copying training dataset
2025-05-09 17:51:27,138:INFO:Defining folds
2025-05-09 17:51:27,138:INFO:Declaring metric variables
2025-05-09 17:51:27,140:INFO:Importing untrained model
2025-05-09 17:51:27,141:INFO:Extra Trees Classifier Imported successfully
2025-05-09 17:51:27,143:INFO:Starting cross validation
2025-05-09 17:51:27,144:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:51:31,623:INFO:Calculating mean and std
2025-05-09 17:51:31,628:INFO:Creating metrics dataframe
2025-05-09 17:51:31,635:INFO:Uploading results into container
2025-05-09 17:51:31,636:INFO:Uploading model into container now
2025-05-09 17:51:31,636:INFO:_master_model_container: 12
2025-05-09 17:51:31,636:INFO:_display_container: 2
2025-05-09 17:51:31,637:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-09 17:51:31,637:INFO:create_model() successfully completed......................................
2025-05-09 17:51:31,740:INFO:SubProcess create_model() end ==================================
2025-05-09 17:51:31,740:INFO:Creating metrics dataframe
2025-05-09 17:51:31,745:INFO:Initializing Light Gradient Boosting Machine
2025-05-09 17:51:31,745:INFO:Total runtime is 0.7876676837603251 minutes
2025-05-09 17:51:31,746:INFO:SubProcess create_model() called ==================================
2025-05-09 17:51:31,746:INFO:Initializing create_model()
2025-05-09 17:51:31,747:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e2e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:51:31,747:INFO:Checking exceptions
2025-05-09 17:51:31,747:INFO:Importing libraries
2025-05-09 17:51:31,747:INFO:Copying training dataset
2025-05-09 17:51:31,764:INFO:Defining folds
2025-05-09 17:51:31,764:INFO:Declaring metric variables
2025-05-09 17:51:31,766:INFO:Importing untrained model
2025-05-09 17:51:31,768:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:51:31,771:INFO:Starting cross validation
2025-05-09 17:51:31,772:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:51:35,790:INFO:Calculating mean and std
2025-05-09 17:51:35,791:INFO:Creating metrics dataframe
2025-05-09 17:51:35,792:INFO:Uploading results into container
2025-05-09 17:51:35,792:INFO:Uploading model into container now
2025-05-09 17:51:35,792:INFO:_master_model_container: 13
2025-05-09 17:51:35,792:INFO:_display_container: 2
2025-05-09 17:51:35,793:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:51:35,793:INFO:create_model() successfully completed......................................
2025-05-09 17:51:35,855:INFO:SubProcess create_model() end ==================================
2025-05-09 17:51:35,855:INFO:Creating metrics dataframe
2025-05-09 17:51:35,859:INFO:Initializing Dummy Classifier
2025-05-09 17:51:35,859:INFO:Total runtime is 0.8562336524327596 minutes
2025-05-09 17:51:35,860:INFO:SubProcess create_model() called ==================================
2025-05-09 17:51:35,860:INFO:Initializing create_model()
2025-05-09 17:51:35,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e2e390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:51:35,860:INFO:Checking exceptions
2025-05-09 17:51:35,860:INFO:Importing libraries
2025-05-09 17:51:35,860:INFO:Copying training dataset
2025-05-09 17:51:35,870:INFO:Defining folds
2025-05-09 17:51:35,870:INFO:Declaring metric variables
2025-05-09 17:51:35,871:INFO:Importing untrained model
2025-05-09 17:51:35,872:INFO:Dummy Classifier Imported successfully
2025-05-09 17:51:35,874:INFO:Starting cross validation
2025-05-09 17:51:35,875:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:51:36,915:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:51:36,942:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:51:36,955:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:51:36,983:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:51:37,017:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:51:37,026:INFO:Calculating mean and std
2025-05-09 17:51:37,026:INFO:Creating metrics dataframe
2025-05-09 17:51:37,027:INFO:Uploading results into container
2025-05-09 17:51:37,027:INFO:Uploading model into container now
2025-05-09 17:51:37,028:INFO:_master_model_container: 14
2025-05-09 17:51:37,028:INFO:_display_container: 2
2025-05-09 17:51:37,028:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-09 17:51:37,028:INFO:create_model() successfully completed......................................
2025-05-09 17:51:37,084:INFO:SubProcess create_model() end ==================================
2025-05-09 17:51:37,084:INFO:Creating metrics dataframe
2025-05-09 17:51:37,089:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-09 17:51:37,092:INFO:Initializing create_model()
2025-05-09 17:51:37,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:51:37,092:INFO:Checking exceptions
2025-05-09 17:51:37,092:INFO:Importing libraries
2025-05-09 17:51:37,092:INFO:Copying training dataset
2025-05-09 17:51:37,101:INFO:Defining folds
2025-05-09 17:51:37,101:INFO:Declaring metric variables
2025-05-09 17:51:37,102:INFO:Importing untrained model
2025-05-09 17:51:37,102:INFO:Declaring custom model
2025-05-09 17:51:37,102:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:51:37,103:INFO:Cross validation set to False
2025-05-09 17:51:37,103:INFO:Fitting Model
2025-05-09 17:51:38,384:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-09 17:51:38,394:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004830 seconds.
2025-05-09 17:51:38,394:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-09 17:51:38,394:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-09 17:51:38,394:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-09 17:51:38,394:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-09 17:51:38,394:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-09 17:51:39,152:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:51:39,152:INFO:create_model() successfully completed......................................
2025-05-09 17:51:39,207:INFO:Initializing create_model()
2025-05-09 17:51:39,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:51:39,207:INFO:Checking exceptions
2025-05-09 17:51:39,208:INFO:Importing libraries
2025-05-09 17:51:39,208:INFO:Copying training dataset
2025-05-09 17:51:39,217:INFO:Defining folds
2025-05-09 17:51:39,217:INFO:Declaring metric variables
2025-05-09 17:51:39,217:INFO:Importing untrained model
2025-05-09 17:51:39,217:INFO:Declaring custom model
2025-05-09 17:51:39,217:INFO:Gradient Boosting Classifier Imported successfully
2025-05-09 17:51:39,218:INFO:Cross validation set to False
2025-05-09 17:51:39,218:INFO:Fitting Model
2025-05-09 17:51:55,231:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-09 17:51:55,231:INFO:create_model() successfully completed......................................
2025-05-09 17:51:55,289:INFO:Initializing create_model()
2025-05-09 17:51:55,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:51:55,289:INFO:Checking exceptions
2025-05-09 17:51:55,290:INFO:Importing libraries
2025-05-09 17:51:55,290:INFO:Copying training dataset
2025-05-09 17:51:55,300:INFO:Defining folds
2025-05-09 17:51:55,300:INFO:Declaring metric variables
2025-05-09 17:51:55,300:INFO:Importing untrained model
2025-05-09 17:51:55,300:INFO:Declaring custom model
2025-05-09 17:51:55,300:INFO:Random Forest Classifier Imported successfully
2025-05-09 17:51:55,301:INFO:Cross validation set to False
2025-05-09 17:51:55,301:INFO:Fitting Model
2025-05-09 17:51:57,407:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-09 17:51:57,407:INFO:create_model() successfully completed......................................
2025-05-09 17:51:57,468:INFO:_master_model_container: 14
2025-05-09 17:51:57,468:INFO:_display_container: 2
2025-05-09 17:51:57,469:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-09 17:51:57,469:INFO:compare_models() successfully completed......................................
2025-05-09 17:51:57,480:INFO:Initializing evaluate_model()
2025-05-09 17:51:57,480:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-09 17:51:57,488:INFO:Initializing plot_model()
2025-05-09 17:51:57,489:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-09 17:51:57,489:INFO:Checking exceptions
2025-05-09 17:51:57,494:INFO:Preloading libraries
2025-05-09 17:51:57,496:INFO:Copying training dataset
2025-05-09 17:51:57,496:INFO:Plot type: pipeline
2025-05-09 17:51:57,559:INFO:Visual Rendered Successfully
2025-05-09 17:51:57,616:INFO:plot_model() successfully completed......................................
2025-05-09 17:51:57,618:INFO:Initializing tune_model()
2025-05-09 17:51:57,618:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-09 17:51:57,618:INFO:Checking exceptions
2025-05-09 17:51:57,628:INFO:Copying training dataset
2025-05-09 17:51:57,637:INFO:Checking base model
2025-05-09 17:51:57,637:INFO:Base model : Light Gradient Boosting Machine
2025-05-09 17:51:57,639:INFO:Declaring metric variables
2025-05-09 17:51:57,640:INFO:Defining Hyperparameters
2025-05-09 17:51:57,700:INFO:Tuning with n_jobs=-1
2025-05-09 17:51:57,700:INFO:Initializing RandomizedSearchCV
2025-05-09 17:52:32,039:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-09 17:52:32,042:INFO:Hyperparameter search completed
2025-05-09 17:52:32,042:INFO:SubProcess create_model() called ==================================
2025-05-09 17:52:32,043:INFO:Initializing create_model()
2025-05-09 17:52:32,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3340ac310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-09 17:52:32,043:INFO:Checking exceptions
2025-05-09 17:52:32,043:INFO:Importing libraries
2025-05-09 17:52:32,043:INFO:Copying training dataset
2025-05-09 17:52:32,054:INFO:Defining folds
2025-05-09 17:52:32,054:INFO:Declaring metric variables
2025-05-09 17:52:32,059:INFO:Importing untrained model
2025-05-09 17:52:32,060:INFO:Declaring custom model
2025-05-09 17:52:32,063:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:52:32,066:INFO:Starting cross validation
2025-05-09 17:52:32,068:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:52:38,293:INFO:Calculating mean and std
2025-05-09 17:52:38,294:INFO:Creating metrics dataframe
2025-05-09 17:52:38,296:INFO:Finalizing model
2025-05-09 17:52:39,283:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-09 17:52:39,283:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-09 17:52:39,283:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-09 17:52:39,315:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-09 17:52:39,315:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-09 17:52:39,315:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-09 17:52:39,316:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-09 17:52:39,326:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004799 seconds.
2025-05-09 17:52:39,326:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-09 17:52:39,326:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-09 17:52:39,326:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-09 17:52:39,326:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-09 17:52:39,326:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-09 17:52:40,767:INFO:Uploading results into container
2025-05-09 17:52:40,767:INFO:Uploading model into container now
2025-05-09 17:52:40,768:INFO:_master_model_container: 15
2025-05-09 17:52:40,768:INFO:_display_container: 3
2025-05-09 17:52:40,768:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:52:40,768:INFO:create_model() successfully completed......................................
2025-05-09 17:52:40,875:INFO:SubProcess create_model() end ==================================
2025-05-09 17:52:40,875:INFO:choose_better activated
2025-05-09 17:52:40,877:INFO:SubProcess create_model() called ==================================
2025-05-09 17:52:40,877:INFO:Initializing create_model()
2025-05-09 17:52:40,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:52:40,877:INFO:Checking exceptions
2025-05-09 17:52:40,878:INFO:Importing libraries
2025-05-09 17:52:40,878:INFO:Copying training dataset
2025-05-09 17:52:40,887:INFO:Defining folds
2025-05-09 17:52:40,887:INFO:Declaring metric variables
2025-05-09 17:52:40,887:INFO:Importing untrained model
2025-05-09 17:52:40,887:INFO:Declaring custom model
2025-05-09 17:52:40,887:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:52:40,887:INFO:Starting cross validation
2025-05-09 17:52:40,888:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:52:44,954:INFO:Calculating mean and std
2025-05-09 17:52:44,955:INFO:Creating metrics dataframe
2025-05-09 17:52:44,955:INFO:Finalizing model
2025-05-09 17:52:45,987:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-09 17:52:45,996:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004998 seconds.
2025-05-09 17:52:45,996:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-09 17:52:45,996:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-09 17:52:45,996:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-09 17:52:45,997:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-09 17:52:45,997:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-09 17:52:46,745:INFO:Uploading results into container
2025-05-09 17:52:46,745:INFO:Uploading model into container now
2025-05-09 17:52:46,745:INFO:_master_model_container: 16
2025-05-09 17:52:46,745:INFO:_display_container: 4
2025-05-09 17:52:46,746:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:52:46,746:INFO:create_model() successfully completed......................................
2025-05-09 17:52:46,803:INFO:SubProcess create_model() end ==================================
2025-05-09 17:52:46,804:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-09 17:52:46,804:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-09 17:52:46,804:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-09 17:52:46,804:INFO:choose_better completed
2025-05-09 17:52:46,808:INFO:_master_model_container: 16
2025-05-09 17:52:46,808:INFO:_display_container: 3
2025-05-09 17:52:46,808:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:52:46,809:INFO:tune_model() successfully completed......................................
2025-05-09 17:52:46,871:INFO:Initializing evaluate_model()
2025-05-09 17:52:46,871:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-09 17:52:46,879:INFO:Initializing plot_model()
2025-05-09 17:52:46,879:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-09 17:52:46,879:INFO:Checking exceptions
2025-05-09 17:52:46,883:INFO:Preloading libraries
2025-05-09 17:52:46,886:INFO:Copying training dataset
2025-05-09 17:52:46,886:INFO:Plot type: pipeline
2025-05-09 17:52:46,945:INFO:Visual Rendered Successfully
2025-05-09 17:52:47,002:INFO:plot_model() successfully completed......................................
2025-05-09 17:52:47,003:INFO:Initializing interpret_model()
2025-05-09 17:52:47,004:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33787c590>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-09 17:52:47,004:INFO:Checking exceptions
2025-05-09 17:52:47,004:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-09 17:54:40,815:INFO:PyCaret ClassificationExperiment
2025-05-09 17:54:40,815:INFO:Logging name: clf-default-name
2025-05-09 17:54:40,815:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-09 17:54:40,815:INFO:version 3.3.2
2025-05-09 17:54:40,815:INFO:Initializing setup()
2025-05-09 17:54:40,815:INFO:self.USI: 6dda
2025-05-09 17:54:40,815:INFO:self._variable_keys: {'USI', 'html_param', 'exp_name_log', 'seed', 'logging_param', 'X', 'fix_imbalance', 'gpu_n_jobs_param', '_available_plots', 'exp_id', 'is_multiclass', 'X_test', 'y_test', 'memory', 'fold_shuffle_param', 'log_plots_param', 'n_jobs_param', 'target_param', 'fold_groups_param', '_ml_usecase', 'pipeline', 'data', 'gpu_param', 'y', 'idx', 'X_train', 'fold_generator', 'y_train'}
2025-05-09 17:54:40,815:INFO:Checking environment
2025-05-09 17:54:40,815:INFO:python_version: 3.11.0
2025-05-09 17:54:40,815:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-09 17:54:40,815:INFO:machine: arm64
2025-05-09 17:54:40,815:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-09 17:54:40,815:INFO:Memory: svmem(total=17179869184, available=3658072064, percent=78.7, used=6031343616, free=87687168, active=3591634944, inactive=3515154432, wired=2439708672)
2025-05-09 17:54:40,815:INFO:Physical Core: 12
2025-05-09 17:54:40,815:INFO:Logical Core: 12
2025-05-09 17:54:40,815:INFO:Checking libraries
2025-05-09 17:54:40,815:INFO:System:
2025-05-09 17:54:40,815:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-09 17:54:40,815:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-09 17:54:40,815:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-09 17:54:40,815:INFO:PyCaret required dependencies:
2025-05-09 17:54:40,815:INFO:                 pip: 22.3
2025-05-09 17:54:40,815:INFO:          setuptools: 65.5.0
2025-05-09 17:54:40,815:INFO:             pycaret: 3.3.2
2025-05-09 17:54:40,815:INFO:             IPython: 9.2.0
2025-05-09 17:54:40,815:INFO:          ipywidgets: 8.1.7
2025-05-09 17:54:40,815:INFO:                tqdm: 4.67.1
2025-05-09 17:54:40,815:INFO:               numpy: 1.26.4
2025-05-09 17:54:40,815:INFO:              pandas: 2.1.4
2025-05-09 17:54:40,815:INFO:              jinja2: 3.1.6
2025-05-09 17:54:40,815:INFO:               scipy: 1.11.4
2025-05-09 17:54:40,815:INFO:              joblib: 1.3.2
2025-05-09 17:54:40,815:INFO:             sklearn: 1.4.2
2025-05-09 17:54:40,815:INFO:                pyod: 2.0.5
2025-05-09 17:54:40,815:INFO:            imblearn: 0.13.0
2025-05-09 17:54:40,815:INFO:   category_encoders: 2.7.0
2025-05-09 17:54:40,815:INFO:            lightgbm: 4.6.0
2025-05-09 17:54:40,815:INFO:               numba: 0.61.2
2025-05-09 17:54:40,815:INFO:            requests: 2.32.3
2025-05-09 17:54:40,815:INFO:          matplotlib: 3.7.5
2025-05-09 17:54:40,815:INFO:          scikitplot: 0.3.7
2025-05-09 17:54:40,815:INFO:         yellowbrick: 1.5
2025-05-09 17:54:40,816:INFO:              plotly: 5.24.1
2025-05-09 17:54:40,816:INFO:    plotly-resampler: Not installed
2025-05-09 17:54:40,816:INFO:             kaleido: 0.2.1
2025-05-09 17:54:40,816:INFO:           schemdraw: 0.15
2025-05-09 17:54:40,816:INFO:         statsmodels: 0.14.4
2025-05-09 17:54:40,816:INFO:              sktime: 0.26.0
2025-05-09 17:54:40,816:INFO:               tbats: 1.1.3
2025-05-09 17:54:40,816:INFO:            pmdarima: 2.0.4
2025-05-09 17:54:40,816:INFO:              psutil: 7.0.0
2025-05-09 17:54:40,816:INFO:          markupsafe: 3.0.2
2025-05-09 17:54:40,816:INFO:             pickle5: Not installed
2025-05-09 17:54:40,816:INFO:         cloudpickle: 3.1.1
2025-05-09 17:54:40,816:INFO:         deprecation: 2.1.0
2025-05-09 17:54:40,816:INFO:              xxhash: 3.5.0
2025-05-09 17:54:40,816:INFO:           wurlitzer: 3.1.1
2025-05-09 17:54:40,816:INFO:PyCaret optional dependencies:
2025-05-09 17:54:40,816:INFO:                shap: Not installed
2025-05-09 17:54:40,816:INFO:           interpret: Not installed
2025-05-09 17:54:40,816:INFO:                umap: Not installed
2025-05-09 17:54:40,816:INFO:     ydata_profiling: Not installed
2025-05-09 17:54:40,816:INFO:  explainerdashboard: Not installed
2025-05-09 17:54:40,816:INFO:             autoviz: Not installed
2025-05-09 17:54:40,816:INFO:           fairlearn: Not installed
2025-05-09 17:54:40,816:INFO:          deepchecks: Not installed
2025-05-09 17:54:40,816:INFO:             xgboost: Not installed
2025-05-09 17:54:40,816:INFO:            catboost: Not installed
2025-05-09 17:54:40,816:INFO:              kmodes: Not installed
2025-05-09 17:54:40,816:INFO:             mlxtend: Not installed
2025-05-09 17:54:40,816:INFO:       statsforecast: Not installed
2025-05-09 17:54:40,816:INFO:        tune_sklearn: Not installed
2025-05-09 17:54:40,816:INFO:                 ray: Not installed
2025-05-09 17:54:40,816:INFO:            hyperopt: Not installed
2025-05-09 17:54:40,816:INFO:              optuna: Not installed
2025-05-09 17:54:40,816:INFO:               skopt: Not installed
2025-05-09 17:54:40,816:INFO:              mlflow: Not installed
2025-05-09 17:54:40,816:INFO:              gradio: Not installed
2025-05-09 17:54:40,816:INFO:             fastapi: Not installed
2025-05-09 17:54:40,816:INFO:             uvicorn: Not installed
2025-05-09 17:54:40,816:INFO:              m2cgen: Not installed
2025-05-09 17:54:40,816:INFO:           evidently: Not installed
2025-05-09 17:54:40,816:INFO:               fugue: Not installed
2025-05-09 17:54:40,816:INFO:           streamlit: Not installed
2025-05-09 17:54:40,816:INFO:             prophet: Not installed
2025-05-09 17:54:40,816:INFO:None
2025-05-09 17:54:40,816:INFO:Set up data.
2025-05-09 17:54:40,849:INFO:Set up folding strategy.
2025-05-09 17:54:40,849:INFO:Set up train/test split.
2025-05-09 17:54:40,863:INFO:Set up index.
2025-05-09 17:54:40,863:INFO:Assigning column types.
2025-05-09 17:54:40,867:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-09 17:54:40,885:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 17:54:40,886:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:54:40,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:40,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:40,915:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 17:54:40,915:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:54:40,927:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:40,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:40,927:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-09 17:54:40,945:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:54:40,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:40,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:40,975:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:54:40,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:40,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:40,986:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-09 17:54:41,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:41,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:41,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:41,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:41,046:INFO:Preparing preprocessing pipeline...
2025-05-09 17:54:41,048:INFO:Set up simple imputation.
2025-05-09 17:54:41,054:INFO:Set up encoding of ordinal features.
2025-05-09 17:54:41,064:INFO:Set up encoding of categorical features.
2025-05-09 17:54:41,064:INFO:Set up imbalanced handling.
2025-05-09 17:54:41,064:INFO:Set up column transformation.
2025-05-09 17:54:41,318:INFO:Finished creating preprocessing pipeline.
2025-05-09 17:54:41,338:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-09 17:54:41,338:INFO:Creating final display dataframe.
2025-05-09 17:54:41,561:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              6dda
2025-05-09 17:54:41,601:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:41,601:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:41,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:41,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:54:41,637:INFO:setup() successfully completed in 0.82s...............
2025-05-09 17:54:41,637:INFO:Initializing compare_models()
2025-05-09 17:54:41,638:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-09 17:54:41,638:INFO:Checking exceptions
2025-05-09 17:54:41,643:INFO:Preparing display monitor
2025-05-09 17:54:41,656:INFO:Initializing Logistic Regression
2025-05-09 17:54:41,656:INFO:Total runtime is 1.915295918782552e-06 minutes
2025-05-09 17:54:41,657:INFO:SubProcess create_model() called ==================================
2025-05-09 17:54:41,658:INFO:Initializing create_model()
2025-05-09 17:54:41,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33893c810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:54:41,658:INFO:Checking exceptions
2025-05-09 17:54:41,658:INFO:Importing libraries
2025-05-09 17:54:41,658:INFO:Copying training dataset
2025-05-09 17:54:41,669:INFO:Defining folds
2025-05-09 17:54:41,670:INFO:Declaring metric variables
2025-05-09 17:54:41,671:INFO:Importing untrained model
2025-05-09 17:54:41,672:INFO:Logistic Regression Imported successfully
2025-05-09 17:54:41,674:INFO:Starting cross validation
2025-05-09 17:54:41,676:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:54:45,779:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:54:45,790:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:54:45,827:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:54:45,945:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:54:45,952:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:54:46,018:INFO:Calculating mean and std
2025-05-09 17:54:46,019:INFO:Creating metrics dataframe
2025-05-09 17:54:46,021:INFO:Uploading results into container
2025-05-09 17:54:46,021:INFO:Uploading model into container now
2025-05-09 17:54:46,022:INFO:_master_model_container: 1
2025-05-09 17:54:46,022:INFO:_display_container: 2
2025-05-09 17:54:46,022:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-09 17:54:46,022:INFO:create_model() successfully completed......................................
2025-05-09 17:54:46,142:INFO:SubProcess create_model() end ==================================
2025-05-09 17:54:46,142:INFO:Creating metrics dataframe
2025-05-09 17:54:46,146:INFO:Initializing K Neighbors Classifier
2025-05-09 17:54:46,146:INFO:Total runtime is 0.07483643293380737 minutes
2025-05-09 17:54:46,147:INFO:SubProcess create_model() called ==================================
2025-05-09 17:54:46,148:INFO:Initializing create_model()
2025-05-09 17:54:46,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33893c810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:54:46,148:INFO:Checking exceptions
2025-05-09 17:54:46,148:INFO:Importing libraries
2025-05-09 17:54:46,148:INFO:Copying training dataset
2025-05-09 17:54:46,158:INFO:Defining folds
2025-05-09 17:54:46,158:INFO:Declaring metric variables
2025-05-09 17:54:46,159:INFO:Importing untrained model
2025-05-09 17:54:46,160:INFO:K Neighbors Classifier Imported successfully
2025-05-09 17:54:46,162:INFO:Starting cross validation
2025-05-09 17:54:46,163:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:54:51,144:INFO:Calculating mean and std
2025-05-09 17:54:51,145:INFO:Creating metrics dataframe
2025-05-09 17:54:51,146:INFO:Uploading results into container
2025-05-09 17:54:51,147:INFO:Uploading model into container now
2025-05-09 17:54:51,147:INFO:_master_model_container: 2
2025-05-09 17:54:51,147:INFO:_display_container: 2
2025-05-09 17:54:51,148:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-09 17:54:51,148:INFO:create_model() successfully completed......................................
2025-05-09 17:54:51,216:INFO:SubProcess create_model() end ==================================
2025-05-09 17:54:51,216:INFO:Creating metrics dataframe
2025-05-09 17:54:51,219:INFO:Initializing Naive Bayes
2025-05-09 17:54:51,219:INFO:Total runtime is 0.15939248005549111 minutes
2025-05-09 17:54:51,221:INFO:SubProcess create_model() called ==================================
2025-05-09 17:54:51,221:INFO:Initializing create_model()
2025-05-09 17:54:51,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33893c810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:54:51,221:INFO:Checking exceptions
2025-05-09 17:54:51,221:INFO:Importing libraries
2025-05-09 17:54:51,221:INFO:Copying training dataset
2025-05-09 17:54:51,238:INFO:Defining folds
2025-05-09 17:54:51,238:INFO:Declaring metric variables
2025-05-09 17:54:51,240:INFO:Importing untrained model
2025-05-09 17:54:51,241:INFO:Naive Bayes Imported successfully
2025-05-09 17:54:51,244:INFO:Starting cross validation
2025-05-09 17:54:51,245:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:54:52,490:INFO:Calculating mean and std
2025-05-09 17:54:52,491:INFO:Creating metrics dataframe
2025-05-09 17:54:52,492:INFO:Uploading results into container
2025-05-09 17:54:52,492:INFO:Uploading model into container now
2025-05-09 17:54:52,492:INFO:_master_model_container: 3
2025-05-09 17:54:52,492:INFO:_display_container: 2
2025-05-09 17:54:52,493:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-09 17:54:52,493:INFO:create_model() successfully completed......................................
2025-05-09 17:54:52,563:INFO:SubProcess create_model() end ==================================
2025-05-09 17:54:52,563:INFO:Creating metrics dataframe
2025-05-09 17:54:52,566:INFO:Initializing Decision Tree Classifier
2025-05-09 17:54:52,566:INFO:Total runtime is 0.1818472146987915 minutes
2025-05-09 17:54:52,568:INFO:SubProcess create_model() called ==================================
2025-05-09 17:54:52,568:INFO:Initializing create_model()
2025-05-09 17:54:52,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33893c810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:54:52,568:INFO:Checking exceptions
2025-05-09 17:54:52,568:INFO:Importing libraries
2025-05-09 17:54:52,568:INFO:Copying training dataset
2025-05-09 17:54:52,578:INFO:Defining folds
2025-05-09 17:54:52,578:INFO:Declaring metric variables
2025-05-09 17:54:52,579:INFO:Importing untrained model
2025-05-09 17:54:52,580:INFO:Decision Tree Classifier Imported successfully
2025-05-09 17:54:52,582:INFO:Starting cross validation
2025-05-09 17:54:52,583:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:54:54,290:INFO:Calculating mean and std
2025-05-09 17:54:54,291:INFO:Creating metrics dataframe
2025-05-09 17:54:54,293:INFO:Uploading results into container
2025-05-09 17:54:54,293:INFO:Uploading model into container now
2025-05-09 17:54:54,293:INFO:_master_model_container: 4
2025-05-09 17:54:54,293:INFO:_display_container: 2
2025-05-09 17:54:54,294:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-09 17:54:54,294:INFO:create_model() successfully completed......................................
2025-05-09 17:54:54,368:INFO:SubProcess create_model() end ==================================
2025-05-09 17:54:54,368:INFO:Creating metrics dataframe
2025-05-09 17:54:54,371:INFO:Initializing SVM - Linear Kernel
2025-05-09 17:54:54,371:INFO:Total runtime is 0.21192361116409303 minutes
2025-05-09 17:54:54,372:INFO:SubProcess create_model() called ==================================
2025-05-09 17:54:54,372:INFO:Initializing create_model()
2025-05-09 17:54:54,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33893c810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:54:54,373:INFO:Checking exceptions
2025-05-09 17:54:54,373:INFO:Importing libraries
2025-05-09 17:54:54,373:INFO:Copying training dataset
2025-05-09 17:54:54,382:INFO:Defining folds
2025-05-09 17:54:54,382:INFO:Declaring metric variables
2025-05-09 17:54:54,383:INFO:Importing untrained model
2025-05-09 17:54:54,384:INFO:SVM - Linear Kernel Imported successfully
2025-05-09 17:54:54,386:INFO:Starting cross validation
2025-05-09 17:54:54,387:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:54:57,835:INFO:Calculating mean and std
2025-05-09 17:54:57,836:INFO:Creating metrics dataframe
2025-05-09 17:54:57,837:INFO:Uploading results into container
2025-05-09 17:54:57,837:INFO:Uploading model into container now
2025-05-09 17:54:57,838:INFO:_master_model_container: 5
2025-05-09 17:54:57,838:INFO:_display_container: 2
2025-05-09 17:54:57,838:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-09 17:54:57,838:INFO:create_model() successfully completed......................................
2025-05-09 17:54:57,893:INFO:SubProcess create_model() end ==================================
2025-05-09 17:54:57,893:INFO:Creating metrics dataframe
2025-05-09 17:54:57,896:INFO:Initializing Ridge Classifier
2025-05-09 17:54:57,896:INFO:Total runtime is 0.27067242860794066 minutes
2025-05-09 17:54:57,897:INFO:SubProcess create_model() called ==================================
2025-05-09 17:54:57,897:INFO:Initializing create_model()
2025-05-09 17:54:57,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33893c810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:54:57,897:INFO:Checking exceptions
2025-05-09 17:54:57,898:INFO:Importing libraries
2025-05-09 17:54:57,898:INFO:Copying training dataset
2025-05-09 17:54:57,907:INFO:Defining folds
2025-05-09 17:54:57,907:INFO:Declaring metric variables
2025-05-09 17:54:57,908:INFO:Importing untrained model
2025-05-09 17:54:57,909:INFO:Ridge Classifier Imported successfully
2025-05-09 17:54:57,911:INFO:Starting cross validation
2025-05-09 17:54:57,912:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:54:59,069:INFO:Calculating mean and std
2025-05-09 17:54:59,070:INFO:Creating metrics dataframe
2025-05-09 17:54:59,070:INFO:Uploading results into container
2025-05-09 17:54:59,071:INFO:Uploading model into container now
2025-05-09 17:54:59,071:INFO:_master_model_container: 6
2025-05-09 17:54:59,071:INFO:_display_container: 2
2025-05-09 17:54:59,071:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-09 17:54:59,071:INFO:create_model() successfully completed......................................
2025-05-09 17:54:59,125:INFO:SubProcess create_model() end ==================================
2025-05-09 17:54:59,125:INFO:Creating metrics dataframe
2025-05-09 17:54:59,128:INFO:Initializing Random Forest Classifier
2025-05-09 17:54:59,128:INFO:Total runtime is 0.2912131786346435 minutes
2025-05-09 17:54:59,130:INFO:SubProcess create_model() called ==================================
2025-05-09 17:54:59,130:INFO:Initializing create_model()
2025-05-09 17:54:59,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33893c810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:54:59,130:INFO:Checking exceptions
2025-05-09 17:54:59,130:INFO:Importing libraries
2025-05-09 17:54:59,130:INFO:Copying training dataset
2025-05-09 17:54:59,138:INFO:Defining folds
2025-05-09 17:54:59,138:INFO:Declaring metric variables
2025-05-09 17:54:59,139:INFO:Importing untrained model
2025-05-09 17:54:59,141:INFO:Random Forest Classifier Imported successfully
2025-05-09 17:54:59,143:INFO:Starting cross validation
2025-05-09 17:54:59,144:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:55:04,744:INFO:Calculating mean and std
2025-05-09 17:55:04,745:INFO:Creating metrics dataframe
2025-05-09 17:55:04,746:INFO:Uploading results into container
2025-05-09 17:55:04,746:INFO:Uploading model into container now
2025-05-09 17:55:04,746:INFO:_master_model_container: 7
2025-05-09 17:55:04,746:INFO:_display_container: 2
2025-05-09 17:55:04,746:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-09 17:55:04,746:INFO:create_model() successfully completed......................................
2025-05-09 17:55:04,809:INFO:SubProcess create_model() end ==================================
2025-05-09 17:55:04,809:INFO:Creating metrics dataframe
2025-05-09 17:55:04,813:INFO:Initializing Quadratic Discriminant Analysis
2025-05-09 17:55:04,813:INFO:Total runtime is 0.3859584291776021 minutes
2025-05-09 17:55:04,814:INFO:SubProcess create_model() called ==================================
2025-05-09 17:55:04,815:INFO:Initializing create_model()
2025-05-09 17:55:04,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33893c810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:55:04,815:INFO:Checking exceptions
2025-05-09 17:55:04,815:INFO:Importing libraries
2025-05-09 17:55:04,815:INFO:Copying training dataset
2025-05-09 17:55:04,825:INFO:Defining folds
2025-05-09 17:55:04,825:INFO:Declaring metric variables
2025-05-09 17:55:04,827:INFO:Importing untrained model
2025-05-09 17:55:04,828:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-09 17:55:04,830:INFO:Starting cross validation
2025-05-09 17:55:04,831:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:55:05,846:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:55:05,879:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:55:05,901:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:55:05,930:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:55:05,941:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:55:05,961:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:55:05,973:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:55:05,980:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:55:06,006:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:55:06,042:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:55:06,049:INFO:Calculating mean and std
2025-05-09 17:55:06,049:INFO:Creating metrics dataframe
2025-05-09 17:55:06,050:INFO:Uploading results into container
2025-05-09 17:55:06,051:INFO:Uploading model into container now
2025-05-09 17:55:06,051:INFO:_master_model_container: 8
2025-05-09 17:55:06,051:INFO:_display_container: 2
2025-05-09 17:55:06,051:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-09 17:55:06,051:INFO:create_model() successfully completed......................................
2025-05-09 17:55:06,117:INFO:SubProcess create_model() end ==================================
2025-05-09 17:55:06,117:INFO:Creating metrics dataframe
2025-05-09 17:55:06,121:INFO:Initializing Ada Boost Classifier
2025-05-09 17:55:06,121:INFO:Total runtime is 0.40775491396586094 minutes
2025-05-09 17:55:06,122:INFO:SubProcess create_model() called ==================================
2025-05-09 17:55:06,122:INFO:Initializing create_model()
2025-05-09 17:55:06,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33893c810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:55:06,122:INFO:Checking exceptions
2025-05-09 17:55:06,122:INFO:Importing libraries
2025-05-09 17:55:06,122:INFO:Copying training dataset
2025-05-09 17:55:06,132:INFO:Defining folds
2025-05-09 17:55:06,132:INFO:Declaring metric variables
2025-05-09 17:55:06,133:INFO:Importing untrained model
2025-05-09 17:55:06,134:INFO:Ada Boost Classifier Imported successfully
2025-05-09 17:55:06,136:INFO:Starting cross validation
2025-05-09 17:55:06,137:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:55:07,123:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:55:07,156:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:55:07,165:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:55:07,212:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:55:07,215:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:55:09,896:INFO:Calculating mean and std
2025-05-09 17:55:09,898:INFO:Creating metrics dataframe
2025-05-09 17:55:09,900:INFO:Uploading results into container
2025-05-09 17:55:09,900:INFO:Uploading model into container now
2025-05-09 17:55:09,901:INFO:_master_model_container: 9
2025-05-09 17:55:09,901:INFO:_display_container: 2
2025-05-09 17:55:09,901:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-09 17:55:09,901:INFO:create_model() successfully completed......................................
2025-05-09 17:55:09,977:INFO:SubProcess create_model() end ==================================
2025-05-09 17:55:09,977:INFO:Creating metrics dataframe
2025-05-09 17:55:09,981:INFO:Initializing Gradient Boosting Classifier
2025-05-09 17:55:09,981:INFO:Total runtime is 0.472088865439097 minutes
2025-05-09 17:55:09,982:INFO:SubProcess create_model() called ==================================
2025-05-09 17:55:09,982:INFO:Initializing create_model()
2025-05-09 17:55:09,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33893c810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:55:09,982:INFO:Checking exceptions
2025-05-09 17:55:09,983:INFO:Importing libraries
2025-05-09 17:55:09,983:INFO:Copying training dataset
2025-05-09 17:55:09,992:INFO:Defining folds
2025-05-09 17:55:09,992:INFO:Declaring metric variables
2025-05-09 17:55:09,993:INFO:Importing untrained model
2025-05-09 17:55:09,994:INFO:Gradient Boosting Classifier Imported successfully
2025-05-09 17:55:09,997:INFO:Starting cross validation
2025-05-09 17:55:09,998:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:55:23,493:INFO:Calculating mean and std
2025-05-09 17:55:23,494:INFO:Creating metrics dataframe
2025-05-09 17:55:23,495:INFO:Uploading results into container
2025-05-09 17:55:23,496:INFO:Uploading model into container now
2025-05-09 17:55:23,496:INFO:_master_model_container: 10
2025-05-09 17:55:23,496:INFO:_display_container: 2
2025-05-09 17:55:23,496:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-09 17:55:23,496:INFO:create_model() successfully completed......................................
2025-05-09 17:55:23,561:INFO:SubProcess create_model() end ==================================
2025-05-09 17:55:23,562:INFO:Creating metrics dataframe
2025-05-09 17:55:23,566:INFO:Initializing Linear Discriminant Analysis
2025-05-09 17:55:23,566:INFO:Total runtime is 0.6985041141510009 minutes
2025-05-09 17:55:23,567:INFO:SubProcess create_model() called ==================================
2025-05-09 17:55:23,568:INFO:Initializing create_model()
2025-05-09 17:55:23,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33893c810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:55:23,568:INFO:Checking exceptions
2025-05-09 17:55:23,568:INFO:Importing libraries
2025-05-09 17:55:23,568:INFO:Copying training dataset
2025-05-09 17:55:23,577:INFO:Defining folds
2025-05-09 17:55:23,577:INFO:Declaring metric variables
2025-05-09 17:55:23,578:INFO:Importing untrained model
2025-05-09 17:55:23,580:INFO:Linear Discriminant Analysis Imported successfully
2025-05-09 17:55:23,582:INFO:Starting cross validation
2025-05-09 17:55:23,583:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:55:24,848:INFO:Calculating mean and std
2025-05-09 17:55:24,849:INFO:Creating metrics dataframe
2025-05-09 17:55:24,850:INFO:Uploading results into container
2025-05-09 17:55:24,850:INFO:Uploading model into container now
2025-05-09 17:55:24,851:INFO:_master_model_container: 11
2025-05-09 17:55:24,851:INFO:_display_container: 2
2025-05-09 17:55:24,851:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-09 17:55:24,851:INFO:create_model() successfully completed......................................
2025-05-09 17:55:24,923:INFO:SubProcess create_model() end ==================================
2025-05-09 17:55:24,923:INFO:Creating metrics dataframe
2025-05-09 17:55:24,928:INFO:Initializing Extra Trees Classifier
2025-05-09 17:55:24,928:INFO:Total runtime is 0.7211999813715616 minutes
2025-05-09 17:55:24,929:INFO:SubProcess create_model() called ==================================
2025-05-09 17:55:24,929:INFO:Initializing create_model()
2025-05-09 17:55:24,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33893c810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:55:24,929:INFO:Checking exceptions
2025-05-09 17:55:24,929:INFO:Importing libraries
2025-05-09 17:55:24,929:INFO:Copying training dataset
2025-05-09 17:55:24,939:INFO:Defining folds
2025-05-09 17:55:24,939:INFO:Declaring metric variables
2025-05-09 17:55:24,940:INFO:Importing untrained model
2025-05-09 17:55:24,941:INFO:Extra Trees Classifier Imported successfully
2025-05-09 17:55:24,943:INFO:Starting cross validation
2025-05-09 17:55:24,944:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:55:30,420:INFO:Calculating mean and std
2025-05-09 17:55:30,423:INFO:Creating metrics dataframe
2025-05-09 17:55:30,426:INFO:Uploading results into container
2025-05-09 17:55:30,427:INFO:Uploading model into container now
2025-05-09 17:55:30,427:INFO:_master_model_container: 12
2025-05-09 17:55:30,427:INFO:_display_container: 2
2025-05-09 17:55:30,428:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-09 17:55:30,428:INFO:create_model() successfully completed......................................
2025-05-09 17:55:30,542:INFO:SubProcess create_model() end ==================================
2025-05-09 17:55:30,542:INFO:Creating metrics dataframe
2025-05-09 17:55:30,548:INFO:Initializing Light Gradient Boosting Machine
2025-05-09 17:55:30,548:INFO:Total runtime is 0.8148666143417358 minutes
2025-05-09 17:55:30,549:INFO:SubProcess create_model() called ==================================
2025-05-09 17:55:30,549:INFO:Initializing create_model()
2025-05-09 17:55:30,549:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33893c810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:55:30,549:INFO:Checking exceptions
2025-05-09 17:55:30,549:INFO:Importing libraries
2025-05-09 17:55:30,549:INFO:Copying training dataset
2025-05-09 17:55:30,566:INFO:Defining folds
2025-05-09 17:55:30,566:INFO:Declaring metric variables
2025-05-09 17:55:30,568:INFO:Importing untrained model
2025-05-09 17:55:30,569:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:55:30,572:INFO:Starting cross validation
2025-05-09 17:55:30,573:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:55:34,610:INFO:Calculating mean and std
2025-05-09 17:55:34,611:INFO:Creating metrics dataframe
2025-05-09 17:55:34,612:INFO:Uploading results into container
2025-05-09 17:55:34,612:INFO:Uploading model into container now
2025-05-09 17:55:34,612:INFO:_master_model_container: 13
2025-05-09 17:55:34,612:INFO:_display_container: 2
2025-05-09 17:55:34,612:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:55:34,612:INFO:create_model() successfully completed......................................
2025-05-09 17:55:34,673:INFO:SubProcess create_model() end ==================================
2025-05-09 17:55:34,673:INFO:Creating metrics dataframe
2025-05-09 17:55:34,677:INFO:Initializing Dummy Classifier
2025-05-09 17:55:34,677:INFO:Total runtime is 0.8836912790934244 minutes
2025-05-09 17:55:34,678:INFO:SubProcess create_model() called ==================================
2025-05-09 17:55:34,679:INFO:Initializing create_model()
2025-05-09 17:55:34,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33893c810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:55:34,679:INFO:Checking exceptions
2025-05-09 17:55:34,679:INFO:Importing libraries
2025-05-09 17:55:34,679:INFO:Copying training dataset
2025-05-09 17:55:34,688:INFO:Defining folds
2025-05-09 17:55:34,688:INFO:Declaring metric variables
2025-05-09 17:55:34,689:INFO:Importing untrained model
2025-05-09 17:55:34,691:INFO:Dummy Classifier Imported successfully
2025-05-09 17:55:34,694:INFO:Starting cross validation
2025-05-09 17:55:34,695:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:55:35,821:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:55:35,838:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:55:35,843:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:55:35,857:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:55:35,871:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:55:35,887:INFO:Calculating mean and std
2025-05-09 17:55:35,887:INFO:Creating metrics dataframe
2025-05-09 17:55:35,888:INFO:Uploading results into container
2025-05-09 17:55:35,888:INFO:Uploading model into container now
2025-05-09 17:55:35,888:INFO:_master_model_container: 14
2025-05-09 17:55:35,889:INFO:_display_container: 2
2025-05-09 17:55:35,889:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-09 17:55:35,889:INFO:create_model() successfully completed......................................
2025-05-09 17:55:35,947:INFO:SubProcess create_model() end ==================================
2025-05-09 17:55:35,947:INFO:Creating metrics dataframe
2025-05-09 17:55:35,951:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-09 17:55:35,954:INFO:Initializing create_model()
2025-05-09 17:55:35,954:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:55:35,954:INFO:Checking exceptions
2025-05-09 17:55:35,955:INFO:Importing libraries
2025-05-09 17:55:35,955:INFO:Copying training dataset
2025-05-09 17:55:35,964:INFO:Defining folds
2025-05-09 17:55:35,964:INFO:Declaring metric variables
2025-05-09 17:55:35,964:INFO:Importing untrained model
2025-05-09 17:55:35,964:INFO:Declaring custom model
2025-05-09 17:55:35,964:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:55:35,965:INFO:Cross validation set to False
2025-05-09 17:55:35,965:INFO:Fitting Model
2025-05-09 17:55:37,299:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-09 17:55:37,308:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004396 seconds.
2025-05-09 17:55:37,309:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-09 17:55:37,309:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-09 17:55:37,309:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-09 17:55:37,309:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-09 17:55:37,309:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-09 17:55:38,084:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:55:38,084:INFO:create_model() successfully completed......................................
2025-05-09 17:55:38,152:INFO:Initializing create_model()
2025-05-09 17:55:38,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:55:38,153:INFO:Checking exceptions
2025-05-09 17:55:38,153:INFO:Importing libraries
2025-05-09 17:55:38,154:INFO:Copying training dataset
2025-05-09 17:55:38,163:INFO:Defining folds
2025-05-09 17:55:38,163:INFO:Declaring metric variables
2025-05-09 17:55:38,163:INFO:Importing untrained model
2025-05-09 17:55:38,163:INFO:Declaring custom model
2025-05-09 17:55:38,163:INFO:Gradient Boosting Classifier Imported successfully
2025-05-09 17:55:38,164:INFO:Cross validation set to False
2025-05-09 17:55:38,164:INFO:Fitting Model
2025-05-09 17:55:54,215:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-09 17:55:54,216:INFO:create_model() successfully completed......................................
2025-05-09 17:55:54,282:INFO:Initializing create_model()
2025-05-09 17:55:54,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:55:54,282:INFO:Checking exceptions
2025-05-09 17:55:54,282:INFO:Importing libraries
2025-05-09 17:55:54,282:INFO:Copying training dataset
2025-05-09 17:55:54,291:INFO:Defining folds
2025-05-09 17:55:54,291:INFO:Declaring metric variables
2025-05-09 17:55:54,292:INFO:Importing untrained model
2025-05-09 17:55:54,292:INFO:Declaring custom model
2025-05-09 17:55:54,292:INFO:Random Forest Classifier Imported successfully
2025-05-09 17:55:54,292:INFO:Cross validation set to False
2025-05-09 17:55:54,292:INFO:Fitting Model
2025-05-09 17:55:56,468:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-09 17:55:56,468:INFO:create_model() successfully completed......................................
2025-05-09 17:55:56,532:INFO:_master_model_container: 14
2025-05-09 17:55:56,532:INFO:_display_container: 2
2025-05-09 17:55:56,532:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-09 17:55:56,532:INFO:compare_models() successfully completed......................................
2025-05-09 17:55:56,540:INFO:Initializing evaluate_model()
2025-05-09 17:55:56,540:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-09 17:55:56,547:INFO:Initializing plot_model()
2025-05-09 17:55:56,547:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-09 17:55:56,547:INFO:Checking exceptions
2025-05-09 17:55:56,551:INFO:Preloading libraries
2025-05-09 17:55:56,552:INFO:Copying training dataset
2025-05-09 17:55:56,552:INFO:Plot type: pipeline
2025-05-09 17:55:56,612:INFO:Visual Rendered Successfully
2025-05-09 17:55:56,669:INFO:plot_model() successfully completed......................................
2025-05-09 17:55:56,671:INFO:Initializing tune_model()
2025-05-09 17:55:56,671:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-09 17:55:56,671:INFO:Checking exceptions
2025-05-09 17:55:56,680:INFO:Copying training dataset
2025-05-09 17:55:56,687:INFO:Checking base model
2025-05-09 17:55:56,687:INFO:Base model : Light Gradient Boosting Machine
2025-05-09 17:55:56,688:INFO:Declaring metric variables
2025-05-09 17:55:56,689:INFO:Defining Hyperparameters
2025-05-09 17:55:56,759:INFO:Tuning with n_jobs=-1
2025-05-09 17:55:56,759:INFO:Initializing RandomizedSearchCV
2025-05-09 17:56:33,019:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-09 17:56:33,023:INFO:Hyperparameter search completed
2025-05-09 17:56:33,023:INFO:SubProcess create_model() called ==================================
2025-05-09 17:56:33,024:INFO:Initializing create_model()
2025-05-09 17:56:33,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e4ce50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-09 17:56:33,025:INFO:Checking exceptions
2025-05-09 17:56:33,025:INFO:Importing libraries
2025-05-09 17:56:33,025:INFO:Copying training dataset
2025-05-09 17:56:33,043:INFO:Defining folds
2025-05-09 17:56:33,043:INFO:Declaring metric variables
2025-05-09 17:56:33,052:INFO:Importing untrained model
2025-05-09 17:56:33,052:INFO:Declaring custom model
2025-05-09 17:56:33,057:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:56:33,060:INFO:Starting cross validation
2025-05-09 17:56:33,062:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:56:39,445:INFO:Calculating mean and std
2025-05-09 17:56:39,446:INFO:Creating metrics dataframe
2025-05-09 17:56:39,448:INFO:Finalizing model
2025-05-09 17:56:40,444:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-09 17:56:40,445:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-09 17:56:40,445:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-09 17:56:40,475:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-09 17:56:40,475:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-09 17:56:40,476:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-09 17:56:40,476:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-09 17:56:40,491:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010427 seconds.
2025-05-09 17:56:40,491:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-09 17:56:40,491:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-09 17:56:40,491:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-09 17:56:40,491:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-09 17:56:40,492:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-09 17:56:41,930:INFO:Uploading results into container
2025-05-09 17:56:41,931:INFO:Uploading model into container now
2025-05-09 17:56:41,931:INFO:_master_model_container: 15
2025-05-09 17:56:41,931:INFO:_display_container: 3
2025-05-09 17:56:41,932:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:56:41,932:INFO:create_model() successfully completed......................................
2025-05-09 17:56:42,035:INFO:SubProcess create_model() end ==================================
2025-05-09 17:56:42,035:INFO:choose_better activated
2025-05-09 17:56:42,036:INFO:SubProcess create_model() called ==================================
2025-05-09 17:56:42,037:INFO:Initializing create_model()
2025-05-09 17:56:42,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:56:42,037:INFO:Checking exceptions
2025-05-09 17:56:42,038:INFO:Importing libraries
2025-05-09 17:56:42,038:INFO:Copying training dataset
2025-05-09 17:56:42,048:INFO:Defining folds
2025-05-09 17:56:42,048:INFO:Declaring metric variables
2025-05-09 17:56:42,048:INFO:Importing untrained model
2025-05-09 17:56:42,048:INFO:Declaring custom model
2025-05-09 17:56:42,048:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:56:42,048:INFO:Starting cross validation
2025-05-09 17:56:42,049:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:56:46,058:INFO:Calculating mean and std
2025-05-09 17:56:46,059:INFO:Creating metrics dataframe
2025-05-09 17:56:46,060:INFO:Finalizing model
2025-05-09 17:56:47,064:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-09 17:56:47,074:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004827 seconds.
2025-05-09 17:56:47,074:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-09 17:56:47,074:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-09 17:56:47,074:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-09 17:56:47,074:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-09 17:56:47,074:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-09 17:56:47,837:INFO:Uploading results into container
2025-05-09 17:56:47,837:INFO:Uploading model into container now
2025-05-09 17:56:47,838:INFO:_master_model_container: 16
2025-05-09 17:56:47,838:INFO:_display_container: 4
2025-05-09 17:56:47,838:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:56:47,838:INFO:create_model() successfully completed......................................
2025-05-09 17:56:47,895:INFO:SubProcess create_model() end ==================================
2025-05-09 17:56:47,895:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-09 17:56:47,895:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-09 17:56:47,896:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-09 17:56:47,896:INFO:choose_better completed
2025-05-09 17:56:47,899:INFO:_master_model_container: 16
2025-05-09 17:56:47,899:INFO:_display_container: 3
2025-05-09 17:56:47,900:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:56:47,900:INFO:tune_model() successfully completed......................................
2025-05-09 17:56:47,965:INFO:Initializing evaluate_model()
2025-05-09 17:56:47,965:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-09 17:56:47,972:INFO:Initializing plot_model()
2025-05-09 17:56:47,973:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-09 17:56:47,973:INFO:Checking exceptions
2025-05-09 17:56:47,977:INFO:Preloading libraries
2025-05-09 17:56:47,980:INFO:Copying training dataset
2025-05-09 17:56:47,980:INFO:Plot type: pipeline
2025-05-09 17:56:48,039:INFO:Visual Rendered Successfully
2025-05-09 17:56:48,100:INFO:plot_model() successfully completed......................................
2025-05-09 17:56:48,101:INFO:Initializing interpret_model()
2025-05-09 17:56:48,102:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x338948fd0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-09 17:56:48,102:INFO:Checking exceptions
2025-05-09 17:56:48,102:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-09 17:57:37,919:INFO:PyCaret ClassificationExperiment
2025-05-09 17:57:37,919:INFO:Logging name: clf-default-name
2025-05-09 17:57:37,919:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-09 17:57:37,920:INFO:version 3.3.2
2025-05-09 17:57:37,920:INFO:Initializing setup()
2025-05-09 17:57:37,920:INFO:self.USI: d535
2025-05-09 17:57:37,920:INFO:self._variable_keys: {'USI', 'html_param', 'exp_name_log', 'seed', 'logging_param', 'X', 'fix_imbalance', 'gpu_n_jobs_param', '_available_plots', 'exp_id', 'is_multiclass', 'X_test', 'y_test', 'memory', 'fold_shuffle_param', 'log_plots_param', 'n_jobs_param', 'target_param', 'fold_groups_param', '_ml_usecase', 'pipeline', 'data', 'gpu_param', 'y', 'idx', 'X_train', 'fold_generator', 'y_train'}
2025-05-09 17:57:37,920:INFO:Checking environment
2025-05-09 17:57:37,920:INFO:python_version: 3.11.0
2025-05-09 17:57:37,920:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-09 17:57:37,920:INFO:machine: arm64
2025-05-09 17:57:37,920:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-09 17:57:37,920:INFO:Memory: svmem(total=17179869184, available=3643260928, percent=78.8, used=6095355904, free=63242240, active=3597697024, inactive=3547168768, wired=2497658880)
2025-05-09 17:57:37,920:INFO:Physical Core: 12
2025-05-09 17:57:37,920:INFO:Logical Core: 12
2025-05-09 17:57:37,920:INFO:Checking libraries
2025-05-09 17:57:37,920:INFO:System:
2025-05-09 17:57:37,920:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-09 17:57:37,920:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-09 17:57:37,920:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-09 17:57:37,920:INFO:PyCaret required dependencies:
2025-05-09 17:57:37,920:INFO:                 pip: 22.3
2025-05-09 17:57:37,920:INFO:          setuptools: 65.5.0
2025-05-09 17:57:37,920:INFO:             pycaret: 3.3.2
2025-05-09 17:57:37,920:INFO:             IPython: 9.2.0
2025-05-09 17:57:37,920:INFO:          ipywidgets: 8.1.7
2025-05-09 17:57:37,920:INFO:                tqdm: 4.67.1
2025-05-09 17:57:37,920:INFO:               numpy: 1.26.4
2025-05-09 17:57:37,920:INFO:              pandas: 2.1.4
2025-05-09 17:57:37,920:INFO:              jinja2: 3.1.6
2025-05-09 17:57:37,920:INFO:               scipy: 1.11.4
2025-05-09 17:57:37,920:INFO:              joblib: 1.3.2
2025-05-09 17:57:37,920:INFO:             sklearn: 1.4.2
2025-05-09 17:57:37,920:INFO:                pyod: 2.0.5
2025-05-09 17:57:37,920:INFO:            imblearn: 0.13.0
2025-05-09 17:57:37,920:INFO:   category_encoders: 2.7.0
2025-05-09 17:57:37,920:INFO:            lightgbm: 4.6.0
2025-05-09 17:57:37,920:INFO:               numba: 0.61.2
2025-05-09 17:57:37,920:INFO:            requests: 2.32.3
2025-05-09 17:57:37,920:INFO:          matplotlib: 3.7.5
2025-05-09 17:57:37,920:INFO:          scikitplot: 0.3.7
2025-05-09 17:57:37,920:INFO:         yellowbrick: 1.5
2025-05-09 17:57:37,920:INFO:              plotly: 5.24.1
2025-05-09 17:57:37,920:INFO:    plotly-resampler: Not installed
2025-05-09 17:57:37,920:INFO:             kaleido: 0.2.1
2025-05-09 17:57:37,920:INFO:           schemdraw: 0.15
2025-05-09 17:57:37,920:INFO:         statsmodels: 0.14.4
2025-05-09 17:57:37,920:INFO:              sktime: 0.26.0
2025-05-09 17:57:37,920:INFO:               tbats: 1.1.3
2025-05-09 17:57:37,920:INFO:            pmdarima: 2.0.4
2025-05-09 17:57:37,920:INFO:              psutil: 7.0.0
2025-05-09 17:57:37,920:INFO:          markupsafe: 3.0.2
2025-05-09 17:57:37,920:INFO:             pickle5: Not installed
2025-05-09 17:57:37,920:INFO:         cloudpickle: 3.1.1
2025-05-09 17:57:37,920:INFO:         deprecation: 2.1.0
2025-05-09 17:57:37,920:INFO:              xxhash: 3.5.0
2025-05-09 17:57:37,920:INFO:           wurlitzer: 3.1.1
2025-05-09 17:57:37,920:INFO:PyCaret optional dependencies:
2025-05-09 17:57:37,920:INFO:                shap: Not installed
2025-05-09 17:57:37,920:INFO:           interpret: Not installed
2025-05-09 17:57:37,920:INFO:                umap: Not installed
2025-05-09 17:57:37,920:INFO:     ydata_profiling: Not installed
2025-05-09 17:57:37,920:INFO:  explainerdashboard: Not installed
2025-05-09 17:57:37,920:INFO:             autoviz: Not installed
2025-05-09 17:57:37,920:INFO:           fairlearn: Not installed
2025-05-09 17:57:37,920:INFO:          deepchecks: Not installed
2025-05-09 17:57:37,920:INFO:             xgboost: Not installed
2025-05-09 17:57:37,920:INFO:            catboost: Not installed
2025-05-09 17:57:37,920:INFO:              kmodes: Not installed
2025-05-09 17:57:37,920:INFO:             mlxtend: Not installed
2025-05-09 17:57:37,920:INFO:       statsforecast: Not installed
2025-05-09 17:57:37,920:INFO:        tune_sklearn: Not installed
2025-05-09 17:57:37,920:INFO:                 ray: Not installed
2025-05-09 17:57:37,920:INFO:            hyperopt: Not installed
2025-05-09 17:57:37,920:INFO:              optuna: Not installed
2025-05-09 17:57:37,920:INFO:               skopt: Not installed
2025-05-09 17:57:37,921:INFO:              mlflow: Not installed
2025-05-09 17:57:37,921:INFO:              gradio: Not installed
2025-05-09 17:57:37,921:INFO:             fastapi: Not installed
2025-05-09 17:57:37,921:INFO:             uvicorn: Not installed
2025-05-09 17:57:37,921:INFO:              m2cgen: Not installed
2025-05-09 17:57:37,921:INFO:           evidently: Not installed
2025-05-09 17:57:37,921:INFO:               fugue: Not installed
2025-05-09 17:57:37,921:INFO:           streamlit: Not installed
2025-05-09 17:57:37,921:INFO:             prophet: Not installed
2025-05-09 17:57:37,921:INFO:None
2025-05-09 17:57:37,921:INFO:Set up data.
2025-05-09 17:57:37,956:INFO:Set up folding strategy.
2025-05-09 17:57:37,956:INFO:Set up train/test split.
2025-05-09 17:57:37,971:INFO:Set up index.
2025-05-09 17:57:37,971:INFO:Assigning column types.
2025-05-09 17:57:37,975:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-09 17:57:37,994:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 17:57:37,994:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:57:38,006:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,025:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 17:57:38,025:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:57:38,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,037:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-09 17:57:38,055:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:57:38,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,086:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-09 17:57:38,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,097:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,097:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-09 17:57:38,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,160:INFO:Preparing preprocessing pipeline...
2025-05-09 17:57:38,161:INFO:Set up simple imputation.
2025-05-09 17:57:38,167:INFO:Set up encoding of ordinal features.
2025-05-09 17:57:38,179:INFO:Set up encoding of categorical features.
2025-05-09 17:57:38,179:INFO:Set up imbalanced handling.
2025-05-09 17:57:38,179:INFO:Set up column transformation.
2025-05-09 17:57:38,470:INFO:Finished creating preprocessing pipeline.
2025-05-09 17:57:38,492:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-09 17:57:38,492:INFO:Creating final display dataframe.
2025-05-09 17:57:38,718:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              d535
2025-05-09 17:57:38,753:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,785:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 17:57:38,787:INFO:setup() successfully completed in 0.87s...............
2025-05-09 17:57:38,787:INFO:Initializing compare_models()
2025-05-09 17:57:38,787:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-09 17:57:38,788:INFO:Checking exceptions
2025-05-09 17:57:38,792:INFO:Preparing display monitor
2025-05-09 17:57:38,801:INFO:Initializing Logistic Regression
2025-05-09 17:57:38,801:INFO:Total runtime is 1.4543533325195312e-06 minutes
2025-05-09 17:57:38,802:INFO:SubProcess create_model() called ==================================
2025-05-09 17:57:38,802:INFO:Initializing create_model()
2025-05-09 17:57:38,803:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36413b2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:57:38,803:INFO:Checking exceptions
2025-05-09 17:57:38,803:INFO:Importing libraries
2025-05-09 17:57:38,803:INFO:Copying training dataset
2025-05-09 17:57:38,814:INFO:Defining folds
2025-05-09 17:57:38,814:INFO:Declaring metric variables
2025-05-09 17:57:38,815:INFO:Importing untrained model
2025-05-09 17:57:38,817:INFO:Logistic Regression Imported successfully
2025-05-09 17:57:38,819:INFO:Starting cross validation
2025-05-09 17:57:38,820:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:57:42,884:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:57:42,903:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:57:42,912:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:57:42,917:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:57:42,919:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-09 17:57:42,978:INFO:Calculating mean and std
2025-05-09 17:57:42,979:INFO:Creating metrics dataframe
2025-05-09 17:57:42,980:INFO:Uploading results into container
2025-05-09 17:57:42,980:INFO:Uploading model into container now
2025-05-09 17:57:42,980:INFO:_master_model_container: 1
2025-05-09 17:57:42,980:INFO:_display_container: 2
2025-05-09 17:57:42,981:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-09 17:57:42,981:INFO:create_model() successfully completed......................................
2025-05-09 17:57:43,084:INFO:SubProcess create_model() end ==================================
2025-05-09 17:57:43,084:INFO:Creating metrics dataframe
2025-05-09 17:57:43,086:INFO:Initializing K Neighbors Classifier
2025-05-09 17:57:43,087:INFO:Total runtime is 0.07143051624298095 minutes
2025-05-09 17:57:43,088:INFO:SubProcess create_model() called ==================================
2025-05-09 17:57:43,088:INFO:Initializing create_model()
2025-05-09 17:57:43,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36413b2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:57:43,088:INFO:Checking exceptions
2025-05-09 17:57:43,088:INFO:Importing libraries
2025-05-09 17:57:43,088:INFO:Copying training dataset
2025-05-09 17:57:43,098:INFO:Defining folds
2025-05-09 17:57:43,098:INFO:Declaring metric variables
2025-05-09 17:57:43,100:INFO:Importing untrained model
2025-05-09 17:57:43,101:INFO:K Neighbors Classifier Imported successfully
2025-05-09 17:57:43,103:INFO:Starting cross validation
2025-05-09 17:57:43,104:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:57:47,891:INFO:Calculating mean and std
2025-05-09 17:57:47,891:INFO:Creating metrics dataframe
2025-05-09 17:57:47,892:INFO:Uploading results into container
2025-05-09 17:57:47,892:INFO:Uploading model into container now
2025-05-09 17:57:47,893:INFO:_master_model_container: 2
2025-05-09 17:57:47,893:INFO:_display_container: 2
2025-05-09 17:57:47,893:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-09 17:57:47,893:INFO:create_model() successfully completed......................................
2025-05-09 17:57:47,951:INFO:SubProcess create_model() end ==================================
2025-05-09 17:57:47,951:INFO:Creating metrics dataframe
2025-05-09 17:57:47,954:INFO:Initializing Naive Bayes
2025-05-09 17:57:47,954:INFO:Total runtime is 0.15255478223164876 minutes
2025-05-09 17:57:47,955:INFO:SubProcess create_model() called ==================================
2025-05-09 17:57:47,955:INFO:Initializing create_model()
2025-05-09 17:57:47,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36413b2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:57:47,956:INFO:Checking exceptions
2025-05-09 17:57:47,956:INFO:Importing libraries
2025-05-09 17:57:47,956:INFO:Copying training dataset
2025-05-09 17:57:47,964:INFO:Defining folds
2025-05-09 17:57:47,965:INFO:Declaring metric variables
2025-05-09 17:57:47,966:INFO:Importing untrained model
2025-05-09 17:57:47,967:INFO:Naive Bayes Imported successfully
2025-05-09 17:57:47,969:INFO:Starting cross validation
2025-05-09 17:57:47,970:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:57:49,142:INFO:Calculating mean and std
2025-05-09 17:57:49,143:INFO:Creating metrics dataframe
2025-05-09 17:57:49,144:INFO:Uploading results into container
2025-05-09 17:57:49,144:INFO:Uploading model into container now
2025-05-09 17:57:49,144:INFO:_master_model_container: 3
2025-05-09 17:57:49,144:INFO:_display_container: 2
2025-05-09 17:57:49,144:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-09 17:57:49,145:INFO:create_model() successfully completed......................................
2025-05-09 17:57:49,202:INFO:SubProcess create_model() end ==================================
2025-05-09 17:57:49,202:INFO:Creating metrics dataframe
2025-05-09 17:57:49,205:INFO:Initializing Decision Tree Classifier
2025-05-09 17:57:49,205:INFO:Total runtime is 0.17341158390045164 minutes
2025-05-09 17:57:49,207:INFO:SubProcess create_model() called ==================================
2025-05-09 17:57:49,207:INFO:Initializing create_model()
2025-05-09 17:57:49,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36413b2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:57:49,207:INFO:Checking exceptions
2025-05-09 17:57:49,207:INFO:Importing libraries
2025-05-09 17:57:49,207:INFO:Copying training dataset
2025-05-09 17:57:49,216:INFO:Defining folds
2025-05-09 17:57:49,216:INFO:Declaring metric variables
2025-05-09 17:57:49,217:INFO:Importing untrained model
2025-05-09 17:57:49,219:INFO:Decision Tree Classifier Imported successfully
2025-05-09 17:57:49,221:INFO:Starting cross validation
2025-05-09 17:57:49,222:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:57:50,912:INFO:Calculating mean and std
2025-05-09 17:57:50,913:INFO:Creating metrics dataframe
2025-05-09 17:57:50,914:INFO:Uploading results into container
2025-05-09 17:57:50,914:INFO:Uploading model into container now
2025-05-09 17:57:50,915:INFO:_master_model_container: 4
2025-05-09 17:57:50,915:INFO:_display_container: 2
2025-05-09 17:57:50,915:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-09 17:57:50,915:INFO:create_model() successfully completed......................................
2025-05-09 17:57:50,974:INFO:SubProcess create_model() end ==================================
2025-05-09 17:57:50,974:INFO:Creating metrics dataframe
2025-05-09 17:57:50,977:INFO:Initializing SVM - Linear Kernel
2025-05-09 17:57:50,977:INFO:Total runtime is 0.2029438535372416 minutes
2025-05-09 17:57:50,979:INFO:SubProcess create_model() called ==================================
2025-05-09 17:57:50,979:INFO:Initializing create_model()
2025-05-09 17:57:50,979:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36413b2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:57:50,979:INFO:Checking exceptions
2025-05-09 17:57:50,979:INFO:Importing libraries
2025-05-09 17:57:50,979:INFO:Copying training dataset
2025-05-09 17:57:50,988:INFO:Defining folds
2025-05-09 17:57:50,989:INFO:Declaring metric variables
2025-05-09 17:57:50,990:INFO:Importing untrained model
2025-05-09 17:57:50,991:INFO:SVM - Linear Kernel Imported successfully
2025-05-09 17:57:50,993:INFO:Starting cross validation
2025-05-09 17:57:50,995:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:57:54,409:INFO:Calculating mean and std
2025-05-09 17:57:54,411:INFO:Creating metrics dataframe
2025-05-09 17:57:54,412:INFO:Uploading results into container
2025-05-09 17:57:54,413:INFO:Uploading model into container now
2025-05-09 17:57:54,413:INFO:_master_model_container: 5
2025-05-09 17:57:54,413:INFO:_display_container: 2
2025-05-09 17:57:54,414:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-09 17:57:54,414:INFO:create_model() successfully completed......................................
2025-05-09 17:57:54,491:INFO:SubProcess create_model() end ==================================
2025-05-09 17:57:54,491:INFO:Creating metrics dataframe
2025-05-09 17:57:54,494:INFO:Initializing Ridge Classifier
2025-05-09 17:57:54,495:INFO:Total runtime is 0.2615630706151326 minutes
2025-05-09 17:57:54,496:INFO:SubProcess create_model() called ==================================
2025-05-09 17:57:54,496:INFO:Initializing create_model()
2025-05-09 17:57:54,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36413b2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:57:54,496:INFO:Checking exceptions
2025-05-09 17:57:54,496:INFO:Importing libraries
2025-05-09 17:57:54,496:INFO:Copying training dataset
2025-05-09 17:57:54,506:INFO:Defining folds
2025-05-09 17:57:54,506:INFO:Declaring metric variables
2025-05-09 17:57:54,508:INFO:Importing untrained model
2025-05-09 17:57:54,509:INFO:Ridge Classifier Imported successfully
2025-05-09 17:57:54,511:INFO:Starting cross validation
2025-05-09 17:57:54,512:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:57:55,905:INFO:Calculating mean and std
2025-05-09 17:57:55,906:INFO:Creating metrics dataframe
2025-05-09 17:57:55,907:INFO:Uploading results into container
2025-05-09 17:57:55,908:INFO:Uploading model into container now
2025-05-09 17:57:55,908:INFO:_master_model_container: 6
2025-05-09 17:57:55,908:INFO:_display_container: 2
2025-05-09 17:57:55,908:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-09 17:57:55,908:INFO:create_model() successfully completed......................................
2025-05-09 17:57:55,987:INFO:SubProcess create_model() end ==================================
2025-05-09 17:57:55,987:INFO:Creating metrics dataframe
2025-05-09 17:57:55,990:INFO:Initializing Random Forest Classifier
2025-05-09 17:57:55,990:INFO:Total runtime is 0.2864935199419657 minutes
2025-05-09 17:57:55,992:INFO:SubProcess create_model() called ==================================
2025-05-09 17:57:55,992:INFO:Initializing create_model()
2025-05-09 17:57:55,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36413b2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:57:55,992:INFO:Checking exceptions
2025-05-09 17:57:55,992:INFO:Importing libraries
2025-05-09 17:57:55,992:INFO:Copying training dataset
2025-05-09 17:57:56,002:INFO:Defining folds
2025-05-09 17:57:56,002:INFO:Declaring metric variables
2025-05-09 17:57:56,003:INFO:Importing untrained model
2025-05-09 17:57:56,004:INFO:Random Forest Classifier Imported successfully
2025-05-09 17:57:56,007:INFO:Starting cross validation
2025-05-09 17:57:56,008:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:58:02,223:INFO:Calculating mean and std
2025-05-09 17:58:02,224:INFO:Creating metrics dataframe
2025-05-09 17:58:02,225:INFO:Uploading results into container
2025-05-09 17:58:02,225:INFO:Uploading model into container now
2025-05-09 17:58:02,226:INFO:_master_model_container: 7
2025-05-09 17:58:02,226:INFO:_display_container: 2
2025-05-09 17:58:02,226:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-09 17:58:02,226:INFO:create_model() successfully completed......................................
2025-05-09 17:58:02,298:INFO:SubProcess create_model() end ==================================
2025-05-09 17:58:02,298:INFO:Creating metrics dataframe
2025-05-09 17:58:02,302:INFO:Initializing Quadratic Discriminant Analysis
2025-05-09 17:58:02,302:INFO:Total runtime is 0.39168598254521686 minutes
2025-05-09 17:58:02,303:INFO:SubProcess create_model() called ==================================
2025-05-09 17:58:02,303:INFO:Initializing create_model()
2025-05-09 17:58:02,303:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36413b2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:58:02,303:INFO:Checking exceptions
2025-05-09 17:58:02,304:INFO:Importing libraries
2025-05-09 17:58:02,304:INFO:Copying training dataset
2025-05-09 17:58:02,314:INFO:Defining folds
2025-05-09 17:58:02,314:INFO:Declaring metric variables
2025-05-09 17:58:02,316:INFO:Importing untrained model
2025-05-09 17:58:02,317:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-09 17:58:02,319:INFO:Starting cross validation
2025-05-09 17:58:02,320:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:58:03,373:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:58:03,409:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:58:03,430:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:58:03,467:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:58:03,468:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-09 17:58:03,471:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:58:03,489:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:58:03,506:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:58:03,537:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:58:03,540:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:58:03,548:INFO:Calculating mean and std
2025-05-09 17:58:03,551:INFO:Creating metrics dataframe
2025-05-09 17:58:03,553:INFO:Uploading results into container
2025-05-09 17:58:03,554:INFO:Uploading model into container now
2025-05-09 17:58:03,554:INFO:_master_model_container: 8
2025-05-09 17:58:03,554:INFO:_display_container: 2
2025-05-09 17:58:03,555:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-09 17:58:03,555:INFO:create_model() successfully completed......................................
2025-05-09 17:58:03,623:INFO:SubProcess create_model() end ==================================
2025-05-09 17:58:03,623:INFO:Creating metrics dataframe
2025-05-09 17:58:03,627:INFO:Initializing Ada Boost Classifier
2025-05-09 17:58:03,627:INFO:Total runtime is 0.4137760202089945 minutes
2025-05-09 17:58:03,628:INFO:SubProcess create_model() called ==================================
2025-05-09 17:58:03,629:INFO:Initializing create_model()
2025-05-09 17:58:03,629:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36413b2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:58:03,629:INFO:Checking exceptions
2025-05-09 17:58:03,629:INFO:Importing libraries
2025-05-09 17:58:03,629:INFO:Copying training dataset
2025-05-09 17:58:03,639:INFO:Defining folds
2025-05-09 17:58:03,639:INFO:Declaring metric variables
2025-05-09 17:58:03,641:INFO:Importing untrained model
2025-05-09 17:58:03,642:INFO:Ada Boost Classifier Imported successfully
2025-05-09 17:58:03,644:INFO:Starting cross validation
2025-05-09 17:58:03,645:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:58:04,671:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:58:04,696:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:58:04,701:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:58:04,710:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:58:04,788:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-09 17:58:07,441:INFO:Calculating mean and std
2025-05-09 17:58:07,441:INFO:Creating metrics dataframe
2025-05-09 17:58:07,442:INFO:Uploading results into container
2025-05-09 17:58:07,442:INFO:Uploading model into container now
2025-05-09 17:58:07,443:INFO:_master_model_container: 9
2025-05-09 17:58:07,443:INFO:_display_container: 2
2025-05-09 17:58:07,443:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-09 17:58:07,443:INFO:create_model() successfully completed......................................
2025-05-09 17:58:07,510:INFO:SubProcess create_model() end ==================================
2025-05-09 17:58:07,510:INFO:Creating metrics dataframe
2025-05-09 17:58:07,514:INFO:Initializing Gradient Boosting Classifier
2025-05-09 17:58:07,514:INFO:Total runtime is 0.4785478830337524 minutes
2025-05-09 17:58:07,515:INFO:SubProcess create_model() called ==================================
2025-05-09 17:58:07,515:INFO:Initializing create_model()
2025-05-09 17:58:07,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36413b2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:58:07,515:INFO:Checking exceptions
2025-05-09 17:58:07,515:INFO:Importing libraries
2025-05-09 17:58:07,515:INFO:Copying training dataset
2025-05-09 17:58:07,525:INFO:Defining folds
2025-05-09 17:58:07,525:INFO:Declaring metric variables
2025-05-09 17:58:07,526:INFO:Importing untrained model
2025-05-09 17:58:07,527:INFO:Gradient Boosting Classifier Imported successfully
2025-05-09 17:58:07,530:INFO:Starting cross validation
2025-05-09 17:58:07,531:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:58:21,230:INFO:Calculating mean and std
2025-05-09 17:58:21,231:INFO:Creating metrics dataframe
2025-05-09 17:58:21,232:INFO:Uploading results into container
2025-05-09 17:58:21,233:INFO:Uploading model into container now
2025-05-09 17:58:21,233:INFO:_master_model_container: 10
2025-05-09 17:58:21,233:INFO:_display_container: 2
2025-05-09 17:58:21,234:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-09 17:58:21,234:INFO:create_model() successfully completed......................................
2025-05-09 17:58:21,351:INFO:SubProcess create_model() end ==================================
2025-05-09 17:58:21,351:INFO:Creating metrics dataframe
2025-05-09 17:58:21,355:INFO:Initializing Linear Discriminant Analysis
2025-05-09 17:58:21,355:INFO:Total runtime is 0.7092429320017496 minutes
2025-05-09 17:58:21,357:INFO:SubProcess create_model() called ==================================
2025-05-09 17:58:21,357:INFO:Initializing create_model()
2025-05-09 17:58:21,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36413b2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:58:21,357:INFO:Checking exceptions
2025-05-09 17:58:21,357:INFO:Importing libraries
2025-05-09 17:58:21,357:INFO:Copying training dataset
2025-05-09 17:58:21,368:INFO:Defining folds
2025-05-09 17:58:21,368:INFO:Declaring metric variables
2025-05-09 17:58:21,370:INFO:Importing untrained model
2025-05-09 17:58:21,371:INFO:Linear Discriminant Analysis Imported successfully
2025-05-09 17:58:21,374:INFO:Starting cross validation
2025-05-09 17:58:21,375:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:58:22,684:INFO:Calculating mean and std
2025-05-09 17:58:22,685:INFO:Creating metrics dataframe
2025-05-09 17:58:22,689:INFO:Uploading results into container
2025-05-09 17:58:22,690:INFO:Uploading model into container now
2025-05-09 17:58:22,691:INFO:_master_model_container: 11
2025-05-09 17:58:22,691:INFO:_display_container: 2
2025-05-09 17:58:22,691:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-09 17:58:22,691:INFO:create_model() successfully completed......................................
2025-05-09 17:58:22,768:INFO:SubProcess create_model() end ==================================
2025-05-09 17:58:22,768:INFO:Creating metrics dataframe
2025-05-09 17:58:22,773:INFO:Initializing Extra Trees Classifier
2025-05-09 17:58:22,773:INFO:Total runtime is 0.7328689177831014 minutes
2025-05-09 17:58:22,775:INFO:SubProcess create_model() called ==================================
2025-05-09 17:58:22,775:INFO:Initializing create_model()
2025-05-09 17:58:22,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36413b2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:58:22,775:INFO:Checking exceptions
2025-05-09 17:58:22,775:INFO:Importing libraries
2025-05-09 17:58:22,775:INFO:Copying training dataset
2025-05-09 17:58:22,786:INFO:Defining folds
2025-05-09 17:58:22,787:INFO:Declaring metric variables
2025-05-09 17:58:22,788:INFO:Importing untrained model
2025-05-09 17:58:22,790:INFO:Extra Trees Classifier Imported successfully
2025-05-09 17:58:22,792:INFO:Starting cross validation
2025-05-09 17:58:22,793:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:58:27,753:INFO:Calculating mean and std
2025-05-09 17:58:27,756:INFO:Creating metrics dataframe
2025-05-09 17:58:27,761:INFO:Uploading results into container
2025-05-09 17:58:27,761:INFO:Uploading model into container now
2025-05-09 17:58:27,762:INFO:_master_model_container: 12
2025-05-09 17:58:27,762:INFO:_display_container: 2
2025-05-09 17:58:27,763:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-09 17:58:27,763:INFO:create_model() successfully completed......................................
2025-05-09 17:58:27,894:INFO:SubProcess create_model() end ==================================
2025-05-09 17:58:27,894:INFO:Creating metrics dataframe
2025-05-09 17:58:27,898:INFO:Initializing Light Gradient Boosting Machine
2025-05-09 17:58:27,899:INFO:Total runtime is 0.8182962695757547 minutes
2025-05-09 17:58:27,900:INFO:SubProcess create_model() called ==================================
2025-05-09 17:58:27,900:INFO:Initializing create_model()
2025-05-09 17:58:27,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36413b2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:58:27,900:INFO:Checking exceptions
2025-05-09 17:58:27,900:INFO:Importing libraries
2025-05-09 17:58:27,900:INFO:Copying training dataset
2025-05-09 17:58:27,916:INFO:Defining folds
2025-05-09 17:58:27,916:INFO:Declaring metric variables
2025-05-09 17:58:27,918:INFO:Importing untrained model
2025-05-09 17:58:27,919:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:58:27,922:INFO:Starting cross validation
2025-05-09 17:58:27,923:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:58:32,354:INFO:Calculating mean and std
2025-05-09 17:58:32,355:INFO:Creating metrics dataframe
2025-05-09 17:58:32,356:INFO:Uploading results into container
2025-05-09 17:58:32,356:INFO:Uploading model into container now
2025-05-09 17:58:32,356:INFO:_master_model_container: 13
2025-05-09 17:58:32,356:INFO:_display_container: 2
2025-05-09 17:58:32,357:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:58:32,357:INFO:create_model() successfully completed......................................
2025-05-09 17:58:32,417:INFO:SubProcess create_model() end ==================================
2025-05-09 17:58:32,417:INFO:Creating metrics dataframe
2025-05-09 17:58:32,421:INFO:Initializing Dummy Classifier
2025-05-09 17:58:32,422:INFO:Total runtime is 0.8936796704928079 minutes
2025-05-09 17:58:32,423:INFO:SubProcess create_model() called ==================================
2025-05-09 17:58:32,423:INFO:Initializing create_model()
2025-05-09 17:58:32,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36413b2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:58:32,423:INFO:Checking exceptions
2025-05-09 17:58:32,423:INFO:Importing libraries
2025-05-09 17:58:32,423:INFO:Copying training dataset
2025-05-09 17:58:32,435:INFO:Defining folds
2025-05-09 17:58:32,435:INFO:Declaring metric variables
2025-05-09 17:58:32,436:INFO:Importing untrained model
2025-05-09 17:58:32,438:INFO:Dummy Classifier Imported successfully
2025-05-09 17:58:32,440:INFO:Starting cross validation
2025-05-09 17:58:32,441:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:58:33,468:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:58:33,513:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:58:33,515:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:58:33,538:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:58:33,567:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-09 17:58:33,584:INFO:Calculating mean and std
2025-05-09 17:58:33,584:INFO:Creating metrics dataframe
2025-05-09 17:58:33,585:INFO:Uploading results into container
2025-05-09 17:58:33,586:INFO:Uploading model into container now
2025-05-09 17:58:33,586:INFO:_master_model_container: 14
2025-05-09 17:58:33,586:INFO:_display_container: 2
2025-05-09 17:58:33,586:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-09 17:58:33,586:INFO:create_model() successfully completed......................................
2025-05-09 17:58:33,646:INFO:SubProcess create_model() end ==================================
2025-05-09 17:58:33,646:INFO:Creating metrics dataframe
2025-05-09 17:58:33,650:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-09 17:58:33,653:INFO:Initializing create_model()
2025-05-09 17:58:33,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:58:33,653:INFO:Checking exceptions
2025-05-09 17:58:33,654:INFO:Importing libraries
2025-05-09 17:58:33,654:INFO:Copying training dataset
2025-05-09 17:58:33,663:INFO:Defining folds
2025-05-09 17:58:33,663:INFO:Declaring metric variables
2025-05-09 17:58:33,663:INFO:Importing untrained model
2025-05-09 17:58:33,663:INFO:Declaring custom model
2025-05-09 17:58:33,663:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:58:33,664:INFO:Cross validation set to False
2025-05-09 17:58:33,664:INFO:Fitting Model
2025-05-09 17:58:34,673:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-09 17:58:34,684:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005351 seconds.
2025-05-09 17:58:34,684:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-09 17:58:34,684:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-09 17:58:34,685:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-09 17:58:34,685:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-09 17:58:34,685:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-09 17:58:35,441:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:58:35,442:INFO:create_model() successfully completed......................................
2025-05-09 17:58:35,499:INFO:Initializing create_model()
2025-05-09 17:58:35,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:58:35,499:INFO:Checking exceptions
2025-05-09 17:58:35,500:INFO:Importing libraries
2025-05-09 17:58:35,500:INFO:Copying training dataset
2025-05-09 17:58:35,509:INFO:Defining folds
2025-05-09 17:58:35,509:INFO:Declaring metric variables
2025-05-09 17:58:35,509:INFO:Importing untrained model
2025-05-09 17:58:35,509:INFO:Declaring custom model
2025-05-09 17:58:35,509:INFO:Gradient Boosting Classifier Imported successfully
2025-05-09 17:58:35,510:INFO:Cross validation set to False
2025-05-09 17:58:35,510:INFO:Fitting Model
2025-05-09 17:58:51,446:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-09 17:58:51,447:INFO:create_model() successfully completed......................................
2025-05-09 17:58:51,517:INFO:Initializing create_model()
2025-05-09 17:58:51,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:58:51,517:INFO:Checking exceptions
2025-05-09 17:58:51,517:INFO:Importing libraries
2025-05-09 17:58:51,518:INFO:Copying training dataset
2025-05-09 17:58:51,527:INFO:Defining folds
2025-05-09 17:58:51,527:INFO:Declaring metric variables
2025-05-09 17:58:51,527:INFO:Importing untrained model
2025-05-09 17:58:51,527:INFO:Declaring custom model
2025-05-09 17:58:51,528:INFO:Random Forest Classifier Imported successfully
2025-05-09 17:58:51,528:INFO:Cross validation set to False
2025-05-09 17:58:51,528:INFO:Fitting Model
2025-05-09 17:58:53,758:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-09 17:58:53,758:INFO:create_model() successfully completed......................................
2025-05-09 17:58:53,835:INFO:_master_model_container: 14
2025-05-09 17:58:53,835:INFO:_display_container: 2
2025-05-09 17:58:53,835:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-09 17:58:53,836:INFO:compare_models() successfully completed......................................
2025-05-09 17:58:53,846:INFO:Initializing evaluate_model()
2025-05-09 17:58:53,846:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-09 17:58:53,854:INFO:Initializing plot_model()
2025-05-09 17:58:53,854:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-09 17:58:53,854:INFO:Checking exceptions
2025-05-09 17:58:53,859:INFO:Preloading libraries
2025-05-09 17:58:53,860:INFO:Copying training dataset
2025-05-09 17:58:53,860:INFO:Plot type: pipeline
2025-05-09 17:58:53,922:INFO:Visual Rendered Successfully
2025-05-09 17:58:53,985:INFO:plot_model() successfully completed......................................
2025-05-09 17:58:53,987:INFO:Initializing tune_model()
2025-05-09 17:58:53,987:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-09 17:58:53,987:INFO:Checking exceptions
2025-05-09 17:58:53,996:INFO:Copying training dataset
2025-05-09 17:58:54,003:INFO:Checking base model
2025-05-09 17:58:54,003:INFO:Base model : Light Gradient Boosting Machine
2025-05-09 17:58:54,004:INFO:Declaring metric variables
2025-05-09 17:58:54,006:INFO:Defining Hyperparameters
2025-05-09 17:58:54,066:INFO:Tuning with n_jobs=-1
2025-05-09 17:58:54,066:INFO:Initializing RandomizedSearchCV
2025-05-09 17:59:29,655:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-09 17:59:29,657:INFO:Hyperparameter search completed
2025-05-09 17:59:29,657:INFO:SubProcess create_model() called ==================================
2025-05-09 17:59:29,658:INFO:Initializing create_model()
2025-05-09 17:59:29,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x107e14e10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-09 17:59:29,658:INFO:Checking exceptions
2025-05-09 17:59:29,659:INFO:Importing libraries
2025-05-09 17:59:29,659:INFO:Copying training dataset
2025-05-09 17:59:29,679:INFO:Defining folds
2025-05-09 17:59:29,679:INFO:Declaring metric variables
2025-05-09 17:59:29,683:INFO:Importing untrained model
2025-05-09 17:59:29,683:INFO:Declaring custom model
2025-05-09 17:59:29,685:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:59:29,688:INFO:Starting cross validation
2025-05-09 17:59:29,689:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:59:36,107:INFO:Calculating mean and std
2025-05-09 17:59:36,108:INFO:Creating metrics dataframe
2025-05-09 17:59:36,113:INFO:Finalizing model
2025-05-09 17:59:37,152:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-09 17:59:37,152:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-09 17:59:37,152:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-09 17:59:37,184:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-09 17:59:37,184:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-09 17:59:37,184:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-09 17:59:37,184:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-09 17:59:37,194:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005503 seconds.
2025-05-09 17:59:37,194:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-09 17:59:37,194:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-09 17:59:37,194:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-09 17:59:37,195:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-09 17:59:39,147:INFO:Uploading results into container
2025-05-09 17:59:39,148:INFO:Uploading model into container now
2025-05-09 17:59:39,148:INFO:_master_model_container: 15
2025-05-09 17:59:39,148:INFO:_display_container: 3
2025-05-09 17:59:39,149:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:59:39,149:INFO:create_model() successfully completed......................................
2025-05-09 17:59:39,252:INFO:SubProcess create_model() end ==================================
2025-05-09 17:59:39,252:INFO:choose_better activated
2025-05-09 17:59:39,254:INFO:SubProcess create_model() called ==================================
2025-05-09 17:59:39,254:INFO:Initializing create_model()
2025-05-09 17:59:39,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:59:39,254:INFO:Checking exceptions
2025-05-09 17:59:39,255:INFO:Importing libraries
2025-05-09 17:59:39,255:INFO:Copying training dataset
2025-05-09 17:59:39,264:INFO:Defining folds
2025-05-09 17:59:39,264:INFO:Declaring metric variables
2025-05-09 17:59:39,264:INFO:Importing untrained model
2025-05-09 17:59:39,264:INFO:Declaring custom model
2025-05-09 17:59:39,265:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:59:39,265:INFO:Starting cross validation
2025-05-09 17:59:39,266:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 17:59:43,592:INFO:Calculating mean and std
2025-05-09 17:59:43,592:INFO:Creating metrics dataframe
2025-05-09 17:59:43,593:INFO:Finalizing model
2025-05-09 17:59:44,594:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-09 17:59:44,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004846 seconds.
2025-05-09 17:59:44,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-09 17:59:44,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-09 17:59:44,603:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-09 17:59:44,604:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-09 17:59:44,604:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-09 17:59:45,354:INFO:Uploading results into container
2025-05-09 17:59:45,354:INFO:Uploading model into container now
2025-05-09 17:59:45,354:INFO:_master_model_container: 16
2025-05-09 17:59:45,355:INFO:_display_container: 4
2025-05-09 17:59:45,355:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:59:45,355:INFO:create_model() successfully completed......................................
2025-05-09 17:59:45,412:INFO:SubProcess create_model() end ==================================
2025-05-09 17:59:45,412:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-09 17:59:45,412:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-09 17:59:45,413:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-09 17:59:45,413:INFO:choose_better completed
2025-05-09 17:59:45,416:INFO:_master_model_container: 16
2025-05-09 17:59:45,416:INFO:_display_container: 3
2025-05-09 17:59:45,417:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:59:45,417:INFO:tune_model() successfully completed......................................
2025-05-09 17:59:45,479:INFO:Initializing evaluate_model()
2025-05-09 17:59:45,479:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-09 17:59:45,487:INFO:Initializing plot_model()
2025-05-09 17:59:45,487:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-09 17:59:45,487:INFO:Checking exceptions
2025-05-09 17:59:45,491:INFO:Preloading libraries
2025-05-09 17:59:45,494:INFO:Copying training dataset
2025-05-09 17:59:45,494:INFO:Plot type: pipeline
2025-05-09 17:59:45,554:INFO:Visual Rendered Successfully
2025-05-09 17:59:45,615:INFO:plot_model() successfully completed......................................
2025-05-09 17:59:45,616:INFO:Initializing interpret_model()
2025-05-09 17:59:45,617:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-09 17:59:45,617:INFO:Checking exceptions
2025-05-09 17:59:45,617:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-09 17:59:45,617:INFO:Initializing finalize_model()
2025-05-09 17:59:45,617:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-09 17:59:45,617:INFO:Finalizing LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-09 17:59:45,622:INFO:Initializing create_model()
2025-05-09 17:59:45,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:59:45,622:INFO:Checking exceptions
2025-05-09 17:59:45,622:INFO:Importing libraries
2025-05-09 17:59:45,622:INFO:Copying training dataset
2025-05-09 17:59:45,623:INFO:Defining folds
2025-05-09 17:59:45,623:INFO:Declaring metric variables
2025-05-09 17:59:45,623:INFO:Importing untrained model
2025-05-09 17:59:45,623:INFO:Declaring custom model
2025-05-09 17:59:45,623:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 17:59:45,624:INFO:Cross validation set to False
2025-05-09 17:59:45,624:INFO:Fitting Model
2025-05-09 17:59:47,030:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-09 17:59:47,030:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-09 17:59:47,030:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-09 17:59:47,074:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-09 17:59:47,074:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-09 17:59:47,074:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-09 17:59:47,074:INFO:[LightGBM] [Info] Number of positive: 61360, number of negative: 61360
2025-05-09 17:59:47,086:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006014 seconds.
2025-05-09 17:59:47,086:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-09 17:59:47,086:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-09 17:59:47,087:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-09 17:59:47,087:INFO:[LightGBM] [Info] Number of data points in the train set: 122720, number of used features: 28
2025-05-09 17:59:47,087:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-09 17:59:48,613:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-09 17:59:48,613:INFO:create_model() successfully completed......................................
2025-05-09 17:59:48,677:INFO:_master_model_container: 16
2025-05-09 17:59:48,678:INFO:_display_container: 3
2025-05-09 17:59:48,698:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-09 17:59:48,698:INFO:finalize_model() successfully completed......................................
2025-05-09 17:59:48,813:INFO:Initializing save_model()
2025-05-09 17:59:48,813:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-09 17:59:48,813:INFO:Adding model into prep_pipe
2025-05-09 17:59:48,813:WARNING:Only Model saved as it was a pipeline.
2025-05-09 17:59:48,820:INFO:final_cancer_model.pkl saved in current working directory
2025-05-09 17:59:48,843:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-09 17:59:48,843:INFO:save_model() successfully completed......................................
2025-05-09 17:59:48,935:INFO:Initializing predict_model()
2025-05-09 17:59:48,935:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x1077de200>)
2025-05-09 17:59:48,935:INFO:Checking exceptions
2025-05-09 17:59:48,935:INFO:Preloading libraries
2025-05-09 17:59:48,936:INFO:Set up data.
2025-05-09 17:59:48,954:INFO:Set up index.
2025-05-09 17:59:49,296:INFO:Initializing blend_models()
2025-05-09 17:59:49,296:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-09 17:59:49,296:INFO:Checking exceptions
2025-05-09 17:59:49,304:INFO:Importing libraries
2025-05-09 17:59:49,304:INFO:Copying training dataset
2025-05-09 17:59:49,305:INFO:Getting model names
2025-05-09 17:59:49,307:INFO:SubProcess create_model() called ==================================
2025-05-09 17:59:49,309:INFO:Initializing create_model()
2025-05-09 17:59:49,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3616343d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 17:59:49,310:INFO:Checking exceptions
2025-05-09 17:59:49,310:INFO:Importing libraries
2025-05-09 17:59:49,310:INFO:Copying training dataset
2025-05-09 17:59:49,321:INFO:Defining folds
2025-05-09 17:59:49,321:INFO:Declaring metric variables
2025-05-09 17:59:49,322:INFO:Importing untrained model
2025-05-09 17:59:49,322:INFO:Declaring custom model
2025-05-09 17:59:49,324:INFO:Voting Classifier Imported successfully
2025-05-09 17:59:49,327:INFO:Starting cross validation
2025-05-09 17:59:49,328:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 18:00:05,619:INFO:Calculating mean and std
2025-05-09 18:00:05,620:INFO:Creating metrics dataframe
2025-05-09 18:00:05,624:INFO:Finalizing model
2025-05-09 18:00:22,149:INFO:Uploading results into container
2025-05-09 18:00:22,152:INFO:Uploading model into container now
2025-05-09 18:00:22,153:INFO:_master_model_container: 17
2025-05-09 18:00:22,153:INFO:_display_container: 4
2025-05-09 18:00:22,156:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-09 18:00:22,156:INFO:create_model() successfully completed......................................
2025-05-09 18:00:22,260:INFO:SubProcess create_model() end ==================================
2025-05-09 18:00:22,264:INFO:_master_model_container: 17
2025-05-09 18:00:22,264:INFO:_display_container: 4
2025-05-09 18:00:22,266:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-09 18:00:22,266:INFO:blend_models() successfully completed......................................
2025-05-09 18:00:22,329:INFO:Initializing evaluate_model()
2025-05-09 18:00:22,329:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-09 18:00:22,339:INFO:Initializing plot_model()
2025-05-09 18:00:22,339:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-09 18:00:22,339:INFO:Checking exceptions
2025-05-09 18:00:22,342:INFO:Preloading libraries
2025-05-09 18:00:22,429:INFO:Copying training dataset
2025-05-09 18:00:22,429:INFO:Plot type: pipeline
2025-05-09 18:00:22,487:INFO:Visual Rendered Successfully
2025-05-09 18:00:22,549:INFO:plot_model() successfully completed......................................
2025-05-09 18:00:22,559:INFO:Initializing predict_model()
2025-05-09 18:00:22,559:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x35a22dd00>)
2025-05-09 18:00:22,559:INFO:Checking exceptions
2025-05-09 18:00:22,559:INFO:Preloading libraries
2025-05-09 18:00:22,560:INFO:Set up data.
2025-05-09 18:00:22,581:INFO:Set up index.
2025-05-09 18:00:23,186:INFO:Initializing plot_model()
2025-05-09 18:00:23,186:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-09 18:00:23,186:INFO:Checking exceptions
2025-05-09 18:00:23,190:INFO:Preloading libraries
2025-05-09 18:00:23,192:INFO:Copying training dataset
2025-05-09 18:00:23,192:INFO:Plot type: confusion_matrix
2025-05-09 18:00:23,407:INFO:Fitting Model
2025-05-09 18:00:23,408:INFO:Scoring test/hold-out set
2025-05-09 18:00:23,489:INFO:Visual Rendered Successfully
2025-05-09 18:00:23,550:INFO:plot_model() successfully completed......................................
2025-05-09 18:00:23,551:INFO:Initializing plot_model()
2025-05-09 18:00:23,551:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-09 18:00:23,551:INFO:Checking exceptions
2025-05-09 18:00:23,556:INFO:Preloading libraries
2025-05-09 18:00:23,557:INFO:Copying training dataset
2025-05-09 18:00:23,557:INFO:Plot type: auc
2025-05-09 18:00:23,791:INFO:Fitting Model
2025-05-09 18:00:23,793:INFO:Scoring test/hold-out set
2025-05-09 18:00:23,924:INFO:Visual Rendered Successfully
2025-05-09 18:00:23,984:INFO:plot_model() successfully completed......................................
2025-05-09 18:00:23,985:INFO:Initializing plot_model()
2025-05-09 18:00:23,985:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3407db890>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-09 18:00:23,985:INFO:Checking exceptions
2025-05-09 18:00:23,991:INFO:Preloading libraries
2025-05-09 18:00:23,993:INFO:Copying training dataset
2025-05-09 18:00:23,993:INFO:Plot type: feature
2025-05-09 18:00:23,993:WARNING:No coef_ found. Trying feature_importances_
2025-05-09 18:00:24,066:INFO:Visual Rendered Successfully
2025-05-09 18:00:24,124:INFO:plot_model() successfully completed......................................
