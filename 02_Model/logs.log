2025-05-13 15:12:46,822:INFO:PyCaret ClassificationExperiment
2025-05-13 15:12:46,822:INFO:Logging name: clf-default-name
2025-05-13 15:12:46,822:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-13 15:12:46,822:INFO:version 3.3.2
2025-05-13 15:12:46,822:INFO:Initializing setup()
2025-05-13 15:12:46,822:INFO:self.USI: 77f9
2025-05-13 15:12:46,822:INFO:self._variable_keys: {'data', 'memory', 'gpu_param', '_available_plots', 'idx', 'html_param', 'gpu_n_jobs_param', 'fold_generator', 'fold_groups_param', 'logging_param', 'y', 'exp_id', 'X_train', 'is_multiclass', '_ml_usecase', 'X_test', 'y_test', 'y_train', 'exp_name_log', 'X', 'USI', 'fix_imbalance', 'fold_shuffle_param', 'log_plots_param', 'target_param', 'seed', 'pipeline', 'n_jobs_param'}
2025-05-13 15:12:46,822:INFO:Checking environment
2025-05-13 15:12:46,822:INFO:python_version: 3.11.0
2025-05-13 15:12:46,822:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-13 15:12:46,822:INFO:machine: arm64
2025-05-13 15:12:46,822:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:12:46,822:INFO:Memory: svmem(total=17179869184, available=4077387776, percent=76.3, used=6680018944, free=60080128, active=4042293248, inactive=4012113920, wired=2637725696)
2025-05-13 15:12:46,822:INFO:Physical Core: 12
2025-05-13 15:12:46,822:INFO:Logical Core: 12
2025-05-13 15:12:46,822:INFO:Checking libraries
2025-05-13 15:12:46,822:INFO:System:
2025-05-13 15:12:46,822:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-13 15:12:46,822:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-13 15:12:46,822:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:12:46,822:INFO:PyCaret required dependencies:
2025-05-13 15:12:46,823:INFO:                 pip: 22.3
2025-05-13 15:12:46,823:INFO:          setuptools: 65.5.0
2025-05-13 15:12:46,823:INFO:             pycaret: 3.3.2
2025-05-13 15:12:46,823:INFO:             IPython: 9.2.0
2025-05-13 15:12:46,823:INFO:          ipywidgets: 8.1.7
2025-05-13 15:12:46,823:INFO:                tqdm: 4.67.1
2025-05-13 15:12:46,823:INFO:               numpy: 1.26.4
2025-05-13 15:12:46,823:INFO:              pandas: 2.1.4
2025-05-13 15:12:46,823:INFO:              jinja2: 3.1.6
2025-05-13 15:12:46,823:INFO:               scipy: 1.11.4
2025-05-13 15:12:46,823:INFO:              joblib: 1.3.2
2025-05-13 15:12:46,823:INFO:             sklearn: 1.4.2
2025-05-13 15:12:46,823:INFO:                pyod: 2.0.5
2025-05-13 15:12:46,823:INFO:            imblearn: 0.13.0
2025-05-13 15:12:46,823:INFO:   category_encoders: 2.7.0
2025-05-13 15:12:46,823:INFO:            lightgbm: 4.6.0
2025-05-13 15:12:46,823:INFO:               numba: 0.61.2
2025-05-13 15:12:46,823:INFO:            requests: 2.32.3
2025-05-13 15:12:46,823:INFO:          matplotlib: 3.7.5
2025-05-13 15:12:46,823:INFO:          scikitplot: 0.3.7
2025-05-13 15:12:46,823:INFO:         yellowbrick: 1.5
2025-05-13 15:12:46,823:INFO:              plotly: 5.24.1
2025-05-13 15:12:46,823:INFO:    plotly-resampler: Not installed
2025-05-13 15:12:46,823:INFO:             kaleido: 0.2.1
2025-05-13 15:12:46,823:INFO:           schemdraw: 0.15
2025-05-13 15:12:46,823:INFO:         statsmodels: 0.14.4
2025-05-13 15:12:46,823:INFO:              sktime: 0.26.0
2025-05-13 15:12:46,823:INFO:               tbats: 1.1.3
2025-05-13 15:12:46,823:INFO:            pmdarima: 2.0.4
2025-05-13 15:12:46,823:INFO:              psutil: 7.0.0
2025-05-13 15:12:46,823:INFO:          markupsafe: 3.0.2
2025-05-13 15:12:46,823:INFO:             pickle5: Not installed
2025-05-13 15:12:46,823:INFO:         cloudpickle: 3.1.1
2025-05-13 15:12:46,823:INFO:         deprecation: 2.1.0
2025-05-13 15:12:46,823:INFO:              xxhash: 3.5.0
2025-05-13 15:12:46,823:INFO:           wurlitzer: 3.1.1
2025-05-13 15:12:46,823:INFO:PyCaret optional dependencies:
2025-05-13 15:12:46,823:INFO:                shap: 0.47.2
2025-05-13 15:12:46,823:INFO:           interpret: Not installed
2025-05-13 15:12:46,823:INFO:                umap: Not installed
2025-05-13 15:12:46,823:INFO:     ydata_profiling: Not installed
2025-05-13 15:12:46,823:INFO:  explainerdashboard: Not installed
2025-05-13 15:12:46,823:INFO:             autoviz: Not installed
2025-05-13 15:12:46,823:INFO:           fairlearn: Not installed
2025-05-13 15:12:46,823:INFO:          deepchecks: Not installed
2025-05-13 15:12:46,823:INFO:             xgboost: Not installed
2025-05-13 15:12:46,823:INFO:            catboost: Not installed
2025-05-13 15:12:46,823:INFO:              kmodes: Not installed
2025-05-13 15:12:46,823:INFO:             mlxtend: Not installed
2025-05-13 15:12:46,823:INFO:       statsforecast: Not installed
2025-05-13 15:12:46,823:INFO:        tune_sklearn: Not installed
2025-05-13 15:12:46,823:INFO:                 ray: Not installed
2025-05-13 15:12:46,823:INFO:            hyperopt: Not installed
2025-05-13 15:12:46,823:INFO:              optuna: 4.3.0
2025-05-13 15:12:46,823:INFO:               skopt: Not installed
2025-05-13 15:12:46,823:INFO:              mlflow: Not installed
2025-05-13 15:12:46,823:INFO:              gradio: Not installed
2025-05-13 15:12:46,823:INFO:             fastapi: Not installed
2025-05-13 15:12:46,823:INFO:             uvicorn: Not installed
2025-05-13 15:12:46,823:INFO:              m2cgen: Not installed
2025-05-13 15:12:46,823:INFO:           evidently: Not installed
2025-05-13 15:12:46,823:INFO:               fugue: Not installed
2025-05-13 15:12:46,823:INFO:           streamlit: Not installed
2025-05-13 15:12:46,823:INFO:             prophet: Not installed
2025-05-13 15:12:46,823:INFO:None
2025-05-13 15:12:46,823:INFO:Set up data.
2025-05-13 15:12:46,851:INFO:Set up folding strategy.
2025-05-13 15:12:46,851:INFO:Set up train/test split.
2025-05-13 15:12:46,864:INFO:Set up index.
2025-05-13 15:12:46,865:INFO:Assigning column types.
2025-05-13 15:12:46,868:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-13 15:12:46,887:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,887:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,899:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,919:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,931:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-13 15:12:46,951:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,983:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,995:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,995:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-13 15:12:47,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:47,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:47,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:47,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:47,058:INFO:Preparing preprocessing pipeline...
2025-05-13 15:12:47,060:INFO:Set up simple imputation.
2025-05-13 15:12:47,066:INFO:Set up encoding of ordinal features.
2025-05-13 15:12:47,074:INFO:Set up encoding of categorical features.
2025-05-13 15:12:47,074:INFO:Set up imbalanced handling.
2025-05-13 15:12:47,074:INFO:Set up column transformation.
2025-05-13 15:12:48,359:INFO:Finished creating preprocessing pipeline.
2025-05-13 15:12:48,376:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-13 15:12:48,376:INFO:Creating final display dataframe.
2025-05-13 15:12:48,836:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 15)
4        Transformed data shape      (106821, 28)
5   Transformed train set shape       (85902, 28)
6    Transformed test set shape       (20919, 28)
7              Numeric features                 6
8          Categorical features                 8
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              77f9
2025-05-13 15:12:48,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:48,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:48,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:48,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:48,905:INFO:setup() successfully completed in 2.09s...............
2025-05-13 15:12:48,905:INFO:Initializing compare_models()
2025-05-13 15:12:48,906:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-13 15:12:48,906:INFO:Checking exceptions
2025-05-13 15:12:48,913:INFO:Preparing display monitor
2025-05-13 15:12:48,923:INFO:Initializing Logistic Regression
2025-05-13 15:12:48,923:INFO:Total runtime is 2.3523966471354168e-06 minutes
2025-05-13 15:12:48,924:INFO:SubProcess create_model() called ==================================
2025-05-13 15:12:48,925:INFO:Initializing create_model()
2025-05-13 15:12:48,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:12:48,925:INFO:Checking exceptions
2025-05-13 15:12:48,925:INFO:Importing libraries
2025-05-13 15:12:48,925:INFO:Copying training dataset
2025-05-13 15:12:48,937:INFO:Defining folds
2025-05-13 15:12:48,937:INFO:Declaring metric variables
2025-05-13 15:12:48,938:INFO:Importing untrained model
2025-05-13 15:12:48,940:INFO:Logistic Regression Imported successfully
2025-05-13 15:12:48,942:INFO:Starting cross validation
2025-05-13 15:12:48,944:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:12:54,690:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,738:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,739:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,787:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,793:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,842:INFO:Calculating mean and std
2025-05-13 15:12:54,844:INFO:Creating metrics dataframe
2025-05-13 15:12:54,846:INFO:Uploading results into container
2025-05-13 15:12:54,847:INFO:Uploading model into container now
2025-05-13 15:12:54,847:INFO:_master_model_container: 1
2025-05-13 15:12:54,847:INFO:_display_container: 2
2025-05-13 15:12:54,847:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-13 15:12:54,847:INFO:create_model() successfully completed......................................
2025-05-13 15:12:54,986:INFO:SubProcess create_model() end ==================================
2025-05-13 15:12:54,987:INFO:Creating metrics dataframe
2025-05-13 15:12:54,989:INFO:Initializing K Neighbors Classifier
2025-05-13 15:12:54,989:INFO:Total runtime is 0.10111306905746459 minutes
2025-05-13 15:12:54,991:INFO:SubProcess create_model() called ==================================
2025-05-13 15:12:54,991:INFO:Initializing create_model()
2025-05-13 15:12:54,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:12:54,991:INFO:Checking exceptions
2025-05-13 15:12:54,991:INFO:Importing libraries
2025-05-13 15:12:54,991:INFO:Copying training dataset
2025-05-13 15:12:55,002:INFO:Defining folds
2025-05-13 15:12:55,002:INFO:Declaring metric variables
2025-05-13 15:12:55,003:INFO:Importing untrained model
2025-05-13 15:12:55,005:INFO:K Neighbors Classifier Imported successfully
2025-05-13 15:12:55,007:INFO:Starting cross validation
2025-05-13 15:12:55,008:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:00,778:INFO:Calculating mean and std
2025-05-13 15:13:00,779:INFO:Creating metrics dataframe
2025-05-13 15:13:00,781:INFO:Uploading results into container
2025-05-13 15:13:00,781:INFO:Uploading model into container now
2025-05-13 15:13:00,782:INFO:_master_model_container: 2
2025-05-13 15:13:00,782:INFO:_display_container: 2
2025-05-13 15:13:00,782:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-13 15:13:00,782:INFO:create_model() successfully completed......................................
2025-05-13 15:13:00,869:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:00,869:INFO:Creating metrics dataframe
2025-05-13 15:13:00,872:INFO:Initializing Naive Bayes
2025-05-13 15:13:00,872:INFO:Total runtime is 0.19915663401285805 minutes
2025-05-13 15:13:00,873:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:00,873:INFO:Initializing create_model()
2025-05-13 15:13:00,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:00,874:INFO:Checking exceptions
2025-05-13 15:13:00,874:INFO:Importing libraries
2025-05-13 15:13:00,874:INFO:Copying training dataset
2025-05-13 15:13:00,883:INFO:Defining folds
2025-05-13 15:13:00,884:INFO:Declaring metric variables
2025-05-13 15:13:00,885:INFO:Importing untrained model
2025-05-13 15:13:00,887:INFO:Naive Bayes Imported successfully
2025-05-13 15:13:00,889:INFO:Starting cross validation
2025-05-13 15:13:00,890:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:03,066:INFO:Calculating mean and std
2025-05-13 15:13:03,067:INFO:Creating metrics dataframe
2025-05-13 15:13:03,068:INFO:Uploading results into container
2025-05-13 15:13:03,068:INFO:Uploading model into container now
2025-05-13 15:13:03,068:INFO:_master_model_container: 3
2025-05-13 15:13:03,068:INFO:_display_container: 2
2025-05-13 15:13:03,068:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-13 15:13:03,068:INFO:create_model() successfully completed......................................
2025-05-13 15:13:03,147:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:03,147:INFO:Creating metrics dataframe
2025-05-13 15:13:03,150:INFO:Initializing Decision Tree Classifier
2025-05-13 15:13:03,150:INFO:Total runtime is 0.23711818854014077 minutes
2025-05-13 15:13:03,151:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:03,151:INFO:Initializing create_model()
2025-05-13 15:13:03,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:03,151:INFO:Checking exceptions
2025-05-13 15:13:03,151:INFO:Importing libraries
2025-05-13 15:13:03,151:INFO:Copying training dataset
2025-05-13 15:13:03,161:INFO:Defining folds
2025-05-13 15:13:03,161:INFO:Declaring metric variables
2025-05-13 15:13:03,162:INFO:Importing untrained model
2025-05-13 15:13:03,163:INFO:Decision Tree Classifier Imported successfully
2025-05-13 15:13:03,165:INFO:Starting cross validation
2025-05-13 15:13:03,167:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:04,774:INFO:Calculating mean and std
2025-05-13 15:13:04,775:INFO:Creating metrics dataframe
2025-05-13 15:13:04,776:INFO:Uploading results into container
2025-05-13 15:13:04,776:INFO:Uploading model into container now
2025-05-13 15:13:04,776:INFO:_master_model_container: 4
2025-05-13 15:13:04,776:INFO:_display_container: 2
2025-05-13 15:13:04,776:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-13 15:13:04,776:INFO:create_model() successfully completed......................................
2025-05-13 15:13:04,854:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:04,854:INFO:Creating metrics dataframe
2025-05-13 15:13:04,857:INFO:Initializing SVM - Linear Kernel
2025-05-13 15:13:04,857:INFO:Total runtime is 0.26557176907857255 minutes
2025-05-13 15:13:04,858:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:04,858:INFO:Initializing create_model()
2025-05-13 15:13:04,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:04,858:INFO:Checking exceptions
2025-05-13 15:13:04,859:INFO:Importing libraries
2025-05-13 15:13:04,859:INFO:Copying training dataset
2025-05-13 15:13:04,867:INFO:Defining folds
2025-05-13 15:13:04,867:INFO:Declaring metric variables
2025-05-13 15:13:04,868:INFO:Importing untrained model
2025-05-13 15:13:04,869:INFO:SVM - Linear Kernel Imported successfully
2025-05-13 15:13:04,871:INFO:Starting cross validation
2025-05-13 15:13:04,873:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:07,992:INFO:Calculating mean and std
2025-05-13 15:13:07,993:INFO:Creating metrics dataframe
2025-05-13 15:13:07,994:INFO:Uploading results into container
2025-05-13 15:13:07,994:INFO:Uploading model into container now
2025-05-13 15:13:07,994:INFO:_master_model_container: 5
2025-05-13 15:13:07,994:INFO:_display_container: 2
2025-05-13 15:13:07,994:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-13 15:13:07,994:INFO:create_model() successfully completed......................................
2025-05-13 15:13:08,087:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:08,088:INFO:Creating metrics dataframe
2025-05-13 15:13:08,091:INFO:Initializing Ridge Classifier
2025-05-13 15:13:08,091:INFO:Total runtime is 0.31947088638941445 minutes
2025-05-13 15:13:08,092:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:08,092:INFO:Initializing create_model()
2025-05-13 15:13:08,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:08,092:INFO:Checking exceptions
2025-05-13 15:13:08,092:INFO:Importing libraries
2025-05-13 15:13:08,092:INFO:Copying training dataset
2025-05-13 15:13:08,103:INFO:Defining folds
2025-05-13 15:13:08,103:INFO:Declaring metric variables
2025-05-13 15:13:08,104:INFO:Importing untrained model
2025-05-13 15:13:08,105:INFO:Ridge Classifier Imported successfully
2025-05-13 15:13:08,107:INFO:Starting cross validation
2025-05-13 15:13:08,109:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:10,225:INFO:Calculating mean and std
2025-05-13 15:13:10,225:INFO:Creating metrics dataframe
2025-05-13 15:13:10,226:INFO:Uploading results into container
2025-05-13 15:13:10,227:INFO:Uploading model into container now
2025-05-13 15:13:10,227:INFO:_master_model_container: 6
2025-05-13 15:13:10,227:INFO:_display_container: 2
2025-05-13 15:13:10,227:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-13 15:13:10,227:INFO:create_model() successfully completed......................................
2025-05-13 15:13:10,302:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:10,302:INFO:Creating metrics dataframe
2025-05-13 15:13:10,305:INFO:Initializing Random Forest Classifier
2025-05-13 15:13:10,305:INFO:Total runtime is 0.3563728173573812 minutes
2025-05-13 15:13:10,306:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:10,306:INFO:Initializing create_model()
2025-05-13 15:13:10,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:10,306:INFO:Checking exceptions
2025-05-13 15:13:10,307:INFO:Importing libraries
2025-05-13 15:13:10,307:INFO:Copying training dataset
2025-05-13 15:13:10,316:INFO:Defining folds
2025-05-13 15:13:10,316:INFO:Declaring metric variables
2025-05-13 15:13:10,317:INFO:Importing untrained model
2025-05-13 15:13:10,318:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:13:10,320:INFO:Starting cross validation
2025-05-13 15:13:10,321:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:16,029:INFO:Calculating mean and std
2025-05-13 15:13:16,031:INFO:Creating metrics dataframe
2025-05-13 15:13:16,034:INFO:Uploading results into container
2025-05-13 15:13:16,034:INFO:Uploading model into container now
2025-05-13 15:13:16,035:INFO:_master_model_container: 7
2025-05-13 15:13:16,035:INFO:_display_container: 2
2025-05-13 15:13:16,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:13:16,035:INFO:create_model() successfully completed......................................
2025-05-13 15:13:16,135:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:16,135:INFO:Creating metrics dataframe
2025-05-13 15:13:16,138:INFO:Initializing Quadratic Discriminant Analysis
2025-05-13 15:13:16,138:INFO:Total runtime is 0.4535940527915955 minutes
2025-05-13 15:13:16,140:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:16,140:INFO:Initializing create_model()
2025-05-13 15:13:16,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:16,140:INFO:Checking exceptions
2025-05-13 15:13:16,140:INFO:Importing libraries
2025-05-13 15:13:16,140:INFO:Copying training dataset
2025-05-13 15:13:16,153:INFO:Defining folds
2025-05-13 15:13:16,153:INFO:Declaring metric variables
2025-05-13 15:13:16,155:INFO:Importing untrained model
2025-05-13 15:13:16,156:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-13 15:13:16,158:INFO:Starting cross validation
2025-05-13 15:13:16,160:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:17,138:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:17,152:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:17,156:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:17,162:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:17,212:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:17,226:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:17,229:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:17,238:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:18,305:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:18,368:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:18,383:INFO:Calculating mean and std
2025-05-13 15:13:18,384:INFO:Creating metrics dataframe
2025-05-13 15:13:18,385:INFO:Uploading results into container
2025-05-13 15:13:18,385:INFO:Uploading model into container now
2025-05-13 15:13:18,385:INFO:_master_model_container: 8
2025-05-13 15:13:18,385:INFO:_display_container: 2
2025-05-13 15:13:18,385:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-13 15:13:18,385:INFO:create_model() successfully completed......................................
2025-05-13 15:13:18,475:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:18,475:INFO:Creating metrics dataframe
2025-05-13 15:13:18,478:INFO:Initializing Ada Boost Classifier
2025-05-13 15:13:18,478:INFO:Total runtime is 0.4925962845484416 minutes
2025-05-13 15:13:18,480:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:18,480:INFO:Initializing create_model()
2025-05-13 15:13:18,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:18,480:INFO:Checking exceptions
2025-05-13 15:13:18,480:INFO:Importing libraries
2025-05-13 15:13:18,480:INFO:Copying training dataset
2025-05-13 15:13:18,491:INFO:Defining folds
2025-05-13 15:13:18,491:INFO:Declaring metric variables
2025-05-13 15:13:18,492:INFO:Importing untrained model
2025-05-13 15:13:18,493:INFO:Ada Boost Classifier Imported successfully
2025-05-13 15:13:18,496:INFO:Starting cross validation
2025-05-13 15:13:18,497:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:19,402:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:19,467:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:19,479:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:19,484:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:19,507:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:22,144:INFO:Calculating mean and std
2025-05-13 15:13:22,145:INFO:Creating metrics dataframe
2025-05-13 15:13:22,146:INFO:Uploading results into container
2025-05-13 15:13:22,146:INFO:Uploading model into container now
2025-05-13 15:13:22,146:INFO:_master_model_container: 9
2025-05-13 15:13:22,146:INFO:_display_container: 2
2025-05-13 15:13:22,146:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-13 15:13:22,146:INFO:create_model() successfully completed......................................
2025-05-13 15:13:22,220:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:22,220:INFO:Creating metrics dataframe
2025-05-13 15:13:22,224:INFO:Initializing Gradient Boosting Classifier
2025-05-13 15:13:22,224:INFO:Total runtime is 0.5550253868103028 minutes
2025-05-13 15:13:22,225:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:22,225:INFO:Initializing create_model()
2025-05-13 15:13:22,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:22,226:INFO:Checking exceptions
2025-05-13 15:13:22,226:INFO:Importing libraries
2025-05-13 15:13:22,226:INFO:Copying training dataset
2025-05-13 15:13:22,236:INFO:Defining folds
2025-05-13 15:13:22,236:INFO:Declaring metric variables
2025-05-13 15:13:22,238:INFO:Importing untrained model
2025-05-13 15:13:22,239:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:13:22,241:INFO:Starting cross validation
2025-05-13 15:13:22,242:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:35,548:INFO:Calculating mean and std
2025-05-13 15:13:35,550:INFO:Creating metrics dataframe
2025-05-13 15:13:35,551:INFO:Uploading results into container
2025-05-13 15:13:35,552:INFO:Uploading model into container now
2025-05-13 15:13:35,552:INFO:_master_model_container: 10
2025-05-13 15:13:35,552:INFO:_display_container: 2
2025-05-13 15:13:35,552:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:13:35,552:INFO:create_model() successfully completed......................................
2025-05-13 15:13:35,632:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:35,632:INFO:Creating metrics dataframe
2025-05-13 15:13:35,635:INFO:Initializing Linear Discriminant Analysis
2025-05-13 15:13:35,636:INFO:Total runtime is 0.7785467346509298 minutes
2025-05-13 15:13:35,637:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:35,637:INFO:Initializing create_model()
2025-05-13 15:13:35,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:35,637:INFO:Checking exceptions
2025-05-13 15:13:35,637:INFO:Importing libraries
2025-05-13 15:13:35,637:INFO:Copying training dataset
2025-05-13 15:13:35,648:INFO:Defining folds
2025-05-13 15:13:35,648:INFO:Declaring metric variables
2025-05-13 15:13:35,649:INFO:Importing untrained model
2025-05-13 15:13:35,650:INFO:Linear Discriminant Analysis Imported successfully
2025-05-13 15:13:35,653:INFO:Starting cross validation
2025-05-13 15:13:35,654:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:36,781:INFO:Calculating mean and std
2025-05-13 15:13:36,781:INFO:Creating metrics dataframe
2025-05-13 15:13:36,783:INFO:Uploading results into container
2025-05-13 15:13:36,783:INFO:Uploading model into container now
2025-05-13 15:13:36,783:INFO:_master_model_container: 11
2025-05-13 15:13:36,783:INFO:_display_container: 2
2025-05-13 15:13:36,784:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-13 15:13:36,784:INFO:create_model() successfully completed......................................
2025-05-13 15:13:36,862:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:36,862:INFO:Creating metrics dataframe
2025-05-13 15:13:36,866:INFO:Initializing Extra Trees Classifier
2025-05-13 15:13:36,866:INFO:Total runtime is 0.7990583856900534 minutes
2025-05-13 15:13:36,867:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:36,868:INFO:Initializing create_model()
2025-05-13 15:13:36,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:36,868:INFO:Checking exceptions
2025-05-13 15:13:36,868:INFO:Importing libraries
2025-05-13 15:13:36,868:INFO:Copying training dataset
2025-05-13 15:13:36,878:INFO:Defining folds
2025-05-13 15:13:36,878:INFO:Declaring metric variables
2025-05-13 15:13:36,879:INFO:Importing untrained model
2025-05-13 15:13:36,881:INFO:Extra Trees Classifier Imported successfully
2025-05-13 15:13:36,883:INFO:Starting cross validation
2025-05-13 15:13:36,884:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:41,817:INFO:Calculating mean and std
2025-05-13 15:13:41,820:INFO:Creating metrics dataframe
2025-05-13 15:13:41,826:INFO:Uploading results into container
2025-05-13 15:13:41,826:INFO:Uploading model into container now
2025-05-13 15:13:41,827:INFO:_master_model_container: 12
2025-05-13 15:13:41,827:INFO:_display_container: 2
2025-05-13 15:13:41,828:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-13 15:13:41,828:INFO:create_model() successfully completed......................................
2025-05-13 15:13:41,972:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:41,972:INFO:Creating metrics dataframe
2025-05-13 15:13:41,976:INFO:Initializing Light Gradient Boosting Machine
2025-05-13 15:13:41,976:INFO:Total runtime is 0.8842240532239279 minutes
2025-05-13 15:13:41,977:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:41,978:INFO:Initializing create_model()
2025-05-13 15:13:41,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:41,978:INFO:Checking exceptions
2025-05-13 15:13:41,978:INFO:Importing libraries
2025-05-13 15:13:41,978:INFO:Copying training dataset
2025-05-13 15:13:41,990:INFO:Defining folds
2025-05-13 15:13:41,991:INFO:Declaring metric variables
2025-05-13 15:13:41,992:INFO:Importing untrained model
2025-05-13 15:13:41,994:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:13:41,996:INFO:Starting cross validation
2025-05-13 15:13:41,998:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:45,903:INFO:Calculating mean and std
2025-05-13 15:13:45,904:INFO:Creating metrics dataframe
2025-05-13 15:13:45,905:INFO:Uploading results into container
2025-05-13 15:13:45,906:INFO:Uploading model into container now
2025-05-13 15:13:45,906:INFO:_master_model_container: 13
2025-05-13 15:13:45,906:INFO:_display_container: 2
2025-05-13 15:13:45,907:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:13:45,907:INFO:create_model() successfully completed......................................
2025-05-13 15:13:45,990:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:45,990:INFO:Creating metrics dataframe
2025-05-13 15:13:45,994:INFO:Initializing Dummy Classifier
2025-05-13 15:13:45,994:INFO:Total runtime is 0.9511892199516297 minutes
2025-05-13 15:13:45,995:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:45,995:INFO:Initializing create_model()
2025-05-13 15:13:45,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:45,995:INFO:Checking exceptions
2025-05-13 15:13:45,996:INFO:Importing libraries
2025-05-13 15:13:45,996:INFO:Copying training dataset
2025-05-13 15:13:46,006:INFO:Defining folds
2025-05-13 15:13:46,006:INFO:Declaring metric variables
2025-05-13 15:13:46,007:INFO:Importing untrained model
2025-05-13 15:13:46,009:INFO:Dummy Classifier Imported successfully
2025-05-13 15:13:46,011:INFO:Starting cross validation
2025-05-13 15:13:46,012:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:46,982:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,046:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,053:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,094:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,145:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,157:INFO:Calculating mean and std
2025-05-13 15:13:47,158:INFO:Creating metrics dataframe
2025-05-13 15:13:47,159:INFO:Uploading results into container
2025-05-13 15:13:47,159:INFO:Uploading model into container now
2025-05-13 15:13:47,159:INFO:_master_model_container: 14
2025-05-13 15:13:47,159:INFO:_display_container: 2
2025-05-13 15:13:47,159:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-13 15:13:47,159:INFO:create_model() successfully completed......................................
2025-05-13 15:13:47,234:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:47,234:INFO:Creating metrics dataframe
2025-05-13 15:13:47,238:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-13 15:13:47,241:INFO:Initializing create_model()
2025-05-13 15:13:47,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:47,241:INFO:Checking exceptions
2025-05-13 15:13:47,242:INFO:Importing libraries
2025-05-13 15:13:47,242:INFO:Copying training dataset
2025-05-13 15:13:47,252:INFO:Defining folds
2025-05-13 15:13:47,252:INFO:Declaring metric variables
2025-05-13 15:13:47,252:INFO:Importing untrained model
2025-05-13 15:13:47,252:INFO:Declaring custom model
2025-05-13 15:13:47,252:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:13:47,253:INFO:Cross validation set to False
2025-05-13 15:13:47,253:INFO:Fitting Model
2025-05-13 15:14:03,158:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:14:03,159:INFO:create_model() successfully completed......................................
2025-05-13 15:14:03,245:INFO:Initializing create_model()
2025-05-13 15:14:03,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:14:03,246:INFO:Checking exceptions
2025-05-13 15:14:03,246:INFO:Importing libraries
2025-05-13 15:14:03,246:INFO:Copying training dataset
2025-05-13 15:14:03,258:INFO:Defining folds
2025-05-13 15:14:03,258:INFO:Declaring metric variables
2025-05-13 15:14:03,258:INFO:Importing untrained model
2025-05-13 15:14:03,258:INFO:Declaring custom model
2025-05-13 15:14:03,259:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:14:03,260:INFO:Cross validation set to False
2025-05-13 15:14:03,260:INFO:Fitting Model
2025-05-13 15:14:04,294:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-13 15:14:04,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004644 seconds.
2025-05-13 15:14:04,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-13 15:14:04,305:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-13 15:14:04,305:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-13 15:14:04,305:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 27
2025-05-13 15:14:04,305:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-13 15:14:05,066:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:14:05,066:INFO:create_model() successfully completed......................................
2025-05-13 15:14:05,141:INFO:Initializing create_model()
2025-05-13 15:14:05,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:14:05,141:INFO:Checking exceptions
2025-05-13 15:14:05,142:INFO:Importing libraries
2025-05-13 15:14:05,142:INFO:Copying training dataset
2025-05-13 15:14:05,151:INFO:Defining folds
2025-05-13 15:14:05,151:INFO:Declaring metric variables
2025-05-13 15:14:05,151:INFO:Importing untrained model
2025-05-13 15:14:05,151:INFO:Declaring custom model
2025-05-13 15:14:05,151:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:14:05,152:INFO:Cross validation set to False
2025-05-13 15:14:05,152:INFO:Fitting Model
2025-05-13 15:14:07,395:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:14:07,395:INFO:create_model() successfully completed......................................
2025-05-13 15:14:07,478:INFO:_master_model_container: 14
2025-05-13 15:14:07,478:INFO:_display_container: 2
2025-05-13 15:14:07,478:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-13 15:14:07,478:INFO:compare_models() successfully completed......................................
2025-05-13 15:14:07,479:INFO:Initializing evaluate_model()
2025-05-13 15:14:07,479:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:14:07,486:INFO:Initializing plot_model()
2025-05-13 15:14:07,486:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:14:07,486:INFO:Checking exceptions
2025-05-13 15:14:07,490:INFO:Preloading libraries
2025-05-13 15:14:07,494:INFO:Copying training dataset
2025-05-13 15:14:07,494:INFO:Plot type: pipeline
2025-05-13 15:14:07,556:INFO:Visual Rendered Successfully
2025-05-13 15:14:07,633:INFO:plot_model() successfully completed......................................
2025-05-13 15:14:07,635:INFO:Initializing tune_model()
2025-05-13 15:14:07,635:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-13 15:14:07,635:INFO:Checking exceptions
2025-05-13 15:14:07,644:INFO:Copying training dataset
2025-05-13 15:14:07,653:INFO:Checking base model
2025-05-13 15:14:07,653:INFO:Base model : Gradient Boosting Classifier
2025-05-13 15:14:07,654:INFO:Declaring metric variables
2025-05-13 15:14:07,656:INFO:Defining Hyperparameters
2025-05-13 15:14:07,736:INFO:Tuning with n_jobs=-1
2025-05-13 15:14:07,736:INFO:Initializing RandomizedSearchCV
2025-05-13 15:14:45,989:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-13 15:14:45,992:INFO:Hyperparameter search completed
2025-05-13 15:14:45,992:INFO:SubProcess create_model() called ==================================
2025-05-13 15:14:45,993:INFO:Initializing create_model()
2025-05-13 15:14:45,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331be6f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-13 15:14:45,993:INFO:Checking exceptions
2025-05-13 15:14:45,993:INFO:Importing libraries
2025-05-13 15:14:45,993:INFO:Copying training dataset
2025-05-13 15:14:46,009:INFO:Defining folds
2025-05-13 15:14:46,009:INFO:Declaring metric variables
2025-05-13 15:14:46,018:INFO:Importing untrained model
2025-05-13 15:14:46,018:INFO:Declaring custom model
2025-05-13 15:14:46,020:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:14:46,023:INFO:Starting cross validation
2025-05-13 15:14:46,026:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:14:56,051:INFO:Calculating mean and std
2025-05-13 15:14:56,052:INFO:Creating metrics dataframe
2025-05-13 15:14:56,055:INFO:Finalizing model
2025-05-13 15:15:07,296:INFO:Uploading results into container
2025-05-13 15:15:07,297:INFO:Uploading model into container now
2025-05-13 15:15:07,297:INFO:_master_model_container: 15
2025-05-13 15:15:07,297:INFO:_display_container: 3
2025-05-13 15:15:07,298:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:15:07,298:INFO:create_model() successfully completed......................................
2025-05-13 15:15:07,430:INFO:SubProcess create_model() end ==================================
2025-05-13 15:15:07,430:INFO:choose_better activated
2025-05-13 15:15:07,431:INFO:SubProcess create_model() called ==================================
2025-05-13 15:15:07,432:INFO:Initializing create_model()
2025-05-13 15:15:07,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:15:07,432:INFO:Checking exceptions
2025-05-13 15:15:07,433:INFO:Importing libraries
2025-05-13 15:15:07,433:INFO:Copying training dataset
2025-05-13 15:15:07,443:INFO:Defining folds
2025-05-13 15:15:07,443:INFO:Declaring metric variables
2025-05-13 15:15:07,443:INFO:Importing untrained model
2025-05-13 15:15:07,443:INFO:Declaring custom model
2025-05-13 15:15:07,443:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:15:07,443:INFO:Starting cross validation
2025-05-13 15:15:07,444:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:15:20,739:INFO:Calculating mean and std
2025-05-13 15:15:20,741:INFO:Creating metrics dataframe
2025-05-13 15:15:20,745:INFO:Finalizing model
2025-05-13 15:15:36,998:INFO:Uploading results into container
2025-05-13 15:15:36,999:INFO:Uploading model into container now
2025-05-13 15:15:36,999:INFO:_master_model_container: 16
2025-05-13 15:15:36,999:INFO:_display_container: 4
2025-05-13 15:15:37,000:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:15:37,000:INFO:create_model() successfully completed......................................
2025-05-13 15:15:37,130:INFO:SubProcess create_model() end ==================================
2025-05-13 15:15:37,130:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4745
2025-05-13 15:15:37,131:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4906
2025-05-13 15:15:37,131:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-13 15:15:37,131:INFO:choose_better completed
2025-05-13 15:15:37,135:INFO:_master_model_container: 16
2025-05-13 15:15:37,135:INFO:_display_container: 3
2025-05-13 15:15:37,135:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:15:37,135:INFO:tune_model() successfully completed......................................
2025-05-13 15:15:37,226:INFO:Initializing evaluate_model()
2025-05-13 15:15:37,226:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:15:37,235:INFO:Initializing plot_model()
2025-05-13 15:15:37,235:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:15:37,235:INFO:Checking exceptions
2025-05-13 15:15:37,241:INFO:Preloading libraries
2025-05-13 15:15:37,251:INFO:Copying training dataset
2025-05-13 15:15:37,251:INFO:Plot type: pipeline
2025-05-13 15:15:37,309:INFO:Visual Rendered Successfully
2025-05-13 15:15:37,396:INFO:plot_model() successfully completed......................................
2025-05-13 15:15:37,398:INFO:Initializing interpret_model()
2025-05-13 15:15:37,398:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-13 15:15:37,398:INFO:Checking exceptions
2025-05-13 15:15:37,398:INFO:Soft dependency imported: shap: 0.47.2
2025-05-13 15:15:37,568:INFO:Initializing finalize_model()
2025-05-13 15:15:37,568:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-13 15:15:37,569:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:15:37,573:INFO:Initializing create_model()
2025-05-13 15:15:37,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:15:37,573:INFO:Checking exceptions
2025-05-13 15:15:37,573:INFO:Importing libraries
2025-05-13 15:15:37,573:INFO:Copying training dataset
2025-05-13 15:15:37,574:INFO:Defining folds
2025-05-13 15:15:37,574:INFO:Declaring metric variables
2025-05-13 15:15:37,574:INFO:Importing untrained model
2025-05-13 15:15:37,574:INFO:Declaring custom model
2025-05-13 15:15:37,574:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:15:37,575:INFO:Cross validation set to False
2025-05-13 15:15:37,575:INFO:Fitting Model
2025-05-13 15:15:54,143:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:15:54,143:INFO:create_model() successfully completed......................................
2025-05-13 15:15:54,245:INFO:_master_model_container: 16
2025-05-13 15:15:54,245:INFO:_display_container: 3
2025-05-13 15:15:54,269:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:15:54,269:INFO:finalize_model() successfully completed......................................
2025-05-13 15:15:54,396:INFO:Initializing save_model()
2025-05-13 15:15:54,396:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-13 15:15:54,396:INFO:Adding model into prep_pipe
2025-05-13 15:15:54,396:WARNING:Only Model saved as it was a pipeline.
2025-05-13 15:15:54,422:INFO:final_cancer_model.pkl saved in current working directory
2025-05-13 15:15:54,440:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:15:54,440:INFO:save_model() successfully completed......................................
2025-05-13 15:15:54,541:INFO:Initializing predict_model()
2025-05-13 15:15:54,541:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x33692b9c0>)
2025-05-13 15:15:54,541:INFO:Checking exceptions
2025-05-13 15:15:54,541:INFO:Preloading libraries
2025-05-13 15:15:54,542:INFO:Set up data.
2025-05-13 15:15:54,559:INFO:Set up index.
2025-05-13 15:15:55,442:INFO:Initializing blend_models()
2025-05-13 15:15:55,442:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-13 15:15:55,442:INFO:Checking exceptions
2025-05-13 15:15:55,451:INFO:Importing libraries
2025-05-13 15:15:55,451:INFO:Copying training dataset
2025-05-13 15:15:55,452:INFO:Getting model names
2025-05-13 15:15:55,453:INFO:SubProcess create_model() called ==================================
2025-05-13 15:15:55,455:INFO:Initializing create_model()
2025-05-13 15:15:55,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337385d50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:15:55,455:INFO:Checking exceptions
2025-05-13 15:15:55,455:INFO:Importing libraries
2025-05-13 15:15:55,456:INFO:Copying training dataset
2025-05-13 15:15:55,466:INFO:Defining folds
2025-05-13 15:15:55,466:INFO:Declaring metric variables
2025-05-13 15:15:55,467:INFO:Importing untrained model
2025-05-13 15:15:55,467:INFO:Declaring custom model
2025-05-13 15:15:55,469:INFO:Voting Classifier Imported successfully
2025-05-13 15:15:55,471:INFO:Starting cross validation
2025-05-13 15:15:55,472:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:16:11,942:INFO:Calculating mean and std
2025-05-13 15:16:11,945:INFO:Creating metrics dataframe
2025-05-13 15:16:11,954:INFO:Finalizing model
2025-05-13 15:16:28,349:INFO:Uploading results into container
2025-05-13 15:16:28,350:INFO:Uploading model into container now
2025-05-13 15:16:28,350:INFO:_master_model_container: 17
2025-05-13 15:16:28,351:INFO:_display_container: 4
2025-05-13 15:16:28,355:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-13 15:16:28,355:INFO:create_model() successfully completed......................................
2025-05-13 15:16:28,546:INFO:SubProcess create_model() end ==================================
2025-05-13 15:16:28,550:INFO:_master_model_container: 17
2025-05-13 15:16:28,550:INFO:_display_container: 4
2025-05-13 15:16:28,552:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-13 15:16:28,552:INFO:blend_models() successfully completed......................................
2025-05-13 15:16:28,642:INFO:Initializing evaluate_model()
2025-05-13 15:16:28,643:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:16:28,652:INFO:Initializing plot_model()
2025-05-13 15:16:28,653:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:16:28,653:INFO:Checking exceptions
2025-05-13 15:16:28,657:INFO:Preloading libraries
2025-05-13 15:16:28,782:INFO:Copying training dataset
2025-05-13 15:16:28,782:INFO:Plot type: pipeline
2025-05-13 15:16:28,843:INFO:Visual Rendered Successfully
2025-05-13 15:16:28,935:INFO:plot_model() successfully completed......................................
2025-05-13 15:16:28,943:INFO:Initializing predict_model()
2025-05-13 15:16:28,944:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x33f8c8fe0>)
2025-05-13 15:16:28,944:INFO:Checking exceptions
2025-05-13 15:16:28,944:INFO:Preloading libraries
2025-05-13 15:16:28,945:INFO:Set up data.
2025-05-13 15:16:28,967:INFO:Set up index.
2025-05-13 15:16:29,618:INFO:Initializing plot_model()
2025-05-13 15:16:29,618:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:16:29,618:INFO:Checking exceptions
2025-05-13 15:16:29,622:INFO:Preloading libraries
2025-05-13 15:16:29,626:INFO:Copying training dataset
2025-05-13 15:16:29,626:INFO:Plot type: confusion_matrix
2025-05-13 15:16:29,840:INFO:Fitting Model
2025-05-13 15:16:29,841:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:16:29,842:INFO:Scoring test/hold-out set
2025-05-13 15:16:29,921:INFO:Visual Rendered Successfully
2025-05-13 15:16:30,010:INFO:plot_model() successfully completed......................................
2025-05-13 15:16:30,011:INFO:Initializing plot_model()
2025-05-13 15:16:30,011:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:16:30,011:INFO:Checking exceptions
2025-05-13 15:16:30,015:INFO:Preloading libraries
2025-05-13 15:16:30,019:INFO:Copying training dataset
2025-05-13 15:16:30,019:INFO:Plot type: auc
2025-05-13 15:16:30,217:INFO:Fitting Model
2025-05-13 15:16:30,218:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:16:30,219:INFO:Scoring test/hold-out set
2025-05-13 15:16:30,338:INFO:Visual Rendered Successfully
2025-05-13 15:16:30,427:INFO:plot_model() successfully completed......................................
2025-05-13 15:16:30,428:INFO:Initializing plot_model()
2025-05-13 15:16:30,428:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:16:30,428:INFO:Checking exceptions
2025-05-13 15:16:30,432:INFO:Preloading libraries
2025-05-13 15:16:30,436:INFO:Copying training dataset
2025-05-13 15:16:30,436:INFO:Plot type: feature
2025-05-13 15:16:30,436:WARNING:No coef_ found. Trying feature_importances_
2025-05-13 15:16:30,509:INFO:Visual Rendered Successfully
2025-05-13 15:16:30,591:INFO:plot_model() successfully completed......................................
2025-05-13 15:38:44,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 15:38:44,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 15:38:44,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 15:38:44,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 15:38:45,012:INFO:PyCaret ClassificationExperiment
2025-05-13 15:38:45,012:INFO:Logging name: clf-default-name
2025-05-13 15:38:45,012:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-13 15:38:45,012:INFO:version 3.3.2
2025-05-13 15:38:45,012:INFO:Initializing setup()
2025-05-13 15:38:45,012:INFO:self.USI: 4919
2025-05-13 15:38:45,012:INFO:self._variable_keys: {'fold_groups_param', 'html_param', 'USI', 'fix_imbalance', 'log_plots_param', 'idx', 'fold_generator', 'exp_name_log', 'exp_id', 'y', 'is_multiclass', 'memory', 'gpu_param', 'y_test', 'pipeline', 'seed', '_ml_usecase', 'X_train', 'gpu_n_jobs_param', 'y_train', 'fold_shuffle_param', 'X', 'data', '_available_plots', 'X_test', 'target_param', 'n_jobs_param', 'logging_param'}
2025-05-13 15:38:45,012:INFO:Checking environment
2025-05-13 15:38:45,012:INFO:python_version: 3.11.0
2025-05-13 15:38:45,012:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-13 15:38:45,012:INFO:machine: arm64
2025-05-13 15:38:45,012:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:38:45,012:INFO:Memory: svmem(total=17179869184, available=3887300608, percent=77.4, used=6402818048, free=76447744, active=3830382592, inactive=3719823360, wired=2572435456)
2025-05-13 15:38:45,012:INFO:Physical Core: 12
2025-05-13 15:38:45,012:INFO:Logical Core: 12
2025-05-13 15:38:45,012:INFO:Checking libraries
2025-05-13 15:38:45,012:INFO:System:
2025-05-13 15:38:45,012:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-13 15:38:45,012:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-13 15:38:45,012:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:38:45,012:INFO:PyCaret required dependencies:
2025-05-13 15:38:45,037:INFO:                 pip: 22.3
2025-05-13 15:38:45,037:INFO:          setuptools: 65.5.0
2025-05-13 15:38:45,037:INFO:             pycaret: 3.3.2
2025-05-13 15:38:45,037:INFO:             IPython: 9.2.0
2025-05-13 15:38:45,037:INFO:          ipywidgets: 8.1.7
2025-05-13 15:38:45,037:INFO:                tqdm: 4.67.1
2025-05-13 15:38:45,037:INFO:               numpy: 1.26.4
2025-05-13 15:38:45,037:INFO:              pandas: 2.1.4
2025-05-13 15:38:45,037:INFO:              jinja2: 3.1.6
2025-05-13 15:38:45,037:INFO:               scipy: 1.11.4
2025-05-13 15:38:45,037:INFO:              joblib: 1.3.2
2025-05-13 15:38:45,037:INFO:             sklearn: 1.4.2
2025-05-13 15:38:45,037:INFO:                pyod: 2.0.5
2025-05-13 15:38:45,037:INFO:            imblearn: 0.13.0
2025-05-13 15:38:45,037:INFO:   category_encoders: 2.7.0
2025-05-13 15:38:45,037:INFO:            lightgbm: 4.6.0
2025-05-13 15:38:45,037:INFO:               numba: 0.61.2
2025-05-13 15:38:45,037:INFO:            requests: 2.32.3
2025-05-13 15:38:45,037:INFO:          matplotlib: 3.7.5
2025-05-13 15:38:45,038:INFO:          scikitplot: 0.3.7
2025-05-13 15:38:45,038:INFO:         yellowbrick: 1.5
2025-05-13 15:38:45,038:INFO:              plotly: 5.24.1
2025-05-13 15:38:45,038:INFO:    plotly-resampler: Not installed
2025-05-13 15:38:45,038:INFO:             kaleido: 0.2.1
2025-05-13 15:38:45,038:INFO:           schemdraw: 0.15
2025-05-13 15:38:45,038:INFO:         statsmodels: 0.14.4
2025-05-13 15:38:45,038:INFO:              sktime: 0.26.0
2025-05-13 15:38:45,038:INFO:               tbats: 1.1.3
2025-05-13 15:38:45,038:INFO:            pmdarima: 2.0.4
2025-05-13 15:38:45,038:INFO:              psutil: 7.0.0
2025-05-13 15:38:45,038:INFO:          markupsafe: 3.0.2
2025-05-13 15:38:45,038:INFO:             pickle5: Not installed
2025-05-13 15:38:45,038:INFO:         cloudpickle: 3.1.1
2025-05-13 15:38:45,038:INFO:         deprecation: 2.1.0
2025-05-13 15:38:45,038:INFO:              xxhash: 3.5.0
2025-05-13 15:38:45,038:INFO:           wurlitzer: 3.1.1
2025-05-13 15:38:45,038:INFO:PyCaret optional dependencies:
2025-05-13 15:38:45,043:INFO:                shap: 0.47.2
2025-05-13 15:38:45,043:INFO:           interpret: Not installed
2025-05-13 15:38:45,043:INFO:                umap: Not installed
2025-05-13 15:38:45,043:INFO:     ydata_profiling: Not installed
2025-05-13 15:38:45,043:INFO:  explainerdashboard: Not installed
2025-05-13 15:38:45,043:INFO:             autoviz: Not installed
2025-05-13 15:38:45,043:INFO:           fairlearn: Not installed
2025-05-13 15:38:45,043:INFO:          deepchecks: Not installed
2025-05-13 15:38:45,043:INFO:             xgboost: Not installed
2025-05-13 15:38:45,043:INFO:            catboost: Not installed
2025-05-13 15:38:45,043:INFO:              kmodes: Not installed
2025-05-13 15:38:45,043:INFO:             mlxtend: Not installed
2025-05-13 15:38:45,043:INFO:       statsforecast: Not installed
2025-05-13 15:38:45,043:INFO:        tune_sklearn: Not installed
2025-05-13 15:38:45,043:INFO:                 ray: Not installed
2025-05-13 15:38:45,043:INFO:            hyperopt: Not installed
2025-05-13 15:38:45,043:INFO:              optuna: 4.3.0
2025-05-13 15:38:45,043:INFO:               skopt: Not installed
2025-05-13 15:38:45,043:INFO:              mlflow: Not installed
2025-05-13 15:38:45,043:INFO:              gradio: Not installed
2025-05-13 15:38:45,043:INFO:             fastapi: Not installed
2025-05-13 15:38:45,043:INFO:             uvicorn: Not installed
2025-05-13 15:38:45,043:INFO:              m2cgen: Not installed
2025-05-13 15:38:45,043:INFO:           evidently: Not installed
2025-05-13 15:38:45,043:INFO:               fugue: Not installed
2025-05-13 15:38:45,043:INFO:           streamlit: Not installed
2025-05-13 15:38:45,043:INFO:             prophet: Not installed
2025-05-13 15:38:45,043:INFO:None
2025-05-13 15:38:45,043:INFO:Set up data.
2025-05-13 15:38:45,071:INFO:Set up folding strategy.
2025-05-13 15:38:45,071:INFO:Set up train/test split.
2025-05-13 15:38:45,091:INFO:Set up index.
2025-05-13 15:38:45,092:INFO:Assigning column types.
2025-05-13 15:38:45,095:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-13 15:38:45,113:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,115:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,146:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,157:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-13 15:38:45,175:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,204:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,215:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-13 15:38:45,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,276:INFO:Preparing preprocessing pipeline...
2025-05-13 15:38:45,277:INFO:Set up simple imputation.
2025-05-13 15:38:45,282:INFO:Set up encoding of ordinal features.
2025-05-13 15:38:45,290:INFO:Set up encoding of categorical features.
2025-05-13 15:38:45,290:INFO:Set up imbalanced handling.
2025-05-13 15:38:45,290:INFO:Set up column transformation.
2025-05-13 15:38:46,546:INFO:Finished creating preprocessing pipeline.
2025-05-13 15:38:46,561:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-13 15:38:46,561:INFO:Creating final display dataframe.
2025-05-13 15:38:47,001:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 14)
4        Transformed data shape      (106821, 27)
5   Transformed train set shape       (85902, 27)
6    Transformed test set shape       (20919, 27)
7              Numeric features                 6
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              4919
2025-05-13 15:38:47,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:47,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:47,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:47,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:47,068:INFO:setup() successfully completed in 2.06s...............
2025-05-13 15:38:47,068:INFO:Initializing compare_models()
2025-05-13 15:38:47,068:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-13 15:38:47,068:INFO:Checking exceptions
2025-05-13 15:38:47,076:INFO:Preparing display monitor
2025-05-13 15:38:47,108:INFO:Initializing Logistic Regression
2025-05-13 15:38:47,108:INFO:Total runtime is 2.9365221659342447e-06 minutes
2025-05-13 15:38:47,110:INFO:SubProcess create_model() called ==================================
2025-05-13 15:38:47,110:INFO:Initializing create_model()
2025-05-13 15:38:47,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:38:47,110:INFO:Checking exceptions
2025-05-13 15:38:47,110:INFO:Importing libraries
2025-05-13 15:38:47,110:INFO:Copying training dataset
2025-05-13 15:38:47,123:INFO:Defining folds
2025-05-13 15:38:47,123:INFO:Declaring metric variables
2025-05-13 15:38:47,124:INFO:Importing untrained model
2025-05-13 15:38:47,125:INFO:Logistic Regression Imported successfully
2025-05-13 15:38:47,128:INFO:Starting cross validation
2025-05-13 15:38:47,129:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:38:52,369:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,423:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,438:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,454:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,493:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,549:INFO:Calculating mean and std
2025-05-13 15:38:52,551:INFO:Creating metrics dataframe
2025-05-13 15:38:52,552:INFO:Uploading results into container
2025-05-13 15:38:52,553:INFO:Uploading model into container now
2025-05-13 15:38:52,553:INFO:_master_model_container: 1
2025-05-13 15:38:52,553:INFO:_display_container: 2
2025-05-13 15:38:52,554:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-13 15:38:52,554:INFO:create_model() successfully completed......................................
2025-05-13 15:38:52,612:INFO:SubProcess create_model() end ==================================
2025-05-13 15:38:52,613:INFO:Creating metrics dataframe
2025-05-13 15:38:52,615:INFO:Initializing K Neighbors Classifier
2025-05-13 15:38:52,615:INFO:Total runtime is 0.09178495407104492 minutes
2025-05-13 15:38:52,617:INFO:SubProcess create_model() called ==================================
2025-05-13 15:38:52,617:INFO:Initializing create_model()
2025-05-13 15:38:52,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:38:52,617:INFO:Checking exceptions
2025-05-13 15:38:52,617:INFO:Importing libraries
2025-05-13 15:38:52,617:INFO:Copying training dataset
2025-05-13 15:38:52,626:INFO:Defining folds
2025-05-13 15:38:52,626:INFO:Declaring metric variables
2025-05-13 15:38:52,627:INFO:Importing untrained model
2025-05-13 15:38:52,629:INFO:K Neighbors Classifier Imported successfully
2025-05-13 15:38:52,631:INFO:Starting cross validation
2025-05-13 15:38:52,632:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:38:58,431:INFO:Calculating mean and std
2025-05-13 15:38:58,433:INFO:Creating metrics dataframe
2025-05-13 15:38:58,438:INFO:Uploading results into container
2025-05-13 15:38:58,438:INFO:Uploading model into container now
2025-05-13 15:38:58,439:INFO:_master_model_container: 2
2025-05-13 15:38:58,439:INFO:_display_container: 2
2025-05-13 15:38:58,440:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-13 15:38:58,440:INFO:create_model() successfully completed......................................
2025-05-13 15:38:58,526:INFO:SubProcess create_model() end ==================================
2025-05-13 15:38:58,526:INFO:Creating metrics dataframe
2025-05-13 15:38:58,530:INFO:Initializing Naive Bayes
2025-05-13 15:38:58,530:INFO:Total runtime is 0.1903595010439555 minutes
2025-05-13 15:38:58,531:INFO:SubProcess create_model() called ==================================
2025-05-13 15:38:58,531:INFO:Initializing create_model()
2025-05-13 15:38:58,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:38:58,531:INFO:Checking exceptions
2025-05-13 15:38:58,532:INFO:Importing libraries
2025-05-13 15:38:58,532:INFO:Copying training dataset
2025-05-13 15:38:58,542:INFO:Defining folds
2025-05-13 15:38:58,542:INFO:Declaring metric variables
2025-05-13 15:38:58,543:INFO:Importing untrained model
2025-05-13 15:38:58,544:INFO:Naive Bayes Imported successfully
2025-05-13 15:38:58,547:INFO:Starting cross validation
2025-05-13 15:38:58,548:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:00,749:INFO:Calculating mean and std
2025-05-13 15:39:00,749:INFO:Creating metrics dataframe
2025-05-13 15:39:00,750:INFO:Uploading results into container
2025-05-13 15:39:00,751:INFO:Uploading model into container now
2025-05-13 15:39:00,751:INFO:_master_model_container: 3
2025-05-13 15:39:00,751:INFO:_display_container: 2
2025-05-13 15:39:00,751:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-13 15:39:00,751:INFO:create_model() successfully completed......................................
2025-05-13 15:39:00,821:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:00,821:INFO:Creating metrics dataframe
2025-05-13 15:39:00,825:INFO:Initializing Decision Tree Classifier
2025-05-13 15:39:00,825:INFO:Total runtime is 0.2286062002182007 minutes
2025-05-13 15:39:00,826:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:00,826:INFO:Initializing create_model()
2025-05-13 15:39:00,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:00,826:INFO:Checking exceptions
2025-05-13 15:39:00,826:INFO:Importing libraries
2025-05-13 15:39:00,826:INFO:Copying training dataset
2025-05-13 15:39:00,835:INFO:Defining folds
2025-05-13 15:39:00,835:INFO:Declaring metric variables
2025-05-13 15:39:00,836:INFO:Importing untrained model
2025-05-13 15:39:00,837:INFO:Decision Tree Classifier Imported successfully
2025-05-13 15:39:00,839:INFO:Starting cross validation
2025-05-13 15:39:00,841:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:02,424:INFO:Calculating mean and std
2025-05-13 15:39:02,425:INFO:Creating metrics dataframe
2025-05-13 15:39:02,426:INFO:Uploading results into container
2025-05-13 15:39:02,426:INFO:Uploading model into container now
2025-05-13 15:39:02,426:INFO:_master_model_container: 4
2025-05-13 15:39:02,427:INFO:_display_container: 2
2025-05-13 15:39:02,427:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-13 15:39:02,427:INFO:create_model() successfully completed......................................
2025-05-13 15:39:02,470:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:02,471:INFO:Creating metrics dataframe
2025-05-13 15:39:02,474:INFO:Initializing SVM - Linear Kernel
2025-05-13 15:39:02,474:INFO:Total runtime is 0.2560910701751709 minutes
2025-05-13 15:39:02,475:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:02,475:INFO:Initializing create_model()
2025-05-13 15:39:02,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:02,475:INFO:Checking exceptions
2025-05-13 15:39:02,475:INFO:Importing libraries
2025-05-13 15:39:02,475:INFO:Copying training dataset
2025-05-13 15:39:02,484:INFO:Defining folds
2025-05-13 15:39:02,484:INFO:Declaring metric variables
2025-05-13 15:39:02,485:INFO:Importing untrained model
2025-05-13 15:39:02,487:INFO:SVM - Linear Kernel Imported successfully
2025-05-13 15:39:02,489:INFO:Starting cross validation
2025-05-13 15:39:02,490:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:06,111:INFO:Calculating mean and std
2025-05-13 15:39:06,114:INFO:Creating metrics dataframe
2025-05-13 15:39:06,118:INFO:Uploading results into container
2025-05-13 15:39:06,119:INFO:Uploading model into container now
2025-05-13 15:39:06,119:INFO:_master_model_container: 5
2025-05-13 15:39:06,119:INFO:_display_container: 2
2025-05-13 15:39:06,120:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-13 15:39:06,120:INFO:create_model() successfully completed......................................
2025-05-13 15:39:06,209:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:06,209:INFO:Creating metrics dataframe
2025-05-13 15:39:06,213:INFO:Initializing Ridge Classifier
2025-05-13 15:39:06,213:INFO:Total runtime is 0.3184064189592997 minutes
2025-05-13 15:39:06,214:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:06,214:INFO:Initializing create_model()
2025-05-13 15:39:06,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:06,214:INFO:Checking exceptions
2025-05-13 15:39:06,214:INFO:Importing libraries
2025-05-13 15:39:06,215:INFO:Copying training dataset
2025-05-13 15:39:06,226:INFO:Defining folds
2025-05-13 15:39:06,226:INFO:Declaring metric variables
2025-05-13 15:39:06,227:INFO:Importing untrained model
2025-05-13 15:39:06,228:INFO:Ridge Classifier Imported successfully
2025-05-13 15:39:06,230:INFO:Starting cross validation
2025-05-13 15:39:06,231:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:07,261:INFO:Calculating mean and std
2025-05-13 15:39:07,261:INFO:Creating metrics dataframe
2025-05-13 15:39:07,263:INFO:Uploading results into container
2025-05-13 15:39:07,263:INFO:Uploading model into container now
2025-05-13 15:39:07,263:INFO:_master_model_container: 6
2025-05-13 15:39:07,263:INFO:_display_container: 2
2025-05-13 15:39:07,263:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-13 15:39:07,263:INFO:create_model() successfully completed......................................
2025-05-13 15:39:07,310:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:07,310:INFO:Creating metrics dataframe
2025-05-13 15:39:07,313:INFO:Initializing Random Forest Classifier
2025-05-13 15:39:07,313:INFO:Total runtime is 0.3367486516634623 minutes
2025-05-13 15:39:07,314:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:07,314:INFO:Initializing create_model()
2025-05-13 15:39:07,315:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:07,315:INFO:Checking exceptions
2025-05-13 15:39:07,315:INFO:Importing libraries
2025-05-13 15:39:07,315:INFO:Copying training dataset
2025-05-13 15:39:07,325:INFO:Defining folds
2025-05-13 15:39:07,325:INFO:Declaring metric variables
2025-05-13 15:39:07,326:INFO:Importing untrained model
2025-05-13 15:39:07,327:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:39:07,329:INFO:Starting cross validation
2025-05-13 15:39:07,330:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:13,517:INFO:Calculating mean and std
2025-05-13 15:39:13,524:INFO:Creating metrics dataframe
2025-05-13 15:39:13,529:INFO:Uploading results into container
2025-05-13 15:39:13,529:INFO:Uploading model into container now
2025-05-13 15:39:13,530:INFO:_master_model_container: 7
2025-05-13 15:39:13,530:INFO:_display_container: 2
2025-05-13 15:39:13,531:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:39:13,531:INFO:create_model() successfully completed......................................
2025-05-13 15:39:13,613:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:13,613:INFO:Creating metrics dataframe
2025-05-13 15:39:13,617:INFO:Initializing Quadratic Discriminant Analysis
2025-05-13 15:39:13,617:INFO:Total runtime is 0.4418077707290649 minutes
2025-05-13 15:39:13,618:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:13,618:INFO:Initializing create_model()
2025-05-13 15:39:13,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:13,618:INFO:Checking exceptions
2025-05-13 15:39:13,618:INFO:Importing libraries
2025-05-13 15:39:13,619:INFO:Copying training dataset
2025-05-13 15:39:13,635:INFO:Defining folds
2025-05-13 15:39:13,635:INFO:Declaring metric variables
2025-05-13 15:39:13,637:INFO:Importing untrained model
2025-05-13 15:39:13,639:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-13 15:39:13,641:INFO:Starting cross validation
2025-05-13 15:39:13,642:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:14,572:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:14,604:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:14,626:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:14,637:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:14,643:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:14,694:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:14,703:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:15,990:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:16,051:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:16,062:INFO:Calculating mean and std
2025-05-13 15:39:16,063:INFO:Creating metrics dataframe
2025-05-13 15:39:16,064:INFO:Uploading results into container
2025-05-13 15:39:16,064:INFO:Uploading model into container now
2025-05-13 15:39:16,064:INFO:_master_model_container: 8
2025-05-13 15:39:16,064:INFO:_display_container: 2
2025-05-13 15:39:16,064:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-13 15:39:16,064:INFO:create_model() successfully completed......................................
2025-05-13 15:39:16,109:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:16,109:INFO:Creating metrics dataframe
2025-05-13 15:39:16,112:INFO:Initializing Ada Boost Classifier
2025-05-13 15:39:16,112:INFO:Total runtime is 0.48340231974919634 minutes
2025-05-13 15:39:16,114:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:16,114:INFO:Initializing create_model()
2025-05-13 15:39:16,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:16,114:INFO:Checking exceptions
2025-05-13 15:39:16,114:INFO:Importing libraries
2025-05-13 15:39:16,114:INFO:Copying training dataset
2025-05-13 15:39:16,129:INFO:Defining folds
2025-05-13 15:39:16,129:INFO:Declaring metric variables
2025-05-13 15:39:16,130:INFO:Importing untrained model
2025-05-13 15:39:16,132:INFO:Ada Boost Classifier Imported successfully
2025-05-13 15:39:16,134:INFO:Starting cross validation
2025-05-13 15:39:16,135:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:17,048:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:17,069:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:17,089:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:17,096:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:17,097:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:19,884:INFO:Calculating mean and std
2025-05-13 15:39:19,888:INFO:Creating metrics dataframe
2025-05-13 15:39:19,894:INFO:Uploading results into container
2025-05-13 15:39:19,895:INFO:Uploading model into container now
2025-05-13 15:39:19,895:INFO:_master_model_container: 9
2025-05-13 15:39:19,896:INFO:_display_container: 2
2025-05-13 15:39:19,896:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-13 15:39:19,896:INFO:create_model() successfully completed......................................
2025-05-13 15:39:19,990:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:19,991:INFO:Creating metrics dataframe
2025-05-13 15:39:19,995:INFO:Initializing Gradient Boosting Classifier
2025-05-13 15:39:19,995:INFO:Total runtime is 0.5481151382128397 minutes
2025-05-13 15:39:19,997:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:19,997:INFO:Initializing create_model()
2025-05-13 15:39:19,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:19,997:INFO:Checking exceptions
2025-05-13 15:39:19,997:INFO:Importing libraries
2025-05-13 15:39:19,997:INFO:Copying training dataset
2025-05-13 15:39:20,012:INFO:Defining folds
2025-05-13 15:39:20,012:INFO:Declaring metric variables
2025-05-13 15:39:20,014:INFO:Importing untrained model
2025-05-13 15:39:20,016:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:39:20,018:INFO:Starting cross validation
2025-05-13 15:39:20,020:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:32,940:INFO:Calculating mean and std
2025-05-13 15:39:32,941:INFO:Creating metrics dataframe
2025-05-13 15:39:32,942:INFO:Uploading results into container
2025-05-13 15:39:32,942:INFO:Uploading model into container now
2025-05-13 15:39:32,943:INFO:_master_model_container: 10
2025-05-13 15:39:32,943:INFO:_display_container: 2
2025-05-13 15:39:32,943:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:39:32,943:INFO:create_model() successfully completed......................................
2025-05-13 15:39:32,990:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:32,990:INFO:Creating metrics dataframe
2025-05-13 15:39:32,994:INFO:Initializing Linear Discriminant Analysis
2025-05-13 15:39:32,994:INFO:Total runtime is 0.7647580186525981 minutes
2025-05-13 15:39:32,995:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:32,995:INFO:Initializing create_model()
2025-05-13 15:39:32,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:32,995:INFO:Checking exceptions
2025-05-13 15:39:32,995:INFO:Importing libraries
2025-05-13 15:39:32,995:INFO:Copying training dataset
2025-05-13 15:39:33,005:INFO:Defining folds
2025-05-13 15:39:33,005:INFO:Declaring metric variables
2025-05-13 15:39:33,007:INFO:Importing untrained model
2025-05-13 15:39:33,008:INFO:Linear Discriminant Analysis Imported successfully
2025-05-13 15:39:33,010:INFO:Starting cross validation
2025-05-13 15:39:33,011:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:34,122:INFO:Calculating mean and std
2025-05-13 15:39:34,123:INFO:Creating metrics dataframe
2025-05-13 15:39:34,124:INFO:Uploading results into container
2025-05-13 15:39:34,124:INFO:Uploading model into container now
2025-05-13 15:39:34,124:INFO:_master_model_container: 11
2025-05-13 15:39:34,124:INFO:_display_container: 2
2025-05-13 15:39:34,125:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-13 15:39:34,125:INFO:create_model() successfully completed......................................
2025-05-13 15:39:34,166:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:34,166:INFO:Creating metrics dataframe
2025-05-13 15:39:34,171:INFO:Initializing Extra Trees Classifier
2025-05-13 15:39:34,171:INFO:Total runtime is 0.7843758344650269 minutes
2025-05-13 15:39:34,172:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:34,172:INFO:Initializing create_model()
2025-05-13 15:39:34,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:34,172:INFO:Checking exceptions
2025-05-13 15:39:34,172:INFO:Importing libraries
2025-05-13 15:39:34,172:INFO:Copying training dataset
2025-05-13 15:39:34,182:INFO:Defining folds
2025-05-13 15:39:34,182:INFO:Declaring metric variables
2025-05-13 15:39:34,184:INFO:Importing untrained model
2025-05-13 15:39:34,185:INFO:Extra Trees Classifier Imported successfully
2025-05-13 15:39:34,187:INFO:Starting cross validation
2025-05-13 15:39:34,188:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:38,694:INFO:Calculating mean and std
2025-05-13 15:39:38,698:INFO:Creating metrics dataframe
2025-05-13 15:39:38,704:INFO:Uploading results into container
2025-05-13 15:39:38,705:INFO:Uploading model into container now
2025-05-13 15:39:38,706:INFO:_master_model_container: 12
2025-05-13 15:39:38,706:INFO:_display_container: 2
2025-05-13 15:39:38,707:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-13 15:39:38,708:INFO:create_model() successfully completed......................................
2025-05-13 15:39:38,816:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:38,816:INFO:Creating metrics dataframe
2025-05-13 15:39:38,820:INFO:Initializing Light Gradient Boosting Machine
2025-05-13 15:39:38,820:INFO:Total runtime is 0.8618667523066204 minutes
2025-05-13 15:39:38,822:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:38,822:INFO:Initializing create_model()
2025-05-13 15:39:38,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:38,822:INFO:Checking exceptions
2025-05-13 15:39:38,822:INFO:Importing libraries
2025-05-13 15:39:38,822:INFO:Copying training dataset
2025-05-13 15:39:38,838:INFO:Defining folds
2025-05-13 15:39:38,838:INFO:Declaring metric variables
2025-05-13 15:39:38,840:INFO:Importing untrained model
2025-05-13 15:39:38,841:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:39:38,844:INFO:Starting cross validation
2025-05-13 15:39:38,845:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:43,198:INFO:Calculating mean and std
2025-05-13 15:39:43,199:INFO:Creating metrics dataframe
2025-05-13 15:39:43,200:INFO:Uploading results into container
2025-05-13 15:39:43,201:INFO:Uploading model into container now
2025-05-13 15:39:43,201:INFO:_master_model_container: 13
2025-05-13 15:39:43,201:INFO:_display_container: 2
2025-05-13 15:39:43,202:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:39:43,202:INFO:create_model() successfully completed......................................
2025-05-13 15:39:43,256:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:43,256:INFO:Creating metrics dataframe
2025-05-13 15:39:43,260:INFO:Initializing Dummy Classifier
2025-05-13 15:39:43,260:INFO:Total runtime is 0.9358652194341024 minutes
2025-05-13 15:39:43,261:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:43,262:INFO:Initializing create_model()
2025-05-13 15:39:43,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:43,262:INFO:Checking exceptions
2025-05-13 15:39:43,262:INFO:Importing libraries
2025-05-13 15:39:43,262:INFO:Copying training dataset
2025-05-13 15:39:43,271:INFO:Defining folds
2025-05-13 15:39:43,271:INFO:Declaring metric variables
2025-05-13 15:39:43,273:INFO:Importing untrained model
2025-05-13 15:39:43,274:INFO:Dummy Classifier Imported successfully
2025-05-13 15:39:43,276:INFO:Starting cross validation
2025-05-13 15:39:43,277:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:44,246:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,246:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,257:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,268:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,343:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,362:INFO:Calculating mean and std
2025-05-13 15:39:44,363:INFO:Creating metrics dataframe
2025-05-13 15:39:44,365:INFO:Uploading results into container
2025-05-13 15:39:44,365:INFO:Uploading model into container now
2025-05-13 15:39:44,365:INFO:_master_model_container: 14
2025-05-13 15:39:44,365:INFO:_display_container: 2
2025-05-13 15:39:44,365:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-13 15:39:44,366:INFO:create_model() successfully completed......................................
2025-05-13 15:39:44,413:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:44,413:INFO:Creating metrics dataframe
2025-05-13 15:39:44,419:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-13 15:39:44,422:INFO:Initializing create_model()
2025-05-13 15:39:44,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:44,422:INFO:Checking exceptions
2025-05-13 15:39:44,423:INFO:Importing libraries
2025-05-13 15:39:44,423:INFO:Copying training dataset
2025-05-13 15:39:44,432:INFO:Defining folds
2025-05-13 15:39:44,432:INFO:Declaring metric variables
2025-05-13 15:39:44,432:INFO:Importing untrained model
2025-05-13 15:39:44,432:INFO:Declaring custom model
2025-05-13 15:39:44,432:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:39:44,433:INFO:Cross validation set to False
2025-05-13 15:39:44,433:INFO:Fitting Model
2025-05-13 15:40:00,069:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:40:00,070:INFO:create_model() successfully completed......................................
2025-05-13 15:40:00,121:INFO:Initializing create_model()
2025-05-13 15:40:00,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:40:00,121:INFO:Checking exceptions
2025-05-13 15:40:00,122:INFO:Importing libraries
2025-05-13 15:40:00,122:INFO:Copying training dataset
2025-05-13 15:40:00,131:INFO:Defining folds
2025-05-13 15:40:00,131:INFO:Declaring metric variables
2025-05-13 15:40:00,131:INFO:Importing untrained model
2025-05-13 15:40:00,131:INFO:Declaring custom model
2025-05-13 15:40:00,132:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:40:00,132:INFO:Cross validation set to False
2025-05-13 15:40:00,132:INFO:Fitting Model
2025-05-13 15:40:01,091:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-13 15:40:01,104:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008033 seconds.
2025-05-13 15:40:01,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-13 15:40:01,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-13 15:40:01,104:INFO:[LightGBM] [Info] Total Bins 6630
2025-05-13 15:40:01,104:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 26
2025-05-13 15:40:01,104:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-13 15:40:01,859:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:40:01,859:INFO:create_model() successfully completed......................................
2025-05-13 15:40:01,908:INFO:Initializing create_model()
2025-05-13 15:40:01,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:40:01,908:INFO:Checking exceptions
2025-05-13 15:40:01,909:INFO:Importing libraries
2025-05-13 15:40:01,909:INFO:Copying training dataset
2025-05-13 15:40:01,919:INFO:Defining folds
2025-05-13 15:40:01,919:INFO:Declaring metric variables
2025-05-13 15:40:01,919:INFO:Importing untrained model
2025-05-13 15:40:01,919:INFO:Declaring custom model
2025-05-13 15:40:01,919:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:40:01,920:INFO:Cross validation set to False
2025-05-13 15:40:01,920:INFO:Fitting Model
2025-05-13 15:40:04,311:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:40:04,311:INFO:create_model() successfully completed......................................
2025-05-13 15:40:04,360:INFO:_master_model_container: 14
2025-05-13 15:40:04,360:INFO:_display_container: 2
2025-05-13 15:40:04,360:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-13 15:40:04,361:INFO:compare_models() successfully completed......................................
2025-05-13 15:40:04,361:INFO:Initializing evaluate_model()
2025-05-13 15:40:04,361:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:40:04,367:INFO:Initializing plot_model()
2025-05-13 15:40:04,367:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:40:04,367:INFO:Checking exceptions
2025-05-13 15:40:04,371:INFO:Preloading libraries
2025-05-13 15:40:04,374:INFO:Copying training dataset
2025-05-13 15:40:04,374:INFO:Plot type: pipeline
2025-05-13 15:40:04,461:INFO:Visual Rendered Successfully
2025-05-13 15:40:04,506:INFO:plot_model() successfully completed......................................
2025-05-13 15:40:04,508:INFO:Initializing tune_model()
2025-05-13 15:40:04,508:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-13 15:40:04,508:INFO:Checking exceptions
2025-05-13 15:40:04,516:INFO:Copying training dataset
2025-05-13 15:40:04,523:INFO:Checking base model
2025-05-13 15:40:04,523:INFO:Base model : Gradient Boosting Classifier
2025-05-13 15:40:04,524:INFO:Declaring metric variables
2025-05-13 15:40:04,525:INFO:Defining Hyperparameters
2025-05-13 15:40:04,569:INFO:Tuning with n_jobs=-1
2025-05-13 15:40:04,569:INFO:Initializing RandomizedSearchCV
2025-05-13 15:40:45,144:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-13 15:40:45,149:INFO:Hyperparameter search completed
2025-05-13 15:40:45,149:INFO:SubProcess create_model() called ==================================
2025-05-13 15:40:45,150:INFO:Initializing create_model()
2025-05-13 15:40:45,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325fb0410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-13 15:40:45,150:INFO:Checking exceptions
2025-05-13 15:40:45,150:INFO:Importing libraries
2025-05-13 15:40:45,150:INFO:Copying training dataset
2025-05-13 15:40:45,163:INFO:Defining folds
2025-05-13 15:40:45,163:INFO:Declaring metric variables
2025-05-13 15:40:45,166:INFO:Importing untrained model
2025-05-13 15:40:45,166:INFO:Declaring custom model
2025-05-13 15:40:45,169:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:40:45,171:INFO:Starting cross validation
2025-05-13 15:40:45,174:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:40:54,838:INFO:Calculating mean and std
2025-05-13 15:40:54,839:INFO:Creating metrics dataframe
2025-05-13 15:40:54,842:INFO:Finalizing model
2025-05-13 15:41:05,382:INFO:Uploading results into container
2025-05-13 15:41:05,383:INFO:Uploading model into container now
2025-05-13 15:41:05,384:INFO:_master_model_container: 15
2025-05-13 15:41:05,384:INFO:_display_container: 3
2025-05-13 15:41:05,384:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:41:05,384:INFO:create_model() successfully completed......................................
2025-05-13 15:41:05,481:INFO:SubProcess create_model() end ==================================
2025-05-13 15:41:05,481:INFO:choose_better activated
2025-05-13 15:41:05,483:INFO:SubProcess create_model() called ==================================
2025-05-13 15:41:05,483:INFO:Initializing create_model()
2025-05-13 15:41:05,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:41:05,485:INFO:Checking exceptions
2025-05-13 15:41:05,486:INFO:Importing libraries
2025-05-13 15:41:05,486:INFO:Copying training dataset
2025-05-13 15:41:05,496:INFO:Defining folds
2025-05-13 15:41:05,496:INFO:Declaring metric variables
2025-05-13 15:41:05,496:INFO:Importing untrained model
2025-05-13 15:41:05,496:INFO:Declaring custom model
2025-05-13 15:41:05,496:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:41:05,496:INFO:Starting cross validation
2025-05-13 15:41:05,497:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:41:18,521:INFO:Calculating mean and std
2025-05-13 15:41:18,522:INFO:Creating metrics dataframe
2025-05-13 15:41:18,525:INFO:Finalizing model
2025-05-13 15:41:34,251:INFO:Uploading results into container
2025-05-13 15:41:34,251:INFO:Uploading model into container now
2025-05-13 15:41:34,252:INFO:_master_model_container: 16
2025-05-13 15:41:34,252:INFO:_display_container: 4
2025-05-13 15:41:34,252:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:41:34,252:INFO:create_model() successfully completed......................................
2025-05-13 15:41:34,332:INFO:SubProcess create_model() end ==================================
2025-05-13 15:41:34,333:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4809
2025-05-13 15:41:34,333:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4906
2025-05-13 15:41:34,333:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-13 15:41:34,333:INFO:choose_better completed
2025-05-13 15:41:34,337:INFO:_master_model_container: 16
2025-05-13 15:41:34,337:INFO:_display_container: 3
2025-05-13 15:41:34,337:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:41:34,337:INFO:tune_model() successfully completed......................................
2025-05-13 15:41:34,387:INFO:Initializing evaluate_model()
2025-05-13 15:41:34,387:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:41:34,395:INFO:Initializing plot_model()
2025-05-13 15:41:34,395:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:41:34,395:INFO:Checking exceptions
2025-05-13 15:41:34,401:INFO:Preloading libraries
2025-05-13 15:41:34,410:INFO:Copying training dataset
2025-05-13 15:41:34,410:INFO:Plot type: pipeline
2025-05-13 15:41:34,473:INFO:Visual Rendered Successfully
2025-05-13 15:41:34,517:INFO:plot_model() successfully completed......................................
2025-05-13 15:41:34,519:INFO:Initializing interpret_model()
2025-05-13 15:41:34,519:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-13 15:41:34,519:INFO:Checking exceptions
2025-05-13 15:41:34,519:INFO:Soft dependency imported: shap: 0.47.2
2025-05-13 15:41:34,802:INFO:Initializing finalize_model()
2025-05-13 15:41:34,802:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-13 15:41:34,802:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:41:34,806:INFO:Initializing create_model()
2025-05-13 15:41:34,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:41:34,806:INFO:Checking exceptions
2025-05-13 15:41:34,807:INFO:Importing libraries
2025-05-13 15:41:34,807:INFO:Copying training dataset
2025-05-13 15:41:34,807:INFO:Defining folds
2025-05-13 15:41:34,807:INFO:Declaring metric variables
2025-05-13 15:41:34,807:INFO:Importing untrained model
2025-05-13 15:41:34,807:INFO:Declaring custom model
2025-05-13 15:41:34,807:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:41:34,809:INFO:Cross validation set to False
2025-05-13 15:41:34,809:INFO:Fitting Model
2025-05-13 15:41:50,493:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:41:50,494:INFO:create_model() successfully completed......................................
2025-05-13 15:41:50,544:INFO:_master_model_container: 16
2025-05-13 15:41:50,544:INFO:_display_container: 3
2025-05-13 15:41:50,560:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:41:50,560:INFO:finalize_model() successfully completed......................................
2025-05-13 15:41:50,638:INFO:Initializing save_model()
2025-05-13 15:41:50,638:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-13 15:41:50,638:INFO:Adding model into prep_pipe
2025-05-13 15:41:50,638:WARNING:Only Model saved as it was a pipeline.
2025-05-13 15:41:50,661:INFO:final_cancer_model.pkl saved in current working directory
2025-05-13 15:41:50,677:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:41:50,677:INFO:save_model() successfully completed......................................
2025-05-13 15:41:50,739:INFO:Initializing predict_model()
2025-05-13 15:41:50,739:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x325f053a0>)
2025-05-13 15:41:50,739:INFO:Checking exceptions
2025-05-13 15:41:50,739:INFO:Preloading libraries
2025-05-13 15:41:50,740:INFO:Set up data.
2025-05-13 15:41:50,754:INFO:Set up index.
2025-05-13 15:41:51,535:INFO:Initializing blend_models()
2025-05-13 15:41:51,535:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-13 15:41:51,535:INFO:Checking exceptions
2025-05-13 15:41:51,544:INFO:Importing libraries
2025-05-13 15:41:51,544:INFO:Copying training dataset
2025-05-13 15:41:51,545:INFO:Getting model names
2025-05-13 15:41:51,546:INFO:SubProcess create_model() called ==================================
2025-05-13 15:41:51,548:INFO:Initializing create_model()
2025-05-13 15:41:51,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325feed50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:41:51,548:INFO:Checking exceptions
2025-05-13 15:41:51,548:INFO:Importing libraries
2025-05-13 15:41:51,548:INFO:Copying training dataset
2025-05-13 15:41:51,557:INFO:Defining folds
2025-05-13 15:41:51,557:INFO:Declaring metric variables
2025-05-13 15:41:51,558:INFO:Importing untrained model
2025-05-13 15:41:51,558:INFO:Declaring custom model
2025-05-13 15:41:51,560:INFO:Voting Classifier Imported successfully
2025-05-13 15:41:51,562:INFO:Starting cross validation
2025-05-13 15:41:51,563:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:42:08,254:INFO:Calculating mean and std
2025-05-13 15:42:08,257:INFO:Creating metrics dataframe
2025-05-13 15:42:08,271:INFO:Finalizing model
2025-05-13 15:42:24,806:INFO:Uploading results into container
2025-05-13 15:42:24,810:INFO:Uploading model into container now
2025-05-13 15:42:24,810:INFO:_master_model_container: 17
2025-05-13 15:42:24,810:INFO:_display_container: 4
2025-05-13 15:42:24,814:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-13 15:42:24,814:INFO:create_model() successfully completed......................................
2025-05-13 15:42:24,927:INFO:SubProcess create_model() end ==================================
2025-05-13 15:42:24,931:INFO:_master_model_container: 17
2025-05-13 15:42:24,931:INFO:_display_container: 4
2025-05-13 15:42:24,933:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-13 15:42:24,933:INFO:blend_models() successfully completed......................................
2025-05-13 15:42:24,988:INFO:Initializing evaluate_model()
2025-05-13 15:42:24,988:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:42:25,000:INFO:Initializing plot_model()
2025-05-13 15:42:25,000:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:42:25,000:INFO:Checking exceptions
2025-05-13 15:42:25,005:INFO:Preloading libraries
2025-05-13 15:42:25,135:INFO:Copying training dataset
2025-05-13 15:42:25,135:INFO:Plot type: pipeline
2025-05-13 15:42:25,195:INFO:Visual Rendered Successfully
2025-05-13 15:42:25,244:INFO:plot_model() successfully completed......................................
2025-05-13 15:42:25,253:INFO:Initializing predict_model()
2025-05-13 15:42:25,253:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x32fb43600>)
2025-05-13 15:42:25,253:INFO:Checking exceptions
2025-05-13 15:42:25,253:INFO:Preloading libraries
2025-05-13 15:42:25,254:INFO:Set up data.
2025-05-13 15:42:25,269:INFO:Set up index.
2025-05-13 15:42:25,839:INFO:Initializing plot_model()
2025-05-13 15:42:25,839:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:42:25,839:INFO:Checking exceptions
2025-05-13 15:42:25,844:INFO:Preloading libraries
2025-05-13 15:42:25,847:INFO:Copying training dataset
2025-05-13 15:42:25,847:INFO:Plot type: confusion_matrix
2025-05-13 15:42:26,040:INFO:Fitting Model
2025-05-13 15:42:26,042:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:42:26,043:INFO:Scoring test/hold-out set
2025-05-13 15:42:26,117:INFO:Visual Rendered Successfully
2025-05-13 15:42:26,166:INFO:plot_model() successfully completed......................................
2025-05-13 15:42:26,167:INFO:Initializing plot_model()
2025-05-13 15:42:26,167:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:42:26,167:INFO:Checking exceptions
2025-05-13 15:42:26,171:INFO:Preloading libraries
2025-05-13 15:42:26,174:INFO:Copying training dataset
2025-05-13 15:42:26,175:INFO:Plot type: auc
2025-05-13 15:42:26,361:INFO:Fitting Model
2025-05-13 15:42:26,362:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:42:26,363:INFO:Scoring test/hold-out set
2025-05-13 15:42:26,474:INFO:Visual Rendered Successfully
2025-05-13 15:42:26,521:INFO:plot_model() successfully completed......................................
2025-05-13 15:42:26,521:INFO:Initializing plot_model()
2025-05-13 15:42:26,521:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:42:26,521:INFO:Checking exceptions
2025-05-13 15:42:26,527:INFO:Preloading libraries
2025-05-13 15:42:26,530:INFO:Copying training dataset
2025-05-13 15:42:26,530:INFO:Plot type: feature
2025-05-13 15:42:26,531:WARNING:No coef_ found. Trying feature_importances_
2025-05-13 15:42:26,599:INFO:Visual Rendered Successfully
2025-05-13 15:42:26,648:INFO:plot_model() successfully completed......................................
2025-05-13 15:46:43,301:INFO:PyCaret ClassificationExperiment
2025-05-13 15:46:43,301:INFO:Logging name: clf-default-name
2025-05-13 15:46:43,301:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-13 15:46:43,301:INFO:version 3.3.2
2025-05-13 15:46:43,301:INFO:Initializing setup()
2025-05-13 15:46:43,301:INFO:self.USI: 6f06
2025-05-13 15:46:43,301:INFO:self._variable_keys: {'fold_groups_param', 'html_param', 'USI', 'fix_imbalance', 'log_plots_param', 'idx', 'fold_generator', 'exp_name_log', 'exp_id', 'y', 'is_multiclass', 'memory', 'gpu_param', 'y_test', 'pipeline', 'seed', '_ml_usecase', 'X_train', 'gpu_n_jobs_param', 'y_train', 'fold_shuffle_param', 'X', 'data', '_available_plots', 'X_test', 'target_param', 'n_jobs_param', 'logging_param'}
2025-05-13 15:46:43,301:INFO:Checking environment
2025-05-13 15:46:43,301:INFO:python_version: 3.11.0
2025-05-13 15:46:43,301:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-13 15:46:43,301:INFO:machine: arm64
2025-05-13 15:46:43,301:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:46:43,302:INFO:Memory: svmem(total=17179869184, available=3750920192, percent=78.2, used=6131138560, free=61603840, active=3702865920, inactive=3663511552, wired=2428272640)
2025-05-13 15:46:43,302:INFO:Physical Core: 12
2025-05-13 15:46:43,302:INFO:Logical Core: 12
2025-05-13 15:46:43,302:INFO:Checking libraries
2025-05-13 15:46:43,302:INFO:System:
2025-05-13 15:46:43,302:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-13 15:46:43,302:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-13 15:46:43,302:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:46:43,302:INFO:PyCaret required dependencies:
2025-05-13 15:46:43,302:INFO:                 pip: 22.3
2025-05-13 15:46:43,302:INFO:          setuptools: 65.5.0
2025-05-13 15:46:43,302:INFO:             pycaret: 3.3.2
2025-05-13 15:46:43,302:INFO:             IPython: 9.2.0
2025-05-13 15:46:43,302:INFO:          ipywidgets: 8.1.7
2025-05-13 15:46:43,302:INFO:                tqdm: 4.67.1
2025-05-13 15:46:43,302:INFO:               numpy: 1.26.4
2025-05-13 15:46:43,302:INFO:              pandas: 2.1.4
2025-05-13 15:46:43,302:INFO:              jinja2: 3.1.6
2025-05-13 15:46:43,302:INFO:               scipy: 1.11.4
2025-05-13 15:46:43,302:INFO:              joblib: 1.3.2
2025-05-13 15:46:43,302:INFO:             sklearn: 1.4.2
2025-05-13 15:46:43,302:INFO:                pyod: 2.0.5
2025-05-13 15:46:43,302:INFO:            imblearn: 0.13.0
2025-05-13 15:46:43,302:INFO:   category_encoders: 2.7.0
2025-05-13 15:46:43,302:INFO:            lightgbm: 4.6.0
2025-05-13 15:46:43,302:INFO:               numba: 0.61.2
2025-05-13 15:46:43,302:INFO:            requests: 2.32.3
2025-05-13 15:46:43,302:INFO:          matplotlib: 3.7.5
2025-05-13 15:46:43,302:INFO:          scikitplot: 0.3.7
2025-05-13 15:46:43,302:INFO:         yellowbrick: 1.5
2025-05-13 15:46:43,302:INFO:              plotly: 5.24.1
2025-05-13 15:46:43,302:INFO:    plotly-resampler: Not installed
2025-05-13 15:46:43,302:INFO:             kaleido: 0.2.1
2025-05-13 15:46:43,302:INFO:           schemdraw: 0.15
2025-05-13 15:46:43,302:INFO:         statsmodels: 0.14.4
2025-05-13 15:46:43,302:INFO:              sktime: 0.26.0
2025-05-13 15:46:43,302:INFO:               tbats: 1.1.3
2025-05-13 15:46:43,302:INFO:            pmdarima: 2.0.4
2025-05-13 15:46:43,302:INFO:              psutil: 7.0.0
2025-05-13 15:46:43,302:INFO:          markupsafe: 3.0.2
2025-05-13 15:46:43,302:INFO:             pickle5: Not installed
2025-05-13 15:46:43,302:INFO:         cloudpickle: 3.1.1
2025-05-13 15:46:43,302:INFO:         deprecation: 2.1.0
2025-05-13 15:46:43,302:INFO:              xxhash: 3.5.0
2025-05-13 15:46:43,302:INFO:           wurlitzer: 3.1.1
2025-05-13 15:46:43,302:INFO:PyCaret optional dependencies:
2025-05-13 15:46:43,302:INFO:                shap: 0.47.2
2025-05-13 15:46:43,302:INFO:           interpret: Not installed
2025-05-13 15:46:43,302:INFO:                umap: Not installed
2025-05-13 15:46:43,302:INFO:     ydata_profiling: Not installed
2025-05-13 15:46:43,302:INFO:  explainerdashboard: Not installed
2025-05-13 15:46:43,302:INFO:             autoviz: Not installed
2025-05-13 15:46:43,302:INFO:           fairlearn: Not installed
2025-05-13 15:46:43,302:INFO:          deepchecks: Not installed
2025-05-13 15:46:43,302:INFO:             xgboost: Not installed
2025-05-13 15:46:43,302:INFO:            catboost: Not installed
2025-05-13 15:46:43,302:INFO:              kmodes: Not installed
2025-05-13 15:46:43,302:INFO:             mlxtend: Not installed
2025-05-13 15:46:43,302:INFO:       statsforecast: Not installed
2025-05-13 15:46:43,302:INFO:        tune_sklearn: Not installed
2025-05-13 15:46:43,302:INFO:                 ray: Not installed
2025-05-13 15:46:43,302:INFO:            hyperopt: Not installed
2025-05-13 15:46:43,302:INFO:              optuna: 4.3.0
2025-05-13 15:46:43,302:INFO:               skopt: Not installed
2025-05-13 15:46:43,302:INFO:              mlflow: Not installed
2025-05-13 15:46:43,302:INFO:              gradio: Not installed
2025-05-13 15:46:43,302:INFO:             fastapi: Not installed
2025-05-13 15:46:43,302:INFO:             uvicorn: Not installed
2025-05-13 15:46:43,302:INFO:              m2cgen: Not installed
2025-05-13 15:46:43,302:INFO:           evidently: Not installed
2025-05-13 15:46:43,302:INFO:               fugue: Not installed
2025-05-13 15:46:43,302:INFO:           streamlit: Not installed
2025-05-13 15:46:43,302:INFO:             prophet: Not installed
2025-05-13 15:46:43,302:INFO:None
2025-05-13 15:46:43,303:INFO:Set up data.
2025-05-13 15:46:43,335:INFO:Set up folding strategy.
2025-05-13 15:46:43,335:INFO:Set up train/test split.
2025-05-13 15:46:43,348:INFO:Set up index.
2025-05-13 15:46:43,349:INFO:Assigning column types.
2025-05-13 15:46:43,352:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-13 15:46:43,370:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,371:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,403:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,404:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,415:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,415:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-13 15:46:43,433:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,462:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,473:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-13 15:46:43,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,504:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,534:INFO:Preparing preprocessing pipeline...
2025-05-13 15:46:43,536:INFO:Set up simple imputation.
2025-05-13 15:46:43,542:INFO:Set up encoding of ordinal features.
2025-05-13 15:46:43,553:INFO:Set up encoding of categorical features.
2025-05-13 15:46:43,553:INFO:Set up imbalanced handling.
2025-05-13 15:46:43,553:INFO:Set up column transformation.
2025-05-13 15:46:44,751:INFO:Finished creating preprocessing pipeline.
2025-05-13 15:46:44,770:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-13 15:46:44,770:INFO:Creating final display dataframe.
2025-05-13 15:46:45,311:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 17)
4        Transformed data shape      (106821, 35)
5   Transformed train set shape       (85902, 35)
6    Transformed test set shape       (20919, 35)
7              Numeric features                 6
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              6f06
2025-05-13 15:46:45,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:45,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:45,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:45,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:45,374:INFO:setup() successfully completed in 2.08s...............
2025-05-13 15:46:45,375:INFO:Initializing compare_models()
2025-05-13 15:46:45,375:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-13 15:46:45,375:INFO:Checking exceptions
2025-05-13 15:46:45,379:INFO:Preparing display monitor
2025-05-13 15:46:45,388:INFO:Initializing Logistic Regression
2025-05-13 15:46:45,388:INFO:Total runtime is 1.3192494710286458e-06 minutes
2025-05-13 15:46:45,389:INFO:SubProcess create_model() called ==================================
2025-05-13 15:46:45,389:INFO:Initializing create_model()
2025-05-13 15:46:45,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:46:45,389:INFO:Checking exceptions
2025-05-13 15:46:45,389:INFO:Importing libraries
2025-05-13 15:46:45,389:INFO:Copying training dataset
2025-05-13 15:46:45,400:INFO:Defining folds
2025-05-13 15:46:45,400:INFO:Declaring metric variables
2025-05-13 15:46:45,402:INFO:Importing untrained model
2025-05-13 15:46:45,403:INFO:Logistic Regression Imported successfully
2025-05-13 15:46:45,405:INFO:Starting cross validation
2025-05-13 15:46:45,406:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:46:49,918:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:50,095:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:50,115:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:50,134:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:51,151:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:51,219:INFO:Calculating mean and std
2025-05-13 15:46:51,220:INFO:Creating metrics dataframe
2025-05-13 15:46:51,222:INFO:Uploading results into container
2025-05-13 15:46:51,222:INFO:Uploading model into container now
2025-05-13 15:46:51,222:INFO:_master_model_container: 1
2025-05-13 15:46:51,222:INFO:_display_container: 2
2025-05-13 15:46:51,223:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-13 15:46:51,223:INFO:create_model() successfully completed......................................
2025-05-13 15:46:51,317:INFO:SubProcess create_model() end ==================================
2025-05-13 15:46:51,317:INFO:Creating metrics dataframe
2025-05-13 15:46:51,320:INFO:Initializing K Neighbors Classifier
2025-05-13 15:46:51,320:INFO:Total runtime is 0.0988743503888448 minutes
2025-05-13 15:46:51,322:INFO:SubProcess create_model() called ==================================
2025-05-13 15:46:51,322:INFO:Initializing create_model()
2025-05-13 15:46:51,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:46:51,322:INFO:Checking exceptions
2025-05-13 15:46:51,322:INFO:Importing libraries
2025-05-13 15:46:51,322:INFO:Copying training dataset
2025-05-13 15:46:51,333:INFO:Defining folds
2025-05-13 15:46:51,333:INFO:Declaring metric variables
2025-05-13 15:46:51,335:INFO:Importing untrained model
2025-05-13 15:46:51,336:INFO:K Neighbors Classifier Imported successfully
2025-05-13 15:46:51,338:INFO:Starting cross validation
2025-05-13 15:46:51,339:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:46:58,123:INFO:Calculating mean and std
2025-05-13 15:46:58,126:INFO:Creating metrics dataframe
2025-05-13 15:46:58,130:INFO:Uploading results into container
2025-05-13 15:46:58,131:INFO:Uploading model into container now
2025-05-13 15:46:58,131:INFO:_master_model_container: 2
2025-05-13 15:46:58,131:INFO:_display_container: 2
2025-05-13 15:46:58,132:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-13 15:46:58,132:INFO:create_model() successfully completed......................................
2025-05-13 15:46:58,193:INFO:SubProcess create_model() end ==================================
2025-05-13 15:46:58,193:INFO:Creating metrics dataframe
2025-05-13 15:46:58,196:INFO:Initializing Naive Bayes
2025-05-13 15:46:58,196:INFO:Total runtime is 0.21347267230351766 minutes
2025-05-13 15:46:58,197:INFO:SubProcess create_model() called ==================================
2025-05-13 15:46:58,197:INFO:Initializing create_model()
2025-05-13 15:46:58,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:46:58,197:INFO:Checking exceptions
2025-05-13 15:46:58,197:INFO:Importing libraries
2025-05-13 15:46:58,198:INFO:Copying training dataset
2025-05-13 15:46:58,209:INFO:Defining folds
2025-05-13 15:46:58,209:INFO:Declaring metric variables
2025-05-13 15:46:58,210:INFO:Importing untrained model
2025-05-13 15:46:58,212:INFO:Naive Bayes Imported successfully
2025-05-13 15:46:58,214:INFO:Starting cross validation
2025-05-13 15:46:58,216:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:00,598:INFO:Calculating mean and std
2025-05-13 15:47:00,599:INFO:Creating metrics dataframe
2025-05-13 15:47:00,601:INFO:Uploading results into container
2025-05-13 15:47:00,601:INFO:Uploading model into container now
2025-05-13 15:47:00,601:INFO:_master_model_container: 3
2025-05-13 15:47:00,601:INFO:_display_container: 2
2025-05-13 15:47:00,601:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-13 15:47:00,602:INFO:create_model() successfully completed......................................
2025-05-13 15:47:00,655:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:00,655:INFO:Creating metrics dataframe
2025-05-13 15:47:00,658:INFO:Initializing Decision Tree Classifier
2025-05-13 15:47:00,658:INFO:Total runtime is 0.2545124689737956 minutes
2025-05-13 15:47:00,660:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:00,660:INFO:Initializing create_model()
2025-05-13 15:47:00,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:00,660:INFO:Checking exceptions
2025-05-13 15:47:00,660:INFO:Importing libraries
2025-05-13 15:47:00,660:INFO:Copying training dataset
2025-05-13 15:47:00,670:INFO:Defining folds
2025-05-13 15:47:00,670:INFO:Declaring metric variables
2025-05-13 15:47:00,671:INFO:Importing untrained model
2025-05-13 15:47:00,673:INFO:Decision Tree Classifier Imported successfully
2025-05-13 15:47:00,675:INFO:Starting cross validation
2025-05-13 15:47:00,677:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:03,679:INFO:Calculating mean and std
2025-05-13 15:47:03,680:INFO:Creating metrics dataframe
2025-05-13 15:47:03,681:INFO:Uploading results into container
2025-05-13 15:47:03,681:INFO:Uploading model into container now
2025-05-13 15:47:03,682:INFO:_master_model_container: 4
2025-05-13 15:47:03,682:INFO:_display_container: 2
2025-05-13 15:47:03,682:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-13 15:47:03,682:INFO:create_model() successfully completed......................................
2025-05-13 15:47:03,771:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:03,771:INFO:Creating metrics dataframe
2025-05-13 15:47:03,774:INFO:Initializing SVM - Linear Kernel
2025-05-13 15:47:03,775:INFO:Total runtime is 0.3064471522967021 minutes
2025-05-13 15:47:03,776:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:03,776:INFO:Initializing create_model()
2025-05-13 15:47:03,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:03,776:INFO:Checking exceptions
2025-05-13 15:47:03,777:INFO:Importing libraries
2025-05-13 15:47:03,777:INFO:Copying training dataset
2025-05-13 15:47:03,786:INFO:Defining folds
2025-05-13 15:47:03,786:INFO:Declaring metric variables
2025-05-13 15:47:03,788:INFO:Importing untrained model
2025-05-13 15:47:03,789:INFO:SVM - Linear Kernel Imported successfully
2025-05-13 15:47:03,791:INFO:Starting cross validation
2025-05-13 15:47:03,793:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:08,285:INFO:Calculating mean and std
2025-05-13 15:47:08,286:INFO:Creating metrics dataframe
2025-05-13 15:47:08,288:INFO:Uploading results into container
2025-05-13 15:47:08,288:INFO:Uploading model into container now
2025-05-13 15:47:08,288:INFO:_master_model_container: 5
2025-05-13 15:47:08,288:INFO:_display_container: 2
2025-05-13 15:47:08,289:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-13 15:47:08,289:INFO:create_model() successfully completed......................................
2025-05-13 15:47:08,350:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:08,350:INFO:Creating metrics dataframe
2025-05-13 15:47:08,354:INFO:Initializing Ridge Classifier
2025-05-13 15:47:08,354:INFO:Total runtime is 0.3827689170837403 minutes
2025-05-13 15:47:08,355:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:08,356:INFO:Initializing create_model()
2025-05-13 15:47:08,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:08,356:INFO:Checking exceptions
2025-05-13 15:47:08,356:INFO:Importing libraries
2025-05-13 15:47:08,356:INFO:Copying training dataset
2025-05-13 15:47:08,365:INFO:Defining folds
2025-05-13 15:47:08,365:INFO:Declaring metric variables
2025-05-13 15:47:08,367:INFO:Importing untrained model
2025-05-13 15:47:08,368:INFO:Ridge Classifier Imported successfully
2025-05-13 15:47:08,371:INFO:Starting cross validation
2025-05-13 15:47:08,372:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:11,116:INFO:Calculating mean and std
2025-05-13 15:47:11,117:INFO:Creating metrics dataframe
2025-05-13 15:47:11,121:INFO:Uploading results into container
2025-05-13 15:47:11,121:INFO:Uploading model into container now
2025-05-13 15:47:11,122:INFO:_master_model_container: 6
2025-05-13 15:47:11,122:INFO:_display_container: 2
2025-05-13 15:47:11,122:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-13 15:47:11,122:INFO:create_model() successfully completed......................................
2025-05-13 15:47:11,217:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:11,217:INFO:Creating metrics dataframe
2025-05-13 15:47:11,220:INFO:Initializing Random Forest Classifier
2025-05-13 15:47:11,220:INFO:Total runtime is 0.4305449684460958 minutes
2025-05-13 15:47:11,222:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:11,222:INFO:Initializing create_model()
2025-05-13 15:47:11,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:11,222:INFO:Checking exceptions
2025-05-13 15:47:11,222:INFO:Importing libraries
2025-05-13 15:47:11,222:INFO:Copying training dataset
2025-05-13 15:47:11,235:INFO:Defining folds
2025-05-13 15:47:11,235:INFO:Declaring metric variables
2025-05-13 15:47:11,236:INFO:Importing untrained model
2025-05-13 15:47:11,238:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:47:11,240:INFO:Starting cross validation
2025-05-13 15:47:11,242:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:17,420:INFO:Calculating mean and std
2025-05-13 15:47:17,423:INFO:Creating metrics dataframe
2025-05-13 15:47:17,426:INFO:Uploading results into container
2025-05-13 15:47:17,427:INFO:Uploading model into container now
2025-05-13 15:47:17,427:INFO:_master_model_container: 7
2025-05-13 15:47:17,427:INFO:_display_container: 2
2025-05-13 15:47:17,428:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:47:17,428:INFO:create_model() successfully completed......................................
2025-05-13 15:47:17,541:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:17,541:INFO:Creating metrics dataframe
2025-05-13 15:47:17,545:INFO:Initializing Quadratic Discriminant Analysis
2025-05-13 15:47:17,545:INFO:Total runtime is 0.5359603842099507 minutes
2025-05-13 15:47:17,547:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:17,547:INFO:Initializing create_model()
2025-05-13 15:47:17,547:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:17,547:INFO:Checking exceptions
2025-05-13 15:47:17,547:INFO:Importing libraries
2025-05-13 15:47:17,547:INFO:Copying training dataset
2025-05-13 15:47:17,563:INFO:Defining folds
2025-05-13 15:47:17,563:INFO:Declaring metric variables
2025-05-13 15:47:17,565:INFO:Importing untrained model
2025-05-13 15:47:17,566:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-13 15:47:17,568:INFO:Starting cross validation
2025-05-13 15:47:17,570:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:18,910:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:18,918:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:18,944:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:18,969:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:18,984:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:19,055:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:19,093:INFO:Calculating mean and std
2025-05-13 15:47:19,094:INFO:Creating metrics dataframe
2025-05-13 15:47:19,095:INFO:Uploading results into container
2025-05-13 15:47:19,096:INFO:Uploading model into container now
2025-05-13 15:47:19,096:INFO:_master_model_container: 8
2025-05-13 15:47:19,096:INFO:_display_container: 2
2025-05-13 15:47:19,096:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-13 15:47:19,096:INFO:create_model() successfully completed......................................
2025-05-13 15:47:19,150:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:19,150:INFO:Creating metrics dataframe
2025-05-13 15:47:19,154:INFO:Initializing Ada Boost Classifier
2025-05-13 15:47:19,154:INFO:Total runtime is 0.5627730687459309 minutes
2025-05-13 15:47:19,155:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:19,156:INFO:Initializing create_model()
2025-05-13 15:47:19,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:19,156:INFO:Checking exceptions
2025-05-13 15:47:19,156:INFO:Importing libraries
2025-05-13 15:47:19,156:INFO:Copying training dataset
2025-05-13 15:47:19,167:INFO:Defining folds
2025-05-13 15:47:19,167:INFO:Declaring metric variables
2025-05-13 15:47:19,168:INFO:Importing untrained model
2025-05-13 15:47:19,170:INFO:Ada Boost Classifier Imported successfully
2025-05-13 15:47:19,172:INFO:Starting cross validation
2025-05-13 15:47:19,174:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:20,347:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:20,385:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:20,410:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:20,430:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:20,438:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:23,295:INFO:Calculating mean and std
2025-05-13 15:47:23,295:INFO:Creating metrics dataframe
2025-05-13 15:47:23,296:INFO:Uploading results into container
2025-05-13 15:47:23,296:INFO:Uploading model into container now
2025-05-13 15:47:23,296:INFO:_master_model_container: 9
2025-05-13 15:47:23,296:INFO:_display_container: 2
2025-05-13 15:47:23,297:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-13 15:47:23,297:INFO:create_model() successfully completed......................................
2025-05-13 15:47:23,344:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:23,345:INFO:Creating metrics dataframe
2025-05-13 15:47:23,348:INFO:Initializing Gradient Boosting Classifier
2025-05-13 15:47:23,348:INFO:Total runtime is 0.6326791882514953 minutes
2025-05-13 15:47:23,350:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:23,350:INFO:Initializing create_model()
2025-05-13 15:47:23,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:23,350:INFO:Checking exceptions
2025-05-13 15:47:23,350:INFO:Importing libraries
2025-05-13 15:47:23,350:INFO:Copying training dataset
2025-05-13 15:47:23,360:INFO:Defining folds
2025-05-13 15:47:23,360:INFO:Declaring metric variables
2025-05-13 15:47:23,361:INFO:Importing untrained model
2025-05-13 15:47:23,362:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:47:23,365:INFO:Starting cross validation
2025-05-13 15:47:23,366:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:38,117:INFO:Calculating mean and std
2025-05-13 15:47:38,119:INFO:Creating metrics dataframe
2025-05-13 15:47:38,123:INFO:Uploading results into container
2025-05-13 15:47:38,123:INFO:Uploading model into container now
2025-05-13 15:47:38,124:INFO:_master_model_container: 10
2025-05-13 15:47:38,124:INFO:_display_container: 2
2025-05-13 15:47:38,124:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:47:38,125:INFO:create_model() successfully completed......................................
2025-05-13 15:47:38,239:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:38,239:INFO:Creating metrics dataframe
2025-05-13 15:47:38,244:INFO:Initializing Linear Discriminant Analysis
2025-05-13 15:47:38,244:INFO:Total runtime is 0.8809373378753661 minutes
2025-05-13 15:47:38,245:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:38,245:INFO:Initializing create_model()
2025-05-13 15:47:38,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:38,245:INFO:Checking exceptions
2025-05-13 15:47:38,246:INFO:Importing libraries
2025-05-13 15:47:38,246:INFO:Copying training dataset
2025-05-13 15:47:38,263:INFO:Defining folds
2025-05-13 15:47:38,263:INFO:Declaring metric variables
2025-05-13 15:47:38,265:INFO:Importing untrained model
2025-05-13 15:47:38,266:INFO:Linear Discriminant Analysis Imported successfully
2025-05-13 15:47:38,268:INFO:Starting cross validation
2025-05-13 15:47:38,270:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:39,735:INFO:Calculating mean and std
2025-05-13 15:47:39,736:INFO:Creating metrics dataframe
2025-05-13 15:47:39,737:INFO:Uploading results into container
2025-05-13 15:47:39,737:INFO:Uploading model into container now
2025-05-13 15:47:39,738:INFO:_master_model_container: 11
2025-05-13 15:47:39,738:INFO:_display_container: 2
2025-05-13 15:47:39,738:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-13 15:47:39,738:INFO:create_model() successfully completed......................................
2025-05-13 15:47:39,787:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:39,787:INFO:Creating metrics dataframe
2025-05-13 15:47:39,791:INFO:Initializing Extra Trees Classifier
2025-05-13 15:47:39,791:INFO:Total runtime is 0.9067201852798461 minutes
2025-05-13 15:47:39,792:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:39,792:INFO:Initializing create_model()
2025-05-13 15:47:39,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:39,792:INFO:Checking exceptions
2025-05-13 15:47:39,792:INFO:Importing libraries
2025-05-13 15:47:39,792:INFO:Copying training dataset
2025-05-13 15:47:39,802:INFO:Defining folds
2025-05-13 15:47:39,802:INFO:Declaring metric variables
2025-05-13 15:47:39,803:INFO:Importing untrained model
2025-05-13 15:47:39,805:INFO:Extra Trees Classifier Imported successfully
2025-05-13 15:47:39,807:INFO:Starting cross validation
2025-05-13 15:47:39,808:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:44,921:INFO:Calculating mean and std
2025-05-13 15:47:44,925:INFO:Creating metrics dataframe
2025-05-13 15:47:44,931:INFO:Uploading results into container
2025-05-13 15:47:44,932:INFO:Uploading model into container now
2025-05-13 15:47:44,932:INFO:_master_model_container: 12
2025-05-13 15:47:44,933:INFO:_display_container: 2
2025-05-13 15:47:44,933:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-13 15:47:44,933:INFO:create_model() successfully completed......................................
2025-05-13 15:47:45,080:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:45,080:INFO:Creating metrics dataframe
2025-05-13 15:47:45,084:INFO:Initializing Light Gradient Boosting Machine
2025-05-13 15:47:45,084:INFO:Total runtime is 0.9949469526608784 minutes
2025-05-13 15:47:45,086:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:45,086:INFO:Initializing create_model()
2025-05-13 15:47:45,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:45,086:INFO:Checking exceptions
2025-05-13 15:47:45,086:INFO:Importing libraries
2025-05-13 15:47:45,086:INFO:Copying training dataset
2025-05-13 15:47:45,107:INFO:Defining folds
2025-05-13 15:47:45,108:INFO:Declaring metric variables
2025-05-13 15:47:45,109:INFO:Importing untrained model
2025-05-13 15:47:45,111:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:47:45,113:INFO:Starting cross validation
2025-05-13 15:47:45,115:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:49,600:INFO:Calculating mean and std
2025-05-13 15:47:49,601:INFO:Creating metrics dataframe
2025-05-13 15:47:49,602:INFO:Uploading results into container
2025-05-13 15:47:49,602:INFO:Uploading model into container now
2025-05-13 15:47:49,602:INFO:_master_model_container: 13
2025-05-13 15:47:49,602:INFO:_display_container: 2
2025-05-13 15:47:49,603:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:47:49,603:INFO:create_model() successfully completed......................................
2025-05-13 15:47:49,655:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:49,655:INFO:Creating metrics dataframe
2025-05-13 15:47:49,659:INFO:Initializing Dummy Classifier
2025-05-13 15:47:49,659:INFO:Total runtime is 1.0711941679318744 minutes
2025-05-13 15:47:49,661:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:49,661:INFO:Initializing create_model()
2025-05-13 15:47:49,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:49,661:INFO:Checking exceptions
2025-05-13 15:47:49,661:INFO:Importing libraries
2025-05-13 15:47:49,661:INFO:Copying training dataset
2025-05-13 15:47:49,671:INFO:Defining folds
2025-05-13 15:47:49,671:INFO:Declaring metric variables
2025-05-13 15:47:49,672:INFO:Importing untrained model
2025-05-13 15:47:49,673:INFO:Dummy Classifier Imported successfully
2025-05-13 15:47:49,675:INFO:Starting cross validation
2025-05-13 15:47:49,677:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:50,855:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:50,899:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:50,966:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:50,998:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:51,046:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:51,061:INFO:Calculating mean and std
2025-05-13 15:47:51,062:INFO:Creating metrics dataframe
2025-05-13 15:47:51,063:INFO:Uploading results into container
2025-05-13 15:47:51,063:INFO:Uploading model into container now
2025-05-13 15:47:51,064:INFO:_master_model_container: 14
2025-05-13 15:47:51,064:INFO:_display_container: 2
2025-05-13 15:47:51,064:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-13 15:47:51,064:INFO:create_model() successfully completed......................................
2025-05-13 15:47:51,112:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:51,112:INFO:Creating metrics dataframe
2025-05-13 15:47:51,116:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-13 15:47:51,119:INFO:Initializing create_model()
2025-05-13 15:47:51,119:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:51,119:INFO:Checking exceptions
2025-05-13 15:47:51,119:INFO:Importing libraries
2025-05-13 15:47:51,120:INFO:Copying training dataset
2025-05-13 15:47:51,130:INFO:Defining folds
2025-05-13 15:47:51,130:INFO:Declaring metric variables
2025-05-13 15:47:51,130:INFO:Importing untrained model
2025-05-13 15:47:51,130:INFO:Declaring custom model
2025-05-13 15:47:51,130:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:47:51,131:INFO:Cross validation set to False
2025-05-13 15:47:51,131:INFO:Fitting Model
2025-05-13 15:48:08,726:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:48:08,727:INFO:create_model() successfully completed......................................
2025-05-13 15:48:08,794:INFO:Initializing create_model()
2025-05-13 15:48:08,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:48:08,794:INFO:Checking exceptions
2025-05-13 15:48:08,795:INFO:Importing libraries
2025-05-13 15:48:08,795:INFO:Copying training dataset
2025-05-13 15:48:08,805:INFO:Defining folds
2025-05-13 15:48:08,805:INFO:Declaring metric variables
2025-05-13 15:48:08,805:INFO:Importing untrained model
2025-05-13 15:48:08,805:INFO:Declaring custom model
2025-05-13 15:48:08,805:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:48:08,806:INFO:Cross validation set to False
2025-05-13 15:48:08,806:INFO:Fitting Model
2025-05-13 15:48:10,058:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-05-13 15:48:10,059:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-13 15:48:10,069:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005456 seconds.
2025-05-13 15:48:10,069:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-13 15:48:10,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-13 15:48:10,069:INFO:[LightGBM] [Info] Total Bins 8670
2025-05-13 15:48:10,070:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 34
2025-05-13 15:48:10,070:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-13 15:48:10,853:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:48:10,853:INFO:create_model() successfully completed......................................
2025-05-13 15:48:10,907:INFO:Initializing create_model()
2025-05-13 15:48:10,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:48:10,908:INFO:Checking exceptions
2025-05-13 15:48:10,908:INFO:Importing libraries
2025-05-13 15:48:10,909:INFO:Copying training dataset
2025-05-13 15:48:10,919:INFO:Defining folds
2025-05-13 15:48:10,919:INFO:Declaring metric variables
2025-05-13 15:48:10,919:INFO:Importing untrained model
2025-05-13 15:48:10,919:INFO:Declaring custom model
2025-05-13 15:48:10,919:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:48:10,920:INFO:Cross validation set to False
2025-05-13 15:48:10,920:INFO:Fitting Model
2025-05-13 15:48:13,166:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:48:13,166:INFO:create_model() successfully completed......................................
2025-05-13 15:48:13,225:INFO:_master_model_container: 14
2025-05-13 15:48:13,225:INFO:_display_container: 2
2025-05-13 15:48:13,226:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-13 15:48:13,226:INFO:compare_models() successfully completed......................................
2025-05-13 15:48:13,237:INFO:Initializing evaluate_model()
2025-05-13 15:48:13,237:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:48:13,245:INFO:Initializing plot_model()
2025-05-13 15:48:13,245:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:48:13,245:INFO:Checking exceptions
2025-05-13 15:48:13,249:INFO:Preloading libraries
2025-05-13 15:48:13,252:INFO:Copying training dataset
2025-05-13 15:48:13,252:INFO:Plot type: pipeline
2025-05-13 15:48:13,312:INFO:Visual Rendered Successfully
2025-05-13 15:48:13,361:INFO:plot_model() successfully completed......................................
2025-05-13 15:48:13,363:INFO:Initializing tune_model()
2025-05-13 15:48:13,363:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-13 15:48:13,363:INFO:Checking exceptions
2025-05-13 15:48:13,372:INFO:Copying training dataset
2025-05-13 15:48:13,385:INFO:Checking base model
2025-05-13 15:48:13,385:INFO:Base model : Gradient Boosting Classifier
2025-05-13 15:48:13,386:INFO:Declaring metric variables
2025-05-13 15:48:13,388:INFO:Defining Hyperparameters
2025-05-13 15:48:13,444:INFO:Tuning with n_jobs=-1
2025-05-13 15:48:13,444:INFO:Initializing RandomizedSearchCV
2025-05-13 15:48:52,601:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-13 15:48:52,603:INFO:Hyperparameter search completed
2025-05-13 15:48:52,604:INFO:SubProcess create_model() called ==================================
2025-05-13 15:48:52,605:INFO:Initializing create_model()
2025-05-13 15:48:52,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f04c490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-13 15:48:52,605:INFO:Checking exceptions
2025-05-13 15:48:52,605:INFO:Importing libraries
2025-05-13 15:48:52,605:INFO:Copying training dataset
2025-05-13 15:48:52,620:INFO:Defining folds
2025-05-13 15:48:52,620:INFO:Declaring metric variables
2025-05-13 15:48:52,623:INFO:Importing untrained model
2025-05-13 15:48:52,623:INFO:Declaring custom model
2025-05-13 15:48:52,625:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:48:52,628:INFO:Starting cross validation
2025-05-13 15:48:52,631:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:49:02,360:INFO:Calculating mean and std
2025-05-13 15:49:02,361:INFO:Creating metrics dataframe
2025-05-13 15:49:02,363:INFO:Finalizing model
2025-05-13 15:49:13,199:INFO:Uploading results into container
2025-05-13 15:49:13,200:INFO:Uploading model into container now
2025-05-13 15:49:13,201:INFO:_master_model_container: 15
2025-05-13 15:49:13,201:INFO:_display_container: 3
2025-05-13 15:49:13,201:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:49:13,202:INFO:create_model() successfully completed......................................
2025-05-13 15:49:13,289:INFO:SubProcess create_model() end ==================================
2025-05-13 15:49:13,289:INFO:choose_better activated
2025-05-13 15:49:13,292:INFO:SubProcess create_model() called ==================================
2025-05-13 15:49:13,292:INFO:Initializing create_model()
2025-05-13 15:49:13,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:49:13,292:INFO:Checking exceptions
2025-05-13 15:49:13,293:INFO:Importing libraries
2025-05-13 15:49:13,293:INFO:Copying training dataset
2025-05-13 15:49:13,304:INFO:Defining folds
2025-05-13 15:49:13,304:INFO:Declaring metric variables
2025-05-13 15:49:13,304:INFO:Importing untrained model
2025-05-13 15:49:13,304:INFO:Declaring custom model
2025-05-13 15:49:13,304:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:49:13,304:INFO:Starting cross validation
2025-05-13 15:49:13,306:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:49:28,290:INFO:Calculating mean and std
2025-05-13 15:49:28,292:INFO:Creating metrics dataframe
2025-05-13 15:49:28,293:INFO:Finalizing model
2025-05-13 15:49:45,538:INFO:Uploading results into container
2025-05-13 15:49:45,539:INFO:Uploading model into container now
2025-05-13 15:49:45,539:INFO:_master_model_container: 16
2025-05-13 15:49:45,539:INFO:_display_container: 4
2025-05-13 15:49:45,539:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:49:45,539:INFO:create_model() successfully completed......................................
2025-05-13 15:49:45,633:INFO:SubProcess create_model() end ==================================
2025-05-13 15:49:45,633:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4645
2025-05-13 15:49:45,634:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.489
2025-05-13 15:49:45,634:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-13 15:49:45,634:INFO:choose_better completed
2025-05-13 15:49:45,637:INFO:_master_model_container: 16
2025-05-13 15:49:45,637:INFO:_display_container: 3
2025-05-13 15:49:45,638:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:49:45,638:INFO:tune_model() successfully completed......................................
2025-05-13 15:49:45,693:INFO:Initializing evaluate_model()
2025-05-13 15:49:45,693:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:49:45,701:INFO:Initializing plot_model()
2025-05-13 15:49:45,701:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:49:45,701:INFO:Checking exceptions
2025-05-13 15:49:45,709:INFO:Preloading libraries
2025-05-13 15:49:45,717:INFO:Copying training dataset
2025-05-13 15:49:45,717:INFO:Plot type: pipeline
2025-05-13 15:49:45,776:INFO:Visual Rendered Successfully
2025-05-13 15:49:45,831:INFO:plot_model() successfully completed......................................
2025-05-13 15:49:45,833:INFO:Initializing interpret_model()
2025-05-13 15:49:45,833:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-13 15:49:45,833:INFO:Checking exceptions
2025-05-13 15:49:45,833:INFO:Soft dependency imported: shap: 0.47.2
2025-05-13 15:49:45,834:INFO:Initializing finalize_model()
2025-05-13 15:49:45,834:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-13 15:49:45,834:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:49:45,838:INFO:Initializing create_model()
2025-05-13 15:49:45,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:49:45,838:INFO:Checking exceptions
2025-05-13 15:49:45,838:INFO:Importing libraries
2025-05-13 15:49:45,838:INFO:Copying training dataset
2025-05-13 15:49:45,839:INFO:Defining folds
2025-05-13 15:49:45,839:INFO:Declaring metric variables
2025-05-13 15:49:45,839:INFO:Importing untrained model
2025-05-13 15:49:45,839:INFO:Declaring custom model
2025-05-13 15:49:45,840:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:49:45,841:INFO:Cross validation set to False
2025-05-13 15:49:45,841:INFO:Fitting Model
2025-05-13 15:50:00,667:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:50:00,668:INFO:create_model() successfully completed......................................
2025-05-13 15:50:00,713:INFO:_master_model_container: 16
2025-05-13 15:50:00,713:INFO:_display_container: 3
2025-05-13 15:50:00,733:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:50:00,733:INFO:finalize_model() successfully completed......................................
2025-05-13 15:50:00,813:INFO:Initializing save_model()
2025-05-13 15:50:00,813:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-13 15:50:00,813:INFO:Adding model into prep_pipe
2025-05-13 15:50:00,813:WARNING:Only Model saved as it was a pipeline.
2025-05-13 15:50:00,838:INFO:final_cancer_model.pkl saved in current working directory
2025-05-13 15:50:00,858:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:50:00,858:INFO:save_model() successfully completed......................................
2025-05-13 15:50:00,929:INFO:Initializing predict_model()
2025-05-13 15:50:00,929:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x32627cb80>)
2025-05-13 15:50:00,930:INFO:Checking exceptions
2025-05-13 15:50:00,930:INFO:Preloading libraries
2025-05-13 15:50:00,931:INFO:Set up data.
2025-05-13 15:50:00,955:INFO:Set up index.
2025-05-13 15:50:01,788:INFO:Initializing plot_model()
2025-05-13 15:50:01,788:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:50:01,788:INFO:Checking exceptions
2025-05-13 15:50:01,792:INFO:Preloading libraries
2025-05-13 15:50:01,796:INFO:Copying training dataset
2025-05-13 15:50:01,796:INFO:Plot type: confusion_matrix
2025-05-13 15:50:02,029:INFO:Fitting Model
2025-05-13 15:50:02,029:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:50:02,030:INFO:Scoring test/hold-out set
2025-05-13 15:50:02,102:INFO:Visual Rendered Successfully
2025-05-13 15:50:02,152:INFO:plot_model() successfully completed......................................
2025-05-13 15:50:02,152:INFO:Initializing plot_model()
2025-05-13 15:50:02,152:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:50:02,152:INFO:Checking exceptions
2025-05-13 15:50:02,156:INFO:Preloading libraries
2025-05-13 15:50:02,160:INFO:Copying training dataset
2025-05-13 15:50:02,160:INFO:Plot type: auc
2025-05-13 15:50:02,391:INFO:Fitting Model
2025-05-13 15:50:02,392:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:50:02,393:INFO:Scoring test/hold-out set
2025-05-13 15:50:02,507:INFO:Visual Rendered Successfully
2025-05-13 15:50:02,558:INFO:plot_model() successfully completed......................................
2025-05-13 15:50:02,558:INFO:Initializing plot_model()
2025-05-13 15:50:02,558:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:50:02,558:INFO:Checking exceptions
2025-05-13 15:50:02,563:INFO:Preloading libraries
2025-05-13 15:50:02,566:INFO:Copying training dataset
2025-05-13 15:50:02,566:INFO:Plot type: feature
2025-05-13 15:50:02,567:WARNING:No coef_ found. Trying feature_importances_
2025-05-13 15:50:02,641:INFO:Visual Rendered Successfully
2025-05-13 15:50:02,691:INFO:plot_model() successfully completed......................................
2025-05-13 15:50:02,691:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:189: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  age_cancer_ratio = train_df_processed.groupby('Age_Group')['Cancer'].mean() * 100

2025-05-13 15:50:02,713:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 45824 (\N{HANGUL SYLLABLE DAE}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,714:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 51060 (\N{HANGUL SYLLABLE I}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,714:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 49345 (\N{HANGUL SYLLABLE SANG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,714:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 50672 (\N{HANGUL SYLLABLE YEON}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,714:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 47161 (\N{HANGUL SYLLABLE RYEONG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 50516 (\N{HANGUL SYLLABLE AM}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 48156 (\N{HANGUL SYLLABLE BAL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 49373 (\N{HANGUL SYLLABLE SAENG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 48708 (\N{HANGUL SYLLABLE BI}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 50984 (\N{HANGUL SYLLABLE YUL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,718:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50516 (\N{HANGUL SYLLABLE AM}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48156 (\N{HANGUL SYLLABLE BAL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49373 (\N{HANGUL SYLLABLE SAENG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48708 (\N{HANGUL SYLLABLE BI}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50984 (\N{HANGUL SYLLABLE YUL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50672 (\N{HANGUL SYLLABLE YEON}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47161 (\N{HANGUL SYLLABLE RYEONG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 45824 (\N{HANGUL SYLLABLE DAE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,741:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51060 (\N{HANGUL SYLLABLE I}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,741:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49345 (\N{HANGUL SYLLABLE SANG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:51:31,254:INFO:PyCaret ClassificationExperiment
2025-05-13 15:51:31,254:INFO:Logging name: clf-default-name
2025-05-13 15:51:31,254:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-13 15:51:31,254:INFO:version 3.3.2
2025-05-13 15:51:31,255:INFO:Initializing setup()
2025-05-13 15:51:31,255:INFO:self.USI: eba9
2025-05-13 15:51:31,255:INFO:self._variable_keys: {'fold_groups_param', 'html_param', 'USI', 'fix_imbalance', 'log_plots_param', 'idx', 'fold_generator', 'exp_name_log', 'exp_id', 'y', 'is_multiclass', 'memory', 'gpu_param', 'y_test', 'pipeline', 'seed', '_ml_usecase', 'X_train', 'gpu_n_jobs_param', 'y_train', 'fold_shuffle_param', 'X', 'data', '_available_plots', 'X_test', 'target_param', 'n_jobs_param', 'logging_param'}
2025-05-13 15:51:31,255:INFO:Checking environment
2025-05-13 15:51:31,255:INFO:python_version: 3.11.0
2025-05-13 15:51:31,255:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-13 15:51:31,255:INFO:machine: arm64
2025-05-13 15:51:31,255:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:51:31,255:INFO:Memory: svmem(total=17179869184, available=3357442048, percent=80.5, used=5936070656, free=72073216, active=3300605952, inactive=3279241216, wired=2635464704)
2025-05-13 15:51:31,255:INFO:Physical Core: 12
2025-05-13 15:51:31,255:INFO:Logical Core: 12
2025-05-13 15:51:31,255:INFO:Checking libraries
2025-05-13 15:51:31,255:INFO:System:
2025-05-13 15:51:31,255:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-13 15:51:31,255:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-13 15:51:31,255:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:51:31,255:INFO:PyCaret required dependencies:
2025-05-13 15:51:31,255:INFO:                 pip: 22.3
2025-05-13 15:51:31,255:INFO:          setuptools: 65.5.0
2025-05-13 15:51:31,255:INFO:             pycaret: 3.3.2
2025-05-13 15:51:31,255:INFO:             IPython: 9.2.0
2025-05-13 15:51:31,255:INFO:          ipywidgets: 8.1.7
2025-05-13 15:51:31,255:INFO:                tqdm: 4.67.1
2025-05-13 15:51:31,255:INFO:               numpy: 1.26.4
2025-05-13 15:51:31,255:INFO:              pandas: 2.1.4
2025-05-13 15:51:31,255:INFO:              jinja2: 3.1.6
2025-05-13 15:51:31,255:INFO:               scipy: 1.11.4
2025-05-13 15:51:31,255:INFO:              joblib: 1.3.2
2025-05-13 15:51:31,255:INFO:             sklearn: 1.4.2
2025-05-13 15:51:31,255:INFO:                pyod: 2.0.5
2025-05-13 15:51:31,255:INFO:            imblearn: 0.13.0
2025-05-13 15:51:31,255:INFO:   category_encoders: 2.7.0
2025-05-13 15:51:31,255:INFO:            lightgbm: 4.6.0
2025-05-13 15:51:31,255:INFO:               numba: 0.61.2
2025-05-13 15:51:31,255:INFO:            requests: 2.32.3
2025-05-13 15:51:31,255:INFO:          matplotlib: 3.7.5
2025-05-13 15:51:31,255:INFO:          scikitplot: 0.3.7
2025-05-13 15:51:31,255:INFO:         yellowbrick: 1.5
2025-05-13 15:51:31,255:INFO:              plotly: 5.24.1
2025-05-13 15:51:31,255:INFO:    plotly-resampler: Not installed
2025-05-13 15:51:31,255:INFO:             kaleido: 0.2.1
2025-05-13 15:51:31,255:INFO:           schemdraw: 0.15
2025-05-13 15:51:31,255:INFO:         statsmodels: 0.14.4
2025-05-13 15:51:31,255:INFO:              sktime: 0.26.0
2025-05-13 15:51:31,255:INFO:               tbats: 1.1.3
2025-05-13 15:51:31,255:INFO:            pmdarima: 2.0.4
2025-05-13 15:51:31,255:INFO:              psutil: 7.0.0
2025-05-13 15:51:31,255:INFO:          markupsafe: 3.0.2
2025-05-13 15:51:31,255:INFO:             pickle5: Not installed
2025-05-13 15:51:31,255:INFO:         cloudpickle: 3.1.1
2025-05-13 15:51:31,255:INFO:         deprecation: 2.1.0
2025-05-13 15:51:31,255:INFO:              xxhash: 3.5.0
2025-05-13 15:51:31,255:INFO:           wurlitzer: 3.1.1
2025-05-13 15:51:31,255:INFO:PyCaret optional dependencies:
2025-05-13 15:51:31,255:INFO:                shap: 0.47.2
2025-05-13 15:51:31,255:INFO:           interpret: Not installed
2025-05-13 15:51:31,255:INFO:                umap: Not installed
2025-05-13 15:51:31,255:INFO:     ydata_profiling: Not installed
2025-05-13 15:51:31,255:INFO:  explainerdashboard: Not installed
2025-05-13 15:51:31,255:INFO:             autoviz: Not installed
2025-05-13 15:51:31,256:INFO:           fairlearn: Not installed
2025-05-13 15:51:31,256:INFO:          deepchecks: Not installed
2025-05-13 15:51:31,256:INFO:             xgboost: Not installed
2025-05-13 15:51:31,256:INFO:            catboost: Not installed
2025-05-13 15:51:31,256:INFO:              kmodes: Not installed
2025-05-13 15:51:31,256:INFO:             mlxtend: Not installed
2025-05-13 15:51:31,256:INFO:       statsforecast: Not installed
2025-05-13 15:51:31,256:INFO:        tune_sklearn: Not installed
2025-05-13 15:51:31,256:INFO:                 ray: Not installed
2025-05-13 15:51:31,256:INFO:            hyperopt: Not installed
2025-05-13 15:51:31,256:INFO:              optuna: 4.3.0
2025-05-13 15:51:31,256:INFO:               skopt: Not installed
2025-05-13 15:51:31,256:INFO:              mlflow: Not installed
2025-05-13 15:51:31,256:INFO:              gradio: Not installed
2025-05-13 15:51:31,256:INFO:             fastapi: Not installed
2025-05-13 15:51:31,256:INFO:             uvicorn: Not installed
2025-05-13 15:51:31,256:INFO:              m2cgen: Not installed
2025-05-13 15:51:31,256:INFO:           evidently: Not installed
2025-05-13 15:51:31,256:INFO:               fugue: Not installed
2025-05-13 15:51:31,256:INFO:           streamlit: Not installed
2025-05-13 15:51:31,256:INFO:             prophet: Not installed
2025-05-13 15:51:31,256:INFO:None
2025-05-13 15:51:31,256:INFO:Set up data.
2025-05-13 15:51:31,287:INFO:Set up folding strategy.
2025-05-13 15:51:31,287:INFO:Set up train/test split.
2025-05-13 15:51:31,301:INFO:Set up index.
2025-05-13 15:51:31,301:INFO:Assigning column types.
2025-05-13 15:51:31,305:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-13 15:51:31,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,324:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,354:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,366:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-13 15:51:31,385:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,397:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,415:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,426:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-13 15:51:31,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,490:INFO:Preparing preprocessing pipeline...
2025-05-13 15:51:31,491:INFO:Set up simple imputation.
2025-05-13 15:51:31,498:INFO:Set up encoding of ordinal features.
2025-05-13 15:51:31,507:INFO:Set up encoding of categorical features.
2025-05-13 15:51:31,508:INFO:Set up imbalanced handling.
2025-05-13 15:51:31,508:INFO:Set up column transformation.
2025-05-13 15:51:32,709:INFO:Finished creating preprocessing pipeline.
2025-05-13 15:51:32,728:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-13 15:51:32,728:INFO:Creating final display dataframe.
2025-05-13 15:51:33,263:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 17)
4        Transformed data shape      (106821, 37)
5   Transformed train set shape       (85902, 37)
6    Transformed test set shape       (20919, 37)
7              Numeric features                 6
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              eba9
2025-05-13 15:51:33,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:33,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:33,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:33,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:33,329:INFO:setup() successfully completed in 2.08s...............
2025-05-13 15:51:33,330:INFO:Initializing compare_models()
2025-05-13 15:51:33,330:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-13 15:51:33,330:INFO:Checking exceptions
2025-05-13 15:51:33,336:INFO:Preparing display monitor
2025-05-13 15:51:33,344:INFO:Initializing Logistic Regression
2025-05-13 15:51:33,345:INFO:Total runtime is 1.7682711283365886e-06 minutes
2025-05-13 15:51:33,346:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:33,346:INFO:Initializing create_model()
2025-05-13 15:51:33,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:33,346:INFO:Checking exceptions
2025-05-13 15:51:33,346:INFO:Importing libraries
2025-05-13 15:51:33,346:INFO:Copying training dataset
2025-05-13 15:51:33,358:INFO:Defining folds
2025-05-13 15:51:33,358:INFO:Declaring metric variables
2025-05-13 15:51:33,359:INFO:Importing untrained model
2025-05-13 15:51:33,361:INFO:Logistic Regression Imported successfully
2025-05-13 15:51:33,363:INFO:Starting cross validation
2025-05-13 15:51:33,364:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:37,456:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:37,607:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:38,921:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:39,010:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:42,459:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:42,526:INFO:Calculating mean and std
2025-05-13 15:51:42,528:INFO:Creating metrics dataframe
2025-05-13 15:51:42,531:INFO:Uploading results into container
2025-05-13 15:51:42,531:INFO:Uploading model into container now
2025-05-13 15:51:42,532:INFO:_master_model_container: 1
2025-05-13 15:51:42,532:INFO:_display_container: 2
2025-05-13 15:51:42,532:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-13 15:51:42,532:INFO:create_model() successfully completed......................................
2025-05-13 15:51:42,610:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:42,610:INFO:Creating metrics dataframe
2025-05-13 15:51:42,613:INFO:Initializing K Neighbors Classifier
2025-05-13 15:51:42,613:INFO:Total runtime is 0.15447012186050413 minutes
2025-05-13 15:51:42,614:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:42,614:INFO:Initializing create_model()
2025-05-13 15:51:42,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:42,614:INFO:Checking exceptions
2025-05-13 15:51:42,614:INFO:Importing libraries
2025-05-13 15:51:42,614:INFO:Copying training dataset
2025-05-13 15:51:42,626:INFO:Defining folds
2025-05-13 15:51:42,626:INFO:Declaring metric variables
2025-05-13 15:51:42,627:INFO:Importing untrained model
2025-05-13 15:51:42,628:INFO:K Neighbors Classifier Imported successfully
2025-05-13 15:51:42,631:INFO:Starting cross validation
2025-05-13 15:51:42,633:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:48,117:INFO:Calculating mean and std
2025-05-13 15:51:48,118:INFO:Creating metrics dataframe
2025-05-13 15:51:48,119:INFO:Uploading results into container
2025-05-13 15:51:48,119:INFO:Uploading model into container now
2025-05-13 15:51:48,120:INFO:_master_model_container: 2
2025-05-13 15:51:48,120:INFO:_display_container: 2
2025-05-13 15:51:48,120:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-13 15:51:48,120:INFO:create_model() successfully completed......................................
2025-05-13 15:51:48,178:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:48,178:INFO:Creating metrics dataframe
2025-05-13 15:51:48,182:INFO:Initializing Naive Bayes
2025-05-13 15:51:48,182:INFO:Total runtime is 0.24729955196380612 minutes
2025-05-13 15:51:48,184:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:48,184:INFO:Initializing create_model()
2025-05-13 15:51:48,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:48,184:INFO:Checking exceptions
2025-05-13 15:51:48,184:INFO:Importing libraries
2025-05-13 15:51:48,184:INFO:Copying training dataset
2025-05-13 15:51:48,202:INFO:Defining folds
2025-05-13 15:51:48,203:INFO:Declaring metric variables
2025-05-13 15:51:48,204:INFO:Importing untrained model
2025-05-13 15:51:48,205:INFO:Naive Bayes Imported successfully
2025-05-13 15:51:48,208:INFO:Starting cross validation
2025-05-13 15:51:48,209:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:49,622:INFO:Calculating mean and std
2025-05-13 15:51:49,624:INFO:Creating metrics dataframe
2025-05-13 15:51:49,628:INFO:Uploading results into container
2025-05-13 15:51:49,629:INFO:Uploading model into container now
2025-05-13 15:51:49,629:INFO:_master_model_container: 3
2025-05-13 15:51:49,629:INFO:_display_container: 2
2025-05-13 15:51:49,630:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-13 15:51:49,630:INFO:create_model() successfully completed......................................
2025-05-13 15:51:49,734:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:49,735:INFO:Creating metrics dataframe
2025-05-13 15:51:49,738:INFO:Initializing Decision Tree Classifier
2025-05-13 15:51:49,738:INFO:Total runtime is 0.27322769959767657 minutes
2025-05-13 15:51:49,739:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:49,740:INFO:Initializing create_model()
2025-05-13 15:51:49,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:49,740:INFO:Checking exceptions
2025-05-13 15:51:49,740:INFO:Importing libraries
2025-05-13 15:51:49,740:INFO:Copying training dataset
2025-05-13 15:51:49,760:INFO:Defining folds
2025-05-13 15:51:49,760:INFO:Declaring metric variables
2025-05-13 15:51:49,761:INFO:Importing untrained model
2025-05-13 15:51:49,763:INFO:Decision Tree Classifier Imported successfully
2025-05-13 15:51:49,766:INFO:Starting cross validation
2025-05-13 15:51:49,768:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:51,706:INFO:Calculating mean and std
2025-05-13 15:51:51,707:INFO:Creating metrics dataframe
2025-05-13 15:51:51,708:INFO:Uploading results into container
2025-05-13 15:51:51,708:INFO:Uploading model into container now
2025-05-13 15:51:51,709:INFO:_master_model_container: 4
2025-05-13 15:51:51,709:INFO:_display_container: 2
2025-05-13 15:51:51,709:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-13 15:51:51,709:INFO:create_model() successfully completed......................................
2025-05-13 15:51:51,805:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:51,805:INFO:Creating metrics dataframe
2025-05-13 15:51:51,809:INFO:Initializing SVM - Linear Kernel
2025-05-13 15:51:51,809:INFO:Total runtime is 0.30773888429005936 minutes
2025-05-13 15:51:51,811:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:51,811:INFO:Initializing create_model()
2025-05-13 15:51:51,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:51,811:INFO:Checking exceptions
2025-05-13 15:51:51,811:INFO:Importing libraries
2025-05-13 15:51:51,811:INFO:Copying training dataset
2025-05-13 15:51:51,830:INFO:Defining folds
2025-05-13 15:51:51,831:INFO:Declaring metric variables
2025-05-13 15:51:51,834:INFO:Importing untrained model
2025-05-13 15:51:51,838:INFO:SVM - Linear Kernel Imported successfully
2025-05-13 15:51:51,842:INFO:Starting cross validation
2025-05-13 15:51:51,853:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:56,188:INFO:Calculating mean and std
2025-05-13 15:51:56,190:INFO:Creating metrics dataframe
2025-05-13 15:51:56,192:INFO:Uploading results into container
2025-05-13 15:51:56,192:INFO:Uploading model into container now
2025-05-13 15:51:56,192:INFO:_master_model_container: 5
2025-05-13 15:51:56,192:INFO:_display_container: 2
2025-05-13 15:51:56,193:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-13 15:51:56,193:INFO:create_model() successfully completed......................................
2025-05-13 15:51:56,255:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:56,255:INFO:Creating metrics dataframe
2025-05-13 15:51:56,258:INFO:Initializing Ridge Classifier
2025-05-13 15:51:56,258:INFO:Total runtime is 0.3818989992141723 minutes
2025-05-13 15:51:56,260:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:56,260:INFO:Initializing create_model()
2025-05-13 15:51:56,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:56,260:INFO:Checking exceptions
2025-05-13 15:51:56,260:INFO:Importing libraries
2025-05-13 15:51:56,260:INFO:Copying training dataset
2025-05-13 15:51:56,270:INFO:Defining folds
2025-05-13 15:51:56,270:INFO:Declaring metric variables
2025-05-13 15:51:56,271:INFO:Importing untrained model
2025-05-13 15:51:56,272:INFO:Ridge Classifier Imported successfully
2025-05-13 15:51:56,275:INFO:Starting cross validation
2025-05-13 15:51:56,276:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:57,793:INFO:Calculating mean and std
2025-05-13 15:51:57,794:INFO:Creating metrics dataframe
2025-05-13 15:51:57,795:INFO:Uploading results into container
2025-05-13 15:51:57,795:INFO:Uploading model into container now
2025-05-13 15:51:57,795:INFO:_master_model_container: 6
2025-05-13 15:51:57,795:INFO:_display_container: 2
2025-05-13 15:51:57,796:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-13 15:51:57,796:INFO:create_model() successfully completed......................................
2025-05-13 15:51:57,852:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:57,852:INFO:Creating metrics dataframe
2025-05-13 15:51:57,856:INFO:Initializing Random Forest Classifier
2025-05-13 15:51:57,856:INFO:Total runtime is 0.4085217038790384 minutes
2025-05-13 15:51:57,857:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:57,857:INFO:Initializing create_model()
2025-05-13 15:51:57,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:57,857:INFO:Checking exceptions
2025-05-13 15:51:57,857:INFO:Importing libraries
2025-05-13 15:51:57,857:INFO:Copying training dataset
2025-05-13 15:51:57,868:INFO:Defining folds
2025-05-13 15:51:57,868:INFO:Declaring metric variables
2025-05-13 15:51:57,869:INFO:Importing untrained model
2025-05-13 15:51:57,870:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:51:57,873:INFO:Starting cross validation
2025-05-13 15:51:57,874:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:04,077:INFO:Calculating mean and std
2025-05-13 15:52:04,081:INFO:Creating metrics dataframe
2025-05-13 15:52:04,089:INFO:Uploading results into container
2025-05-13 15:52:04,089:INFO:Uploading model into container now
2025-05-13 15:52:04,090:INFO:_master_model_container: 7
2025-05-13 15:52:04,090:INFO:_display_container: 2
2025-05-13 15:52:04,091:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:52:04,092:INFO:create_model() successfully completed......................................
2025-05-13 15:52:04,203:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:04,203:INFO:Creating metrics dataframe
2025-05-13 15:52:04,207:INFO:Initializing Quadratic Discriminant Analysis
2025-05-13 15:52:04,208:INFO:Total runtime is 0.5143866697947184 minutes
2025-05-13 15:52:04,209:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:04,209:INFO:Initializing create_model()
2025-05-13 15:52:04,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:04,210:INFO:Checking exceptions
2025-05-13 15:52:04,210:INFO:Importing libraries
2025-05-13 15:52:04,210:INFO:Copying training dataset
2025-05-13 15:52:04,222:INFO:Defining folds
2025-05-13 15:52:04,222:INFO:Declaring metric variables
2025-05-13 15:52:04,224:INFO:Importing untrained model
2025-05-13 15:52:04,226:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-13 15:52:04,228:INFO:Starting cross validation
2025-05-13 15:52:04,232:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:05,555:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,573:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,586:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,639:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,680:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,689:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:05,733:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:05,770:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:05,782:INFO:Calculating mean and std
2025-05-13 15:52:05,783:INFO:Creating metrics dataframe
2025-05-13 15:52:05,784:INFO:Uploading results into container
2025-05-13 15:52:05,784:INFO:Uploading model into container now
2025-05-13 15:52:05,784:INFO:_master_model_container: 8
2025-05-13 15:52:05,784:INFO:_display_container: 2
2025-05-13 15:52:05,785:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-13 15:52:05,785:INFO:create_model() successfully completed......................................
2025-05-13 15:52:05,838:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:05,838:INFO:Creating metrics dataframe
2025-05-13 15:52:05,842:INFO:Initializing Ada Boost Classifier
2025-05-13 15:52:05,842:INFO:Total runtime is 0.5416210691134135 minutes
2025-05-13 15:52:05,843:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:05,843:INFO:Initializing create_model()
2025-05-13 15:52:05,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:05,843:INFO:Checking exceptions
2025-05-13 15:52:05,843:INFO:Importing libraries
2025-05-13 15:52:05,843:INFO:Copying training dataset
2025-05-13 15:52:05,852:INFO:Defining folds
2025-05-13 15:52:05,852:INFO:Declaring metric variables
2025-05-13 15:52:05,854:INFO:Importing untrained model
2025-05-13 15:52:05,855:INFO:Ada Boost Classifier Imported successfully
2025-05-13 15:52:05,857:INFO:Starting cross validation
2025-05-13 15:52:05,861:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:07,058:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:07,086:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:07,100:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:07,111:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:07,116:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:10,046:INFO:Calculating mean and std
2025-05-13 15:52:10,046:INFO:Creating metrics dataframe
2025-05-13 15:52:10,047:INFO:Uploading results into container
2025-05-13 15:52:10,047:INFO:Uploading model into container now
2025-05-13 15:52:10,048:INFO:_master_model_container: 9
2025-05-13 15:52:10,048:INFO:_display_container: 2
2025-05-13 15:52:10,048:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-13 15:52:10,048:INFO:create_model() successfully completed......................................
2025-05-13 15:52:10,100:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:10,100:INFO:Creating metrics dataframe
2025-05-13 15:52:10,104:INFO:Initializing Gradient Boosting Classifier
2025-05-13 15:52:10,104:INFO:Total runtime is 0.6126559217770894 minutes
2025-05-13 15:52:10,105:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:10,105:INFO:Initializing create_model()
2025-05-13 15:52:10,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:10,105:INFO:Checking exceptions
2025-05-13 15:52:10,105:INFO:Importing libraries
2025-05-13 15:52:10,106:INFO:Copying training dataset
2025-05-13 15:52:10,115:INFO:Defining folds
2025-05-13 15:52:10,116:INFO:Declaring metric variables
2025-05-13 15:52:10,117:INFO:Importing untrained model
2025-05-13 15:52:10,118:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:52:10,120:INFO:Starting cross validation
2025-05-13 15:52:10,122:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:25,448:INFO:Calculating mean and std
2025-05-13 15:52:25,451:INFO:Creating metrics dataframe
2025-05-13 15:52:25,454:INFO:Uploading results into container
2025-05-13 15:52:25,454:INFO:Uploading model into container now
2025-05-13 15:52:25,455:INFO:_master_model_container: 10
2025-05-13 15:52:25,455:INFO:_display_container: 2
2025-05-13 15:52:25,457:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:52:25,457:INFO:create_model() successfully completed......................................
2025-05-13 15:52:25,556:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:25,556:INFO:Creating metrics dataframe
2025-05-13 15:52:25,560:INFO:Initializing Linear Discriminant Analysis
2025-05-13 15:52:25,560:INFO:Total runtime is 0.8702641169230143 minutes
2025-05-13 15:52:25,562:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:25,562:INFO:Initializing create_model()
2025-05-13 15:52:25,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:25,562:INFO:Checking exceptions
2025-05-13 15:52:25,562:INFO:Importing libraries
2025-05-13 15:52:25,562:INFO:Copying training dataset
2025-05-13 15:52:25,580:INFO:Defining folds
2025-05-13 15:52:25,580:INFO:Declaring metric variables
2025-05-13 15:52:25,581:INFO:Importing untrained model
2025-05-13 15:52:25,583:INFO:Linear Discriminant Analysis Imported successfully
2025-05-13 15:52:25,585:INFO:Starting cross validation
2025-05-13 15:52:25,587:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:27,094:INFO:Calculating mean and std
2025-05-13 15:52:27,095:INFO:Creating metrics dataframe
2025-05-13 15:52:27,096:INFO:Uploading results into container
2025-05-13 15:52:27,096:INFO:Uploading model into container now
2025-05-13 15:52:27,096:INFO:_master_model_container: 11
2025-05-13 15:52:27,096:INFO:_display_container: 2
2025-05-13 15:52:27,096:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-13 15:52:27,096:INFO:create_model() successfully completed......................................
2025-05-13 15:52:27,143:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:27,144:INFO:Creating metrics dataframe
2025-05-13 15:52:27,148:INFO:Initializing Extra Trees Classifier
2025-05-13 15:52:27,148:INFO:Total runtime is 0.8967252651850383 minutes
2025-05-13 15:52:27,149:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:27,149:INFO:Initializing create_model()
2025-05-13 15:52:27,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:27,149:INFO:Checking exceptions
2025-05-13 15:52:27,149:INFO:Importing libraries
2025-05-13 15:52:27,149:INFO:Copying training dataset
2025-05-13 15:52:27,158:INFO:Defining folds
2025-05-13 15:52:27,158:INFO:Declaring metric variables
2025-05-13 15:52:27,159:INFO:Importing untrained model
2025-05-13 15:52:27,161:INFO:Extra Trees Classifier Imported successfully
2025-05-13 15:52:27,162:INFO:Starting cross validation
2025-05-13 15:52:27,164:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:32,596:INFO:Calculating mean and std
2025-05-13 15:52:32,600:INFO:Creating metrics dataframe
2025-05-13 15:52:32,604:INFO:Uploading results into container
2025-05-13 15:52:32,605:INFO:Uploading model into container now
2025-05-13 15:52:32,608:INFO:_master_model_container: 12
2025-05-13 15:52:32,608:INFO:_display_container: 2
2025-05-13 15:52:32,611:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-13 15:52:32,611:INFO:create_model() successfully completed......................................
2025-05-13 15:52:32,732:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:32,732:INFO:Creating metrics dataframe
2025-05-13 15:52:32,736:INFO:Initializing Light Gradient Boosting Machine
2025-05-13 15:52:32,737:INFO:Total runtime is 0.9898682355880737 minutes
2025-05-13 15:52:32,738:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:32,738:INFO:Initializing create_model()
2025-05-13 15:52:32,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:32,738:INFO:Checking exceptions
2025-05-13 15:52:32,738:INFO:Importing libraries
2025-05-13 15:52:32,738:INFO:Copying training dataset
2025-05-13 15:52:32,754:INFO:Defining folds
2025-05-13 15:52:32,754:INFO:Declaring metric variables
2025-05-13 15:52:32,756:INFO:Importing untrained model
2025-05-13 15:52:32,758:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:52:32,761:INFO:Starting cross validation
2025-05-13 15:52:32,763:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:37,434:INFO:Calculating mean and std
2025-05-13 15:52:37,435:INFO:Creating metrics dataframe
2025-05-13 15:52:37,435:INFO:Uploading results into container
2025-05-13 15:52:37,436:INFO:Uploading model into container now
2025-05-13 15:52:37,436:INFO:_master_model_container: 13
2025-05-13 15:52:37,436:INFO:_display_container: 2
2025-05-13 15:52:37,436:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:52:37,436:INFO:create_model() successfully completed......................................
2025-05-13 15:52:37,487:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:37,487:INFO:Creating metrics dataframe
2025-05-13 15:52:37,491:INFO:Initializing Dummy Classifier
2025-05-13 15:52:37,491:INFO:Total runtime is 1.0691153526306152 minutes
2025-05-13 15:52:37,493:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:37,493:INFO:Initializing create_model()
2025-05-13 15:52:37,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:37,493:INFO:Checking exceptions
2025-05-13 15:52:37,493:INFO:Importing libraries
2025-05-13 15:52:37,493:INFO:Copying training dataset
2025-05-13 15:52:37,503:INFO:Defining folds
2025-05-13 15:52:37,503:INFO:Declaring metric variables
2025-05-13 15:52:37,504:INFO:Importing untrained model
2025-05-13 15:52:37,505:INFO:Dummy Classifier Imported successfully
2025-05-13 15:52:37,508:INFO:Starting cross validation
2025-05-13 15:52:37,509:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:38,748:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,813:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,824:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,851:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,854:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,870:INFO:Calculating mean and std
2025-05-13 15:52:38,871:INFO:Creating metrics dataframe
2025-05-13 15:52:38,873:INFO:Uploading results into container
2025-05-13 15:52:38,873:INFO:Uploading model into container now
2025-05-13 15:52:38,873:INFO:_master_model_container: 14
2025-05-13 15:52:38,873:INFO:_display_container: 2
2025-05-13 15:52:38,874:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-13 15:52:38,874:INFO:create_model() successfully completed......................................
2025-05-13 15:52:38,938:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:38,938:INFO:Creating metrics dataframe
2025-05-13 15:52:38,943:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-13 15:52:38,947:INFO:Initializing create_model()
2025-05-13 15:52:38,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:38,947:INFO:Checking exceptions
2025-05-13 15:52:38,948:INFO:Importing libraries
2025-05-13 15:52:38,948:INFO:Copying training dataset
2025-05-13 15:52:38,958:INFO:Defining folds
2025-05-13 15:52:38,958:INFO:Declaring metric variables
2025-05-13 15:52:38,958:INFO:Importing untrained model
2025-05-13 15:52:38,958:INFO:Declaring custom model
2025-05-13 15:52:38,958:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:52:38,960:INFO:Cross validation set to False
2025-05-13 15:52:38,960:INFO:Fitting Model
2025-05-13 15:52:56,429:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:52:56,430:INFO:create_model() successfully completed......................................
2025-05-13 15:52:56,502:INFO:Initializing create_model()
2025-05-13 15:52:56,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:56,502:INFO:Checking exceptions
2025-05-13 15:52:56,503:INFO:Importing libraries
2025-05-13 15:52:56,503:INFO:Copying training dataset
2025-05-13 15:52:56,513:INFO:Defining folds
2025-05-13 15:52:56,513:INFO:Declaring metric variables
2025-05-13 15:52:56,513:INFO:Importing untrained model
2025-05-13 15:52:56,514:INFO:Declaring custom model
2025-05-13 15:52:56,514:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:52:56,516:INFO:Cross validation set to False
2025-05-13 15:52:56,516:INFO:Fitting Model
2025-05-13 15:52:57,743:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-05-13 15:52:57,743:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-13 15:52:57,754:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005956 seconds.
2025-05-13 15:52:57,754:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-13 15:52:57,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-13 15:52:57,755:INFO:[LightGBM] [Info] Total Bins 9180
2025-05-13 15:52:57,755:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 36
2025-05-13 15:52:57,755:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-13 15:52:58,537:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:52:58,537:INFO:create_model() successfully completed......................................
2025-05-13 15:52:58,597:INFO:Initializing create_model()
2025-05-13 15:52:58,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:58,597:INFO:Checking exceptions
2025-05-13 15:52:58,598:INFO:Importing libraries
2025-05-13 15:52:58,598:INFO:Copying training dataset
2025-05-13 15:52:58,607:INFO:Defining folds
2025-05-13 15:52:58,607:INFO:Declaring metric variables
2025-05-13 15:52:58,607:INFO:Importing untrained model
2025-05-13 15:52:58,607:INFO:Declaring custom model
2025-05-13 15:52:58,608:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:52:58,609:INFO:Cross validation set to False
2025-05-13 15:52:58,609:INFO:Fitting Model
2025-05-13 15:53:01,182:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:53:01,182:INFO:create_model() successfully completed......................................
2025-05-13 15:53:01,254:INFO:_master_model_container: 14
2025-05-13 15:53:01,254:INFO:_display_container: 2
2025-05-13 15:53:01,255:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-13 15:53:01,255:INFO:compare_models() successfully completed......................................
2025-05-13 15:53:01,274:INFO:Initializing evaluate_model()
2025-05-13 15:53:01,274:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:53:01,283:INFO:Initializing plot_model()
2025-05-13 15:53:01,283:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:53:01,283:INFO:Checking exceptions
2025-05-13 15:53:01,288:INFO:Preloading libraries
2025-05-13 15:53:01,291:INFO:Copying training dataset
2025-05-13 15:53:01,291:INFO:Plot type: pipeline
2025-05-13 15:53:01,362:INFO:Visual Rendered Successfully
2025-05-13 15:53:01,418:INFO:plot_model() successfully completed......................................
2025-05-13 15:53:01,419:INFO:Initializing tune_model()
2025-05-13 15:53:01,419:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-13 15:53:01,420:INFO:Checking exceptions
2025-05-13 15:53:01,429:INFO:Copying training dataset
2025-05-13 15:53:01,436:INFO:Checking base model
2025-05-13 15:53:01,436:INFO:Base model : Gradient Boosting Classifier
2025-05-13 15:53:01,438:INFO:Declaring metric variables
2025-05-13 15:53:01,439:INFO:Defining Hyperparameters
2025-05-13 15:53:01,494:INFO:Tuning with n_jobs=-1
2025-05-13 15:53:01,494:INFO:Initializing RandomizedSearchCV
2025-05-13 15:53:45,641:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-13 15:53:45,644:INFO:Hyperparameter search completed
2025-05-13 15:53:45,646:INFO:SubProcess create_model() called ==================================
2025-05-13 15:53:45,647:INFO:Initializing create_model()
2025-05-13 15:53:45,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32feeeed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-13 15:53:45,647:INFO:Checking exceptions
2025-05-13 15:53:45,647:INFO:Importing libraries
2025-05-13 15:53:45,648:INFO:Copying training dataset
2025-05-13 15:53:45,665:INFO:Defining folds
2025-05-13 15:53:45,665:INFO:Declaring metric variables
2025-05-13 15:53:45,671:INFO:Importing untrained model
2025-05-13 15:53:45,671:INFO:Declaring custom model
2025-05-13 15:53:45,674:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:53:45,677:INFO:Starting cross validation
2025-05-13 15:53:45,682:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:53:56,758:INFO:Calculating mean and std
2025-05-13 15:53:56,759:INFO:Creating metrics dataframe
2025-05-13 15:53:56,762:INFO:Finalizing model
2025-05-13 15:54:08,504:INFO:Uploading results into container
2025-05-13 15:54:08,506:INFO:Uploading model into container now
2025-05-13 15:54:08,507:INFO:_master_model_container: 15
2025-05-13 15:54:08,507:INFO:_display_container: 3
2025-05-13 15:54:08,508:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:54:08,508:INFO:create_model() successfully completed......................................
2025-05-13 15:54:08,596:INFO:SubProcess create_model() end ==================================
2025-05-13 15:54:08,596:INFO:choose_better activated
2025-05-13 15:54:08,598:INFO:SubProcess create_model() called ==================================
2025-05-13 15:54:08,598:INFO:Initializing create_model()
2025-05-13 15:54:08,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:54:08,598:INFO:Checking exceptions
2025-05-13 15:54:08,599:INFO:Importing libraries
2025-05-13 15:54:08,599:INFO:Copying training dataset
2025-05-13 15:54:08,608:INFO:Defining folds
2025-05-13 15:54:08,608:INFO:Declaring metric variables
2025-05-13 15:54:08,608:INFO:Importing untrained model
2025-05-13 15:54:08,609:INFO:Declaring custom model
2025-05-13 15:54:08,609:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:54:08,609:INFO:Starting cross validation
2025-05-13 15:54:08,610:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:54:24,304:INFO:Calculating mean and std
2025-05-13 15:54:24,305:INFO:Creating metrics dataframe
2025-05-13 15:54:24,309:INFO:Finalizing model
2025-05-13 15:54:42,775:INFO:Uploading results into container
2025-05-13 15:54:42,776:INFO:Uploading model into container now
2025-05-13 15:54:42,776:INFO:_master_model_container: 16
2025-05-13 15:54:42,776:INFO:_display_container: 4
2025-05-13 15:54:42,777:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:54:42,777:INFO:create_model() successfully completed......................................
2025-05-13 15:54:42,888:INFO:SubProcess create_model() end ==================================
2025-05-13 15:54:42,889:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4636
2025-05-13 15:54:42,889:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4897
2025-05-13 15:54:42,889:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-13 15:54:42,889:INFO:choose_better completed
2025-05-13 15:54:42,894:INFO:_master_model_container: 16
2025-05-13 15:54:42,894:INFO:_display_container: 3
2025-05-13 15:54:42,894:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:54:42,894:INFO:tune_model() successfully completed......................................
2025-05-13 15:54:42,951:INFO:Initializing evaluate_model()
2025-05-13 15:54:42,951:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:54:42,964:INFO:Initializing plot_model()
2025-05-13 15:54:42,965:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:54:42,965:INFO:Checking exceptions
2025-05-13 15:54:42,971:INFO:Preloading libraries
2025-05-13 15:54:42,984:INFO:Copying training dataset
2025-05-13 15:54:42,984:INFO:Plot type: pipeline
2025-05-13 15:54:43,044:INFO:Visual Rendered Successfully
2025-05-13 15:54:43,096:INFO:plot_model() successfully completed......................................
2025-05-13 15:54:43,098:INFO:Initializing interpret_model()
2025-05-13 15:54:43,098:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-13 15:54:43,098:INFO:Checking exceptions
2025-05-13 15:54:43,099:INFO:Soft dependency imported: shap: 0.47.2
2025-05-13 15:54:43,099:INFO:Initializing finalize_model()
2025-05-13 15:54:43,099:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-13 15:54:43,099:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:54:43,103:INFO:Initializing create_model()
2025-05-13 15:54:43,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:54:43,103:INFO:Checking exceptions
2025-05-13 15:54:43,104:INFO:Importing libraries
2025-05-13 15:54:43,104:INFO:Copying training dataset
2025-05-13 15:54:43,104:INFO:Defining folds
2025-05-13 15:54:43,104:INFO:Declaring metric variables
2025-05-13 15:54:43,104:INFO:Importing untrained model
2025-05-13 15:54:43,104:INFO:Declaring custom model
2025-05-13 15:54:43,105:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:54:43,106:INFO:Cross validation set to False
2025-05-13 15:54:43,106:INFO:Fitting Model
2025-05-13 15:54:59,325:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:54:59,326:INFO:create_model() successfully completed......................................
2025-05-13 15:54:59,373:INFO:_master_model_container: 16
2025-05-13 15:54:59,373:INFO:_display_container: 3
2025-05-13 15:54:59,392:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:54:59,392:INFO:finalize_model() successfully completed......................................
2025-05-13 15:54:59,473:INFO:Initializing save_model()
2025-05-13 15:54:59,473:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-13 15:54:59,473:INFO:Adding model into prep_pipe
2025-05-13 15:54:59,473:WARNING:Only Model saved as it was a pipeline.
2025-05-13 15:54:59,497:INFO:final_cancer_model.pkl saved in current working directory
2025-05-13 15:54:59,516:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:54:59,516:INFO:save_model() successfully completed......................................
2025-05-13 15:54:59,584:INFO:Initializing predict_model()
2025-05-13 15:54:59,584:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x32627cb80>)
2025-05-13 15:54:59,584:INFO:Checking exceptions
2025-05-13 15:54:59,584:INFO:Preloading libraries
2025-05-13 15:54:59,585:INFO:Set up data.
2025-05-13 15:54:59,602:INFO:Set up index.
2025-05-13 15:55:00,476:INFO:Initializing plot_model()
2025-05-13 15:55:00,476:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:55:00,476:INFO:Checking exceptions
2025-05-13 15:55:00,481:INFO:Preloading libraries
2025-05-13 15:55:00,485:INFO:Copying training dataset
2025-05-13 15:55:00,485:INFO:Plot type: confusion_matrix
2025-05-13 15:55:00,717:INFO:Fitting Model
2025-05-13 15:55:00,717:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:55:00,718:INFO:Scoring test/hold-out set
2025-05-13 15:55:00,791:INFO:Visual Rendered Successfully
2025-05-13 15:55:00,840:INFO:plot_model() successfully completed......................................
2025-05-13 15:55:00,840:INFO:Initializing plot_model()
2025-05-13 15:55:00,840:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:55:00,840:INFO:Checking exceptions
2025-05-13 15:55:00,844:INFO:Preloading libraries
2025-05-13 15:55:00,848:INFO:Copying training dataset
2025-05-13 15:55:00,848:INFO:Plot type: auc
2025-05-13 15:55:01,085:INFO:Fitting Model
2025-05-13 15:55:01,086:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:55:01,087:INFO:Scoring test/hold-out set
2025-05-13 15:55:01,202:INFO:Visual Rendered Successfully
2025-05-13 15:55:01,252:INFO:plot_model() successfully completed......................................
2025-05-13 15:55:01,252:INFO:Initializing plot_model()
2025-05-13 15:55:01,252:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:55:01,252:INFO:Checking exceptions
2025-05-13 15:55:01,257:INFO:Preloading libraries
2025-05-13 15:55:01,260:INFO:Copying training dataset
2025-05-13 15:55:01,260:INFO:Plot type: feature
2025-05-13 15:55:01,261:WARNING:No coef_ found. Trying feature_importances_
2025-05-13 15:55:01,335:INFO:Visual Rendered Successfully
2025-05-13 15:55:01,394:INFO:plot_model() successfully completed......................................
2025-05-13 15:55:01,394:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:189: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  age_cancer_ratio = train_df_processed.groupby('Age_Group')['Cancer'].mean() * 100

2025-05-13 15:55:01,413:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 45824 (\N{HANGUL SYLLABLE DAE}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,414:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 51060 (\N{HANGUL SYLLABLE I}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,414:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 49345 (\N{HANGUL SYLLABLE SANG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,415:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 50672 (\N{HANGUL SYLLABLE YEON}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,415:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 47161 (\N{HANGUL SYLLABLE RYEONG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 50516 (\N{HANGUL SYLLABLE AM}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 48156 (\N{HANGUL SYLLABLE BAL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 49373 (\N{HANGUL SYLLABLE SAENG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 48708 (\N{HANGUL SYLLABLE BI}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 50984 (\N{HANGUL SYLLABLE YUL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,419:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50516 (\N{HANGUL SYLLABLE AM}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48156 (\N{HANGUL SYLLABLE BAL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49373 (\N{HANGUL SYLLABLE SAENG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48708 (\N{HANGUL SYLLABLE BI}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50984 (\N{HANGUL SYLLABLE YUL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50672 (\N{HANGUL SYLLABLE YEON}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47161 (\N{HANGUL SYLLABLE RYEONG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 45824 (\N{HANGUL SYLLABLE DAE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,443:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51060 (\N{HANGUL SYLLABLE I}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,443:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49345 (\N{HANGUL SYLLABLE SANG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-14 10:51:08,952:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 10:51:08,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 10:51:08,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 10:51:08,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 10:51:20,862:INFO:PyCaret ClassificationExperiment
2025-05-14 10:51:20,862:INFO:Logging name: clf-default-name
2025-05-14 10:51:20,862:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 10:51:20,862:INFO:version 3.3.2
2025-05-14 10:51:20,862:INFO:Initializing setup()
2025-05-14 10:51:20,862:INFO:self.USI: 5a61
2025-05-14 10:51:20,862:INFO:self._variable_keys: {'USI', 'exp_id', 'X', 'y_train', 'is_multiclass', 'memory', 'idx', 'data', 'y_test', 'n_jobs_param', 'pipeline', 'y', 'fold_generator', 'logging_param', 'fold_groups_param', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'html_param', 'X_test', 'gpu_param', 'X_train', '_available_plots', 'seed', 'exp_name_log', 'fold_shuffle_param', 'log_plots_param', 'target_param'}
2025-05-14 10:51:20,862:INFO:Checking environment
2025-05-14 10:51:20,862:INFO:python_version: 3.11.0
2025-05-14 10:51:20,862:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-14 10:51:20,862:INFO:machine: arm64
2025-05-14 10:51:20,862:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-14 10:51:20,862:INFO:Memory: svmem(total=17179869184, available=4668735488, percent=72.8, used=7316209664, free=78315520, active=4616912896, inactive=4583325696, wired=2699296768)
2025-05-14 10:51:20,862:INFO:Physical Core: 12
2025-05-14 10:51:20,862:INFO:Logical Core: 12
2025-05-14 10:51:20,862:INFO:Checking libraries
2025-05-14 10:51:20,862:INFO:System:
2025-05-14 10:51:20,862:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-14 10:51:20,862:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-14 10:51:20,862:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-14 10:51:20,862:INFO:PyCaret required dependencies:
2025-05-14 10:51:21,005:INFO:                 pip: 22.3
2025-05-14 10:51:21,005:INFO:          setuptools: 65.5.0
2025-05-14 10:51:21,005:INFO:             pycaret: 3.3.2
2025-05-14 10:51:21,005:INFO:             IPython: 9.2.0
2025-05-14 10:51:21,005:INFO:          ipywidgets: 8.1.7
2025-05-14 10:51:21,006:INFO:                tqdm: 4.67.1
2025-05-14 10:51:21,006:INFO:               numpy: 1.26.4
2025-05-14 10:51:21,006:INFO:              pandas: 2.1.4
2025-05-14 10:51:21,006:INFO:              jinja2: 3.1.6
2025-05-14 10:51:21,006:INFO:               scipy: 1.11.4
2025-05-14 10:51:21,006:INFO:              joblib: 1.3.2
2025-05-14 10:51:21,006:INFO:             sklearn: 1.4.2
2025-05-14 10:51:21,006:INFO:                pyod: 2.0.5
2025-05-14 10:51:21,006:INFO:            imblearn: 0.13.0
2025-05-14 10:51:21,006:INFO:   category_encoders: 2.7.0
2025-05-14 10:51:21,006:INFO:            lightgbm: 4.6.0
2025-05-14 10:51:21,006:INFO:               numba: 0.61.2
2025-05-14 10:51:21,006:INFO:            requests: 2.32.3
2025-05-14 10:51:21,006:INFO:          matplotlib: 3.7.5
2025-05-14 10:51:21,006:INFO:          scikitplot: 0.3.7
2025-05-14 10:51:21,006:INFO:         yellowbrick: 1.5
2025-05-14 10:51:21,006:INFO:              plotly: 5.24.1
2025-05-14 10:51:21,006:INFO:    plotly-resampler: Not installed
2025-05-14 10:51:21,006:INFO:             kaleido: 0.2.1
2025-05-14 10:51:21,006:INFO:           schemdraw: 0.15
2025-05-14 10:51:21,006:INFO:         statsmodels: 0.14.4
2025-05-14 10:51:21,006:INFO:              sktime: 0.26.0
2025-05-14 10:51:21,006:INFO:               tbats: 1.1.3
2025-05-14 10:51:21,006:INFO:            pmdarima: 2.0.4
2025-05-14 10:51:21,006:INFO:              psutil: 7.0.0
2025-05-14 10:51:21,006:INFO:          markupsafe: 3.0.2
2025-05-14 10:51:21,006:INFO:             pickle5: Not installed
2025-05-14 10:51:21,006:INFO:         cloudpickle: 3.1.1
2025-05-14 10:51:21,006:INFO:         deprecation: 2.1.0
2025-05-14 10:51:21,006:INFO:              xxhash: 3.5.0
2025-05-14 10:51:21,006:INFO:           wurlitzer: 3.1.1
2025-05-14 10:51:21,006:INFO:PyCaret optional dependencies:
2025-05-14 10:51:21,011:INFO:                shap: 0.47.2
2025-05-14 10:51:21,011:INFO:           interpret: Not installed
2025-05-14 10:51:21,011:INFO:                umap: Not installed
2025-05-14 10:51:21,011:INFO:     ydata_profiling: Not installed
2025-05-14 10:51:21,011:INFO:  explainerdashboard: Not installed
2025-05-14 10:51:21,011:INFO:             autoviz: Not installed
2025-05-14 10:51:21,011:INFO:           fairlearn: Not installed
2025-05-14 10:51:21,011:INFO:          deepchecks: Not installed
2025-05-14 10:51:21,011:INFO:             xgboost: Not installed
2025-05-14 10:51:21,011:INFO:            catboost: 1.2.8
2025-05-14 10:51:21,011:INFO:              kmodes: Not installed
2025-05-14 10:51:21,011:INFO:             mlxtend: Not installed
2025-05-14 10:51:21,011:INFO:       statsforecast: Not installed
2025-05-14 10:51:21,011:INFO:        tune_sklearn: Not installed
2025-05-14 10:51:21,011:INFO:                 ray: Not installed
2025-05-14 10:51:21,011:INFO:            hyperopt: Not installed
2025-05-14 10:51:21,011:INFO:              optuna: 4.3.0
2025-05-14 10:51:21,011:INFO:               skopt: Not installed
2025-05-14 10:51:21,011:INFO:              mlflow: Not installed
2025-05-14 10:51:21,011:INFO:              gradio: Not installed
2025-05-14 10:51:21,011:INFO:             fastapi: Not installed
2025-05-14 10:51:21,011:INFO:             uvicorn: Not installed
2025-05-14 10:51:21,011:INFO:              m2cgen: Not installed
2025-05-14 10:51:21,011:INFO:           evidently: Not installed
2025-05-14 10:51:21,011:INFO:               fugue: Not installed
2025-05-14 10:51:21,011:INFO:           streamlit: Not installed
2025-05-14 10:51:21,011:INFO:             prophet: Not installed
2025-05-14 10:51:21,011:INFO:None
2025-05-14 10:51:21,011:INFO:Set up data.
2025-05-14 10:51:21,049:INFO:Set up folding strategy.
2025-05-14 10:51:21,049:INFO:Set up train/test split.
2025-05-14 10:51:21,082:INFO:Set up index.
2025-05-14 10:51:21,082:INFO:Assigning column types.
2025-05-14 10:51:21,088:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 10:51:21,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 10:51:21,108:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:51:21,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:21,122:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:21,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 10:51:21,141:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:51:21,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:21,152:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:21,152:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 10:51:21,170:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:51:21,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:21,181:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:21,199:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:51:21,210:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:21,210:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:21,211:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 10:51:21,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:21,241:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:21,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:21,271:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:21,273:INFO:Preparing preprocessing pipeline...
2025-05-14 10:51:21,275:INFO:Set up simple imputation.
2025-05-14 10:51:21,283:INFO:Set up encoding of ordinal features.
2025-05-14 10:51:21,294:INFO:Set up encoding of categorical features.
2025-05-14 10:51:21,294:INFO:Set up imbalanced handling.
2025-05-14 10:51:21,294:INFO:Set up column transformation.
2025-05-14 10:51:22,754:INFO:Finished creating preprocessing pipeline.
2025-05-14 10:51:22,773:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-14 10:51:22,773:INFO:Creating final display dataframe.
2025-05-14 10:51:23,278:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              5a61
2025-05-14 10:51:23,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:23,315:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:23,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:23,346:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:23,347:INFO:setup() successfully completed in 2.49s...............
2025-05-14 10:51:23,347:INFO:Initializing compare_models()
2025-05-14 10:51:23,347:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 10:51:23,347:INFO:Checking exceptions
2025-05-14 10:51:23,357:INFO:Preparing display monitor
2025-05-14 10:51:23,368:INFO:Initializing Logistic Regression
2025-05-14 10:51:23,368:INFO:Total runtime is 1.7523765563964843e-06 minutes
2025-05-14 10:51:23,369:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:23,369:INFO:Initializing create_model()
2025-05-14 10:51:23,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:23,369:INFO:Checking exceptions
2025-05-14 10:51:23,370:INFO:Importing libraries
2025-05-14 10:51:23,370:INFO:Copying training dataset
2025-05-14 10:51:23,383:INFO:Defining folds
2025-05-14 10:51:23,383:INFO:Declaring metric variables
2025-05-14 10:51:23,385:INFO:Importing untrained model
2025-05-14 10:51:23,387:INFO:Logistic Regression Imported successfully
2025-05-14 10:51:23,389:INFO:Starting cross validation
2025-05-14 10:51:23,390:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:29,189:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 10:51:29,349:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 10:51:29,374:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 10:51:29,408:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 10:51:29,422:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 10:51:29,486:INFO:Calculating mean and std
2025-05-14 10:51:29,488:INFO:Creating metrics dataframe
2025-05-14 10:51:29,492:INFO:Uploading results into container
2025-05-14 10:51:29,493:INFO:Uploading model into container now
2025-05-14 10:51:29,494:INFO:_master_model_container: 1
2025-05-14 10:51:29,495:INFO:_display_container: 2
2025-05-14 10:51:29,497:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 10:51:29,497:INFO:create_model() successfully completed......................................
2025-05-14 10:51:29,632:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:29,632:INFO:Creating metrics dataframe
2025-05-14 10:51:29,635:INFO:Initializing K Neighbors Classifier
2025-05-14 10:51:29,635:INFO:Total runtime is 0.10445725123087564 minutes
2025-05-14 10:51:29,637:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:29,637:INFO:Initializing create_model()
2025-05-14 10:51:29,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:29,637:INFO:Checking exceptions
2025-05-14 10:51:29,637:INFO:Importing libraries
2025-05-14 10:51:29,637:INFO:Copying training dataset
2025-05-14 10:51:29,648:INFO:Defining folds
2025-05-14 10:51:29,648:INFO:Declaring metric variables
2025-05-14 10:51:29,649:INFO:Importing untrained model
2025-05-14 10:51:29,651:INFO:K Neighbors Classifier Imported successfully
2025-05-14 10:51:29,653:INFO:Starting cross validation
2025-05-14 10:51:29,654:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:35,685:INFO:Calculating mean and std
2025-05-14 10:51:35,686:INFO:Creating metrics dataframe
2025-05-14 10:51:35,692:INFO:Uploading results into container
2025-05-14 10:51:35,692:INFO:Uploading model into container now
2025-05-14 10:51:35,693:INFO:_master_model_container: 2
2025-05-14 10:51:35,693:INFO:_display_container: 2
2025-05-14 10:51:35,693:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 10:51:35,693:INFO:create_model() successfully completed......................................
2025-05-14 10:51:35,772:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:35,772:INFO:Creating metrics dataframe
2025-05-14 10:51:35,775:INFO:Initializing Naive Bayes
2025-05-14 10:51:35,775:INFO:Total runtime is 0.20678410132726033 minutes
2025-05-14 10:51:35,776:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:35,776:INFO:Initializing create_model()
2025-05-14 10:51:35,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:35,776:INFO:Checking exceptions
2025-05-14 10:51:35,776:INFO:Importing libraries
2025-05-14 10:51:35,776:INFO:Copying training dataset
2025-05-14 10:51:35,788:INFO:Defining folds
2025-05-14 10:51:35,788:INFO:Declaring metric variables
2025-05-14 10:51:35,790:INFO:Importing untrained model
2025-05-14 10:51:35,791:INFO:Naive Bayes Imported successfully
2025-05-14 10:51:35,793:INFO:Starting cross validation
2025-05-14 10:51:35,794:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:38,097:INFO:Calculating mean and std
2025-05-14 10:51:38,098:INFO:Creating metrics dataframe
2025-05-14 10:51:38,099:INFO:Uploading results into container
2025-05-14 10:51:38,099:INFO:Uploading model into container now
2025-05-14 10:51:38,099:INFO:_master_model_container: 3
2025-05-14 10:51:38,099:INFO:_display_container: 2
2025-05-14 10:51:38,099:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 10:51:38,099:INFO:create_model() successfully completed......................................
2025-05-14 10:51:38,167:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:38,167:INFO:Creating metrics dataframe
2025-05-14 10:51:38,170:INFO:Initializing Decision Tree Classifier
2025-05-14 10:51:38,170:INFO:Total runtime is 0.2467023173967997 minutes
2025-05-14 10:51:38,171:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:38,171:INFO:Initializing create_model()
2025-05-14 10:51:38,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:38,171:INFO:Checking exceptions
2025-05-14 10:51:38,172:INFO:Importing libraries
2025-05-14 10:51:38,172:INFO:Copying training dataset
2025-05-14 10:51:38,181:INFO:Defining folds
2025-05-14 10:51:38,181:INFO:Declaring metric variables
2025-05-14 10:51:38,182:INFO:Importing untrained model
2025-05-14 10:51:38,183:INFO:Decision Tree Classifier Imported successfully
2025-05-14 10:51:38,186:INFO:Starting cross validation
2025-05-14 10:51:38,187:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:39,861:INFO:Calculating mean and std
2025-05-14 10:51:39,861:INFO:Creating metrics dataframe
2025-05-14 10:51:39,862:INFO:Uploading results into container
2025-05-14 10:51:39,862:INFO:Uploading model into container now
2025-05-14 10:51:39,863:INFO:_master_model_container: 4
2025-05-14 10:51:39,863:INFO:_display_container: 2
2025-05-14 10:51:39,863:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-14 10:51:39,863:INFO:create_model() successfully completed......................................
2025-05-14 10:51:39,922:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:39,923:INFO:Creating metrics dataframe
2025-05-14 10:51:39,926:INFO:Initializing SVM - Linear Kernel
2025-05-14 10:51:39,926:INFO:Total runtime is 0.2759643832842509 minutes
2025-05-14 10:51:39,927:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:39,927:INFO:Initializing create_model()
2025-05-14 10:51:39,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:39,927:INFO:Checking exceptions
2025-05-14 10:51:39,927:INFO:Importing libraries
2025-05-14 10:51:39,927:INFO:Copying training dataset
2025-05-14 10:51:39,936:INFO:Defining folds
2025-05-14 10:51:39,936:INFO:Declaring metric variables
2025-05-14 10:51:39,938:INFO:Importing untrained model
2025-05-14 10:51:39,939:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 10:51:39,941:INFO:Starting cross validation
2025-05-14 10:51:39,942:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:43,401:INFO:Calculating mean and std
2025-05-14 10:51:43,406:INFO:Creating metrics dataframe
2025-05-14 10:51:43,409:INFO:Uploading results into container
2025-05-14 10:51:43,409:INFO:Uploading model into container now
2025-05-14 10:51:43,410:INFO:_master_model_container: 5
2025-05-14 10:51:43,410:INFO:_display_container: 2
2025-05-14 10:51:43,411:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 10:51:43,411:INFO:create_model() successfully completed......................................
2025-05-14 10:51:43,491:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:43,491:INFO:Creating metrics dataframe
2025-05-14 10:51:43,494:INFO:Initializing Ridge Classifier
2025-05-14 10:51:43,494:INFO:Total runtime is 0.3354432185490926 minutes
2025-05-14 10:51:43,496:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:43,496:INFO:Initializing create_model()
2025-05-14 10:51:43,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:43,496:INFO:Checking exceptions
2025-05-14 10:51:43,496:INFO:Importing libraries
2025-05-14 10:51:43,496:INFO:Copying training dataset
2025-05-14 10:51:43,507:INFO:Defining folds
2025-05-14 10:51:43,507:INFO:Declaring metric variables
2025-05-14 10:51:43,508:INFO:Importing untrained model
2025-05-14 10:51:43,509:INFO:Ridge Classifier Imported successfully
2025-05-14 10:51:43,511:INFO:Starting cross validation
2025-05-14 10:51:43,513:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:45,748:INFO:Calculating mean and std
2025-05-14 10:51:45,748:INFO:Creating metrics dataframe
2025-05-14 10:51:45,750:INFO:Uploading results into container
2025-05-14 10:51:45,750:INFO:Uploading model into container now
2025-05-14 10:51:45,750:INFO:_master_model_container: 6
2025-05-14 10:51:45,750:INFO:_display_container: 2
2025-05-14 10:51:45,750:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-14 10:51:45,751:INFO:create_model() successfully completed......................................
2025-05-14 10:51:45,815:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:45,815:INFO:Creating metrics dataframe
2025-05-14 10:51:45,818:INFO:Initializing Random Forest Classifier
2025-05-14 10:51:45,818:INFO:Total runtime is 0.37417763471603394 minutes
2025-05-14 10:51:45,820:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:45,820:INFO:Initializing create_model()
2025-05-14 10:51:45,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:45,820:INFO:Checking exceptions
2025-05-14 10:51:45,820:INFO:Importing libraries
2025-05-14 10:51:45,820:INFO:Copying training dataset
2025-05-14 10:51:45,830:INFO:Defining folds
2025-05-14 10:51:45,830:INFO:Declaring metric variables
2025-05-14 10:51:45,831:INFO:Importing untrained model
2025-05-14 10:51:45,833:INFO:Random Forest Classifier Imported successfully
2025-05-14 10:51:45,835:INFO:Starting cross validation
2025-05-14 10:51:45,836:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:51,899:INFO:Calculating mean and std
2025-05-14 10:51:51,900:INFO:Creating metrics dataframe
2025-05-14 10:51:51,901:INFO:Uploading results into container
2025-05-14 10:51:51,901:INFO:Uploading model into container now
2025-05-14 10:51:51,902:INFO:_master_model_container: 7
2025-05-14 10:51:51,902:INFO:_display_container: 2
2025-05-14 10:51:51,903:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 10:51:51,903:INFO:create_model() successfully completed......................................
2025-05-14 10:51:51,983:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:51,983:INFO:Creating metrics dataframe
2025-05-14 10:51:51,987:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 10:51:51,987:INFO:Total runtime is 0.4769856532414754 minutes
2025-05-14 10:51:51,988:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:51,989:INFO:Initializing create_model()
2025-05-14 10:51:51,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:51,989:INFO:Checking exceptions
2025-05-14 10:51:51,989:INFO:Importing libraries
2025-05-14 10:51:51,989:INFO:Copying training dataset
2025-05-14 10:51:52,005:INFO:Defining folds
2025-05-14 10:51:52,006:INFO:Declaring metric variables
2025-05-14 10:51:52,007:INFO:Importing untrained model
2025-05-14 10:51:52,008:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 10:51:52,011:INFO:Starting cross validation
2025-05-14 10:51:52,012:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:53,094:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 10:51:53,115:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 10:51:53,150:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 10:51:53,185:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 10:51:53,189:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:51:53,203:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:51:53,229:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 10:51:53,246:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:51:53,272:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:51:53,311:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:51:53,329:INFO:Calculating mean and std
2025-05-14 10:51:53,331:INFO:Creating metrics dataframe
2025-05-14 10:51:53,338:INFO:Uploading results into container
2025-05-14 10:51:53,339:INFO:Uploading model into container now
2025-05-14 10:51:53,339:INFO:_master_model_container: 8
2025-05-14 10:51:53,339:INFO:_display_container: 2
2025-05-14 10:51:53,339:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 10:51:53,339:INFO:create_model() successfully completed......................................
2025-05-14 10:51:53,442:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:53,442:INFO:Creating metrics dataframe
2025-05-14 10:51:53,446:INFO:Initializing Ada Boost Classifier
2025-05-14 10:51:53,446:INFO:Total runtime is 0.5013117671012878 minutes
2025-05-14 10:51:53,448:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:53,448:INFO:Initializing create_model()
2025-05-14 10:51:53,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:53,448:INFO:Checking exceptions
2025-05-14 10:51:53,448:INFO:Importing libraries
2025-05-14 10:51:53,448:INFO:Copying training dataset
2025-05-14 10:51:53,460:INFO:Defining folds
2025-05-14 10:51:53,460:INFO:Declaring metric variables
2025-05-14 10:51:53,461:INFO:Importing untrained model
2025-05-14 10:51:53,463:INFO:Ada Boost Classifier Imported successfully
2025-05-14 10:51:53,465:INFO:Starting cross validation
2025-05-14 10:51:53,466:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:54,498:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 10:51:54,527:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 10:51:54,529:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 10:51:54,614:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 10:51:56,147:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 10:51:58,813:INFO:Calculating mean and std
2025-05-14 10:51:58,814:INFO:Creating metrics dataframe
2025-05-14 10:51:58,816:INFO:Uploading results into container
2025-05-14 10:51:58,816:INFO:Uploading model into container now
2025-05-14 10:51:58,816:INFO:_master_model_container: 9
2025-05-14 10:51:58,816:INFO:_display_container: 2
2025-05-14 10:51:58,816:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-14 10:51:58,816:INFO:create_model() successfully completed......................................
2025-05-14 10:51:58,885:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:58,885:INFO:Creating metrics dataframe
2025-05-14 10:51:58,889:INFO:Initializing Gradient Boosting Classifier
2025-05-14 10:51:58,889:INFO:Total runtime is 0.5920176029205322 minutes
2025-05-14 10:51:58,890:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:58,890:INFO:Initializing create_model()
2025-05-14 10:51:58,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:58,890:INFO:Checking exceptions
2025-05-14 10:51:58,890:INFO:Importing libraries
2025-05-14 10:51:58,890:INFO:Copying training dataset
2025-05-14 10:51:58,902:INFO:Defining folds
2025-05-14 10:51:58,902:INFO:Declaring metric variables
2025-05-14 10:51:58,903:INFO:Importing untrained model
2025-05-14 10:51:58,905:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 10:51:58,907:INFO:Starting cross validation
2025-05-14 10:51:58,908:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:52:12,615:INFO:Calculating mean and std
2025-05-14 10:52:12,616:INFO:Creating metrics dataframe
2025-05-14 10:52:12,618:INFO:Uploading results into container
2025-05-14 10:52:12,618:INFO:Uploading model into container now
2025-05-14 10:52:12,618:INFO:_master_model_container: 10
2025-05-14 10:52:12,618:INFO:_display_container: 2
2025-05-14 10:52:12,619:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 10:52:12,619:INFO:create_model() successfully completed......................................
2025-05-14 10:52:12,694:INFO:SubProcess create_model() end ==================================
2025-05-14 10:52:12,694:INFO:Creating metrics dataframe
2025-05-14 10:52:12,698:INFO:Initializing Linear Discriminant Analysis
2025-05-14 10:52:12,698:INFO:Total runtime is 0.8221716483434041 minutes
2025-05-14 10:52:12,699:INFO:SubProcess create_model() called ==================================
2025-05-14 10:52:12,699:INFO:Initializing create_model()
2025-05-14 10:52:12,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:52:12,700:INFO:Checking exceptions
2025-05-14 10:52:12,700:INFO:Importing libraries
2025-05-14 10:52:12,700:INFO:Copying training dataset
2025-05-14 10:52:12,711:INFO:Defining folds
2025-05-14 10:52:12,711:INFO:Declaring metric variables
2025-05-14 10:52:12,712:INFO:Importing untrained model
2025-05-14 10:52:12,713:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 10:52:12,715:INFO:Starting cross validation
2025-05-14 10:52:12,717:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:52:14,014:INFO:Calculating mean and std
2025-05-14 10:52:14,015:INFO:Creating metrics dataframe
2025-05-14 10:52:14,016:INFO:Uploading results into container
2025-05-14 10:52:14,017:INFO:Uploading model into container now
2025-05-14 10:52:14,017:INFO:_master_model_container: 11
2025-05-14 10:52:14,017:INFO:_display_container: 2
2025-05-14 10:52:14,017:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 10:52:14,017:INFO:create_model() successfully completed......................................
2025-05-14 10:52:14,087:INFO:SubProcess create_model() end ==================================
2025-05-14 10:52:14,087:INFO:Creating metrics dataframe
2025-05-14 10:52:14,091:INFO:Initializing Extra Trees Classifier
2025-05-14 10:52:14,091:INFO:Total runtime is 0.8453885197639465 minutes
2025-05-14 10:52:14,092:INFO:SubProcess create_model() called ==================================
2025-05-14 10:52:14,093:INFO:Initializing create_model()
2025-05-14 10:52:14,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:52:14,093:INFO:Checking exceptions
2025-05-14 10:52:14,093:INFO:Importing libraries
2025-05-14 10:52:14,093:INFO:Copying training dataset
2025-05-14 10:52:14,105:INFO:Defining folds
2025-05-14 10:52:14,105:INFO:Declaring metric variables
2025-05-14 10:52:14,106:INFO:Importing untrained model
2025-05-14 10:52:14,108:INFO:Extra Trees Classifier Imported successfully
2025-05-14 10:52:14,110:INFO:Starting cross validation
2025-05-14 10:52:14,111:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:52:18,626:INFO:Calculating mean and std
2025-05-14 10:52:18,629:INFO:Creating metrics dataframe
2025-05-14 10:52:18,632:INFO:Uploading results into container
2025-05-14 10:52:18,633:INFO:Uploading model into container now
2025-05-14 10:52:18,633:INFO:_master_model_container: 12
2025-05-14 10:52:18,633:INFO:_display_container: 2
2025-05-14 10:52:18,634:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-14 10:52:18,634:INFO:create_model() successfully completed......................................
2025-05-14 10:52:18,787:INFO:SubProcess create_model() end ==================================
2025-05-14 10:52:18,787:INFO:Creating metrics dataframe
2025-05-14 10:52:18,792:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 10:52:18,792:INFO:Total runtime is 0.9237370332082112 minutes
2025-05-14 10:52:18,794:INFO:SubProcess create_model() called ==================================
2025-05-14 10:52:18,795:INFO:Initializing create_model()
2025-05-14 10:52:18,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:52:18,795:INFO:Checking exceptions
2025-05-14 10:52:18,795:INFO:Importing libraries
2025-05-14 10:52:18,795:INFO:Copying training dataset
2025-05-14 10:52:18,809:INFO:Defining folds
2025-05-14 10:52:18,809:INFO:Declaring metric variables
2025-05-14 10:52:18,811:INFO:Importing untrained model
2025-05-14 10:52:18,813:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 10:52:18,815:INFO:Starting cross validation
2025-05-14 10:52:18,816:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:52:23,127:INFO:Calculating mean and std
2025-05-14 10:52:23,127:INFO:Creating metrics dataframe
2025-05-14 10:52:23,128:INFO:Uploading results into container
2025-05-14 10:52:23,129:INFO:Uploading model into container now
2025-05-14 10:52:23,129:INFO:_master_model_container: 13
2025-05-14 10:52:23,129:INFO:_display_container: 2
2025-05-14 10:52:23,129:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 10:52:23,129:INFO:create_model() successfully completed......................................
2025-05-14 10:52:23,198:INFO:SubProcess create_model() end ==================================
2025-05-14 10:52:23,198:INFO:Creating metrics dataframe
2025-05-14 10:52:23,203:INFO:Initializing CatBoost Classifier
2025-05-14 10:52:23,203:INFO:Total runtime is 0.9972560683886209 minutes
2025-05-14 10:52:23,204:INFO:SubProcess create_model() called ==================================
2025-05-14 10:52:23,205:INFO:Initializing create_model()
2025-05-14 10:52:23,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:52:23,205:INFO:Checking exceptions
2025-05-14 10:52:23,205:INFO:Importing libraries
2025-05-14 10:52:23,205:INFO:Copying training dataset
2025-05-14 10:52:23,215:INFO:Defining folds
2025-05-14 10:52:23,215:INFO:Declaring metric variables
2025-05-14 10:52:23,216:INFO:Importing untrained model
2025-05-14 10:52:23,218:INFO:CatBoost Classifier Imported successfully
2025-05-14 10:52:23,220:INFO:Starting cross validation
2025-05-14 10:52:23,222:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:52:40,313:INFO:Calculating mean and std
2025-05-14 10:52:40,315:INFO:Creating metrics dataframe
2025-05-14 10:52:40,316:INFO:Uploading results into container
2025-05-14 10:52:40,317:INFO:Uploading model into container now
2025-05-14 10:52:40,317:INFO:_master_model_container: 14
2025-05-14 10:52:40,317:INFO:_display_container: 2
2025-05-14 10:52:40,317:INFO:<catboost.core.CatBoostClassifier object at 0x33ce16410>
2025-05-14 10:52:40,317:INFO:create_model() successfully completed......................................
2025-05-14 10:52:40,400:INFO:SubProcess create_model() end ==================================
2025-05-14 10:52:40,400:INFO:Creating metrics dataframe
2025-05-14 10:52:40,404:INFO:Initializing Dummy Classifier
2025-05-14 10:52:40,404:INFO:Total runtime is 1.2839414199193318 minutes
2025-05-14 10:52:40,406:INFO:SubProcess create_model() called ==================================
2025-05-14 10:52:40,406:INFO:Initializing create_model()
2025-05-14 10:52:40,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:52:40,406:INFO:Checking exceptions
2025-05-14 10:52:40,406:INFO:Importing libraries
2025-05-14 10:52:40,406:INFO:Copying training dataset
2025-05-14 10:52:40,418:INFO:Defining folds
2025-05-14 10:52:40,418:INFO:Declaring metric variables
2025-05-14 10:52:40,420:INFO:Importing untrained model
2025-05-14 10:52:40,421:INFO:Dummy Classifier Imported successfully
2025-05-14 10:52:40,424:INFO:Starting cross validation
2025-05-14 10:52:40,425:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:52:41,493:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:52:41,507:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:52:41,539:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:52:41,589:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:52:41,668:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:52:41,676:INFO:Calculating mean and std
2025-05-14 10:52:41,676:INFO:Creating metrics dataframe
2025-05-14 10:52:41,677:INFO:Uploading results into container
2025-05-14 10:52:41,677:INFO:Uploading model into container now
2025-05-14 10:52:41,677:INFO:_master_model_container: 15
2025-05-14 10:52:41,677:INFO:_display_container: 2
2025-05-14 10:52:41,677:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-14 10:52:41,678:INFO:create_model() successfully completed......................................
2025-05-14 10:52:41,741:INFO:SubProcess create_model() end ==================================
2025-05-14 10:52:41,741:INFO:Creating metrics dataframe
2025-05-14 10:52:41,746:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2025-05-14 10:52:41,749:INFO:Initializing create_model()
2025-05-14 10:52:41,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:52:41,749:INFO:Checking exceptions
2025-05-14 10:52:41,750:INFO:Importing libraries
2025-05-14 10:52:41,750:INFO:Copying training dataset
2025-05-14 10:52:41,760:INFO:Defining folds
2025-05-14 10:52:41,760:INFO:Declaring metric variables
2025-05-14 10:52:41,760:INFO:Importing untrained model
2025-05-14 10:52:41,760:INFO:Declaring custom model
2025-05-14 10:52:41,760:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 10:52:41,761:INFO:Cross validation set to False
2025-05-14 10:52:41,761:INFO:Fitting Model
2025-05-14 10:52:43,157:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 10:52:43,167:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004613 seconds.
2025-05-14 10:52:43,167:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 10:52:43,167:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 10:52:43,167:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 10:52:43,167:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 10:52:43,167:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 10:52:43,924:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 10:52:43,924:INFO:create_model() successfully completed......................................
2025-05-14 10:52:43,984:INFO:Initializing create_model()
2025-05-14 10:52:43,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:52:43,984:INFO:Checking exceptions
2025-05-14 10:52:43,985:INFO:Importing libraries
2025-05-14 10:52:43,985:INFO:Copying training dataset
2025-05-14 10:52:43,995:INFO:Defining folds
2025-05-14 10:52:43,995:INFO:Declaring metric variables
2025-05-14 10:52:43,995:INFO:Importing untrained model
2025-05-14 10:52:43,995:INFO:Declaring custom model
2025-05-14 10:52:43,996:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 10:52:43,996:INFO:Cross validation set to False
2025-05-14 10:52:43,996:INFO:Fitting Model
2025-05-14 10:53:00,176:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 10:53:00,176:INFO:create_model() successfully completed......................................
2025-05-14 10:53:00,278:INFO:Initializing create_model()
2025-05-14 10:53:00,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:53:00,278:INFO:Checking exceptions
2025-05-14 10:53:00,279:INFO:Importing libraries
2025-05-14 10:53:00,279:INFO:Copying training dataset
2025-05-14 10:53:00,290:INFO:Defining folds
2025-05-14 10:53:00,290:INFO:Declaring metric variables
2025-05-14 10:53:00,290:INFO:Importing untrained model
2025-05-14 10:53:00,290:INFO:Declaring custom model
2025-05-14 10:53:00,290:INFO:Random Forest Classifier Imported successfully
2025-05-14 10:53:00,291:INFO:Cross validation set to False
2025-05-14 10:53:00,291:INFO:Fitting Model
2025-05-14 10:53:02,663:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 10:53:02,663:INFO:create_model() successfully completed......................................
2025-05-14 10:53:02,729:INFO:_master_model_container: 15
2025-05-14 10:53:02,730:INFO:_display_container: 2
2025-05-14 10:53:02,730:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-14 10:53:02,730:INFO:compare_models() successfully completed......................................
2025-05-14 10:53:02,731:INFO:Initializing evaluate_model()
2025-05-14 10:53:02,731:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 10:53:02,737:INFO:Initializing plot_model()
2025-05-14 10:53:02,737:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 10:53:02,737:INFO:Checking exceptions
2025-05-14 10:53:02,741:INFO:Preloading libraries
2025-05-14 10:53:02,742:INFO:Copying training dataset
2025-05-14 10:53:02,742:INFO:Plot type: pipeline
2025-05-14 10:53:02,818:INFO:Visual Rendered Successfully
2025-05-14 10:53:02,881:INFO:plot_model() successfully completed......................................
2025-05-14 10:53:02,882:INFO:Initializing tune_model()
2025-05-14 10:53:02,882:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 10:53:02,882:INFO:Checking exceptions
2025-05-14 10:53:02,891:INFO:Copying training dataset
2025-05-14 10:53:02,898:INFO:Checking base model
2025-05-14 10:53:02,898:INFO:Base model : Light Gradient Boosting Machine
2025-05-14 10:53:02,899:INFO:Declaring metric variables
2025-05-14 10:53:02,900:INFO:Defining Hyperparameters
2025-05-14 10:53:02,961:INFO:Tuning with n_jobs=-1
2025-05-14 10:53:02,961:INFO:Initializing RandomizedSearchCV
2025-05-14 10:53:41,166:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-14 10:53:41,169:INFO:Hyperparameter search completed
2025-05-14 10:53:41,170:INFO:SubProcess create_model() called ==================================
2025-05-14 10:53:41,172:INFO:Initializing create_model()
2025-05-14 10:53:41,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336c18dd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-14 10:53:41,172:INFO:Checking exceptions
2025-05-14 10:53:41,172:INFO:Importing libraries
2025-05-14 10:53:41,172:INFO:Copying training dataset
2025-05-14 10:53:41,196:INFO:Defining folds
2025-05-14 10:53:41,196:INFO:Declaring metric variables
2025-05-14 10:53:41,201:INFO:Importing untrained model
2025-05-14 10:53:41,201:INFO:Declaring custom model
2025-05-14 10:53:41,204:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 10:53:41,210:INFO:Starting cross validation
2025-05-14 10:53:41,221:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:53:48,107:INFO:Calculating mean and std
2025-05-14 10:53:48,110:INFO:Creating metrics dataframe
2025-05-14 10:53:48,116:INFO:Finalizing model
2025-05-14 10:53:49,208:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 10:53:49,208:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 10:53:49,208:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 10:53:49,242:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 10:53:49,242:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 10:53:49,242:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 10:53:49,242:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 10:53:49,258:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009285 seconds.
2025-05-14 10:53:49,258:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 10:53:49,258:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 10:53:49,258:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 10:53:49,258:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 10:53:49,258:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 10:53:50,712:INFO:Uploading results into container
2025-05-14 10:53:50,713:INFO:Uploading model into container now
2025-05-14 10:53:50,713:INFO:_master_model_container: 16
2025-05-14 10:53:50,713:INFO:_display_container: 3
2025-05-14 10:53:50,714:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 10:53:50,714:INFO:create_model() successfully completed......................................
2025-05-14 10:53:50,819:INFO:SubProcess create_model() end ==================================
2025-05-14 10:53:50,819:INFO:choose_better activated
2025-05-14 10:53:50,820:INFO:SubProcess create_model() called ==================================
2025-05-14 10:53:50,821:INFO:Initializing create_model()
2025-05-14 10:53:50,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:53:50,821:INFO:Checking exceptions
2025-05-14 10:53:50,822:INFO:Importing libraries
2025-05-14 10:53:50,822:INFO:Copying training dataset
2025-05-14 10:53:50,831:INFO:Defining folds
2025-05-14 10:53:50,832:INFO:Declaring metric variables
2025-05-14 10:53:50,832:INFO:Importing untrained model
2025-05-14 10:53:50,832:INFO:Declaring custom model
2025-05-14 10:53:50,832:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 10:53:50,832:INFO:Starting cross validation
2025-05-14 10:53:50,833:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:53:54,673:INFO:Calculating mean and std
2025-05-14 10:53:54,673:INFO:Creating metrics dataframe
2025-05-14 10:53:54,674:INFO:Finalizing model
2025-05-14 10:53:55,728:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 10:53:55,740:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005132 seconds.
2025-05-14 10:53:55,740:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 10:53:55,740:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 10:53:55,740:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 10:53:55,740:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 10:53:55,740:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 10:53:56,505:INFO:Uploading results into container
2025-05-14 10:53:56,505:INFO:Uploading model into container now
2025-05-14 10:53:56,506:INFO:_master_model_container: 17
2025-05-14 10:53:56,506:INFO:_display_container: 4
2025-05-14 10:53:56,506:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 10:53:56,506:INFO:create_model() successfully completed......................................
2025-05-14 10:53:56,569:INFO:SubProcess create_model() end ==================================
2025-05-14 10:53:56,569:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-14 10:53:56,570:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-14 10:53:56,570:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-14 10:53:56,570:INFO:choose_better completed
2025-05-14 10:53:56,574:INFO:_master_model_container: 17
2025-05-14 10:53:56,574:INFO:_display_container: 3
2025-05-14 10:53:56,574:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 10:53:56,574:INFO:tune_model() successfully completed......................................
2025-05-14 10:53:56,639:INFO:Initializing evaluate_model()
2025-05-14 10:53:56,639:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 10:53:56,646:INFO:Initializing plot_model()
2025-05-14 10:53:56,646:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 10:53:56,646:INFO:Checking exceptions
2025-05-14 10:53:56,650:INFO:Preloading libraries
2025-05-14 10:53:56,652:INFO:Copying training dataset
2025-05-14 10:53:56,652:INFO:Plot type: pipeline
2025-05-14 10:53:56,709:INFO:Visual Rendered Successfully
2025-05-14 10:53:56,771:INFO:plot_model() successfully completed......................................
2025-05-14 10:53:56,773:INFO:Initializing interpret_model()
2025-05-14 10:53:56,773:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 10:53:56,773:INFO:Checking exceptions
2025-05-14 10:53:56,773:INFO:Soft dependency imported: shap: 0.47.2
2025-05-14 10:53:57,857:INFO:plot type: summary
2025-05-14 10:53:57,857:INFO:Creating TreeExplainer
2025-05-14 10:53:57,934:INFO:Compiling shap values
2025-05-14 10:53:59,133:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning:

LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray


2025-05-14 10:53:59,133:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning:

The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.


2025-05-14 10:54:00,416:INFO:Visual Rendered Successfully
2025-05-14 10:54:00,416:INFO:interpret_model() successfully completed......................................
2025-05-14 10:54:00,490:INFO:PyCaret ClassificationExperiment
2025-05-14 10:54:00,490:INFO:Logging name: clf-default-name
2025-05-14 10:54:00,490:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 10:54:00,490:INFO:version 3.3.2
2025-05-14 10:54:00,490:INFO:Initializing setup()
2025-05-14 10:54:00,490:INFO:self.USI: 9474
2025-05-14 10:54:00,490:INFO:self._variable_keys: {'USI', 'exp_id', 'X', 'y_train', 'is_multiclass', 'memory', 'idx', 'data', 'y_test', 'n_jobs_param', 'pipeline', 'y', 'fold_generator', 'logging_param', 'fold_groups_param', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'html_param', 'X_test', 'gpu_param', 'X_train', '_available_plots', 'seed', 'exp_name_log', 'fold_shuffle_param', 'log_plots_param', 'target_param'}
2025-05-14 10:54:00,490:INFO:Checking environment
2025-05-14 10:54:00,490:INFO:python_version: 3.11.0
2025-05-14 10:54:00,490:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-14 10:54:00,490:INFO:machine: arm64
2025-05-14 10:54:00,490:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-14 10:54:00,490:INFO:Memory: svmem(total=17179869184, available=3576659968, percent=79.2, used=5830524928, free=57999360, active=3528589312, inactive=3503734784, wired=2301935616)
2025-05-14 10:54:00,490:INFO:Physical Core: 12
2025-05-14 10:54:00,490:INFO:Logical Core: 12
2025-05-14 10:54:00,491:INFO:Checking libraries
2025-05-14 10:54:00,491:INFO:System:
2025-05-14 10:54:00,491:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-14 10:54:00,491:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-14 10:54:00,491:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-14 10:54:00,491:INFO:PyCaret required dependencies:
2025-05-14 10:54:00,491:INFO:                 pip: 22.3
2025-05-14 10:54:00,491:INFO:          setuptools: 65.5.0
2025-05-14 10:54:00,491:INFO:             pycaret: 3.3.2
2025-05-14 10:54:00,491:INFO:             IPython: 9.2.0
2025-05-14 10:54:00,491:INFO:          ipywidgets: 8.1.7
2025-05-14 10:54:00,491:INFO:                tqdm: 4.67.1
2025-05-14 10:54:00,491:INFO:               numpy: 1.26.4
2025-05-14 10:54:00,491:INFO:              pandas: 2.1.4
2025-05-14 10:54:00,491:INFO:              jinja2: 3.1.6
2025-05-14 10:54:00,491:INFO:               scipy: 1.11.4
2025-05-14 10:54:00,491:INFO:              joblib: 1.3.2
2025-05-14 10:54:00,491:INFO:             sklearn: 1.4.2
2025-05-14 10:54:00,491:INFO:                pyod: 2.0.5
2025-05-14 10:54:00,491:INFO:            imblearn: 0.13.0
2025-05-14 10:54:00,491:INFO:   category_encoders: 2.7.0
2025-05-14 10:54:00,491:INFO:            lightgbm: 4.6.0
2025-05-14 10:54:00,491:INFO:               numba: 0.61.2
2025-05-14 10:54:00,491:INFO:            requests: 2.32.3
2025-05-14 10:54:00,491:INFO:          matplotlib: 3.7.5
2025-05-14 10:54:00,491:INFO:          scikitplot: 0.3.7
2025-05-14 10:54:00,491:INFO:         yellowbrick: 1.5
2025-05-14 10:54:00,491:INFO:              plotly: 5.24.1
2025-05-14 10:54:00,491:INFO:    plotly-resampler: Not installed
2025-05-14 10:54:00,491:INFO:             kaleido: 0.2.1
2025-05-14 10:54:00,491:INFO:           schemdraw: 0.15
2025-05-14 10:54:00,491:INFO:         statsmodels: 0.14.4
2025-05-14 10:54:00,491:INFO:              sktime: 0.26.0
2025-05-14 10:54:00,491:INFO:               tbats: 1.1.3
2025-05-14 10:54:00,491:INFO:            pmdarima: 2.0.4
2025-05-14 10:54:00,491:INFO:              psutil: 7.0.0
2025-05-14 10:54:00,491:INFO:          markupsafe: 3.0.2
2025-05-14 10:54:00,491:INFO:             pickle5: Not installed
2025-05-14 10:54:00,491:INFO:         cloudpickle: 3.1.1
2025-05-14 10:54:00,491:INFO:         deprecation: 2.1.0
2025-05-14 10:54:00,491:INFO:              xxhash: 3.5.0
2025-05-14 10:54:00,491:INFO:           wurlitzer: 3.1.1
2025-05-14 10:54:00,491:INFO:PyCaret optional dependencies:
2025-05-14 10:54:00,491:INFO:                shap: 0.47.2
2025-05-14 10:54:00,491:INFO:           interpret: Not installed
2025-05-14 10:54:00,491:INFO:                umap: Not installed
2025-05-14 10:54:00,491:INFO:     ydata_profiling: Not installed
2025-05-14 10:54:00,491:INFO:  explainerdashboard: Not installed
2025-05-14 10:54:00,491:INFO:             autoviz: Not installed
2025-05-14 10:54:00,491:INFO:           fairlearn: Not installed
2025-05-14 10:54:00,491:INFO:          deepchecks: Not installed
2025-05-14 10:54:00,491:INFO:             xgboost: Not installed
2025-05-14 10:54:00,491:INFO:            catboost: 1.2.8
2025-05-14 10:54:00,491:INFO:              kmodes: Not installed
2025-05-14 10:54:00,491:INFO:             mlxtend: Not installed
2025-05-14 10:54:00,491:INFO:       statsforecast: Not installed
2025-05-14 10:54:00,491:INFO:        tune_sklearn: Not installed
2025-05-14 10:54:00,491:INFO:                 ray: Not installed
2025-05-14 10:54:00,491:INFO:            hyperopt: Not installed
2025-05-14 10:54:00,491:INFO:              optuna: 4.3.0
2025-05-14 10:54:00,491:INFO:               skopt: Not installed
2025-05-14 10:54:00,491:INFO:              mlflow: Not installed
2025-05-14 10:54:00,491:INFO:              gradio: Not installed
2025-05-14 10:54:00,491:INFO:             fastapi: Not installed
2025-05-14 10:54:00,491:INFO:             uvicorn: Not installed
2025-05-14 10:54:00,491:INFO:              m2cgen: Not installed
2025-05-14 10:54:00,491:INFO:           evidently: Not installed
2025-05-14 10:54:00,491:INFO:               fugue: Not installed
2025-05-14 10:54:00,491:INFO:           streamlit: Not installed
2025-05-14 10:54:00,491:INFO:             prophet: Not installed
2025-05-14 10:54:00,491:INFO:None
2025-05-14 10:54:00,491:INFO:Set up data.
2025-05-14 10:54:00,542:INFO:Set up folding strategy.
2025-05-14 10:54:00,542:INFO:Set up train/test split.
2025-05-14 10:54:00,558:INFO:Set up index.
2025-05-14 10:54:00,559:INFO:Assigning column types.
2025-05-14 10:54:00,563:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 10:54:00,581:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 10:54:00,581:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:54:00,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:00,592:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:00,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 10:54:00,610:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:54:00,621:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:00,621:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:00,622:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 10:54:00,639:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:54:00,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:00,650:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:00,668:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:54:00,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:00,679:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:00,679:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 10:54:00,708:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:00,708:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:00,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:00,738:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:00,738:INFO:Preparing preprocessing pipeline...
2025-05-14 10:54:00,739:INFO:Set up simple imputation.
2025-05-14 10:54:00,746:INFO:Set up encoding of ordinal features.
2025-05-14 10:54:00,758:INFO:Set up encoding of categorical features.
2025-05-14 10:54:00,758:INFO:Set up imbalanced handling.
2025-05-14 10:54:00,758:INFO:Set up column transformation.
2025-05-14 10:54:02,096:INFO:Finished creating preprocessing pipeline.
2025-05-14 10:54:02,115:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-14 10:54:02,115:INFO:Creating final display dataframe.
2025-05-14 10:54:02,707:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (87159, 16)
4        Transformed data shape      (133528, 29)
5   Transformed train set shape      (107380, 29)
6    Transformed test set shape       (26148, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              9474
2025-05-14 10:54:02,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:02,738:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:02,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:02,768:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:02,768:INFO:setup() successfully completed in 2.28s...............
2025-05-14 10:54:02,768:INFO:Initializing get_config()
2025-05-14 10:54:02,768:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33e429d90>, variable=prep_pipe)
2025-05-14 11:00:07,141:INFO:PyCaret ClassificationExperiment
2025-05-14 11:00:07,141:INFO:Logging name: clf-default-name
2025-05-14 11:00:07,141:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 11:00:07,141:INFO:version 3.3.2
2025-05-14 11:00:07,141:INFO:Initializing setup()
2025-05-14 11:00:07,141:INFO:self.USI: cab3
2025-05-14 11:00:07,141:INFO:self._variable_keys: {'USI', 'exp_id', 'X', 'y_train', 'is_multiclass', 'memory', 'idx', 'data', 'y_test', 'n_jobs_param', 'pipeline', 'y', 'fold_generator', 'logging_param', 'fold_groups_param', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'html_param', 'X_test', 'gpu_param', 'X_train', '_available_plots', 'seed', 'exp_name_log', 'fold_shuffle_param', 'log_plots_param', 'target_param'}
2025-05-14 11:00:07,141:INFO:Checking environment
2025-05-14 11:00:07,141:INFO:python_version: 3.11.0
2025-05-14 11:00:07,141:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-14 11:00:07,141:INFO:machine: arm64
2025-05-14 11:00:07,141:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:00:07,142:INFO:Memory: svmem(total=17179869184, available=4533993472, percent=73.6, used=7127662592, free=59342848, active=4499062784, inactive=4463542272, wired=2628599808)
2025-05-14 11:00:07,142:INFO:Physical Core: 12
2025-05-14 11:00:07,142:INFO:Logical Core: 12
2025-05-14 11:00:07,142:INFO:Checking libraries
2025-05-14 11:00:07,142:INFO:System:
2025-05-14 11:00:07,142:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-14 11:00:07,142:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-14 11:00:07,142:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:00:07,142:INFO:PyCaret required dependencies:
2025-05-14 11:00:07,142:INFO:                 pip: 22.3
2025-05-14 11:00:07,142:INFO:          setuptools: 65.5.0
2025-05-14 11:00:07,142:INFO:             pycaret: 3.3.2
2025-05-14 11:00:07,142:INFO:             IPython: 9.2.0
2025-05-14 11:00:07,142:INFO:          ipywidgets: 8.1.7
2025-05-14 11:00:07,142:INFO:                tqdm: 4.67.1
2025-05-14 11:00:07,142:INFO:               numpy: 1.26.4
2025-05-14 11:00:07,142:INFO:              pandas: 2.1.4
2025-05-14 11:00:07,142:INFO:              jinja2: 3.1.6
2025-05-14 11:00:07,142:INFO:               scipy: 1.11.4
2025-05-14 11:00:07,142:INFO:              joblib: 1.3.2
2025-05-14 11:00:07,142:INFO:             sklearn: 1.4.2
2025-05-14 11:00:07,142:INFO:                pyod: 2.0.5
2025-05-14 11:00:07,142:INFO:            imblearn: 0.13.0
2025-05-14 11:00:07,142:INFO:   category_encoders: 2.7.0
2025-05-14 11:00:07,142:INFO:            lightgbm: 4.6.0
2025-05-14 11:00:07,142:INFO:               numba: 0.61.2
2025-05-14 11:00:07,142:INFO:            requests: 2.32.3
2025-05-14 11:00:07,142:INFO:          matplotlib: 3.7.5
2025-05-14 11:00:07,142:INFO:          scikitplot: 0.3.7
2025-05-14 11:00:07,142:INFO:         yellowbrick: 1.5
2025-05-14 11:00:07,142:INFO:              plotly: 5.24.1
2025-05-14 11:00:07,142:INFO:    plotly-resampler: Not installed
2025-05-14 11:00:07,142:INFO:             kaleido: 0.2.1
2025-05-14 11:00:07,142:INFO:           schemdraw: 0.15
2025-05-14 11:00:07,142:INFO:         statsmodels: 0.14.4
2025-05-14 11:00:07,142:INFO:              sktime: 0.26.0
2025-05-14 11:00:07,142:INFO:               tbats: 1.1.3
2025-05-14 11:00:07,142:INFO:            pmdarima: 2.0.4
2025-05-14 11:00:07,142:INFO:              psutil: 7.0.0
2025-05-14 11:00:07,142:INFO:          markupsafe: 3.0.2
2025-05-14 11:00:07,142:INFO:             pickle5: Not installed
2025-05-14 11:00:07,142:INFO:         cloudpickle: 3.1.1
2025-05-14 11:00:07,142:INFO:         deprecation: 2.1.0
2025-05-14 11:00:07,142:INFO:              xxhash: 3.5.0
2025-05-14 11:00:07,142:INFO:           wurlitzer: 3.1.1
2025-05-14 11:00:07,142:INFO:PyCaret optional dependencies:
2025-05-14 11:00:07,142:INFO:                shap: 0.47.2
2025-05-14 11:00:07,142:INFO:           interpret: Not installed
2025-05-14 11:00:07,142:INFO:                umap: Not installed
2025-05-14 11:00:07,142:INFO:     ydata_profiling: Not installed
2025-05-14 11:00:07,142:INFO:  explainerdashboard: Not installed
2025-05-14 11:00:07,142:INFO:             autoviz: Not installed
2025-05-14 11:00:07,142:INFO:           fairlearn: Not installed
2025-05-14 11:00:07,142:INFO:          deepchecks: Not installed
2025-05-14 11:00:07,142:INFO:             xgboost: Not installed
2025-05-14 11:00:07,142:INFO:            catboost: 1.2.8
2025-05-14 11:00:07,142:INFO:              kmodes: Not installed
2025-05-14 11:00:07,142:INFO:             mlxtend: Not installed
2025-05-14 11:00:07,142:INFO:       statsforecast: Not installed
2025-05-14 11:00:07,142:INFO:        tune_sklearn: Not installed
2025-05-14 11:00:07,142:INFO:                 ray: Not installed
2025-05-14 11:00:07,142:INFO:            hyperopt: Not installed
2025-05-14 11:00:07,142:INFO:              optuna: 4.3.0
2025-05-14 11:00:07,142:INFO:               skopt: Not installed
2025-05-14 11:00:07,142:INFO:              mlflow: Not installed
2025-05-14 11:00:07,142:INFO:              gradio: Not installed
2025-05-14 11:00:07,142:INFO:             fastapi: Not installed
2025-05-14 11:00:07,142:INFO:             uvicorn: Not installed
2025-05-14 11:00:07,142:INFO:              m2cgen: Not installed
2025-05-14 11:00:07,142:INFO:           evidently: Not installed
2025-05-14 11:00:07,142:INFO:               fugue: Not installed
2025-05-14 11:00:07,142:INFO:           streamlit: Not installed
2025-05-14 11:00:07,142:INFO:             prophet: Not installed
2025-05-14 11:00:07,142:INFO:None
2025-05-14 11:00:07,142:INFO:Set up data.
2025-05-14 11:00:07,174:INFO:Set up folding strategy.
2025-05-14 11:00:07,174:INFO:Set up train/test split.
2025-05-14 11:00:07,188:INFO:Set up index.
2025-05-14 11:00:07,188:INFO:Assigning column types.
2025-05-14 11:00:07,192:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 11:00:07,210:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:00:07,210:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:00:07,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:07,223:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:07,242:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:00:07,242:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:00:07,253:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:07,253:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:07,253:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 11:00:07,270:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:00:07,281:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:07,281:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:07,298:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:00:07,309:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:07,309:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:07,310:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 11:00:07,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:07,339:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:07,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:07,368:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:07,368:INFO:Preparing preprocessing pipeline...
2025-05-14 11:00:07,370:INFO:Set up simple imputation.
2025-05-14 11:00:07,376:INFO:Set up encoding of ordinal features.
2025-05-14 11:00:07,385:INFO:Set up encoding of categorical features.
2025-05-14 11:00:07,385:INFO:Set up imbalanced handling.
2025-05-14 11:00:07,385:INFO:Set up column transformation.
2025-05-14 11:00:07,739:INFO:Finished creating preprocessing pipeline.
2025-05-14 11:00:07,759:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-14 11:00:07,759:INFO:Creating final display dataframe.
2025-05-14 11:00:08,323:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              cab3
2025-05-14 11:00:08,355:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:08,356:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:08,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:08,388:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:08,389:INFO:setup() successfully completed in 1.25s...............
2025-05-14 11:00:08,389:INFO:Initializing compare_models()
2025-05-14 11:00:08,389:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 11:00:08,389:INFO:Checking exceptions
2025-05-14 11:00:08,395:INFO:Preparing display monitor
2025-05-14 11:00:08,404:INFO:Initializing Logistic Regression
2025-05-14 11:00:08,404:INFO:Total runtime is 1.8715858459472655e-06 minutes
2025-05-14 11:00:08,405:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:08,406:INFO:Initializing create_model()
2025-05-14 11:00:08,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:08,406:INFO:Checking exceptions
2025-05-14 11:00:08,406:INFO:Importing libraries
2025-05-14 11:00:08,406:INFO:Copying training dataset
2025-05-14 11:00:08,418:INFO:Defining folds
2025-05-14 11:00:08,418:INFO:Declaring metric variables
2025-05-14 11:00:08,419:INFO:Importing untrained model
2025-05-14 11:00:08,421:INFO:Logistic Regression Imported successfully
2025-05-14 11:00:08,423:INFO:Starting cross validation
2025-05-14 11:00:08,425:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:14,416:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:00:14,489:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:00:14,618:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:00:14,657:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:00:14,678:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:00:14,741:INFO:Calculating mean and std
2025-05-14 11:00:14,743:INFO:Creating metrics dataframe
2025-05-14 11:00:14,748:INFO:Uploading results into container
2025-05-14 11:00:14,748:INFO:Uploading model into container now
2025-05-14 11:00:14,750:INFO:_master_model_container: 1
2025-05-14 11:00:14,750:INFO:_display_container: 2
2025-05-14 11:00:14,750:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 11:00:14,751:INFO:create_model() successfully completed......................................
2025-05-14 11:00:14,880:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:14,880:INFO:Creating metrics dataframe
2025-05-14 11:00:14,883:INFO:Initializing K Neighbors Classifier
2025-05-14 11:00:14,883:INFO:Total runtime is 0.1079794685045878 minutes
2025-05-14 11:00:14,884:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:14,884:INFO:Initializing create_model()
2025-05-14 11:00:14,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:14,884:INFO:Checking exceptions
2025-05-14 11:00:14,885:INFO:Importing libraries
2025-05-14 11:00:14,885:INFO:Copying training dataset
2025-05-14 11:00:14,894:INFO:Defining folds
2025-05-14 11:00:14,895:INFO:Declaring metric variables
2025-05-14 11:00:14,896:INFO:Importing untrained model
2025-05-14 11:00:14,897:INFO:K Neighbors Classifier Imported successfully
2025-05-14 11:00:14,899:INFO:Starting cross validation
2025-05-14 11:00:14,900:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:21,174:INFO:Calculating mean and std
2025-05-14 11:00:21,175:INFO:Creating metrics dataframe
2025-05-14 11:00:21,177:INFO:Uploading results into container
2025-05-14 11:00:21,177:INFO:Uploading model into container now
2025-05-14 11:00:21,178:INFO:_master_model_container: 2
2025-05-14 11:00:21,178:INFO:_display_container: 2
2025-05-14 11:00:21,178:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 11:00:21,178:INFO:create_model() successfully completed......................................
2025-05-14 11:00:21,271:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:21,271:INFO:Creating metrics dataframe
2025-05-14 11:00:21,274:INFO:Initializing Naive Bayes
2025-05-14 11:00:21,274:INFO:Total runtime is 0.21450820366541545 minutes
2025-05-14 11:00:21,276:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:21,276:INFO:Initializing create_model()
2025-05-14 11:00:21,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:21,276:INFO:Checking exceptions
2025-05-14 11:00:21,276:INFO:Importing libraries
2025-05-14 11:00:21,276:INFO:Copying training dataset
2025-05-14 11:00:21,287:INFO:Defining folds
2025-05-14 11:00:21,287:INFO:Declaring metric variables
2025-05-14 11:00:21,288:INFO:Importing untrained model
2025-05-14 11:00:21,290:INFO:Naive Bayes Imported successfully
2025-05-14 11:00:21,292:INFO:Starting cross validation
2025-05-14 11:00:21,293:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:23,696:INFO:Calculating mean and std
2025-05-14 11:00:23,701:INFO:Creating metrics dataframe
2025-05-14 11:00:23,705:INFO:Uploading results into container
2025-05-14 11:00:23,705:INFO:Uploading model into container now
2025-05-14 11:00:23,705:INFO:_master_model_container: 3
2025-05-14 11:00:23,706:INFO:_display_container: 2
2025-05-14 11:00:23,706:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 11:00:23,706:INFO:create_model() successfully completed......................................
2025-05-14 11:00:23,816:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:23,817:INFO:Creating metrics dataframe
2025-05-14 11:00:23,820:INFO:Initializing Decision Tree Classifier
2025-05-14 11:00:23,820:INFO:Total runtime is 0.25692960023880007 minutes
2025-05-14 11:00:23,821:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:23,821:INFO:Initializing create_model()
2025-05-14 11:00:23,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:23,821:INFO:Checking exceptions
2025-05-14 11:00:23,821:INFO:Importing libraries
2025-05-14 11:00:23,821:INFO:Copying training dataset
2025-05-14 11:00:23,831:INFO:Defining folds
2025-05-14 11:00:23,831:INFO:Declaring metric variables
2025-05-14 11:00:23,832:INFO:Importing untrained model
2025-05-14 11:00:23,834:INFO:Decision Tree Classifier Imported successfully
2025-05-14 11:00:23,835:INFO:Starting cross validation
2025-05-14 11:00:23,837:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:25,527:INFO:Calculating mean and std
2025-05-14 11:00:25,528:INFO:Creating metrics dataframe
2025-05-14 11:00:25,529:INFO:Uploading results into container
2025-05-14 11:00:25,529:INFO:Uploading model into container now
2025-05-14 11:00:25,529:INFO:_master_model_container: 4
2025-05-14 11:00:25,529:INFO:_display_container: 2
2025-05-14 11:00:25,530:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-14 11:00:25,530:INFO:create_model() successfully completed......................................
2025-05-14 11:00:25,601:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:25,601:INFO:Creating metrics dataframe
2025-05-14 11:00:25,604:INFO:Initializing SVM - Linear Kernel
2025-05-14 11:00:25,604:INFO:Total runtime is 0.2866738001505534 minutes
2025-05-14 11:00:25,605:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:25,606:INFO:Initializing create_model()
2025-05-14 11:00:25,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:25,606:INFO:Checking exceptions
2025-05-14 11:00:25,606:INFO:Importing libraries
2025-05-14 11:00:25,606:INFO:Copying training dataset
2025-05-14 11:00:25,616:INFO:Defining folds
2025-05-14 11:00:25,616:INFO:Declaring metric variables
2025-05-14 11:00:25,617:INFO:Importing untrained model
2025-05-14 11:00:25,618:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 11:00:25,620:INFO:Starting cross validation
2025-05-14 11:00:25,621:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:29,616:INFO:Calculating mean and std
2025-05-14 11:00:29,617:INFO:Creating metrics dataframe
2025-05-14 11:00:29,618:INFO:Uploading results into container
2025-05-14 11:00:29,619:INFO:Uploading model into container now
2025-05-14 11:00:29,619:INFO:_master_model_container: 5
2025-05-14 11:00:29,619:INFO:_display_container: 2
2025-05-14 11:00:29,619:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 11:00:29,619:INFO:create_model() successfully completed......................................
2025-05-14 11:00:29,701:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:29,701:INFO:Creating metrics dataframe
2025-05-14 11:00:29,704:INFO:Initializing Ridge Classifier
2025-05-14 11:00:29,704:INFO:Total runtime is 0.35500620206197103 minutes
2025-05-14 11:00:29,706:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:29,706:INFO:Initializing create_model()
2025-05-14 11:00:29,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:29,706:INFO:Checking exceptions
2025-05-14 11:00:29,706:INFO:Importing libraries
2025-05-14 11:00:29,706:INFO:Copying training dataset
2025-05-14 11:00:29,715:INFO:Defining folds
2025-05-14 11:00:29,715:INFO:Declaring metric variables
2025-05-14 11:00:29,716:INFO:Importing untrained model
2025-05-14 11:00:29,717:INFO:Ridge Classifier Imported successfully
2025-05-14 11:00:29,720:INFO:Starting cross validation
2025-05-14 11:00:29,721:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:30,912:INFO:Calculating mean and std
2025-05-14 11:00:30,913:INFO:Creating metrics dataframe
2025-05-14 11:00:30,914:INFO:Uploading results into container
2025-05-14 11:00:30,915:INFO:Uploading model into container now
2025-05-14 11:00:30,915:INFO:_master_model_container: 6
2025-05-14 11:00:30,915:INFO:_display_container: 2
2025-05-14 11:00:30,915:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-14 11:00:30,915:INFO:create_model() successfully completed......................................
2025-05-14 11:00:31,001:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:31,002:INFO:Creating metrics dataframe
2025-05-14 11:00:31,005:INFO:Initializing Random Forest Classifier
2025-05-14 11:00:31,005:INFO:Total runtime is 0.376682968934377 minutes
2025-05-14 11:00:31,006:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:31,006:INFO:Initializing create_model()
2025-05-14 11:00:31,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:31,006:INFO:Checking exceptions
2025-05-14 11:00:31,006:INFO:Importing libraries
2025-05-14 11:00:31,006:INFO:Copying training dataset
2025-05-14 11:00:31,016:INFO:Defining folds
2025-05-14 11:00:31,016:INFO:Declaring metric variables
2025-05-14 11:00:31,018:INFO:Importing untrained model
2025-05-14 11:00:31,019:INFO:Random Forest Classifier Imported successfully
2025-05-14 11:00:31,021:INFO:Starting cross validation
2025-05-14 11:00:31,022:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:37,090:INFO:Calculating mean and std
2025-05-14 11:00:37,092:INFO:Creating metrics dataframe
2025-05-14 11:00:37,097:INFO:Uploading results into container
2025-05-14 11:00:37,098:INFO:Uploading model into container now
2025-05-14 11:00:37,098:INFO:_master_model_container: 7
2025-05-14 11:00:37,098:INFO:_display_container: 2
2025-05-14 11:00:37,099:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 11:00:37,099:INFO:create_model() successfully completed......................................
2025-05-14 11:00:37,193:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:37,193:INFO:Creating metrics dataframe
2025-05-14 11:00:37,196:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 11:00:37,197:INFO:Total runtime is 0.47987731695175173 minutes
2025-05-14 11:00:37,198:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:37,198:INFO:Initializing create_model()
2025-05-14 11:00:37,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:37,198:INFO:Checking exceptions
2025-05-14 11:00:37,198:INFO:Importing libraries
2025-05-14 11:00:37,199:INFO:Copying training dataset
2025-05-14 11:00:37,219:INFO:Defining folds
2025-05-14 11:00:37,219:INFO:Declaring metric variables
2025-05-14 11:00:37,220:INFO:Importing untrained model
2025-05-14 11:00:37,222:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 11:00:37,224:INFO:Starting cross validation
2025-05-14 11:00:37,225:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:38,298:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:00:38,306:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:00:38,381:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:00:38,381:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:00:38,393:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:00:38,393:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:00:38,456:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:00:38,471:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:00:39,899:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:00:39,975:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:00:39,986:INFO:Calculating mean and std
2025-05-14 11:00:39,989:INFO:Creating metrics dataframe
2025-05-14 11:00:39,992:INFO:Uploading results into container
2025-05-14 11:00:39,992:INFO:Uploading model into container now
2025-05-14 11:00:39,993:INFO:_master_model_container: 8
2025-05-14 11:00:39,993:INFO:_display_container: 2
2025-05-14 11:00:39,994:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 11:00:39,994:INFO:create_model() successfully completed......................................
2025-05-14 11:00:40,130:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:40,130:INFO:Creating metrics dataframe
2025-05-14 11:00:40,134:INFO:Initializing Ada Boost Classifier
2025-05-14 11:00:40,134:INFO:Total runtime is 0.5288336197535197 minutes
2025-05-14 11:00:40,135:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:40,135:INFO:Initializing create_model()
2025-05-14 11:00:40,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:40,136:INFO:Checking exceptions
2025-05-14 11:00:40,136:INFO:Importing libraries
2025-05-14 11:00:40,136:INFO:Copying training dataset
2025-05-14 11:00:40,150:INFO:Defining folds
2025-05-14 11:00:40,150:INFO:Declaring metric variables
2025-05-14 11:00:40,151:INFO:Importing untrained model
2025-05-14 11:00:40,153:INFO:Ada Boost Classifier Imported successfully
2025-05-14 11:00:40,155:INFO:Starting cross validation
2025-05-14 11:00:40,156:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:41,160:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:00:41,173:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:00:41,217:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:00:41,239:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:00:41,253:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:00:44,016:INFO:Calculating mean and std
2025-05-14 11:00:44,017:INFO:Creating metrics dataframe
2025-05-14 11:00:44,018:INFO:Uploading results into container
2025-05-14 11:00:44,018:INFO:Uploading model into container now
2025-05-14 11:00:44,019:INFO:_master_model_container: 9
2025-05-14 11:00:44,019:INFO:_display_container: 2
2025-05-14 11:00:44,019:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-14 11:00:44,019:INFO:create_model() successfully completed......................................
2025-05-14 11:00:44,090:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:44,090:INFO:Creating metrics dataframe
2025-05-14 11:00:44,094:INFO:Initializing Gradient Boosting Classifier
2025-05-14 11:00:44,094:INFO:Total runtime is 0.5948346853256226 minutes
2025-05-14 11:00:44,095:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:44,095:INFO:Initializing create_model()
2025-05-14 11:00:44,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:44,096:INFO:Checking exceptions
2025-05-14 11:00:44,096:INFO:Importing libraries
2025-05-14 11:00:44,096:INFO:Copying training dataset
2025-05-14 11:00:44,106:INFO:Defining folds
2025-05-14 11:00:44,106:INFO:Declaring metric variables
2025-05-14 11:00:44,107:INFO:Importing untrained model
2025-05-14 11:00:44,108:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 11:00:44,110:INFO:Starting cross validation
2025-05-14 11:00:44,111:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:57,930:INFO:Calculating mean and std
2025-05-14 11:00:57,931:INFO:Creating metrics dataframe
2025-05-14 11:00:57,931:INFO:Uploading results into container
2025-05-14 11:00:57,932:INFO:Uploading model into container now
2025-05-14 11:00:57,932:INFO:_master_model_container: 10
2025-05-14 11:00:57,932:INFO:_display_container: 2
2025-05-14 11:00:57,932:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 11:00:57,932:INFO:create_model() successfully completed......................................
2025-05-14 11:00:58,001:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:58,001:INFO:Creating metrics dataframe
2025-05-14 11:00:58,005:INFO:Initializing Linear Discriminant Analysis
2025-05-14 11:00:58,005:INFO:Total runtime is 0.8266853849093119 minutes
2025-05-14 11:00:58,006:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:58,006:INFO:Initializing create_model()
2025-05-14 11:00:58,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:58,007:INFO:Checking exceptions
2025-05-14 11:00:58,007:INFO:Importing libraries
2025-05-14 11:00:58,007:INFO:Copying training dataset
2025-05-14 11:00:58,017:INFO:Defining folds
2025-05-14 11:00:58,017:INFO:Declaring metric variables
2025-05-14 11:00:58,018:INFO:Importing untrained model
2025-05-14 11:00:58,019:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 11:00:58,022:INFO:Starting cross validation
2025-05-14 11:00:58,023:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:59,283:INFO:Calculating mean and std
2025-05-14 11:00:59,284:INFO:Creating metrics dataframe
2025-05-14 11:00:59,287:INFO:Uploading results into container
2025-05-14 11:00:59,287:INFO:Uploading model into container now
2025-05-14 11:00:59,288:INFO:_master_model_container: 11
2025-05-14 11:00:59,288:INFO:_display_container: 2
2025-05-14 11:00:59,288:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 11:00:59,288:INFO:create_model() successfully completed......................................
2025-05-14 11:00:59,464:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:59,464:INFO:Creating metrics dataframe
2025-05-14 11:00:59,468:INFO:Initializing Extra Trees Classifier
2025-05-14 11:00:59,468:INFO:Total runtime is 0.8510716358820597 minutes
2025-05-14 11:00:59,470:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:59,470:INFO:Initializing create_model()
2025-05-14 11:00:59,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:59,470:INFO:Checking exceptions
2025-05-14 11:00:59,470:INFO:Importing libraries
2025-05-14 11:00:59,470:INFO:Copying training dataset
2025-05-14 11:00:59,481:INFO:Defining folds
2025-05-14 11:00:59,482:INFO:Declaring metric variables
2025-05-14 11:00:59,483:INFO:Importing untrained model
2025-05-14 11:00:59,484:INFO:Extra Trees Classifier Imported successfully
2025-05-14 11:00:59,486:INFO:Starting cross validation
2025-05-14 11:00:59,487:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:01:04,566:INFO:Calculating mean and std
2025-05-14 11:01:04,569:INFO:Creating metrics dataframe
2025-05-14 11:01:04,572:INFO:Uploading results into container
2025-05-14 11:01:04,573:INFO:Uploading model into container now
2025-05-14 11:01:04,573:INFO:_master_model_container: 12
2025-05-14 11:01:04,573:INFO:_display_container: 2
2025-05-14 11:01:04,574:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-14 11:01:04,575:INFO:create_model() successfully completed......................................
2025-05-14 11:01:04,730:INFO:SubProcess create_model() end ==================================
2025-05-14 11:01:04,730:INFO:Creating metrics dataframe
2025-05-14 11:01:04,736:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 11:01:04,736:INFO:Total runtime is 0.9388732671737671 minutes
2025-05-14 11:01:04,738:INFO:SubProcess create_model() called ==================================
2025-05-14 11:01:04,738:INFO:Initializing create_model()
2025-05-14 11:01:04,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:01:04,738:INFO:Checking exceptions
2025-05-14 11:01:04,738:INFO:Importing libraries
2025-05-14 11:01:04,738:INFO:Copying training dataset
2025-05-14 11:01:04,751:INFO:Defining folds
2025-05-14 11:01:04,751:INFO:Declaring metric variables
2025-05-14 11:01:04,752:INFO:Importing untrained model
2025-05-14 11:01:04,754:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:01:04,756:INFO:Starting cross validation
2025-05-14 11:01:04,757:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:01:08,937:INFO:Calculating mean and std
2025-05-14 11:01:08,938:INFO:Creating metrics dataframe
2025-05-14 11:01:08,939:INFO:Uploading results into container
2025-05-14 11:01:08,939:INFO:Uploading model into container now
2025-05-14 11:01:08,939:INFO:_master_model_container: 13
2025-05-14 11:01:08,939:INFO:_display_container: 2
2025-05-14 11:01:08,940:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:01:08,940:INFO:create_model() successfully completed......................................
2025-05-14 11:01:09,024:INFO:SubProcess create_model() end ==================================
2025-05-14 11:01:09,024:INFO:Creating metrics dataframe
2025-05-14 11:01:09,029:INFO:Initializing CatBoost Classifier
2025-05-14 11:01:09,029:INFO:Total runtime is 1.010413901011149 minutes
2025-05-14 11:01:09,030:INFO:SubProcess create_model() called ==================================
2025-05-14 11:01:09,031:INFO:Initializing create_model()
2025-05-14 11:01:09,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:01:09,031:INFO:Checking exceptions
2025-05-14 11:01:09,031:INFO:Importing libraries
2025-05-14 11:01:09,031:INFO:Copying training dataset
2025-05-14 11:01:09,044:INFO:Defining folds
2025-05-14 11:01:09,044:INFO:Declaring metric variables
2025-05-14 11:01:09,046:INFO:Importing untrained model
2025-05-14 11:01:09,049:INFO:CatBoost Classifier Imported successfully
2025-05-14 11:01:09,051:INFO:Starting cross validation
2025-05-14 11:01:09,052:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:01:26,715:INFO:Calculating mean and std
2025-05-14 11:01:26,718:INFO:Creating metrics dataframe
2025-05-14 11:01:26,723:INFO:Uploading results into container
2025-05-14 11:01:26,724:INFO:Uploading model into container now
2025-05-14 11:01:26,724:INFO:_master_model_container: 14
2025-05-14 11:01:26,724:INFO:_display_container: 2
2025-05-14 11:01:26,724:INFO:<catboost.core.CatBoostClassifier object at 0x335bf9190>
2025-05-14 11:01:26,724:INFO:create_model() successfully completed......................................
2025-05-14 11:01:26,933:INFO:SubProcess create_model() end ==================================
2025-05-14 11:01:26,933:INFO:Creating metrics dataframe
2025-05-14 11:01:26,939:INFO:Initializing Dummy Classifier
2025-05-14 11:01:26,939:INFO:Total runtime is 1.3089109857877095 minutes
2025-05-14 11:01:26,940:INFO:SubProcess create_model() called ==================================
2025-05-14 11:01:26,940:INFO:Initializing create_model()
2025-05-14 11:01:26,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:01:26,940:INFO:Checking exceptions
2025-05-14 11:01:26,940:INFO:Importing libraries
2025-05-14 11:01:26,940:INFO:Copying training dataset
2025-05-14 11:01:26,957:INFO:Defining folds
2025-05-14 11:01:26,957:INFO:Declaring metric variables
2025-05-14 11:01:26,958:INFO:Importing untrained model
2025-05-14 11:01:26,960:INFO:Dummy Classifier Imported successfully
2025-05-14 11:01:26,962:INFO:Starting cross validation
2025-05-14 11:01:26,963:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:01:28,065:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:01:28,099:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:01:28,124:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:01:28,154:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:01:28,214:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:01:28,223:INFO:Calculating mean and std
2025-05-14 11:01:28,225:INFO:Creating metrics dataframe
2025-05-14 11:01:28,226:INFO:Uploading results into container
2025-05-14 11:01:28,226:INFO:Uploading model into container now
2025-05-14 11:01:28,226:INFO:_master_model_container: 15
2025-05-14 11:01:28,226:INFO:_display_container: 2
2025-05-14 11:01:28,226:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-14 11:01:28,226:INFO:create_model() successfully completed......................................
2025-05-14 11:01:28,305:INFO:SubProcess create_model() end ==================================
2025-05-14 11:01:28,305:INFO:Creating metrics dataframe
2025-05-14 11:01:28,310:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2025-05-14 11:01:28,313:INFO:Initializing create_model()
2025-05-14 11:01:28,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:01:28,313:INFO:Checking exceptions
2025-05-14 11:01:28,314:INFO:Importing libraries
2025-05-14 11:01:28,314:INFO:Copying training dataset
2025-05-14 11:01:28,324:INFO:Defining folds
2025-05-14 11:01:28,324:INFO:Declaring metric variables
2025-05-14 11:01:28,324:INFO:Importing untrained model
2025-05-14 11:01:28,324:INFO:Declaring custom model
2025-05-14 11:01:28,325:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:01:28,325:INFO:Cross validation set to False
2025-05-14 11:01:28,325:INFO:Fitting Model
2025-05-14 11:01:29,674:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 11:01:29,684:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005028 seconds.
2025-05-14 11:01:29,684:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:01:29,684:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:01:29,684:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:01:29,684:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 11:01:29,685:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:01:30,451:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:01:30,451:INFO:create_model() successfully completed......................................
2025-05-14 11:01:30,545:INFO:Initializing create_model()
2025-05-14 11:01:30,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:01:30,545:INFO:Checking exceptions
2025-05-14 11:01:30,546:INFO:Importing libraries
2025-05-14 11:01:30,546:INFO:Copying training dataset
2025-05-14 11:01:30,556:INFO:Defining folds
2025-05-14 11:01:30,556:INFO:Declaring metric variables
2025-05-14 11:01:30,556:INFO:Importing untrained model
2025-05-14 11:01:30,556:INFO:Declaring custom model
2025-05-14 11:01:30,557:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 11:01:30,558:INFO:Cross validation set to False
2025-05-14 11:01:30,558:INFO:Fitting Model
2025-05-14 11:01:47,181:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 11:01:47,182:INFO:create_model() successfully completed......................................
2025-05-14 11:01:47,321:INFO:Initializing create_model()
2025-05-14 11:01:47,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:01:47,321:INFO:Checking exceptions
2025-05-14 11:01:47,322:INFO:Importing libraries
2025-05-14 11:01:47,322:INFO:Copying training dataset
2025-05-14 11:01:47,333:INFO:Defining folds
2025-05-14 11:01:47,333:INFO:Declaring metric variables
2025-05-14 11:01:47,333:INFO:Importing untrained model
2025-05-14 11:01:47,333:INFO:Declaring custom model
2025-05-14 11:01:47,333:INFO:Random Forest Classifier Imported successfully
2025-05-14 11:01:47,334:INFO:Cross validation set to False
2025-05-14 11:01:47,334:INFO:Fitting Model
2025-05-14 11:01:49,607:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 11:01:49,607:INFO:create_model() successfully completed......................................
2025-05-14 11:01:49,691:INFO:_master_model_container: 15
2025-05-14 11:01:49,691:INFO:_display_container: 2
2025-05-14 11:01:49,692:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-14 11:01:49,692:INFO:compare_models() successfully completed......................................
2025-05-14 11:01:49,699:INFO:Initializing evaluate_model()
2025-05-14 11:01:49,699:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 11:01:49,706:INFO:Initializing plot_model()
2025-05-14 11:01:49,706:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 11:01:49,706:INFO:Checking exceptions
2025-05-14 11:01:49,710:INFO:Preloading libraries
2025-05-14 11:01:49,712:INFO:Copying training dataset
2025-05-14 11:01:49,712:INFO:Plot type: pipeline
2025-05-14 11:01:49,779:INFO:Visual Rendered Successfully
2025-05-14 11:01:49,863:INFO:plot_model() successfully completed......................................
2025-05-14 11:01:49,865:INFO:Initializing tune_model()
2025-05-14 11:01:49,865:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 11:01:49,865:INFO:Checking exceptions
2025-05-14 11:01:49,875:INFO:Copying training dataset
2025-05-14 11:01:49,883:INFO:Checking base model
2025-05-14 11:01:49,883:INFO:Base model : Light Gradient Boosting Machine
2025-05-14 11:01:49,885:INFO:Declaring metric variables
2025-05-14 11:01:49,886:INFO:Defining Hyperparameters
2025-05-14 11:01:49,966:INFO:Tuning with n_jobs=-1
2025-05-14 11:01:49,967:INFO:Initializing RandomizedSearchCV
2025-05-14 11:02:28,587:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-14 11:02:28,589:INFO:Hyperparameter search completed
2025-05-14 11:02:28,589:INFO:SubProcess create_model() called ==================================
2025-05-14 11:02:28,590:INFO:Initializing create_model()
2025-05-14 11:02:28,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33fab9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-14 11:02:28,590:INFO:Checking exceptions
2025-05-14 11:02:28,590:INFO:Importing libraries
2025-05-14 11:02:28,591:INFO:Copying training dataset
2025-05-14 11:02:28,604:INFO:Defining folds
2025-05-14 11:02:28,605:INFO:Declaring metric variables
2025-05-14 11:02:28,613:INFO:Importing untrained model
2025-05-14 11:02:28,613:INFO:Declaring custom model
2025-05-14 11:02:28,616:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:02:28,619:INFO:Starting cross validation
2025-05-14 11:02:28,621:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:02:35,416:INFO:Calculating mean and std
2025-05-14 11:02:35,417:INFO:Creating metrics dataframe
2025-05-14 11:02:35,421:INFO:Finalizing model
2025-05-14 11:02:36,442:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:02:36,442:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:02:36,442:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:02:36,473:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:02:36,473:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:02:36,473:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:02:36,474:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 11:02:36,483:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004784 seconds.
2025-05-14 11:02:36,483:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:02:36,483:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:02:36,483:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:02:36,484:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 11:02:36,484:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:02:37,927:INFO:Uploading results into container
2025-05-14 11:02:37,927:INFO:Uploading model into container now
2025-05-14 11:02:37,928:INFO:_master_model_container: 16
2025-05-14 11:02:37,928:INFO:_display_container: 3
2025-05-14 11:02:37,928:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:02:37,928:INFO:create_model() successfully completed......................................
2025-05-14 11:02:38,054:INFO:SubProcess create_model() end ==================================
2025-05-14 11:02:38,054:INFO:choose_better activated
2025-05-14 11:02:38,055:INFO:SubProcess create_model() called ==================================
2025-05-14 11:02:38,056:INFO:Initializing create_model()
2025-05-14 11:02:38,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:02:38,056:INFO:Checking exceptions
2025-05-14 11:02:38,057:INFO:Importing libraries
2025-05-14 11:02:38,057:INFO:Copying training dataset
2025-05-14 11:02:38,066:INFO:Defining folds
2025-05-14 11:02:38,066:INFO:Declaring metric variables
2025-05-14 11:02:38,066:INFO:Importing untrained model
2025-05-14 11:02:38,066:INFO:Declaring custom model
2025-05-14 11:02:38,066:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:02:38,066:INFO:Starting cross validation
2025-05-14 11:02:38,067:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:02:42,137:INFO:Calculating mean and std
2025-05-14 11:02:42,138:INFO:Creating metrics dataframe
2025-05-14 11:02:42,140:INFO:Finalizing model
2025-05-14 11:02:43,184:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 11:02:43,198:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004945 seconds.
2025-05-14 11:02:43,198:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:02:43,198:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:02:43,198:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:02:43,198:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 11:02:43,199:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:02:43,949:INFO:Uploading results into container
2025-05-14 11:02:43,949:INFO:Uploading model into container now
2025-05-14 11:02:43,949:INFO:_master_model_container: 17
2025-05-14 11:02:43,949:INFO:_display_container: 4
2025-05-14 11:02:43,950:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:02:43,950:INFO:create_model() successfully completed......................................
2025-05-14 11:02:44,029:INFO:SubProcess create_model() end ==================================
2025-05-14 11:02:44,030:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-14 11:02:44,030:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-14 11:02:44,030:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-14 11:02:44,030:INFO:choose_better completed
2025-05-14 11:02:44,035:INFO:_master_model_container: 17
2025-05-14 11:02:44,035:INFO:_display_container: 3
2025-05-14 11:02:44,035:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:02:44,035:INFO:tune_model() successfully completed......................................
2025-05-14 11:02:44,109:INFO:Initializing evaluate_model()
2025-05-14 11:02:44,109:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 11:02:44,116:INFO:Initializing plot_model()
2025-05-14 11:02:44,116:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 11:02:44,116:INFO:Checking exceptions
2025-05-14 11:02:44,120:INFO:Preloading libraries
2025-05-14 11:02:44,122:INFO:Copying training dataset
2025-05-14 11:02:44,123:INFO:Plot type: pipeline
2025-05-14 11:02:44,183:INFO:Visual Rendered Successfully
2025-05-14 11:02:44,271:INFO:plot_model() successfully completed......................................
2025-05-14 11:02:44,273:INFO:Initializing interpret_model()
2025-05-14 11:02:44,273:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 11:02:44,273:INFO:Checking exceptions
2025-05-14 11:02:44,273:INFO:Soft dependency imported: shap: 0.47.2
2025-05-14 11:02:44,363:INFO:plot type: summary
2025-05-14 11:02:44,363:INFO:Creating TreeExplainer
2025-05-14 11:02:44,440:INFO:Compiling shap values
2025-05-14 11:02:45,787:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning:

LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray


2025-05-14 11:02:45,787:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning:

The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.


2025-05-14 11:02:47,056:INFO:Visual Rendered Successfully
2025-05-14 11:02:47,057:INFO:interpret_model() successfully completed......................................
2025-05-14 11:02:47,132:INFO:PyCaret ClassificationExperiment
2025-05-14 11:02:47,132:INFO:Logging name: clf-default-name
2025-05-14 11:02:47,132:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 11:02:47,132:INFO:version 3.3.2
2025-05-14 11:02:47,132:INFO:Initializing setup()
2025-05-14 11:02:47,133:INFO:self.USI: d78a
2025-05-14 11:02:47,133:INFO:self._variable_keys: {'USI', 'exp_id', 'X', 'y_train', 'is_multiclass', 'memory', 'idx', 'data', 'y_test', 'n_jobs_param', 'pipeline', 'y', 'fold_generator', 'logging_param', 'fold_groups_param', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'html_param', 'X_test', 'gpu_param', 'X_train', '_available_plots', 'seed', 'exp_name_log', 'fold_shuffle_param', 'log_plots_param', 'target_param'}
2025-05-14 11:02:47,133:INFO:Checking environment
2025-05-14 11:02:47,133:INFO:python_version: 3.11.0
2025-05-14 11:02:47,133:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-14 11:02:47,133:INFO:machine: arm64
2025-05-14 11:02:47,133:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:02:47,133:INFO:Memory: svmem(total=17179869184, available=3373498368, percent=80.4, used=5730254848, free=93257728, active=3292807168, inactive=3248226304, wired=2437447680)
2025-05-14 11:02:47,133:INFO:Physical Core: 12
2025-05-14 11:02:47,133:INFO:Logical Core: 12
2025-05-14 11:02:47,133:INFO:Checking libraries
2025-05-14 11:02:47,133:INFO:System:
2025-05-14 11:02:47,133:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-14 11:02:47,133:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-14 11:02:47,133:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:02:47,133:INFO:PyCaret required dependencies:
2025-05-14 11:02:47,133:INFO:                 pip: 22.3
2025-05-14 11:02:47,133:INFO:          setuptools: 65.5.0
2025-05-14 11:02:47,133:INFO:             pycaret: 3.3.2
2025-05-14 11:02:47,133:INFO:             IPython: 9.2.0
2025-05-14 11:02:47,133:INFO:          ipywidgets: 8.1.7
2025-05-14 11:02:47,133:INFO:                tqdm: 4.67.1
2025-05-14 11:02:47,133:INFO:               numpy: 1.26.4
2025-05-14 11:02:47,133:INFO:              pandas: 2.1.4
2025-05-14 11:02:47,133:INFO:              jinja2: 3.1.6
2025-05-14 11:02:47,133:INFO:               scipy: 1.11.4
2025-05-14 11:02:47,133:INFO:              joblib: 1.3.2
2025-05-14 11:02:47,133:INFO:             sklearn: 1.4.2
2025-05-14 11:02:47,133:INFO:                pyod: 2.0.5
2025-05-14 11:02:47,133:INFO:            imblearn: 0.13.0
2025-05-14 11:02:47,133:INFO:   category_encoders: 2.7.0
2025-05-14 11:02:47,133:INFO:            lightgbm: 4.6.0
2025-05-14 11:02:47,133:INFO:               numba: 0.61.2
2025-05-14 11:02:47,133:INFO:            requests: 2.32.3
2025-05-14 11:02:47,133:INFO:          matplotlib: 3.7.5
2025-05-14 11:02:47,133:INFO:          scikitplot: 0.3.7
2025-05-14 11:02:47,133:INFO:         yellowbrick: 1.5
2025-05-14 11:02:47,133:INFO:              plotly: 5.24.1
2025-05-14 11:02:47,133:INFO:    plotly-resampler: Not installed
2025-05-14 11:02:47,133:INFO:             kaleido: 0.2.1
2025-05-14 11:02:47,133:INFO:           schemdraw: 0.15
2025-05-14 11:02:47,133:INFO:         statsmodels: 0.14.4
2025-05-14 11:02:47,133:INFO:              sktime: 0.26.0
2025-05-14 11:02:47,133:INFO:               tbats: 1.1.3
2025-05-14 11:02:47,133:INFO:            pmdarima: 2.0.4
2025-05-14 11:02:47,133:INFO:              psutil: 7.0.0
2025-05-14 11:02:47,133:INFO:          markupsafe: 3.0.2
2025-05-14 11:02:47,133:INFO:             pickle5: Not installed
2025-05-14 11:02:47,133:INFO:         cloudpickle: 3.1.1
2025-05-14 11:02:47,133:INFO:         deprecation: 2.1.0
2025-05-14 11:02:47,133:INFO:              xxhash: 3.5.0
2025-05-14 11:02:47,133:INFO:           wurlitzer: 3.1.1
2025-05-14 11:02:47,133:INFO:PyCaret optional dependencies:
2025-05-14 11:02:47,133:INFO:                shap: 0.47.2
2025-05-14 11:02:47,133:INFO:           interpret: Not installed
2025-05-14 11:02:47,133:INFO:                umap: Not installed
2025-05-14 11:02:47,133:INFO:     ydata_profiling: Not installed
2025-05-14 11:02:47,133:INFO:  explainerdashboard: Not installed
2025-05-14 11:02:47,133:INFO:             autoviz: Not installed
2025-05-14 11:02:47,133:INFO:           fairlearn: Not installed
2025-05-14 11:02:47,133:INFO:          deepchecks: Not installed
2025-05-14 11:02:47,133:INFO:             xgboost: Not installed
2025-05-14 11:02:47,133:INFO:            catboost: 1.2.8
2025-05-14 11:02:47,133:INFO:              kmodes: Not installed
2025-05-14 11:02:47,133:INFO:             mlxtend: Not installed
2025-05-14 11:02:47,133:INFO:       statsforecast: Not installed
2025-05-14 11:02:47,133:INFO:        tune_sklearn: Not installed
2025-05-14 11:02:47,133:INFO:                 ray: Not installed
2025-05-14 11:02:47,133:INFO:            hyperopt: Not installed
2025-05-14 11:02:47,133:INFO:              optuna: 4.3.0
2025-05-14 11:02:47,133:INFO:               skopt: Not installed
2025-05-14 11:02:47,133:INFO:              mlflow: Not installed
2025-05-14 11:02:47,133:INFO:              gradio: Not installed
2025-05-14 11:02:47,133:INFO:             fastapi: Not installed
2025-05-14 11:02:47,133:INFO:             uvicorn: Not installed
2025-05-14 11:02:47,133:INFO:              m2cgen: Not installed
2025-05-14 11:02:47,133:INFO:           evidently: Not installed
2025-05-14 11:02:47,133:INFO:               fugue: Not installed
2025-05-14 11:02:47,133:INFO:           streamlit: Not installed
2025-05-14 11:02:47,133:INFO:             prophet: Not installed
2025-05-14 11:02:47,133:INFO:None
2025-05-14 11:02:47,133:INFO:Set up data.
2025-05-14 11:02:47,176:INFO:Set up folding strategy.
2025-05-14 11:02:47,176:INFO:Set up train/test split.
2025-05-14 11:02:47,194:INFO:Set up index.
2025-05-14 11:02:47,195:INFO:Assigning column types.
2025-05-14 11:02:47,199:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 11:02:47,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:02:47,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:02:47,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:47,230:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:47,249:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:02:47,250:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:02:47,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:47,261:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:47,262:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 11:02:47,280:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:02:47,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:47,292:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:47,310:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:02:47,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:47,322:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:47,322:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 11:02:47,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:47,351:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:47,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:47,381:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:47,381:INFO:Preparing preprocessing pipeline...
2025-05-14 11:02:47,382:INFO:Set up simple imputation.
2025-05-14 11:02:47,390:INFO:Set up encoding of ordinal features.
2025-05-14 11:02:47,401:INFO:Set up encoding of categorical features.
2025-05-14 11:02:47,401:INFO:Set up imbalanced handling.
2025-05-14 11:02:47,401:INFO:Set up column transformation.
2025-05-14 11:02:47,726:INFO:Finished creating preprocessing pipeline.
2025-05-14 11:02:47,745:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-14 11:02:47,745:INFO:Creating final display dataframe.
2025-05-14 11:02:48,220:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (87159, 16)
4        Transformed data shape      (133528, 29)
5   Transformed train set shape      (107380, 29)
6    Transformed test set shape       (26148, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              d78a
2025-05-14 11:02:48,253:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:48,253:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:48,282:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:48,284:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:48,284:INFO:setup() successfully completed in 1.15s...............
2025-05-14 11:02:48,285:INFO:Initializing create_model()
2025-05-14 11:02:48,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3322edb90>, estimator=LGBMClassifier, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:02:48,285:INFO:Checking exceptions
2025-05-14 11:04:48,925:INFO:PyCaret ClassificationExperiment
2025-05-14 11:04:48,925:INFO:Logging name: clf-default-name
2025-05-14 11:04:48,925:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 11:04:48,925:INFO:version 3.3.2
2025-05-14 11:04:48,925:INFO:Initializing setup()
2025-05-14 11:04:48,925:INFO:self.USI: 2e14
2025-05-14 11:04:48,925:INFO:self._variable_keys: {'USI', 'exp_id', 'X', 'y_train', 'is_multiclass', 'memory', 'idx', 'data', 'y_test', 'n_jobs_param', 'pipeline', 'y', 'fold_generator', 'logging_param', 'fold_groups_param', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'html_param', 'X_test', 'gpu_param', 'X_train', '_available_plots', 'seed', 'exp_name_log', 'fold_shuffle_param', 'log_plots_param', 'target_param'}
2025-05-14 11:04:48,926:INFO:Checking environment
2025-05-14 11:04:48,926:INFO:python_version: 3.11.0
2025-05-14 11:04:48,926:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-14 11:04:48,926:INFO:machine: arm64
2025-05-14 11:04:48,926:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:04:48,926:INFO:Memory: svmem(total=17179869184, available=3378610176, percent=80.3, used=6051807232, free=59047936, active=3343253504, inactive=3309256704, wired=2708553728)
2025-05-14 11:04:48,926:INFO:Physical Core: 12
2025-05-14 11:04:48,926:INFO:Logical Core: 12
2025-05-14 11:04:48,926:INFO:Checking libraries
2025-05-14 11:04:48,926:INFO:System:
2025-05-14 11:04:48,926:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-14 11:04:48,926:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-14 11:04:48,926:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:04:48,926:INFO:PyCaret required dependencies:
2025-05-14 11:04:48,926:INFO:                 pip: 22.3
2025-05-14 11:04:48,926:INFO:          setuptools: 65.5.0
2025-05-14 11:04:48,926:INFO:             pycaret: 3.3.2
2025-05-14 11:04:48,926:INFO:             IPython: 9.2.0
2025-05-14 11:04:48,926:INFO:          ipywidgets: 8.1.7
2025-05-14 11:04:48,926:INFO:                tqdm: 4.67.1
2025-05-14 11:04:48,926:INFO:               numpy: 1.26.4
2025-05-14 11:04:48,926:INFO:              pandas: 2.1.4
2025-05-14 11:04:48,926:INFO:              jinja2: 3.1.6
2025-05-14 11:04:48,926:INFO:               scipy: 1.11.4
2025-05-14 11:04:48,926:INFO:              joblib: 1.3.2
2025-05-14 11:04:48,926:INFO:             sklearn: 1.4.2
2025-05-14 11:04:48,926:INFO:                pyod: 2.0.5
2025-05-14 11:04:48,926:INFO:            imblearn: 0.13.0
2025-05-14 11:04:48,926:INFO:   category_encoders: 2.7.0
2025-05-14 11:04:48,926:INFO:            lightgbm: 4.6.0
2025-05-14 11:04:48,926:INFO:               numba: 0.61.2
2025-05-14 11:04:48,926:INFO:            requests: 2.32.3
2025-05-14 11:04:48,926:INFO:          matplotlib: 3.7.5
2025-05-14 11:04:48,926:INFO:          scikitplot: 0.3.7
2025-05-14 11:04:48,926:INFO:         yellowbrick: 1.5
2025-05-14 11:04:48,926:INFO:              plotly: 5.24.1
2025-05-14 11:04:48,926:INFO:    plotly-resampler: Not installed
2025-05-14 11:04:48,926:INFO:             kaleido: 0.2.1
2025-05-14 11:04:48,926:INFO:           schemdraw: 0.15
2025-05-14 11:04:48,926:INFO:         statsmodels: 0.14.4
2025-05-14 11:04:48,926:INFO:              sktime: 0.26.0
2025-05-14 11:04:48,926:INFO:               tbats: 1.1.3
2025-05-14 11:04:48,926:INFO:            pmdarima: 2.0.4
2025-05-14 11:04:48,926:INFO:              psutil: 7.0.0
2025-05-14 11:04:48,926:INFO:          markupsafe: 3.0.2
2025-05-14 11:04:48,926:INFO:             pickle5: Not installed
2025-05-14 11:04:48,926:INFO:         cloudpickle: 3.1.1
2025-05-14 11:04:48,926:INFO:         deprecation: 2.1.0
2025-05-14 11:04:48,926:INFO:              xxhash: 3.5.0
2025-05-14 11:04:48,926:INFO:           wurlitzer: 3.1.1
2025-05-14 11:04:48,926:INFO:PyCaret optional dependencies:
2025-05-14 11:04:48,927:INFO:                shap: 0.47.2
2025-05-14 11:04:48,927:INFO:           interpret: Not installed
2025-05-14 11:04:48,927:INFO:                umap: Not installed
2025-05-14 11:04:48,927:INFO:     ydata_profiling: Not installed
2025-05-14 11:04:48,927:INFO:  explainerdashboard: Not installed
2025-05-14 11:04:48,927:INFO:             autoviz: Not installed
2025-05-14 11:04:48,927:INFO:           fairlearn: Not installed
2025-05-14 11:04:48,927:INFO:          deepchecks: Not installed
2025-05-14 11:04:48,927:INFO:             xgboost: Not installed
2025-05-14 11:04:48,927:INFO:            catboost: 1.2.8
2025-05-14 11:04:48,927:INFO:              kmodes: Not installed
2025-05-14 11:04:48,927:INFO:             mlxtend: Not installed
2025-05-14 11:04:48,927:INFO:       statsforecast: Not installed
2025-05-14 11:04:48,927:INFO:        tune_sklearn: Not installed
2025-05-14 11:04:48,927:INFO:                 ray: Not installed
2025-05-14 11:04:48,927:INFO:            hyperopt: Not installed
2025-05-14 11:04:48,927:INFO:              optuna: 4.3.0
2025-05-14 11:04:48,927:INFO:               skopt: Not installed
2025-05-14 11:04:48,927:INFO:              mlflow: Not installed
2025-05-14 11:04:48,927:INFO:              gradio: Not installed
2025-05-14 11:04:48,927:INFO:             fastapi: Not installed
2025-05-14 11:04:48,927:INFO:             uvicorn: Not installed
2025-05-14 11:04:48,927:INFO:              m2cgen: Not installed
2025-05-14 11:04:48,927:INFO:           evidently: Not installed
2025-05-14 11:04:48,927:INFO:               fugue: Not installed
2025-05-14 11:04:48,927:INFO:           streamlit: Not installed
2025-05-14 11:04:48,927:INFO:             prophet: Not installed
2025-05-14 11:04:48,927:INFO:None
2025-05-14 11:04:48,927:INFO:Set up data.
2025-05-14 11:04:48,965:INFO:Set up folding strategy.
2025-05-14 11:04:48,966:INFO:Set up train/test split.
2025-05-14 11:04:48,980:INFO:Set up index.
2025-05-14 11:04:48,981:INFO:Assigning column types.
2025-05-14 11:04:48,985:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 11:04:49,003:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:04:49,004:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:04:49,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,015:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,033:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:04:49,034:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:04:49,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,050:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,050:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 11:04:49,068:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:04:49,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,080:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,099:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:04:49,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,111:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,111:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 11:04:49,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,141:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,170:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,171:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,172:INFO:Preparing preprocessing pipeline...
2025-05-14 11:04:49,173:INFO:Set up simple imputation.
2025-05-14 11:04:49,181:INFO:Set up encoding of ordinal features.
2025-05-14 11:04:49,192:INFO:Set up encoding of categorical features.
2025-05-14 11:04:49,192:INFO:Set up imbalanced handling.
2025-05-14 11:04:49,192:INFO:Set up column transformation.
2025-05-14 11:04:49,483:INFO:Finished creating preprocessing pipeline.
2025-05-14 11:04:49,504:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-14 11:04:49,504:INFO:Creating final display dataframe.
2025-05-14 11:04:49,733:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              2e14
2025-05-14 11:04:49,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,769:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,810:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,813:INFO:setup() successfully completed in 0.89s...............
2025-05-14 11:04:49,813:INFO:Initializing compare_models()
2025-05-14 11:04:49,813:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 11:04:49,813:INFO:Checking exceptions
2025-05-14 11:04:49,819:INFO:Preparing display monitor
2025-05-14 11:04:49,838:INFO:Initializing Logistic Regression
2025-05-14 11:04:49,838:INFO:Total runtime is 1.720587412516276e-06 minutes
2025-05-14 11:04:49,840:INFO:SubProcess create_model() called ==================================
2025-05-14 11:04:49,840:INFO:Initializing create_model()
2025-05-14 11:04:49,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:04:49,841:INFO:Checking exceptions
2025-05-14 11:04:49,841:INFO:Importing libraries
2025-05-14 11:04:49,841:INFO:Copying training dataset
2025-05-14 11:04:49,870:INFO:Defining folds
2025-05-14 11:04:49,870:INFO:Declaring metric variables
2025-05-14 11:04:49,871:INFO:Importing untrained model
2025-05-14 11:04:49,873:INFO:Logistic Regression Imported successfully
2025-05-14 11:04:49,876:INFO:Starting cross validation
2025-05-14 11:04:49,877:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:04:53,802:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:04:53,848:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:04:53,885:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:04:53,905:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:04:53,905:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:04:53,960:INFO:Calculating mean and std
2025-05-14 11:04:53,960:INFO:Creating metrics dataframe
2025-05-14 11:04:53,961:INFO:Uploading results into container
2025-05-14 11:04:53,962:INFO:Uploading model into container now
2025-05-14 11:04:53,962:INFO:_master_model_container: 1
2025-05-14 11:04:53,962:INFO:_display_container: 2
2025-05-14 11:04:53,962:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 11:04:53,962:INFO:create_model() successfully completed......................................
2025-05-14 11:04:54,105:INFO:SubProcess create_model() end ==================================
2025-05-14 11:04:54,105:INFO:Creating metrics dataframe
2025-05-14 11:04:54,107:INFO:Initializing K Neighbors Classifier
2025-05-14 11:04:54,107:INFO:Total runtime is 0.07115906476974487 minutes
2025-05-14 11:04:54,108:INFO:SubProcess create_model() called ==================================
2025-05-14 11:04:54,109:INFO:Initializing create_model()
2025-05-14 11:04:54,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:04:54,109:INFO:Checking exceptions
2025-05-14 11:04:54,109:INFO:Importing libraries
2025-05-14 11:04:54,109:INFO:Copying training dataset
2025-05-14 11:04:54,118:INFO:Defining folds
2025-05-14 11:04:54,118:INFO:Declaring metric variables
2025-05-14 11:04:54,119:INFO:Importing untrained model
2025-05-14 11:04:54,120:INFO:K Neighbors Classifier Imported successfully
2025-05-14 11:04:54,122:INFO:Starting cross validation
2025-05-14 11:04:54,123:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:04:58,983:INFO:Calculating mean and std
2025-05-14 11:04:58,985:INFO:Creating metrics dataframe
2025-05-14 11:04:58,989:INFO:Uploading results into container
2025-05-14 11:04:58,990:INFO:Uploading model into container now
2025-05-14 11:04:58,990:INFO:_master_model_container: 2
2025-05-14 11:04:58,990:INFO:_display_container: 2
2025-05-14 11:04:58,991:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 11:04:58,991:INFO:create_model() successfully completed......................................
2025-05-14 11:04:59,084:INFO:SubProcess create_model() end ==================================
2025-05-14 11:04:59,084:INFO:Creating metrics dataframe
2025-05-14 11:04:59,087:INFO:Initializing Naive Bayes
2025-05-14 11:04:59,087:INFO:Total runtime is 0.15415916840235394 minutes
2025-05-14 11:04:59,088:INFO:SubProcess create_model() called ==================================
2025-05-14 11:04:59,088:INFO:Initializing create_model()
2025-05-14 11:04:59,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:04:59,089:INFO:Checking exceptions
2025-05-14 11:04:59,089:INFO:Importing libraries
2025-05-14 11:04:59,089:INFO:Copying training dataset
2025-05-14 11:04:59,100:INFO:Defining folds
2025-05-14 11:04:59,100:INFO:Declaring metric variables
2025-05-14 11:04:59,101:INFO:Importing untrained model
2025-05-14 11:04:59,103:INFO:Naive Bayes Imported successfully
2025-05-14 11:04:59,105:INFO:Starting cross validation
2025-05-14 11:04:59,106:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:00,286:INFO:Calculating mean and std
2025-05-14 11:05:00,287:INFO:Creating metrics dataframe
2025-05-14 11:05:00,287:INFO:Uploading results into container
2025-05-14 11:05:00,288:INFO:Uploading model into container now
2025-05-14 11:05:00,288:INFO:_master_model_container: 3
2025-05-14 11:05:00,288:INFO:_display_container: 2
2025-05-14 11:05:00,288:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 11:05:00,288:INFO:create_model() successfully completed......................................
2025-05-14 11:05:00,372:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:00,372:INFO:Creating metrics dataframe
2025-05-14 11:05:00,375:INFO:Initializing Decision Tree Classifier
2025-05-14 11:05:00,376:INFO:Total runtime is 0.17563133239746095 minutes
2025-05-14 11:05:00,377:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:00,377:INFO:Initializing create_model()
2025-05-14 11:05:00,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:00,377:INFO:Checking exceptions
2025-05-14 11:05:00,377:INFO:Importing libraries
2025-05-14 11:05:00,377:INFO:Copying training dataset
2025-05-14 11:05:00,387:INFO:Defining folds
2025-05-14 11:05:00,388:INFO:Declaring metric variables
2025-05-14 11:05:00,389:INFO:Importing untrained model
2025-05-14 11:05:00,390:INFO:Decision Tree Classifier Imported successfully
2025-05-14 11:05:00,392:INFO:Starting cross validation
2025-05-14 11:05:00,393:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:02,072:INFO:Calculating mean and std
2025-05-14 11:05:02,073:INFO:Creating metrics dataframe
2025-05-14 11:05:02,074:INFO:Uploading results into container
2025-05-14 11:05:02,074:INFO:Uploading model into container now
2025-05-14 11:05:02,074:INFO:_master_model_container: 4
2025-05-14 11:05:02,074:INFO:_display_container: 2
2025-05-14 11:05:02,074:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-14 11:05:02,074:INFO:create_model() successfully completed......................................
2025-05-14 11:05:02,196:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:02,196:INFO:Creating metrics dataframe
2025-05-14 11:05:02,199:INFO:Initializing SVM - Linear Kernel
2025-05-14 11:05:02,199:INFO:Total runtime is 0.20602888663609825 minutes
2025-05-14 11:05:02,201:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:02,201:INFO:Initializing create_model()
2025-05-14 11:05:02,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:02,201:INFO:Checking exceptions
2025-05-14 11:05:02,201:INFO:Importing libraries
2025-05-14 11:05:02,201:INFO:Copying training dataset
2025-05-14 11:05:02,219:INFO:Defining folds
2025-05-14 11:05:02,219:INFO:Declaring metric variables
2025-05-14 11:05:02,221:INFO:Importing untrained model
2025-05-14 11:05:02,222:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 11:05:02,225:INFO:Starting cross validation
2025-05-14 11:05:02,226:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:05,469:INFO:Calculating mean and std
2025-05-14 11:05:05,469:INFO:Creating metrics dataframe
2025-05-14 11:05:05,470:INFO:Uploading results into container
2025-05-14 11:05:05,470:INFO:Uploading model into container now
2025-05-14 11:05:05,471:INFO:_master_model_container: 5
2025-05-14 11:05:05,471:INFO:_display_container: 2
2025-05-14 11:05:05,471:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 11:05:05,471:INFO:create_model() successfully completed......................................
2025-05-14 11:05:05,555:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:05,555:INFO:Creating metrics dataframe
2025-05-14 11:05:05,559:INFO:Initializing Ridge Classifier
2025-05-14 11:05:05,559:INFO:Total runtime is 0.262016499042511 minutes
2025-05-14 11:05:05,560:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:05,560:INFO:Initializing create_model()
2025-05-14 11:05:05,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:05,560:INFO:Checking exceptions
2025-05-14 11:05:05,560:INFO:Importing libraries
2025-05-14 11:05:05,560:INFO:Copying training dataset
2025-05-14 11:05:05,570:INFO:Defining folds
2025-05-14 11:05:05,570:INFO:Declaring metric variables
2025-05-14 11:05:05,571:INFO:Importing untrained model
2025-05-14 11:05:05,572:INFO:Ridge Classifier Imported successfully
2025-05-14 11:05:05,574:INFO:Starting cross validation
2025-05-14 11:05:05,575:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:06,741:INFO:Calculating mean and std
2025-05-14 11:05:06,742:INFO:Creating metrics dataframe
2025-05-14 11:05:06,744:INFO:Uploading results into container
2025-05-14 11:05:06,744:INFO:Uploading model into container now
2025-05-14 11:05:06,744:INFO:_master_model_container: 6
2025-05-14 11:05:06,744:INFO:_display_container: 2
2025-05-14 11:05:06,744:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-14 11:05:06,745:INFO:create_model() successfully completed......................................
2025-05-14 11:05:06,832:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:06,833:INFO:Creating metrics dataframe
2025-05-14 11:05:06,836:INFO:Initializing Random Forest Classifier
2025-05-14 11:05:06,836:INFO:Total runtime is 0.2833044846852621 minutes
2025-05-14 11:05:06,837:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:06,837:INFO:Initializing create_model()
2025-05-14 11:05:06,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:06,837:INFO:Checking exceptions
2025-05-14 11:05:06,838:INFO:Importing libraries
2025-05-14 11:05:06,838:INFO:Copying training dataset
2025-05-14 11:05:06,847:INFO:Defining folds
2025-05-14 11:05:06,847:INFO:Declaring metric variables
2025-05-14 11:05:06,848:INFO:Importing untrained model
2025-05-14 11:05:06,849:INFO:Random Forest Classifier Imported successfully
2025-05-14 11:05:06,851:INFO:Starting cross validation
2025-05-14 11:05:06,853:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:13,258:INFO:Calculating mean and std
2025-05-14 11:05:13,259:INFO:Creating metrics dataframe
2025-05-14 11:05:13,261:INFO:Uploading results into container
2025-05-14 11:05:13,262:INFO:Uploading model into container now
2025-05-14 11:05:13,262:INFO:_master_model_container: 7
2025-05-14 11:05:13,262:INFO:_display_container: 2
2025-05-14 11:05:13,262:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 11:05:13,263:INFO:create_model() successfully completed......................................
2025-05-14 11:05:13,432:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:13,432:INFO:Creating metrics dataframe
2025-05-14 11:05:13,437:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 11:05:13,437:INFO:Total runtime is 0.3933164517084758 minutes
2025-05-14 11:05:13,438:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:13,438:INFO:Initializing create_model()
2025-05-14 11:05:13,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:13,438:INFO:Checking exceptions
2025-05-14 11:05:13,438:INFO:Importing libraries
2025-05-14 11:05:13,439:INFO:Copying training dataset
2025-05-14 11:05:13,457:INFO:Defining folds
2025-05-14 11:05:13,457:INFO:Declaring metric variables
2025-05-14 11:05:13,459:INFO:Importing untrained model
2025-05-14 11:05:13,460:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 11:05:13,463:INFO:Starting cross validation
2025-05-14 11:05:13,464:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:14,535:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:05:14,580:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:05:14,618:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:05:14,625:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:05:14,648:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:05:14,659:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:05:14,671:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:05:14,702:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:05:14,729:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:05:14,744:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:05:14,756:INFO:Calculating mean and std
2025-05-14 11:05:14,757:INFO:Creating metrics dataframe
2025-05-14 11:05:14,757:INFO:Uploading results into container
2025-05-14 11:05:14,758:INFO:Uploading model into container now
2025-05-14 11:05:14,758:INFO:_master_model_container: 8
2025-05-14 11:05:14,758:INFO:_display_container: 2
2025-05-14 11:05:14,758:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 11:05:14,758:INFO:create_model() successfully completed......................................
2025-05-14 11:05:14,845:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:14,845:INFO:Creating metrics dataframe
2025-05-14 11:05:14,849:INFO:Initializing Ada Boost Classifier
2025-05-14 11:05:14,849:INFO:Total runtime is 0.4168615857760112 minutes
2025-05-14 11:05:14,850:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:14,851:INFO:Initializing create_model()
2025-05-14 11:05:14,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:14,851:INFO:Checking exceptions
2025-05-14 11:05:14,851:INFO:Importing libraries
2025-05-14 11:05:14,851:INFO:Copying training dataset
2025-05-14 11:05:14,861:INFO:Defining folds
2025-05-14 11:05:14,861:INFO:Declaring metric variables
2025-05-14 11:05:14,862:INFO:Importing untrained model
2025-05-14 11:05:14,863:INFO:Ada Boost Classifier Imported successfully
2025-05-14 11:05:14,865:INFO:Starting cross validation
2025-05-14 11:05:14,867:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:15,912:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:05:15,922:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:05:15,947:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:05:15,972:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:05:16,050:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:05:18,797:INFO:Calculating mean and std
2025-05-14 11:05:18,799:INFO:Creating metrics dataframe
2025-05-14 11:05:18,803:INFO:Uploading results into container
2025-05-14 11:05:18,803:INFO:Uploading model into container now
2025-05-14 11:05:18,803:INFO:_master_model_container: 9
2025-05-14 11:05:18,803:INFO:_display_container: 2
2025-05-14 11:05:18,804:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-14 11:05:18,804:INFO:create_model() successfully completed......................................
2025-05-14 11:05:18,929:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:18,929:INFO:Creating metrics dataframe
2025-05-14 11:05:18,933:INFO:Initializing Gradient Boosting Classifier
2025-05-14 11:05:18,933:INFO:Total runtime is 0.48493014971415205 minutes
2025-05-14 11:05:18,935:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:18,935:INFO:Initializing create_model()
2025-05-14 11:05:18,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:18,935:INFO:Checking exceptions
2025-05-14 11:05:18,935:INFO:Importing libraries
2025-05-14 11:05:18,935:INFO:Copying training dataset
2025-05-14 11:05:18,946:INFO:Defining folds
2025-05-14 11:05:18,946:INFO:Declaring metric variables
2025-05-14 11:05:18,947:INFO:Importing untrained model
2025-05-14 11:05:18,948:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 11:05:18,950:INFO:Starting cross validation
2025-05-14 11:05:18,951:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:32,764:INFO:Calculating mean and std
2025-05-14 11:05:32,768:INFO:Creating metrics dataframe
2025-05-14 11:05:32,772:INFO:Uploading results into container
2025-05-14 11:05:32,772:INFO:Uploading model into container now
2025-05-14 11:05:32,772:INFO:_master_model_container: 10
2025-05-14 11:05:32,773:INFO:_display_container: 2
2025-05-14 11:05:32,773:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 11:05:32,773:INFO:create_model() successfully completed......................................
2025-05-14 11:05:32,910:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:32,910:INFO:Creating metrics dataframe
2025-05-14 11:05:32,915:INFO:Initializing Linear Discriminant Analysis
2025-05-14 11:05:32,915:INFO:Total runtime is 0.7179495851198833 minutes
2025-05-14 11:05:32,916:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:32,916:INFO:Initializing create_model()
2025-05-14 11:05:32,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:32,916:INFO:Checking exceptions
2025-05-14 11:05:32,916:INFO:Importing libraries
2025-05-14 11:05:32,916:INFO:Copying training dataset
2025-05-14 11:05:32,931:INFO:Defining folds
2025-05-14 11:05:32,931:INFO:Declaring metric variables
2025-05-14 11:05:32,932:INFO:Importing untrained model
2025-05-14 11:05:32,934:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 11:05:32,936:INFO:Starting cross validation
2025-05-14 11:05:32,938:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:34,204:INFO:Calculating mean and std
2025-05-14 11:05:34,204:INFO:Creating metrics dataframe
2025-05-14 11:05:34,205:INFO:Uploading results into container
2025-05-14 11:05:34,205:INFO:Uploading model into container now
2025-05-14 11:05:34,206:INFO:_master_model_container: 11
2025-05-14 11:05:34,206:INFO:_display_container: 2
2025-05-14 11:05:34,206:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 11:05:34,206:INFO:create_model() successfully completed......................................
2025-05-14 11:05:34,292:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:34,292:INFO:Creating metrics dataframe
2025-05-14 11:05:34,296:INFO:Initializing Extra Trees Classifier
2025-05-14 11:05:34,296:INFO:Total runtime is 0.7409696499506633 minutes
2025-05-14 11:05:34,297:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:34,297:INFO:Initializing create_model()
2025-05-14 11:05:34,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:34,297:INFO:Checking exceptions
2025-05-14 11:05:34,297:INFO:Importing libraries
2025-05-14 11:05:34,297:INFO:Copying training dataset
2025-05-14 11:05:34,307:INFO:Defining folds
2025-05-14 11:05:34,307:INFO:Declaring metric variables
2025-05-14 11:05:34,308:INFO:Importing untrained model
2025-05-14 11:05:34,309:INFO:Extra Trees Classifier Imported successfully
2025-05-14 11:05:34,311:INFO:Starting cross validation
2025-05-14 11:05:34,312:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:39,553:INFO:Calculating mean and std
2025-05-14 11:05:39,564:INFO:Creating metrics dataframe
2025-05-14 11:05:39,571:INFO:Uploading results into container
2025-05-14 11:05:39,572:INFO:Uploading model into container now
2025-05-14 11:05:39,573:INFO:_master_model_container: 12
2025-05-14 11:05:39,573:INFO:_display_container: 2
2025-05-14 11:05:39,574:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-14 11:05:39,574:INFO:create_model() successfully completed......................................
2025-05-14 11:05:39,745:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:39,745:INFO:Creating metrics dataframe
2025-05-14 11:05:39,750:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 11:05:39,750:INFO:Total runtime is 0.8318687995274862 minutes
2025-05-14 11:05:39,751:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:39,751:INFO:Initializing create_model()
2025-05-14 11:05:39,751:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:39,751:INFO:Checking exceptions
2025-05-14 11:05:39,752:INFO:Importing libraries
2025-05-14 11:05:39,752:INFO:Copying training dataset
2025-05-14 11:05:39,774:INFO:Defining folds
2025-05-14 11:05:39,774:INFO:Declaring metric variables
2025-05-14 11:05:39,776:INFO:Importing untrained model
2025-05-14 11:05:39,778:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:05:39,781:INFO:Starting cross validation
2025-05-14 11:05:39,783:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:43,882:INFO:Calculating mean and std
2025-05-14 11:05:43,882:INFO:Creating metrics dataframe
2025-05-14 11:05:43,883:INFO:Uploading results into container
2025-05-14 11:05:43,883:INFO:Uploading model into container now
2025-05-14 11:05:43,884:INFO:_master_model_container: 13
2025-05-14 11:05:43,884:INFO:_display_container: 2
2025-05-14 11:05:43,884:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:05:43,884:INFO:create_model() successfully completed......................................
2025-05-14 11:05:43,969:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:43,970:INFO:Creating metrics dataframe
2025-05-14 11:05:43,974:INFO:Initializing CatBoost Classifier
2025-05-14 11:05:43,974:INFO:Total runtime is 0.9022688349088033 minutes
2025-05-14 11:05:43,975:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:43,975:INFO:Initializing create_model()
2025-05-14 11:05:43,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:43,975:INFO:Checking exceptions
2025-05-14 11:05:43,975:INFO:Importing libraries
2025-05-14 11:05:43,975:INFO:Copying training dataset
2025-05-14 11:05:43,985:INFO:Defining folds
2025-05-14 11:05:43,985:INFO:Declaring metric variables
2025-05-14 11:05:43,986:INFO:Importing untrained model
2025-05-14 11:05:43,987:INFO:CatBoost Classifier Imported successfully
2025-05-14 11:05:43,989:INFO:Starting cross validation
2025-05-14 11:05:43,990:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:06:00,969:INFO:Calculating mean and std
2025-05-14 11:06:00,972:INFO:Creating metrics dataframe
2025-05-14 11:06:00,975:INFO:Uploading results into container
2025-05-14 11:06:00,976:INFO:Uploading model into container now
2025-05-14 11:06:00,976:INFO:_master_model_container: 14
2025-05-14 11:06:00,976:INFO:_display_container: 2
2025-05-14 11:06:00,977:INFO:<catboost.core.CatBoostClassifier object at 0x33cd75150>
2025-05-14 11:06:00,977:INFO:create_model() successfully completed......................................
2025-05-14 11:06:01,115:INFO:SubProcess create_model() end ==================================
2025-05-14 11:06:01,115:INFO:Creating metrics dataframe
2025-05-14 11:06:01,120:INFO:Initializing Dummy Classifier
2025-05-14 11:06:01,120:INFO:Total runtime is 1.1880457003911336 minutes
2025-05-14 11:06:01,122:INFO:SubProcess create_model() called ==================================
2025-05-14 11:06:01,122:INFO:Initializing create_model()
2025-05-14 11:06:01,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:06:01,122:INFO:Checking exceptions
2025-05-14 11:06:01,122:INFO:Importing libraries
2025-05-14 11:06:01,122:INFO:Copying training dataset
2025-05-14 11:06:01,136:INFO:Defining folds
2025-05-14 11:06:01,136:INFO:Declaring metric variables
2025-05-14 11:06:01,137:INFO:Importing untrained model
2025-05-14 11:06:01,139:INFO:Dummy Classifier Imported successfully
2025-05-14 11:06:01,141:INFO:Starting cross validation
2025-05-14 11:06:01,143:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:06:02,216:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:06:02,287:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:06:02,288:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:06:02,317:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:06:02,340:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:06:02,351:INFO:Calculating mean and std
2025-05-14 11:06:02,351:INFO:Creating metrics dataframe
2025-05-14 11:06:02,352:INFO:Uploading results into container
2025-05-14 11:06:02,352:INFO:Uploading model into container now
2025-05-14 11:06:02,353:INFO:_master_model_container: 15
2025-05-14 11:06:02,353:INFO:_display_container: 2
2025-05-14 11:06:02,353:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-14 11:06:02,353:INFO:create_model() successfully completed......................................
2025-05-14 11:06:02,440:INFO:SubProcess create_model() end ==================================
2025-05-14 11:06:02,440:INFO:Creating metrics dataframe
2025-05-14 11:06:02,445:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2025-05-14 11:06:02,449:INFO:Initializing create_model()
2025-05-14 11:06:02,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:06:02,449:INFO:Checking exceptions
2025-05-14 11:06:02,450:INFO:Importing libraries
2025-05-14 11:06:02,450:INFO:Copying training dataset
2025-05-14 11:06:02,461:INFO:Defining folds
2025-05-14 11:06:02,461:INFO:Declaring metric variables
2025-05-14 11:06:02,461:INFO:Importing untrained model
2025-05-14 11:06:02,461:INFO:Declaring custom model
2025-05-14 11:06:02,462:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:06:02,462:INFO:Cross validation set to False
2025-05-14 11:06:02,462:INFO:Fitting Model
2025-05-14 11:06:03,494:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 11:06:03,512:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008441 seconds.
2025-05-14 11:06:03,512:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:06:03,512:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:06:03,512:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:06:03,512:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 11:06:03,512:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:06:04,267:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:06:04,267:INFO:create_model() successfully completed......................................
2025-05-14 11:06:04,353:INFO:Initializing create_model()
2025-05-14 11:06:04,353:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:06:04,354:INFO:Checking exceptions
2025-05-14 11:06:04,354:INFO:Importing libraries
2025-05-14 11:06:04,354:INFO:Copying training dataset
2025-05-14 11:06:04,363:INFO:Defining folds
2025-05-14 11:06:04,363:INFO:Declaring metric variables
2025-05-14 11:06:04,364:INFO:Importing untrained model
2025-05-14 11:06:04,364:INFO:Declaring custom model
2025-05-14 11:06:04,364:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 11:06:04,365:INFO:Cross validation set to False
2025-05-14 11:06:04,365:INFO:Fitting Model
2025-05-14 11:06:20,273:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 11:06:20,274:INFO:create_model() successfully completed......................................
2025-05-14 11:06:20,353:INFO:Initializing create_model()
2025-05-14 11:06:20,353:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:06:20,353:INFO:Checking exceptions
2025-05-14 11:06:20,354:INFO:Importing libraries
2025-05-14 11:06:20,354:INFO:Copying training dataset
2025-05-14 11:06:20,364:INFO:Defining folds
2025-05-14 11:06:20,364:INFO:Declaring metric variables
2025-05-14 11:06:20,364:INFO:Importing untrained model
2025-05-14 11:06:20,364:INFO:Declaring custom model
2025-05-14 11:06:20,364:INFO:Random Forest Classifier Imported successfully
2025-05-14 11:06:20,365:INFO:Cross validation set to False
2025-05-14 11:06:20,365:INFO:Fitting Model
2025-05-14 11:06:22,564:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 11:06:22,564:INFO:create_model() successfully completed......................................
2025-05-14 11:06:22,651:INFO:_master_model_container: 15
2025-05-14 11:06:22,651:INFO:_display_container: 2
2025-05-14 11:06:22,652:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-14 11:06:22,652:INFO:compare_models() successfully completed......................................
2025-05-14 11:06:22,667:INFO:Initializing evaluate_model()
2025-05-14 11:06:22,668:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 11:06:22,679:INFO:Initializing plot_model()
2025-05-14 11:06:22,679:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 11:06:22,679:INFO:Checking exceptions
2025-05-14 11:06:22,684:INFO:Preloading libraries
2025-05-14 11:06:22,686:INFO:Copying training dataset
2025-05-14 11:06:22,686:INFO:Plot type: pipeline
2025-05-14 11:06:22,746:INFO:Visual Rendered Successfully
2025-05-14 11:06:22,830:INFO:plot_model() successfully completed......................................
2025-05-14 11:06:22,832:INFO:Initializing tune_model()
2025-05-14 11:06:22,832:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 11:06:22,832:INFO:Checking exceptions
2025-05-14 11:06:22,843:INFO:Copying training dataset
2025-05-14 11:06:22,852:INFO:Checking base model
2025-05-14 11:06:22,852:INFO:Base model : Light Gradient Boosting Machine
2025-05-14 11:06:22,854:INFO:Declaring metric variables
2025-05-14 11:06:22,855:INFO:Defining Hyperparameters
2025-05-14 11:06:22,941:INFO:Tuning with n_jobs=-1
2025-05-14 11:06:22,941:INFO:Initializing RandomizedSearchCV
2025-05-14 11:06:58,123:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-14 11:06:58,126:INFO:Hyperparameter search completed
2025-05-14 11:06:58,126:INFO:SubProcess create_model() called ==================================
2025-05-14 11:06:58,128:INFO:Initializing create_model()
2025-05-14 11:06:58,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x346bb4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-14 11:06:58,128:INFO:Checking exceptions
2025-05-14 11:06:58,128:INFO:Importing libraries
2025-05-14 11:06:58,128:INFO:Copying training dataset
2025-05-14 11:06:58,143:INFO:Defining folds
2025-05-14 11:06:58,143:INFO:Declaring metric variables
2025-05-14 11:06:58,149:INFO:Importing untrained model
2025-05-14 11:06:58,149:INFO:Declaring custom model
2025-05-14 11:06:58,153:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:06:58,157:INFO:Starting cross validation
2025-05-14 11:06:58,161:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:07:04,908:INFO:Calculating mean and std
2025-05-14 11:07:04,909:INFO:Creating metrics dataframe
2025-05-14 11:07:04,911:INFO:Finalizing model
2025-05-14 11:07:05,937:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:07:05,937:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:07:05,937:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:07:05,968:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:07:05,968:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:07:05,968:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:07:05,968:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 11:07:05,983:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008904 seconds.
2025-05-14 11:07:05,983:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:07:05,983:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:07:05,983:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:07:05,983:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 11:07:05,983:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:07:07,447:INFO:Uploading results into container
2025-05-14 11:07:07,448:INFO:Uploading model into container now
2025-05-14 11:07:07,448:INFO:_master_model_container: 16
2025-05-14 11:07:07,448:INFO:_display_container: 3
2025-05-14 11:07:07,449:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:07:07,449:INFO:create_model() successfully completed......................................
2025-05-14 11:07:07,581:INFO:SubProcess create_model() end ==================================
2025-05-14 11:07:07,582:INFO:choose_better activated
2025-05-14 11:07:07,583:INFO:SubProcess create_model() called ==================================
2025-05-14 11:07:07,584:INFO:Initializing create_model()
2025-05-14 11:07:07,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:07:07,584:INFO:Checking exceptions
2025-05-14 11:07:07,584:INFO:Importing libraries
2025-05-14 11:07:07,584:INFO:Copying training dataset
2025-05-14 11:07:07,594:INFO:Defining folds
2025-05-14 11:07:07,594:INFO:Declaring metric variables
2025-05-14 11:07:07,594:INFO:Importing untrained model
2025-05-14 11:07:07,594:INFO:Declaring custom model
2025-05-14 11:07:07,594:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:07:07,594:INFO:Starting cross validation
2025-05-14 11:07:07,595:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:07:11,476:INFO:Calculating mean and std
2025-05-14 11:07:11,477:INFO:Creating metrics dataframe
2025-05-14 11:07:11,478:INFO:Finalizing model
2025-05-14 11:07:12,483:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 11:07:12,493:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004739 seconds.
2025-05-14 11:07:12,493:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:07:12,493:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:07:12,493:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:07:12,493:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 11:07:12,493:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:07:13,247:INFO:Uploading results into container
2025-05-14 11:07:13,248:INFO:Uploading model into container now
2025-05-14 11:07:13,248:INFO:_master_model_container: 17
2025-05-14 11:07:13,248:INFO:_display_container: 4
2025-05-14 11:07:13,248:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:07:13,248:INFO:create_model() successfully completed......................................
2025-05-14 11:07:13,330:INFO:SubProcess create_model() end ==================================
2025-05-14 11:07:13,331:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-14 11:07:13,331:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-14 11:07:13,331:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-14 11:07:13,331:INFO:choose_better completed
2025-05-14 11:07:13,335:INFO:_master_model_container: 17
2025-05-14 11:07:13,335:INFO:_display_container: 3
2025-05-14 11:07:13,336:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:07:13,336:INFO:tune_model() successfully completed......................................
2025-05-14 11:07:13,425:INFO:Initializing evaluate_model()
2025-05-14 11:07:13,425:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 11:07:13,432:INFO:Initializing plot_model()
2025-05-14 11:07:13,433:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 11:07:13,433:INFO:Checking exceptions
2025-05-14 11:07:13,437:INFO:Preloading libraries
2025-05-14 11:07:13,440:INFO:Copying training dataset
2025-05-14 11:07:13,440:INFO:Plot type: pipeline
2025-05-14 11:07:13,499:INFO:Visual Rendered Successfully
2025-05-14 11:07:13,581:INFO:plot_model() successfully completed......................................
2025-05-14 11:07:13,583:INFO:Initializing interpret_model()
2025-05-14 11:07:13,583:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 11:07:13,583:INFO:Checking exceptions
2025-05-14 11:07:13,583:INFO:Soft dependency imported: shap: 0.47.2
2025-05-14 11:07:13,669:INFO:plot type: summary
2025-05-14 11:07:13,669:INFO:Creating TreeExplainer
2025-05-14 11:07:13,746:INFO:Compiling shap values
2025-05-14 11:07:15,028:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning:

LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray


2025-05-14 11:07:15,028:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning:

The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.


2025-05-14 11:07:16,301:INFO:Visual Rendered Successfully
2025-05-14 11:07:16,301:INFO:interpret_model() successfully completed......................................
2025-05-14 11:07:16,405:INFO:gpu_param set to False
2025-05-14 11:07:16,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,437:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,468:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,472:INFO:PyCaret ClassificationExperiment
2025-05-14 11:07:16,472:INFO:Logging name: clf-default-name
2025-05-14 11:07:16,473:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 11:07:16,473:INFO:version 3.3.2
2025-05-14 11:07:16,473:INFO:Initializing setup()
2025-05-14 11:07:16,473:INFO:self.USI: 237b
2025-05-14 11:07:16,473:INFO:self._variable_keys: {'USI', 'exp_id', 'X', 'y_train', 'is_multiclass', 'memory', 'idx', 'data', 'y_test', 'n_jobs_param', 'pipeline', 'y', 'fold_generator', 'logging_param', 'fold_groups_param', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'html_param', 'X_test', 'gpu_param', 'X_train', '_available_plots', 'seed', 'exp_name_log', 'fold_shuffle_param', 'log_plots_param', 'target_param'}
2025-05-14 11:07:16,473:INFO:Checking environment
2025-05-14 11:07:16,473:INFO:python_version: 3.11.0
2025-05-14 11:07:16,473:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-14 11:07:16,473:INFO:machine: arm64
2025-05-14 11:07:16,473:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:07:16,473:INFO:Memory: svmem(total=17179869184, available=3439935488, percent=80.0, used=5903941632, free=67928064, active=3393896448, inactive=3368665088, wired=2510045184)
2025-05-14 11:07:16,473:INFO:Physical Core: 12
2025-05-14 11:07:16,473:INFO:Logical Core: 12
2025-05-14 11:07:16,473:INFO:Checking libraries
2025-05-14 11:07:16,473:INFO:System:
2025-05-14 11:07:16,473:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-14 11:07:16,473:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-14 11:07:16,473:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:07:16,473:INFO:PyCaret required dependencies:
2025-05-14 11:07:16,473:INFO:                 pip: 22.3
2025-05-14 11:07:16,473:INFO:          setuptools: 65.5.0
2025-05-14 11:07:16,473:INFO:             pycaret: 3.3.2
2025-05-14 11:07:16,473:INFO:             IPython: 9.2.0
2025-05-14 11:07:16,473:INFO:          ipywidgets: 8.1.7
2025-05-14 11:07:16,473:INFO:                tqdm: 4.67.1
2025-05-14 11:07:16,473:INFO:               numpy: 1.26.4
2025-05-14 11:07:16,473:INFO:              pandas: 2.1.4
2025-05-14 11:07:16,473:INFO:              jinja2: 3.1.6
2025-05-14 11:07:16,473:INFO:               scipy: 1.11.4
2025-05-14 11:07:16,473:INFO:              joblib: 1.3.2
2025-05-14 11:07:16,473:INFO:             sklearn: 1.4.2
2025-05-14 11:07:16,473:INFO:                pyod: 2.0.5
2025-05-14 11:07:16,473:INFO:            imblearn: 0.13.0
2025-05-14 11:07:16,473:INFO:   category_encoders: 2.7.0
2025-05-14 11:07:16,473:INFO:            lightgbm: 4.6.0
2025-05-14 11:07:16,473:INFO:               numba: 0.61.2
2025-05-14 11:07:16,473:INFO:            requests: 2.32.3
2025-05-14 11:07:16,473:INFO:          matplotlib: 3.7.5
2025-05-14 11:07:16,473:INFO:          scikitplot: 0.3.7
2025-05-14 11:07:16,473:INFO:         yellowbrick: 1.5
2025-05-14 11:07:16,473:INFO:              plotly: 5.24.1
2025-05-14 11:07:16,473:INFO:    plotly-resampler: Not installed
2025-05-14 11:07:16,473:INFO:             kaleido: 0.2.1
2025-05-14 11:07:16,473:INFO:           schemdraw: 0.15
2025-05-14 11:07:16,473:INFO:         statsmodels: 0.14.4
2025-05-14 11:07:16,473:INFO:              sktime: 0.26.0
2025-05-14 11:07:16,473:INFO:               tbats: 1.1.3
2025-05-14 11:07:16,473:INFO:            pmdarima: 2.0.4
2025-05-14 11:07:16,473:INFO:              psutil: 7.0.0
2025-05-14 11:07:16,473:INFO:          markupsafe: 3.0.2
2025-05-14 11:07:16,473:INFO:             pickle5: Not installed
2025-05-14 11:07:16,473:INFO:         cloudpickle: 3.1.1
2025-05-14 11:07:16,473:INFO:         deprecation: 2.1.0
2025-05-14 11:07:16,474:INFO:              xxhash: 3.5.0
2025-05-14 11:07:16,474:INFO:           wurlitzer: 3.1.1
2025-05-14 11:07:16,474:INFO:PyCaret optional dependencies:
2025-05-14 11:07:16,474:INFO:                shap: 0.47.2
2025-05-14 11:07:16,474:INFO:           interpret: Not installed
2025-05-14 11:07:16,474:INFO:                umap: Not installed
2025-05-14 11:07:16,474:INFO:     ydata_profiling: Not installed
2025-05-14 11:07:16,474:INFO:  explainerdashboard: Not installed
2025-05-14 11:07:16,474:INFO:             autoviz: Not installed
2025-05-14 11:07:16,474:INFO:           fairlearn: Not installed
2025-05-14 11:07:16,474:INFO:          deepchecks: Not installed
2025-05-14 11:07:16,474:INFO:             xgboost: Not installed
2025-05-14 11:07:16,474:INFO:            catboost: 1.2.8
2025-05-14 11:07:16,474:INFO:              kmodes: Not installed
2025-05-14 11:07:16,474:INFO:             mlxtend: Not installed
2025-05-14 11:07:16,474:INFO:       statsforecast: Not installed
2025-05-14 11:07:16,474:INFO:        tune_sklearn: Not installed
2025-05-14 11:07:16,474:INFO:                 ray: Not installed
2025-05-14 11:07:16,474:INFO:            hyperopt: Not installed
2025-05-14 11:07:16,474:INFO:              optuna: 4.3.0
2025-05-14 11:07:16,474:INFO:               skopt: Not installed
2025-05-14 11:07:16,474:INFO:              mlflow: Not installed
2025-05-14 11:07:16,474:INFO:              gradio: Not installed
2025-05-14 11:07:16,474:INFO:             fastapi: Not installed
2025-05-14 11:07:16,474:INFO:             uvicorn: Not installed
2025-05-14 11:07:16,474:INFO:              m2cgen: Not installed
2025-05-14 11:07:16,474:INFO:           evidently: Not installed
2025-05-14 11:07:16,474:INFO:               fugue: Not installed
2025-05-14 11:07:16,474:INFO:           streamlit: Not installed
2025-05-14 11:07:16,474:INFO:             prophet: Not installed
2025-05-14 11:07:16,474:INFO:None
2025-05-14 11:07:16,474:INFO:Set up data.
2025-05-14 11:07:16,517:INFO:Set up folding strategy.
2025-05-14 11:07:16,517:INFO:Set up train/test split.
2025-05-14 11:07:16,535:INFO:Set up index.
2025-05-14 11:07:16,535:INFO:Assigning column types.
2025-05-14 11:07:16,539:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 11:07:16,558:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:07:16,558:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:07:16,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,570:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,588:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:07:16,589:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:07:16,600:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,600:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,600:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 11:07:16,619:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:07:16,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,631:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,649:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:07:16,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,661:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,661:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 11:07:16,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,691:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,720:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,721:INFO:Preparing preprocessing pipeline...
2025-05-14 11:07:16,722:INFO:Set up simple imputation.
2025-05-14 11:07:16,730:INFO:Set up encoding of ordinal features.
2025-05-14 11:07:16,741:INFO:Set up encoding of categorical features.
2025-05-14 11:07:16,741:INFO:Set up imbalanced handling.
2025-05-14 11:07:16,741:INFO:Set up column transformation.
2025-05-14 11:07:17,059:INFO:Finished creating preprocessing pipeline.
2025-05-14 11:07:17,078:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-14 11:07:17,078:INFO:Creating final display dataframe.
2025-05-14 11:07:17,319:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (87159, 16)
4        Transformed data shape      (133528, 29)
5   Transformed train set shape      (107380, 29)
6    Transformed test set shape       (26148, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              237b
2025-05-14 11:07:17,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:17,352:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:17,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:17,384:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:17,385:INFO:setup() successfully completed in 0.92s...............
2025-05-14 11:07:17,385:INFO:Initializing create_model()
2025-05-14 11:07:17,385:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:07:17,385:INFO:Checking exceptions
2025-05-14 11:07:17,391:INFO:Importing libraries
2025-05-14 11:07:17,391:INFO:Copying training dataset
2025-05-14 11:07:17,403:INFO:Defining folds
2025-05-14 11:07:17,403:INFO:Declaring metric variables
2025-05-14 11:07:17,404:INFO:Importing untrained model
2025-05-14 11:07:17,406:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:07:17,408:INFO:Starting cross validation
2025-05-14 11:07:17,410:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:07:21,836:INFO:Calculating mean and std
2025-05-14 11:07:21,837:INFO:Creating metrics dataframe
2025-05-14 11:07:21,839:INFO:Finalizing model
2025-05-14 11:07:23,134:INFO:[LightGBM] [Info] Number of positive: 53690, number of negative: 53690
2025-05-14 11:07:23,147:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005997 seconds.
2025-05-14 11:07:23,147:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:07:23,147:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:07:23,148:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:07:23,148:INFO:[LightGBM] [Info] Number of data points in the train set: 107380, number of used features: 28
2025-05-14 11:07:23,148:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:07:23,928:INFO:Uploading results into container
2025-05-14 11:07:23,929:INFO:Uploading model into container now
2025-05-14 11:07:23,932:INFO:_master_model_container: 1
2025-05-14 11:07:23,932:INFO:_display_container: 2
2025-05-14 11:07:23,933:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:07:23,933:INFO:create_model() successfully completed......................................
2025-05-14 11:07:24,033:INFO:Initializing tune_model()
2025-05-14 11:07:24,033:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 11:07:24,033:INFO:Checking exceptions
2025-05-14 11:07:24,045:INFO:Copying training dataset
2025-05-14 11:07:24,055:INFO:Checking base model
2025-05-14 11:07:24,055:INFO:Base model : Light Gradient Boosting Machine
2025-05-14 11:07:24,057:INFO:Declaring metric variables
2025-05-14 11:07:24,058:INFO:Defining Hyperparameters
2025-05-14 11:07:24,159:INFO:Tuning with n_jobs=-1
2025-05-14 11:07:24,159:INFO:Initializing RandomizedSearchCV
2025-05-14 11:08:03,873:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-14 11:08:03,877:INFO:Hyperparameter search completed
2025-05-14 11:08:03,878:INFO:SubProcess create_model() called ==================================
2025-05-14 11:08:03,879:INFO:Initializing create_model()
2025-05-14 11:08:03,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33289f3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-14 11:08:03,879:INFO:Checking exceptions
2025-05-14 11:08:03,879:INFO:Importing libraries
2025-05-14 11:08:03,879:INFO:Copying training dataset
2025-05-14 11:08:03,902:INFO:Defining folds
2025-05-14 11:08:03,902:INFO:Declaring metric variables
2025-05-14 11:08:03,908:INFO:Importing untrained model
2025-05-14 11:08:03,908:INFO:Declaring custom model
2025-05-14 11:08:03,912:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:08:03,914:INFO:Starting cross validation
2025-05-14 11:08:03,916:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:08:11,300:INFO:Calculating mean and std
2025-05-14 11:08:11,301:INFO:Creating metrics dataframe
2025-05-14 11:08:11,305:INFO:Finalizing model
2025-05-14 11:08:12,576:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:08:12,576:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:08:12,576:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:08:12,615:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:08:12,615:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:08:12,615:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:08:12,616:INFO:[LightGBM] [Info] Number of positive: 53690, number of negative: 53690
2025-05-14 11:08:12,626:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005761 seconds.
2025-05-14 11:08:12,626:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:08:12,626:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:08:12,627:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:08:12,627:INFO:[LightGBM] [Info] Number of data points in the train set: 107380, number of used features: 28
2025-05-14 11:08:12,627:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:08:14,110:INFO:Uploading results into container
2025-05-14 11:08:14,110:INFO:Uploading model into container now
2025-05-14 11:08:14,110:INFO:_master_model_container: 2
2025-05-14 11:08:14,111:INFO:_display_container: 3
2025-05-14 11:08:14,111:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:08:14,111:INFO:create_model() successfully completed......................................
2025-05-14 11:08:14,248:INFO:SubProcess create_model() end ==================================
2025-05-14 11:08:14,248:INFO:choose_better activated
2025-05-14 11:08:14,250:INFO:SubProcess create_model() called ==================================
2025-05-14 11:08:14,250:INFO:Initializing create_model()
2025-05-14 11:08:14,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:08:14,250:INFO:Checking exceptions
2025-05-14 11:08:14,251:INFO:Importing libraries
2025-05-14 11:08:14,251:INFO:Copying training dataset
2025-05-14 11:08:14,262:INFO:Defining folds
2025-05-14 11:08:14,262:INFO:Declaring metric variables
2025-05-14 11:08:14,262:INFO:Importing untrained model
2025-05-14 11:08:14,262:INFO:Declaring custom model
2025-05-14 11:08:14,263:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:08:14,263:INFO:Starting cross validation
2025-05-14 11:08:14,264:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:08:18,602:INFO:Calculating mean and std
2025-05-14 11:08:18,602:INFO:Creating metrics dataframe
2025-05-14 11:08:18,603:INFO:Finalizing model
2025-05-14 11:08:19,889:INFO:[LightGBM] [Info] Number of positive: 53690, number of negative: 53690
2025-05-14 11:08:19,900:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005382 seconds.
2025-05-14 11:08:19,900:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:08:19,900:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:08:19,900:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:08:19,900:INFO:[LightGBM] [Info] Number of data points in the train set: 107380, number of used features: 28
2025-05-14 11:08:19,900:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:08:20,686:INFO:Uploading results into container
2025-05-14 11:08:20,686:INFO:Uploading model into container now
2025-05-14 11:08:20,686:INFO:_master_model_container: 3
2025-05-14 11:08:20,686:INFO:_display_container: 4
2025-05-14 11:08:20,686:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:08:20,686:INFO:create_model() successfully completed......................................
2025-05-14 11:08:20,776:INFO:SubProcess create_model() end ==================================
2025-05-14 11:08:20,776:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4728
2025-05-14 11:08:20,776:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4908
2025-05-14 11:08:20,777:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-14 11:08:20,777:INFO:choose_better completed
2025-05-14 11:08:20,780:INFO:_master_model_container: 3
2025-05-14 11:08:20,780:INFO:_display_container: 3
2025-05-14 11:08:20,781:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:08:20,781:INFO:tune_model() successfully completed......................................
2025-05-14 11:08:20,873:INFO:Initializing finalize_model()
2025-05-14 11:08:20,873:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-14 11:08:20,874:INFO:Finalizing LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:08:20,878:INFO:Initializing create_model()
2025-05-14 11:08:20,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:08:20,878:INFO:Checking exceptions
2025-05-14 11:08:20,879:INFO:Importing libraries
2025-05-14 11:08:20,879:INFO:Copying training dataset
2025-05-14 11:08:20,880:INFO:Defining folds
2025-05-14 11:08:20,880:INFO:Declaring metric variables
2025-05-14 11:08:20,880:INFO:Importing untrained model
2025-05-14 11:08:20,880:INFO:Declaring custom model
2025-05-14 11:08:20,881:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:08:20,881:INFO:Cross validation set to False
2025-05-14 11:08:20,881:INFO:Fitting Model
2025-05-14 11:08:22,750:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:08:22,750:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:08:22,750:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:08:22,814:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:08:22,814:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:08:22,814:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:08:22,814:INFO:[LightGBM] [Info] Number of positive: 76700, number of negative: 76700
2025-05-14 11:08:22,831:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007302 seconds.
2025-05-14 11:08:22,831:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:08:22,831:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:08:22,831:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:08:22,831:INFO:[LightGBM] [Info] Number of data points in the train set: 153400, number of used features: 28
2025-05-14 11:08:22,831:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:08:24,598:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-14 11:08:24,599:INFO:create_model() successfully completed......................................
2025-05-14 11:08:24,749:INFO:_master_model_container: 3
2025-05-14 11:08:24,749:INFO:_display_container: 3
2025-05-14 11:08:24,771:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-14 11:08:24,771:INFO:finalize_model() successfully completed......................................
2025-05-14 11:08:24,913:INFO:Initializing save_model()
2025-05-14 11:08:24,913:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-14 11:08:24,913:INFO:Adding model into prep_pipe
2025-05-14 11:08:24,913:WARNING:Only Model saved as it was a pipeline.
2025-05-14 11:08:24,924:INFO:final_cancer_model.pkl saved in current working directory
2025-05-14 11:08:24,946:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-14 11:08:24,946:INFO:save_model() successfully completed......................................
2025-05-14 11:08:25,067:INFO:Initializing predict_model()
2025-05-14 11:08:25,067:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x33ed3bba0>)
2025-05-14 11:08:25,067:INFO:Checking exceptions
2025-05-14 11:08:25,067:INFO:Preloading libraries
2025-05-14 11:08:25,069:INFO:Set up data.
2025-05-14 11:08:25,089:INFO:Set up index.
2025-05-14 11:08:25,607:INFO:Initializing create_model()
2025-05-14 11:08:25,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:08:25,607:INFO:Checking exceptions
2025-05-14 11:08:25,612:INFO:Importing libraries
2025-05-14 11:08:25,612:INFO:Copying training dataset
2025-05-14 11:08:25,627:INFO:Defining folds
2025-05-14 11:08:25,627:INFO:Declaring metric variables
2025-05-14 11:08:25,628:INFO:Importing untrained model
2025-05-14 11:08:25,630:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:08:25,633:INFO:Starting cross validation
2025-05-14 11:08:25,634:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:08:30,296:INFO:Calculating mean and std
2025-05-14 11:08:30,297:INFO:Creating metrics dataframe
2025-05-14 11:08:30,299:INFO:Finalizing model
2025-05-14 11:08:31,564:INFO:[LightGBM] [Info] Number of positive: 53690, number of negative: 53690
2025-05-14 11:08:31,576:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005518 seconds.
2025-05-14 11:08:31,576:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:08:31,576:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:08:31,576:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:08:31,576:INFO:[LightGBM] [Info] Number of data points in the train set: 107380, number of used features: 28
2025-05-14 11:08:31,577:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:08:32,360:INFO:Uploading results into container
2025-05-14 11:08:32,360:INFO:Uploading model into container now
2025-05-14 11:08:32,364:INFO:_master_model_container: 4
2025-05-14 11:08:32,364:INFO:_display_container: 4
2025-05-14 11:08:32,364:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:08:32,364:INFO:create_model() successfully completed......................................
2025-05-14 11:08:32,448:INFO:Initializing create_model()
2025-05-14 11:08:32,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:08:32,448:INFO:Checking exceptions
2025-05-14 11:08:32,454:INFO:Importing libraries
2025-05-14 11:08:32,454:INFO:Copying training dataset
2025-05-14 11:08:32,467:INFO:Defining folds
2025-05-14 11:08:32,467:INFO:Declaring metric variables
2025-05-14 11:08:32,468:INFO:Importing untrained model
2025-05-14 11:08:32,470:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 11:08:32,472:INFO:Starting cross validation
2025-05-14 11:08:32,474:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:08:49,630:INFO:Calculating mean and std
2025-05-14 11:08:49,634:INFO:Creating metrics dataframe
2025-05-14 11:08:49,645:INFO:Finalizing model
2025-05-14 11:09:10,589:INFO:Uploading results into container
2025-05-14 11:09:10,591:INFO:Uploading model into container now
2025-05-14 11:09:10,597:INFO:_master_model_container: 5
2025-05-14 11:09:10,597:INFO:_display_container: 5
2025-05-14 11:09:10,598:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 11:09:10,598:INFO:create_model() successfully completed......................................
2025-05-14 11:09:10,756:INFO:Initializing create_model()
2025-05-14 11:09:10,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:09:10,756:INFO:Checking exceptions
2025-05-14 11:09:10,762:INFO:Importing libraries
2025-05-14 11:09:10,762:INFO:Copying training dataset
2025-05-14 11:09:10,775:INFO:Defining folds
2025-05-14 11:09:10,775:INFO:Declaring metric variables
2025-05-14 11:09:10,777:INFO:Importing untrained model
2025-05-14 11:09:10,778:INFO:Random Forest Classifier Imported successfully
2025-05-14 11:09:10,781:INFO:Starting cross validation
2025-05-14 11:09:10,783:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:09:18,893:INFO:Calculating mean and std
2025-05-14 11:09:18,895:INFO:Creating metrics dataframe
2025-05-14 11:09:18,902:INFO:Finalizing model
2025-05-14 11:09:21,988:INFO:Uploading results into container
2025-05-14 11:09:21,988:INFO:Uploading model into container now
2025-05-14 11:09:21,993:INFO:_master_model_container: 6
2025-05-14 11:09:21,993:INFO:_display_container: 6
2025-05-14 11:09:21,993:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 11:09:21,993:INFO:create_model() successfully completed......................................
2025-05-14 11:09:22,134:INFO:Initializing blend_models()
2025-05-14 11:09:22,135:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-14 11:09:22,135:INFO:Checking exceptions
2025-05-14 11:09:22,147:INFO:Importing libraries
2025-05-14 11:09:22,147:INFO:Copying training dataset
2025-05-14 11:09:22,149:INFO:Getting model names
2025-05-14 11:09:22,151:INFO:SubProcess create_model() called ==================================
2025-05-14 11:09:22,153:INFO:Initializing create_model()
2025-05-14 11:09:22,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332814a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:09:22,153:INFO:Checking exceptions
2025-05-14 11:09:22,153:INFO:Importing libraries
2025-05-14 11:09:22,153:INFO:Copying training dataset
2025-05-14 11:09:22,166:INFO:Defining folds
2025-05-14 11:09:22,166:INFO:Declaring metric variables
2025-05-14 11:09:22,167:INFO:Importing untrained model
2025-05-14 11:09:22,167:INFO:Declaring custom model
2025-05-14 11:09:22,170:INFO:Voting Classifier Imported successfully
2025-05-14 11:09:22,172:INFO:Starting cross validation
2025-05-14 11:09:22,173:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:09:43,763:INFO:Calculating mean and std
2025-05-14 11:09:43,766:INFO:Creating metrics dataframe
2025-05-14 11:09:43,779:INFO:Finalizing model
2025-05-14 11:10:05,337:INFO:Uploading results into container
2025-05-14 11:10:05,340:INFO:Uploading model into container now
2025-05-14 11:10:05,341:INFO:_master_model_container: 7
2025-05-14 11:10:05,342:INFO:_display_container: 7
2025-05-14 11:10:05,345:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-14 11:10:05,345:INFO:create_model() successfully completed......................................
2025-05-14 11:10:05,557:INFO:SubProcess create_model() end ==================================
2025-05-14 11:10:05,562:INFO:_master_model_container: 7
2025-05-14 11:10:05,562:INFO:_display_container: 7
2025-05-14 11:10:05,564:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-14 11:10:05,564:INFO:blend_models() successfully completed......................................
2025-05-14 11:10:05,655:INFO:Initializing predict_model()
2025-05-14 11:10:05,655:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x330b251c0>)
2025-05-14 11:10:05,655:INFO:Checking exceptions
2025-05-14 11:10:05,655:INFO:Preloading libraries
2025-05-14 11:10:05,656:INFO:Set up data.
2025-05-14 11:10:05,679:INFO:Set up index.
2025-05-14 11:10:06,443:INFO:Initializing plot_model()
2025-05-14 11:10:06,443:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 11:10:06,443:INFO:Checking exceptions
2025-05-14 11:10:06,450:INFO:Preloading libraries
2025-05-14 11:10:06,453:INFO:Copying training dataset
2025-05-14 11:10:06,453:INFO:Plot type: confusion_matrix
2025-05-14 11:10:06,713:INFO:Fitting Model
2025-05-14 11:10:06,716:INFO:Scoring test/hold-out set
2025-05-14 11:10:06,717:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:10:06,717:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:10:06,717:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:10:06,762:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:10:06,762:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:10:06,762:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:10:06,840:INFO:Visual Rendered Successfully
2025-05-14 11:10:06,927:INFO:plot_model() successfully completed......................................
2025-05-14 11:10:06,949:INFO:Initializing plot_model()
2025-05-14 11:10:06,949:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 11:10:06,949:INFO:Checking exceptions
2025-05-14 11:10:06,954:INFO:Preloading libraries
2025-05-14 11:10:06,957:INFO:Copying training dataset
2025-05-14 11:10:06,957:INFO:Plot type: auc
2025-05-14 11:10:07,210:INFO:Fitting Model
2025-05-14 11:10:07,212:INFO:Scoring test/hold-out set
2025-05-14 11:10:07,213:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:10:07,213:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:10:07,213:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:10:07,253:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:10:07,253:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:10:07,253:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:10:07,375:INFO:Visual Rendered Successfully
2025-05-14 11:10:07,468:INFO:plot_model() successfully completed......................................
2025-05-14 11:10:07,491:INFO:Initializing plot_model()
2025-05-14 11:10:07,491:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 11:10:07,491:INFO:Checking exceptions
2025-05-14 11:10:07,496:INFO:Preloading libraries
2025-05-14 11:10:07,500:INFO:Copying training dataset
2025-05-14 11:10:07,500:INFO:Plot type: feature
2025-05-14 11:10:07,500:WARNING:No coef_ found. Trying feature_importances_
2025-05-14 11:10:07,580:INFO:Visual Rendered Successfully
2025-05-14 11:10:07,674:INFO:plot_model() successfully completed......................................
2025-05-14 12:30:03,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 12:30:03,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 12:30:03,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 12:30:03,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 12:30:30,661:INFO:PyCaret ClassificationExperiment
2025-05-14 12:30:30,661:INFO:Logging name: clf-default-name
2025-05-14 12:30:30,662:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 12:30:30,662:INFO:version 3.3.2
2025-05-14 12:30:30,662:INFO:Initializing setup()
2025-05-14 12:30:30,662:INFO:self.USI: e4f1
2025-05-14 12:30:30,662:INFO:self._variable_keys: {'y_test', 'gpu_n_jobs_param', 'y', 'exp_name_log', 'gpu_param', 'X_test', 'memory', 'is_multiclass', 'X', 'fix_imbalance', '_ml_usecase', 'pipeline', 'fold_generator', 'fold_groups_param', 'X_train', 'USI', 'logging_param', 'seed', 'n_jobs_param', 'data', 'html_param', 'log_plots_param', 'y_train', 'idx', '_available_plots', 'fold_shuffle_param', 'target_param', 'exp_id'}
2025-05-14 12:30:30,662:INFO:Checking environment
2025-05-14 12:30:30,662:INFO:python_version: 3.11.0
2025-05-14 12:30:30,662:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-14 12:30:30,662:INFO:machine: arm64
2025-05-14 12:30:30,662:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-14 12:30:30,662:INFO:Memory: svmem(total=17179869184, available=3493691392, percent=79.7, used=6216794112, free=60456960, active=3455139840, inactive=3423518720, wired=2761654272)
2025-05-14 12:30:30,662:INFO:Physical Core: 12
2025-05-14 12:30:30,662:INFO:Logical Core: 12
2025-05-14 12:30:30,662:INFO:Checking libraries
2025-05-14 12:30:30,662:INFO:System:
2025-05-14 12:30:30,662:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-14 12:30:30,662:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-14 12:30:30,662:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-14 12:30:30,662:INFO:PyCaret required dependencies:
2025-05-14 12:30:30,696:INFO:                 pip: 22.3
2025-05-14 12:30:30,696:INFO:          setuptools: 65.5.0
2025-05-14 12:30:30,696:INFO:             pycaret: 3.3.2
2025-05-14 12:30:30,696:INFO:             IPython: 9.2.0
2025-05-14 12:30:30,696:INFO:          ipywidgets: 8.1.7
2025-05-14 12:30:30,696:INFO:                tqdm: 4.67.1
2025-05-14 12:30:30,696:INFO:               numpy: 1.26.4
2025-05-14 12:30:30,696:INFO:              pandas: 2.1.4
2025-05-14 12:30:30,696:INFO:              jinja2: 3.1.6
2025-05-14 12:30:30,696:INFO:               scipy: 1.11.4
2025-05-14 12:30:30,696:INFO:              joblib: 1.3.2
2025-05-14 12:30:30,696:INFO:             sklearn: 1.4.2
2025-05-14 12:30:30,696:INFO:                pyod: 2.0.5
2025-05-14 12:30:30,696:INFO:            imblearn: 0.13.0
2025-05-14 12:30:30,696:INFO:   category_encoders: 2.7.0
2025-05-14 12:30:30,696:INFO:            lightgbm: 4.6.0
2025-05-14 12:30:30,696:INFO:               numba: 0.61.2
2025-05-14 12:30:30,696:INFO:            requests: 2.32.3
2025-05-14 12:30:30,696:INFO:          matplotlib: 3.7.5
2025-05-14 12:30:30,696:INFO:          scikitplot: 0.3.7
2025-05-14 12:30:30,696:INFO:         yellowbrick: 1.5
2025-05-14 12:30:30,696:INFO:              plotly: 5.24.1
2025-05-14 12:30:30,696:INFO:    plotly-resampler: Not installed
2025-05-14 12:30:30,696:INFO:             kaleido: 0.2.1
2025-05-14 12:30:30,696:INFO:           schemdraw: 0.15
2025-05-14 12:30:30,696:INFO:         statsmodels: 0.14.4
2025-05-14 12:30:30,696:INFO:              sktime: 0.26.0
2025-05-14 12:30:30,696:INFO:               tbats: 1.1.3
2025-05-14 12:30:30,696:INFO:            pmdarima: 2.0.4
2025-05-14 12:30:30,696:INFO:              psutil: 7.0.0
2025-05-14 12:30:30,696:INFO:          markupsafe: 3.0.2
2025-05-14 12:30:30,696:INFO:             pickle5: Not installed
2025-05-14 12:30:30,696:INFO:         cloudpickle: 3.1.1
2025-05-14 12:30:30,696:INFO:         deprecation: 2.1.0
2025-05-14 12:30:30,696:INFO:              xxhash: 3.5.0
2025-05-14 12:30:30,696:INFO:           wurlitzer: 3.1.1
2025-05-14 12:30:30,696:INFO:PyCaret optional dependencies:
2025-05-14 12:30:30,701:INFO:                shap: 0.47.2
2025-05-14 12:30:30,701:INFO:           interpret: Not installed
2025-05-14 12:30:30,701:INFO:                umap: Not installed
2025-05-14 12:30:30,701:INFO:     ydata_profiling: Not installed
2025-05-14 12:30:30,701:INFO:  explainerdashboard: Not installed
2025-05-14 12:30:30,701:INFO:             autoviz: Not installed
2025-05-14 12:30:30,701:INFO:           fairlearn: Not installed
2025-05-14 12:30:30,701:INFO:          deepchecks: Not installed
2025-05-14 12:30:30,701:INFO:             xgboost: Not installed
2025-05-14 12:30:30,701:INFO:            catboost: 1.2.8
2025-05-14 12:30:30,701:INFO:              kmodes: Not installed
2025-05-14 12:30:30,701:INFO:             mlxtend: Not installed
2025-05-14 12:30:30,701:INFO:       statsforecast: Not installed
2025-05-14 12:30:30,701:INFO:        tune_sklearn: Not installed
2025-05-14 12:30:30,701:INFO:                 ray: Not installed
2025-05-14 12:30:30,701:INFO:            hyperopt: Not installed
2025-05-14 12:30:30,701:INFO:              optuna: 4.3.0
2025-05-14 12:30:30,701:INFO:               skopt: Not installed
2025-05-14 12:30:30,702:INFO:              mlflow: Not installed
2025-05-14 12:30:30,702:INFO:              gradio: Not installed
2025-05-14 12:30:30,702:INFO:             fastapi: Not installed
2025-05-14 12:30:30,702:INFO:             uvicorn: Not installed
2025-05-14 12:30:30,702:INFO:              m2cgen: Not installed
2025-05-14 12:30:30,702:INFO:           evidently: Not installed
2025-05-14 12:30:30,702:INFO:               fugue: Not installed
2025-05-14 12:30:30,702:INFO:           streamlit: Not installed
2025-05-14 12:30:30,702:INFO:             prophet: Not installed
2025-05-14 12:30:30,702:INFO:None
2025-05-14 12:30:30,702:INFO:Set up data.
2025-05-14 12:30:30,740:INFO:Set up folding strategy.
2025-05-14 12:30:30,740:INFO:Set up train/test split.
2025-05-14 12:30:30,767:INFO:Set up index.
2025-05-14 12:30:30,768:INFO:Assigning column types.
2025-05-14 12:30:30,778:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 12:30:30,795:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 12:30:30,796:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 12:30:30,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:30:30,810:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:30:30,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 12:30:30,869:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 12:30:30,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:30:30,880:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:30:30,880:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 12:30:30,898:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 12:30:30,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:30:30,909:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:30:30,928:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 12:30:30,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:30:30,939:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:30:30,939:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 12:30:30,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:30:30,968:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:30:30,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:30:30,997:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:30:30,998:INFO:Preparing preprocessing pipeline...
2025-05-14 12:30:31,001:INFO:Set up simple imputation.
2025-05-14 12:30:31,011:INFO:Set up encoding of ordinal features.
2025-05-14 12:30:31,039:INFO:Set up encoding of categorical features.
2025-05-14 12:30:31,039:INFO:Set up imbalanced handling.
2025-05-14 12:30:31,039:INFO:Set up column transformation.
2025-05-14 12:30:32,929:INFO:Finished creating preprocessing pipeline.
2025-05-14 12:30:32,948:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'TSH_Normal', 'T4_Normal',
                                             'T3_Normal', 'TSH_T4_Ratio',
                                             'T3_T4_Ratio',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Smoke_Bina...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-14 12:30:32,948:INFO:Creating final display dataframe.
2025-05-14 12:30:33,542:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 30)
4        Transformed data shape      (106821, 43)
5   Transformed train set shape       (85902, 43)
6    Transformed test set shape       (20919, 43)
7              Numeric features                19
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              e4f1
2025-05-14 12:30:33,578:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:30:33,578:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:30:33,608:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:30:33,608:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:30:33,609:INFO:setup() successfully completed in 2.95s...............
2025-05-14 12:30:33,610:INFO:Initializing compare_models()
2025-05-14 12:30:33,610:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 12:30:33,610:INFO:Checking exceptions
2025-05-14 12:30:33,621:INFO:Preparing display monitor
2025-05-14 12:30:33,653:INFO:Initializing Logistic Regression
2025-05-14 12:30:33,653:INFO:Total runtime is 3.619988759358724e-06 minutes
2025-05-14 12:30:33,654:INFO:SubProcess create_model() called ==================================
2025-05-14 12:30:33,655:INFO:Initializing create_model()
2025-05-14 12:30:33,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:30:33,655:INFO:Checking exceptions
2025-05-14 12:30:33,655:INFO:Importing libraries
2025-05-14 12:30:33,655:INFO:Copying training dataset
2025-05-14 12:30:33,681:INFO:Defining folds
2025-05-14 12:30:33,681:INFO:Declaring metric variables
2025-05-14 12:30:33,682:INFO:Importing untrained model
2025-05-14 12:30:33,684:INFO:Logistic Regression Imported successfully
2025-05-14 12:30:33,686:INFO:Starting cross validation
2025-05-14 12:30:33,687:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:30:40,815:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 12:30:41,055:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 12:30:41,063:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 12:30:41,170:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 12:30:41,334:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 12:30:41,408:INFO:Calculating mean and std
2025-05-14 12:30:41,411:INFO:Creating metrics dataframe
2025-05-14 12:30:41,415:INFO:Uploading results into container
2025-05-14 12:30:41,416:INFO:Uploading model into container now
2025-05-14 12:30:41,416:INFO:_master_model_container: 1
2025-05-14 12:30:41,416:INFO:_display_container: 2
2025-05-14 12:30:41,417:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 12:30:41,417:INFO:create_model() successfully completed......................................
2025-05-14 12:30:41,521:INFO:SubProcess create_model() end ==================================
2025-05-14 12:30:41,521:INFO:Creating metrics dataframe
2025-05-14 12:30:41,525:INFO:Initializing K Neighbors Classifier
2025-05-14 12:30:41,525:INFO:Total runtime is 0.13119333585103354 minutes
2025-05-14 12:30:41,526:INFO:SubProcess create_model() called ==================================
2025-05-14 12:30:41,526:INFO:Initializing create_model()
2025-05-14 12:30:41,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:30:41,526:INFO:Checking exceptions
2025-05-14 12:30:41,526:INFO:Importing libraries
2025-05-14 12:30:41,526:INFO:Copying training dataset
2025-05-14 12:30:41,552:INFO:Defining folds
2025-05-14 12:30:41,552:INFO:Declaring metric variables
2025-05-14 12:30:41,554:INFO:Importing untrained model
2025-05-14 12:30:41,555:INFO:K Neighbors Classifier Imported successfully
2025-05-14 12:30:41,558:INFO:Starting cross validation
2025-05-14 12:30:41,561:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:30:48,805:INFO:Calculating mean and std
2025-05-14 12:30:48,808:INFO:Creating metrics dataframe
2025-05-14 12:30:48,810:INFO:Uploading results into container
2025-05-14 12:30:48,811:INFO:Uploading model into container now
2025-05-14 12:30:48,811:INFO:_master_model_container: 2
2025-05-14 12:30:48,811:INFO:_display_container: 2
2025-05-14 12:30:48,811:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 12:30:48,811:INFO:create_model() successfully completed......................................
2025-05-14 12:30:48,880:INFO:SubProcess create_model() end ==================================
2025-05-14 12:30:48,880:INFO:Creating metrics dataframe
2025-05-14 12:30:48,883:INFO:Initializing Naive Bayes
2025-05-14 12:30:48,883:INFO:Total runtime is 0.25382932027180993 minutes
2025-05-14 12:30:48,884:INFO:SubProcess create_model() called ==================================
2025-05-14 12:30:48,884:INFO:Initializing create_model()
2025-05-14 12:30:48,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:30:48,884:INFO:Checking exceptions
2025-05-14 12:30:48,884:INFO:Importing libraries
2025-05-14 12:30:48,884:INFO:Copying training dataset
2025-05-14 12:30:48,908:INFO:Defining folds
2025-05-14 12:30:48,908:INFO:Declaring metric variables
2025-05-14 12:30:48,910:INFO:Importing untrained model
2025-05-14 12:30:48,911:INFO:Naive Bayes Imported successfully
2025-05-14 12:30:48,914:INFO:Starting cross validation
2025-05-14 12:30:48,915:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:30:51,925:INFO:Calculating mean and std
2025-05-14 12:30:51,926:INFO:Creating metrics dataframe
2025-05-14 12:30:51,927:INFO:Uploading results into container
2025-05-14 12:30:51,927:INFO:Uploading model into container now
2025-05-14 12:30:51,928:INFO:_master_model_container: 3
2025-05-14 12:30:51,928:INFO:_display_container: 2
2025-05-14 12:30:51,928:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 12:30:51,928:INFO:create_model() successfully completed......................................
2025-05-14 12:30:51,991:INFO:SubProcess create_model() end ==================================
2025-05-14 12:30:51,991:INFO:Creating metrics dataframe
2025-05-14 12:30:51,995:INFO:Initializing Decision Tree Classifier
2025-05-14 12:30:51,995:INFO:Total runtime is 0.3056937177975973 minutes
2025-05-14 12:30:51,996:INFO:SubProcess create_model() called ==================================
2025-05-14 12:30:51,996:INFO:Initializing create_model()
2025-05-14 12:30:51,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:30:51,996:INFO:Checking exceptions
2025-05-14 12:30:51,996:INFO:Importing libraries
2025-05-14 12:30:51,996:INFO:Copying training dataset
2025-05-14 12:30:52,019:INFO:Defining folds
2025-05-14 12:30:52,019:INFO:Declaring metric variables
2025-05-14 12:30:52,020:INFO:Importing untrained model
2025-05-14 12:30:52,022:INFO:Decision Tree Classifier Imported successfully
2025-05-14 12:30:52,024:INFO:Starting cross validation
2025-05-14 12:30:52,025:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:30:55,852:INFO:Calculating mean and std
2025-05-14 12:30:55,854:INFO:Creating metrics dataframe
2025-05-14 12:30:55,857:INFO:Uploading results into container
2025-05-14 12:30:55,858:INFO:Uploading model into container now
2025-05-14 12:30:55,858:INFO:_master_model_container: 4
2025-05-14 12:30:55,858:INFO:_display_container: 2
2025-05-14 12:30:55,859:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-14 12:30:55,859:INFO:create_model() successfully completed......................................
2025-05-14 12:30:55,957:INFO:SubProcess create_model() end ==================================
2025-05-14 12:30:55,957:INFO:Creating metrics dataframe
2025-05-14 12:30:55,962:INFO:Initializing SVM - Linear Kernel
2025-05-14 12:30:55,962:INFO:Total runtime is 0.3718165516853333 minutes
2025-05-14 12:30:55,963:INFO:SubProcess create_model() called ==================================
2025-05-14 12:30:55,963:INFO:Initializing create_model()
2025-05-14 12:30:55,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:30:55,964:INFO:Checking exceptions
2025-05-14 12:30:55,964:INFO:Importing libraries
2025-05-14 12:30:55,964:INFO:Copying training dataset
2025-05-14 12:30:55,990:INFO:Defining folds
2025-05-14 12:30:55,990:INFO:Declaring metric variables
2025-05-14 12:30:55,991:INFO:Importing untrained model
2025-05-14 12:30:55,993:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 12:30:55,995:INFO:Starting cross validation
2025-05-14 12:30:56,002:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:31:01,452:INFO:Calculating mean and std
2025-05-14 12:31:01,453:INFO:Creating metrics dataframe
2025-05-14 12:31:01,457:INFO:Uploading results into container
2025-05-14 12:31:01,457:INFO:Uploading model into container now
2025-05-14 12:31:01,457:INFO:_master_model_container: 5
2025-05-14 12:31:01,457:INFO:_display_container: 2
2025-05-14 12:31:01,457:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 12:31:01,457:INFO:create_model() successfully completed......................................
2025-05-14 12:31:01,515:INFO:SubProcess create_model() end ==================================
2025-05-14 12:31:01,515:INFO:Creating metrics dataframe
2025-05-14 12:31:01,519:INFO:Initializing Ridge Classifier
2025-05-14 12:31:01,519:INFO:Total runtime is 0.4644290685653687 minutes
2025-05-14 12:31:01,520:INFO:SubProcess create_model() called ==================================
2025-05-14 12:31:01,520:INFO:Initializing create_model()
2025-05-14 12:31:01,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:31:01,520:INFO:Checking exceptions
2025-05-14 12:31:01,520:INFO:Importing libraries
2025-05-14 12:31:01,520:INFO:Copying training dataset
2025-05-14 12:31:01,543:INFO:Defining folds
2025-05-14 12:31:01,543:INFO:Declaring metric variables
2025-05-14 12:31:01,544:INFO:Importing untrained model
2025-05-14 12:31:01,546:INFO:Ridge Classifier Imported successfully
2025-05-14 12:31:01,548:INFO:Starting cross validation
2025-05-14 12:31:01,549:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:31:03,160:INFO:Calculating mean and std
2025-05-14 12:31:03,161:INFO:Creating metrics dataframe
2025-05-14 12:31:03,162:INFO:Uploading results into container
2025-05-14 12:31:03,163:INFO:Uploading model into container now
2025-05-14 12:31:03,163:INFO:_master_model_container: 6
2025-05-14 12:31:03,163:INFO:_display_container: 2
2025-05-14 12:31:03,163:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-14 12:31:03,163:INFO:create_model() successfully completed......................................
2025-05-14 12:31:03,223:INFO:SubProcess create_model() end ==================================
2025-05-14 12:31:03,223:INFO:Creating metrics dataframe
2025-05-14 12:31:03,226:INFO:Initializing Random Forest Classifier
2025-05-14 12:31:03,226:INFO:Total runtime is 0.4928905010223389 minutes
2025-05-14 12:31:03,228:INFO:SubProcess create_model() called ==================================
2025-05-14 12:31:03,228:INFO:Initializing create_model()
2025-05-14 12:31:03,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:31:03,228:INFO:Checking exceptions
2025-05-14 12:31:03,228:INFO:Importing libraries
2025-05-14 12:31:03,228:INFO:Copying training dataset
2025-05-14 12:31:03,250:INFO:Defining folds
2025-05-14 12:31:03,251:INFO:Declaring metric variables
2025-05-14 12:31:03,252:INFO:Importing untrained model
2025-05-14 12:31:03,253:INFO:Random Forest Classifier Imported successfully
2025-05-14 12:31:03,255:INFO:Starting cross validation
2025-05-14 12:31:03,257:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:31:10,756:INFO:Calculating mean and std
2025-05-14 12:31:10,758:INFO:Creating metrics dataframe
2025-05-14 12:31:10,761:INFO:Uploading results into container
2025-05-14 12:31:10,761:INFO:Uploading model into container now
2025-05-14 12:31:10,762:INFO:_master_model_container: 7
2025-05-14 12:31:10,762:INFO:_display_container: 2
2025-05-14 12:31:10,762:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 12:31:10,762:INFO:create_model() successfully completed......................................
2025-05-14 12:31:10,825:INFO:SubProcess create_model() end ==================================
2025-05-14 12:31:10,825:INFO:Creating metrics dataframe
2025-05-14 12:31:10,829:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 12:31:10,829:INFO:Total runtime is 0.6195954163869222 minutes
2025-05-14 12:31:10,830:INFO:SubProcess create_model() called ==================================
2025-05-14 12:31:10,830:INFO:Initializing create_model()
2025-05-14 12:31:10,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:31:10,830:INFO:Checking exceptions
2025-05-14 12:31:10,831:INFO:Importing libraries
2025-05-14 12:31:10,831:INFO:Copying training dataset
2025-05-14 12:31:10,853:INFO:Defining folds
2025-05-14 12:31:10,853:INFO:Declaring metric variables
2025-05-14 12:31:10,855:INFO:Importing untrained model
2025-05-14 12:31:10,856:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 12:31:10,858:INFO:Starting cross validation
2025-05-14 12:31:10,860:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:31:12,271:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 12:31:12,361:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 12:31:12,378:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 12:31:12,386:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 12:31:12,388:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 12:31:12,394:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:31:12,487:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:31:12,504:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:31:12,505:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:31:12,526:INFO:Calculating mean and std
2025-05-14 12:31:12,526:INFO:Creating metrics dataframe
2025-05-14 12:31:12,527:INFO:Uploading results into container
2025-05-14 12:31:12,528:INFO:Uploading model into container now
2025-05-14 12:31:12,528:INFO:_master_model_container: 8
2025-05-14 12:31:12,528:INFO:_display_container: 2
2025-05-14 12:31:12,528:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 12:31:12,529:INFO:create_model() successfully completed......................................
2025-05-14 12:31:12,587:INFO:SubProcess create_model() end ==================================
2025-05-14 12:31:12,587:INFO:Creating metrics dataframe
2025-05-14 12:31:12,590:INFO:Initializing Ada Boost Classifier
2025-05-14 12:31:12,590:INFO:Total runtime is 0.648954168955485 minutes
2025-05-14 12:31:12,591:INFO:SubProcess create_model() called ==================================
2025-05-14 12:31:12,592:INFO:Initializing create_model()
2025-05-14 12:31:12,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:31:12,592:INFO:Checking exceptions
2025-05-14 12:31:12,592:INFO:Importing libraries
2025-05-14 12:31:12,592:INFO:Copying training dataset
2025-05-14 12:31:12,621:INFO:Defining folds
2025-05-14 12:31:12,621:INFO:Declaring metric variables
2025-05-14 12:31:12,623:INFO:Importing untrained model
2025-05-14 12:31:12,624:INFO:Ada Boost Classifier Imported successfully
2025-05-14 12:31:12,627:INFO:Starting cross validation
2025-05-14 12:31:12,631:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:31:14,096:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 12:31:14,128:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 12:31:14,158:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 12:31:14,171:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 12:31:14,172:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 12:31:18,511:INFO:Calculating mean and std
2025-05-14 12:31:18,511:INFO:Creating metrics dataframe
2025-05-14 12:31:18,513:INFO:Uploading results into container
2025-05-14 12:31:18,513:INFO:Uploading model into container now
2025-05-14 12:31:18,513:INFO:_master_model_container: 9
2025-05-14 12:31:18,513:INFO:_display_container: 2
2025-05-14 12:31:18,513:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-14 12:31:18,513:INFO:create_model() successfully completed......................................
2025-05-14 12:31:18,576:INFO:SubProcess create_model() end ==================================
2025-05-14 12:31:18,576:INFO:Creating metrics dataframe
2025-05-14 12:31:18,580:INFO:Initializing Gradient Boosting Classifier
2025-05-14 12:31:18,580:INFO:Total runtime is 0.7487783352533975 minutes
2025-05-14 12:31:18,581:INFO:SubProcess create_model() called ==================================
2025-05-14 12:31:18,581:INFO:Initializing create_model()
2025-05-14 12:31:18,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:31:18,581:INFO:Checking exceptions
2025-05-14 12:31:18,581:INFO:Importing libraries
2025-05-14 12:31:18,581:INFO:Copying training dataset
2025-05-14 12:31:18,604:INFO:Defining folds
2025-05-14 12:31:18,604:INFO:Declaring metric variables
2025-05-14 12:31:18,605:INFO:Importing untrained model
2025-05-14 12:31:18,607:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 12:31:18,609:INFO:Starting cross validation
2025-05-14 12:31:18,611:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:31:41,933:INFO:Calculating mean and std
2025-05-14 12:31:41,935:INFO:Creating metrics dataframe
2025-05-14 12:31:41,939:INFO:Uploading results into container
2025-05-14 12:31:41,939:INFO:Uploading model into container now
2025-05-14 12:31:41,940:INFO:_master_model_container: 10
2025-05-14 12:31:41,940:INFO:_display_container: 2
2025-05-14 12:31:41,941:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 12:31:41,943:INFO:create_model() successfully completed......................................
2025-05-14 12:31:42,039:INFO:SubProcess create_model() end ==================================
2025-05-14 12:31:42,040:INFO:Creating metrics dataframe
2025-05-14 12:31:42,043:INFO:Initializing Linear Discriminant Analysis
2025-05-14 12:31:42,043:INFO:Total runtime is 1.1398409008979797 minutes
2025-05-14 12:31:42,045:INFO:SubProcess create_model() called ==================================
2025-05-14 12:31:42,045:INFO:Initializing create_model()
2025-05-14 12:31:42,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:31:42,045:INFO:Checking exceptions
2025-05-14 12:31:42,045:INFO:Importing libraries
2025-05-14 12:31:42,045:INFO:Copying training dataset
2025-05-14 12:31:42,077:INFO:Defining folds
2025-05-14 12:31:42,077:INFO:Declaring metric variables
2025-05-14 12:31:42,079:INFO:Importing untrained model
2025-05-14 12:31:42,080:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 12:31:42,082:INFO:Starting cross validation
2025-05-14 12:31:42,084:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:31:43,848:INFO:Calculating mean and std
2025-05-14 12:31:43,849:INFO:Creating metrics dataframe
2025-05-14 12:31:43,850:INFO:Uploading results into container
2025-05-14 12:31:43,850:INFO:Uploading model into container now
2025-05-14 12:31:43,850:INFO:_master_model_container: 11
2025-05-14 12:31:43,850:INFO:_display_container: 2
2025-05-14 12:31:43,850:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 12:31:43,850:INFO:create_model() successfully completed......................................
2025-05-14 12:31:43,901:INFO:SubProcess create_model() end ==================================
2025-05-14 12:31:43,901:INFO:Creating metrics dataframe
2025-05-14 12:31:43,906:INFO:Initializing Extra Trees Classifier
2025-05-14 12:31:43,906:INFO:Total runtime is 1.1708778381347655 minutes
2025-05-14 12:31:43,907:INFO:SubProcess create_model() called ==================================
2025-05-14 12:31:43,907:INFO:Initializing create_model()
2025-05-14 12:31:43,907:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:31:43,907:INFO:Checking exceptions
2025-05-14 12:31:43,908:INFO:Importing libraries
2025-05-14 12:31:43,908:INFO:Copying training dataset
2025-05-14 12:31:43,932:INFO:Defining folds
2025-05-14 12:31:43,932:INFO:Declaring metric variables
2025-05-14 12:31:43,933:INFO:Importing untrained model
2025-05-14 12:31:43,935:INFO:Extra Trees Classifier Imported successfully
2025-05-14 12:31:43,937:INFO:Starting cross validation
2025-05-14 12:31:43,939:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:31:49,431:INFO:Calculating mean and std
2025-05-14 12:31:49,434:INFO:Creating metrics dataframe
2025-05-14 12:31:49,445:INFO:Uploading results into container
2025-05-14 12:31:49,446:INFO:Uploading model into container now
2025-05-14 12:31:49,446:INFO:_master_model_container: 12
2025-05-14 12:31:49,446:INFO:_display_container: 2
2025-05-14 12:31:49,447:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-14 12:31:49,447:INFO:create_model() successfully completed......................................
2025-05-14 12:31:49,551:INFO:SubProcess create_model() end ==================================
2025-05-14 12:31:49,551:INFO:Creating metrics dataframe
2025-05-14 12:31:49,555:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 12:31:49,555:INFO:Total runtime is 1.2650405844052632 minutes
2025-05-14 12:31:49,557:INFO:SubProcess create_model() called ==================================
2025-05-14 12:31:49,557:INFO:Initializing create_model()
2025-05-14 12:31:49,557:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:31:49,558:INFO:Checking exceptions
2025-05-14 12:31:49,558:INFO:Importing libraries
2025-05-14 12:31:49,558:INFO:Copying training dataset
2025-05-14 12:31:49,591:INFO:Defining folds
2025-05-14 12:31:49,591:INFO:Declaring metric variables
2025-05-14 12:31:49,592:INFO:Importing untrained model
2025-05-14 12:31:49,594:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 12:31:49,596:INFO:Starting cross validation
2025-05-14 12:31:49,598:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:31:54,094:INFO:Calculating mean and std
2025-05-14 12:31:54,095:INFO:Creating metrics dataframe
2025-05-14 12:31:54,096:INFO:Uploading results into container
2025-05-14 12:31:54,096:INFO:Uploading model into container now
2025-05-14 12:31:54,096:INFO:_master_model_container: 13
2025-05-14 12:31:54,096:INFO:_display_container: 2
2025-05-14 12:31:54,097:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 12:31:54,097:INFO:create_model() successfully completed......................................
2025-05-14 12:31:54,149:INFO:SubProcess create_model() end ==================================
2025-05-14 12:31:54,149:INFO:Creating metrics dataframe
2025-05-14 12:31:54,153:INFO:Initializing CatBoost Classifier
2025-05-14 12:31:54,153:INFO:Total runtime is 1.3416728695233662 minutes
2025-05-14 12:31:54,155:INFO:SubProcess create_model() called ==================================
2025-05-14 12:31:54,155:INFO:Initializing create_model()
2025-05-14 12:31:54,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:31:54,155:INFO:Checking exceptions
2025-05-14 12:31:54,155:INFO:Importing libraries
2025-05-14 12:31:54,155:INFO:Copying training dataset
2025-05-14 12:31:54,179:INFO:Defining folds
2025-05-14 12:31:54,179:INFO:Declaring metric variables
2025-05-14 12:31:54,180:INFO:Importing untrained model
2025-05-14 12:31:54,181:INFO:CatBoost Classifier Imported successfully
2025-05-14 12:31:54,184:INFO:Starting cross validation
2025-05-14 12:31:54,185:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:32:13,730:INFO:Calculating mean and std
2025-05-14 12:32:13,732:INFO:Creating metrics dataframe
2025-05-14 12:32:13,735:INFO:Uploading results into container
2025-05-14 12:32:13,736:INFO:Uploading model into container now
2025-05-14 12:32:13,736:INFO:_master_model_container: 14
2025-05-14 12:32:13,736:INFO:_display_container: 2
2025-05-14 12:32:13,736:INFO:<catboost.core.CatBoostClassifier object at 0x3277c0f10>
2025-05-14 12:32:13,737:INFO:create_model() successfully completed......................................
2025-05-14 12:32:13,824:INFO:SubProcess create_model() end ==================================
2025-05-14 12:32:13,824:INFO:Creating metrics dataframe
2025-05-14 12:32:13,829:INFO:Initializing Dummy Classifier
2025-05-14 12:32:13,829:INFO:Total runtime is 1.6695985714594521 minutes
2025-05-14 12:32:13,830:INFO:SubProcess create_model() called ==================================
2025-05-14 12:32:13,830:INFO:Initializing create_model()
2025-05-14 12:32:13,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32663c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:32:13,830:INFO:Checking exceptions
2025-05-14 12:32:13,830:INFO:Importing libraries
2025-05-14 12:32:13,830:INFO:Copying training dataset
2025-05-14 12:32:13,859:INFO:Defining folds
2025-05-14 12:32:13,859:INFO:Declaring metric variables
2025-05-14 12:32:13,861:INFO:Importing untrained model
2025-05-14 12:32:13,863:INFO:Dummy Classifier Imported successfully
2025-05-14 12:32:13,865:INFO:Starting cross validation
2025-05-14 12:32:13,867:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:32:15,336:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:32:15,390:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:32:15,438:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:32:15,448:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:32:15,468:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:32:15,487:INFO:Calculating mean and std
2025-05-14 12:32:15,487:INFO:Creating metrics dataframe
2025-05-14 12:32:15,489:INFO:Uploading results into container
2025-05-14 12:32:15,489:INFO:Uploading model into container now
2025-05-14 12:32:15,489:INFO:_master_model_container: 15
2025-05-14 12:32:15,489:INFO:_display_container: 2
2025-05-14 12:32:15,489:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-14 12:32:15,490:INFO:create_model() successfully completed......................................
2025-05-14 12:32:15,551:INFO:SubProcess create_model() end ==================================
2025-05-14 12:32:15,551:INFO:Creating metrics dataframe
2025-05-14 12:32:15,559:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-14 12:32:15,562:INFO:Initializing create_model()
2025-05-14 12:32:15,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:32:15,562:INFO:Checking exceptions
2025-05-14 12:32:15,563:INFO:Importing libraries
2025-05-14 12:32:15,563:INFO:Copying training dataset
2025-05-14 12:32:15,588:INFO:Defining folds
2025-05-14 12:32:15,588:INFO:Declaring metric variables
2025-05-14 12:32:15,588:INFO:Importing untrained model
2025-05-14 12:32:15,588:INFO:Declaring custom model
2025-05-14 12:32:15,588:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 12:32:15,589:INFO:Cross validation set to False
2025-05-14 12:32:15,589:INFO:Fitting Model
2025-05-14 12:32:43,626:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 12:32:43,627:INFO:create_model() successfully completed......................................
2025-05-14 12:32:43,674:INFO:Initializing create_model()
2025-05-14 12:32:43,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:32:43,674:INFO:Checking exceptions
2025-05-14 12:32:43,675:INFO:Importing libraries
2025-05-14 12:32:43,675:INFO:Copying training dataset
2025-05-14 12:32:43,698:INFO:Defining folds
2025-05-14 12:32:43,698:INFO:Declaring metric variables
2025-05-14 12:32:43,698:INFO:Importing untrained model
2025-05-14 12:32:43,698:INFO:Declaring custom model
2025-05-14 12:32:43,698:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 12:32:43,699:INFO:Cross validation set to False
2025-05-14 12:32:43,699:INFO:Fitting Model
2025-05-14 12:32:45,325:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 12:32:45,340:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008406 seconds.
2025-05-14 12:32:45,340:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 12:32:45,340:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 12:32:45,341:INFO:[LightGBM] [Info] Total Bins 10457
2025-05-14 12:32:45,341:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 42
2025-05-14 12:32:45,341:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 12:32:46,173:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 12:32:46,173:INFO:create_model() successfully completed......................................
2025-05-14 12:32:46,224:INFO:Initializing create_model()
2025-05-14 12:32:46,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:32:46,224:INFO:Checking exceptions
2025-05-14 12:32:46,225:INFO:Importing libraries
2025-05-14 12:32:46,225:INFO:Copying training dataset
2025-05-14 12:32:46,247:INFO:Defining folds
2025-05-14 12:32:46,247:INFO:Declaring metric variables
2025-05-14 12:32:46,247:INFO:Importing untrained model
2025-05-14 12:32:46,247:INFO:Declaring custom model
2025-05-14 12:32:46,247:INFO:Random Forest Classifier Imported successfully
2025-05-14 12:32:46,248:INFO:Cross validation set to False
2025-05-14 12:32:46,248:INFO:Fitting Model
2025-05-14 12:32:49,689:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 12:32:49,690:INFO:create_model() successfully completed......................................
2025-05-14 12:32:49,772:INFO:_master_model_container: 15
2025-05-14 12:32:49,772:INFO:_display_container: 2
2025-05-14 12:32:49,772:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-14 12:32:49,773:INFO:compare_models() successfully completed......................................
2025-05-14 12:32:49,773:INFO:Initializing evaluate_model()
2025-05-14 12:32:49,773:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 12:32:49,793:INFO:Initializing plot_model()
2025-05-14 12:32:49,793:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 12:32:49,793:INFO:Checking exceptions
2025-05-14 12:32:49,803:INFO:Preloading libraries
2025-05-14 12:32:49,807:INFO:Copying training dataset
2025-05-14 12:32:49,807:INFO:Plot type: pipeline
2025-05-14 12:32:49,914:INFO:Visual Rendered Successfully
2025-05-14 12:32:49,972:INFO:plot_model() successfully completed......................................
2025-05-14 12:32:49,974:INFO:Initializing tune_model()
2025-05-14 12:32:49,974:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 12:32:49,974:INFO:Checking exceptions
2025-05-14 12:32:49,989:INFO:Copying training dataset
2025-05-14 12:32:50,005:INFO:Checking base model
2025-05-14 12:32:50,005:INFO:Base model : Gradient Boosting Classifier
2025-05-14 12:32:50,007:INFO:Declaring metric variables
2025-05-14 12:32:50,009:INFO:Defining Hyperparameters
2025-05-14 12:32:50,061:INFO:Tuning with n_jobs=-1
2025-05-14 12:32:50,061:INFO:Initializing RandomizedSearchCV
2025-05-14 12:33:42,013:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-14 12:33:42,015:INFO:Hyperparameter search completed
2025-05-14 12:33:42,015:INFO:SubProcess create_model() called ==================================
2025-05-14 12:33:42,016:INFO:Initializing create_model()
2025-05-14 12:33:42,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330cdf810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-14 12:33:42,016:INFO:Checking exceptions
2025-05-14 12:33:42,016:INFO:Importing libraries
2025-05-14 12:33:42,017:INFO:Copying training dataset
2025-05-14 12:33:42,070:INFO:Defining folds
2025-05-14 12:33:42,070:INFO:Declaring metric variables
2025-05-14 12:33:42,082:INFO:Importing untrained model
2025-05-14 12:33:42,083:INFO:Declaring custom model
2025-05-14 12:33:42,088:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 12:33:42,091:INFO:Starting cross validation
2025-05-14 12:33:42,093:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:33:55,000:INFO:Calculating mean and std
2025-05-14 12:33:55,002:INFO:Creating metrics dataframe
2025-05-14 12:33:55,009:INFO:Finalizing model
2025-05-14 12:34:09,078:INFO:Uploading results into container
2025-05-14 12:34:09,079:INFO:Uploading model into container now
2025-05-14 12:34:09,079:INFO:_master_model_container: 16
2025-05-14 12:34:09,079:INFO:_display_container: 3
2025-05-14 12:34:09,080:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 12:34:09,080:INFO:create_model() successfully completed......................................
2025-05-14 12:34:09,155:INFO:SubProcess create_model() end ==================================
2025-05-14 12:34:09,155:INFO:choose_better activated
2025-05-14 12:34:09,157:INFO:SubProcess create_model() called ==================================
2025-05-14 12:34:09,157:INFO:Initializing create_model()
2025-05-14 12:34:09,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:34:09,157:INFO:Checking exceptions
2025-05-14 12:34:09,158:INFO:Importing libraries
2025-05-14 12:34:09,158:INFO:Copying training dataset
2025-05-14 12:34:09,178:INFO:Defining folds
2025-05-14 12:34:09,178:INFO:Declaring metric variables
2025-05-14 12:34:09,178:INFO:Importing untrained model
2025-05-14 12:34:09,178:INFO:Declaring custom model
2025-05-14 12:34:09,178:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 12:34:09,178:INFO:Starting cross validation
2025-05-14 12:34:09,179:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:34:32,777:INFO:Calculating mean and std
2025-05-14 12:34:32,780:INFO:Creating metrics dataframe
2025-05-14 12:34:32,783:INFO:Finalizing model
2025-05-14 12:35:01,003:INFO:Uploading results into container
2025-05-14 12:35:01,004:INFO:Uploading model into container now
2025-05-14 12:35:01,005:INFO:_master_model_container: 17
2025-05-14 12:35:01,005:INFO:_display_container: 4
2025-05-14 12:35:01,005:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 12:35:01,005:INFO:create_model() successfully completed......................................
2025-05-14 12:35:01,081:INFO:SubProcess create_model() end ==================================
2025-05-14 12:35:01,082:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4652
2025-05-14 12:35:01,082:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4905
2025-05-14 12:35:01,082:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-14 12:35:01,082:INFO:choose_better completed
2025-05-14 12:35:01,086:INFO:_master_model_container: 17
2025-05-14 12:35:01,086:INFO:_display_container: 3
2025-05-14 12:35:01,086:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 12:35:01,086:INFO:tune_model() successfully completed......................................
2025-05-14 12:35:01,132:INFO:Initializing evaluate_model()
2025-05-14 12:35:01,132:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 12:35:01,144:INFO:Initializing plot_model()
2025-05-14 12:35:01,144:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 12:35:01,144:INFO:Checking exceptions
2025-05-14 12:35:01,154:INFO:Preloading libraries
2025-05-14 12:35:01,163:INFO:Copying training dataset
2025-05-14 12:35:01,163:INFO:Plot type: pipeline
2025-05-14 12:35:01,220:INFO:Visual Rendered Successfully
2025-05-14 12:35:01,270:INFO:plot_model() successfully completed......................................
2025-05-14 12:35:01,272:INFO:Initializing interpret_model()
2025-05-14 12:35:01,272:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 12:35:01,272:INFO:Checking exceptions
2025-05-14 12:35:01,272:INFO:Soft dependency imported: shap: 0.47.2
2025-05-14 12:35:01,540:INFO:Initializing finalize_model()
2025-05-14 12:35:01,540:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-14 12:35:01,540:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 12:35:01,549:INFO:Initializing create_model()
2025-05-14 12:35:01,549:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:35:01,549:INFO:Checking exceptions
2025-05-14 12:35:01,550:INFO:Importing libraries
2025-05-14 12:35:01,550:INFO:Copying training dataset
2025-05-14 12:35:01,551:INFO:Defining folds
2025-05-14 12:35:01,551:INFO:Declaring metric variables
2025-05-14 12:35:01,551:INFO:Importing untrained model
2025-05-14 12:35:01,551:INFO:Declaring custom model
2025-05-14 12:35:01,551:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 12:35:01,552:INFO:Cross validation set to False
2025-05-14 12:35:01,552:INFO:Fitting Model
2025-05-14 12:35:22,163:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'TSH_Normal', 'T4_Normal',
                                             'T3_Normal', 'TSH_T4_Ratio',
                                             'T3_T4_Ratio',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabetes_Binary', 'Risk_Score'...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-14 12:35:22,165:INFO:create_model() successfully completed......................................
2025-05-14 12:35:22,266:INFO:_master_model_container: 17
2025-05-14 12:35:22,267:INFO:_display_container: 3
2025-05-14 12:35:22,286:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'TSH_Normal', 'T4_Normal',
                                             'T3_Normal', 'TSH_T4_Ratio',
                                             'T3_T4_Ratio',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabetes_Binary', 'Risk_Score'...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-14 12:35:22,286:INFO:finalize_model() successfully completed......................................
2025-05-14 12:35:22,374:INFO:Initializing save_model()
2025-05-14 12:35:22,374:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'TSH_Normal', 'T4_Normal',
                                             'T3_Normal', 'TSH_T4_Ratio',
                                             'T3_T4_Ratio',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabetes_Binary', 'Risk_Score'...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'TSH_Normal', 'T4_Normal',
                                             'T3_Normal', 'TSH_T4_Ratio',
                                             'T3_T4_Ratio',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Smoke_Bina...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-14 12:35:22,374:INFO:Adding model into prep_pipe
2025-05-14 12:35:22,374:WARNING:Only Model saved as it was a pipeline.
2025-05-14 12:35:22,403:INFO:final_cancer_model.pkl saved in current working directory
2025-05-14 12:35:22,424:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'TSH_Normal', 'T4_Normal',
                                             'T3_Normal', 'TSH_T4_Ratio',
                                             'T3_T4_Ratio',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabetes_Binary', 'Risk_Score'...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-14 12:35:22,424:INFO:save_model() successfully completed......................................
2025-05-14 12:35:22,532:INFO:Initializing predict_model()
2025-05-14 12:35:22,532:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'TSH_Normal', 'T4_Normal',
                                             'T3_Normal', 'TSH_T4_Ratio',
                                             'T3_T4_Ratio',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabetes_Binary', 'Risk_Score'...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x334889620>)
2025-05-14 12:35:22,532:INFO:Checking exceptions
2025-05-14 12:35:22,532:INFO:Preloading libraries
2025-05-14 12:35:22,534:INFO:Set up data.
2025-05-14 12:35:22,586:INFO:Set up index.
2025-05-14 12:35:23,513:INFO:Initializing blend_models()
2025-05-14 12:35:23,513:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-14 12:35:23,513:INFO:Checking exceptions
2025-05-14 12:35:23,528:INFO:Importing libraries
2025-05-14 12:35:23,528:INFO:Copying training dataset
2025-05-14 12:35:23,529:INFO:Getting model names
2025-05-14 12:35:23,531:INFO:SubProcess create_model() called ==================================
2025-05-14 12:35:23,533:INFO:Initializing create_model()
2025-05-14 12:35:23,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333b4a1d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:35:23,533:INFO:Checking exceptions
2025-05-14 12:35:23,533:INFO:Importing libraries
2025-05-14 12:35:23,533:INFO:Copying training dataset
2025-05-14 12:35:23,563:INFO:Defining folds
2025-05-14 12:35:23,563:INFO:Declaring metric variables
2025-05-14 12:35:23,564:INFO:Importing untrained model
2025-05-14 12:35:23,564:INFO:Declaring custom model
2025-05-14 12:35:23,567:INFO:Voting Classifier Imported successfully
2025-05-14 12:35:23,570:INFO:Starting cross validation
2025-05-14 12:35:23,578:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:35:51,551:INFO:Calculating mean and std
2025-05-14 12:35:51,553:INFO:Creating metrics dataframe
2025-05-14 12:35:51,559:INFO:Finalizing model
2025-05-14 12:36:21,033:INFO:Uploading results into container
2025-05-14 12:36:21,036:INFO:Uploading model into container now
2025-05-14 12:36:21,037:INFO:_master_model_container: 18
2025-05-14 12:36:21,037:INFO:_display_container: 4
2025-05-14 12:36:21,049:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-14 12:36:21,049:INFO:create_model() successfully completed......................................
2025-05-14 12:36:21,147:INFO:SubProcess create_model() end ==================================
2025-05-14 12:36:21,151:INFO:_master_model_container: 18
2025-05-14 12:36:21,151:INFO:_display_container: 4
2025-05-14 12:36:21,153:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-14 12:36:21,153:INFO:blend_models() successfully completed......................................
2025-05-14 12:36:21,211:INFO:Initializing evaluate_model()
2025-05-14 12:36:21,212:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 12:36:21,226:INFO:Initializing plot_model()
2025-05-14 12:36:21,226:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 12:36:21,226:INFO:Checking exceptions
2025-05-14 12:36:21,235:INFO:Preloading libraries
2025-05-14 12:36:21,331:INFO:Copying training dataset
2025-05-14 12:36:21,331:INFO:Plot type: pipeline
2025-05-14 12:36:21,392:INFO:Visual Rendered Successfully
2025-05-14 12:36:21,450:INFO:plot_model() successfully completed......................................
2025-05-14 12:36:21,461:INFO:Initializing predict_model()
2025-05-14 12:36:21,461:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x3348b3ec0>)
2025-05-14 12:36:21,461:INFO:Checking exceptions
2025-05-14 12:36:21,461:INFO:Preloading libraries
2025-05-14 12:36:21,462:INFO:Set up data.
2025-05-14 12:36:21,484:INFO:Set up index.
2025-05-14 12:36:22,318:INFO:Initializing plot_model()
2025-05-14 12:36:22,318:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 12:36:22,318:INFO:Checking exceptions
2025-05-14 12:36:22,326:INFO:Preloading libraries
2025-05-14 12:36:22,330:INFO:Copying training dataset
2025-05-14 12:36:22,330:INFO:Plot type: confusion_matrix
2025-05-14 12:36:22,614:INFO:Fitting Model
2025-05-14 12:36:22,615:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-14 12:36:22,616:INFO:Scoring test/hold-out set
2025-05-14 12:36:22,696:INFO:Visual Rendered Successfully
2025-05-14 12:36:22,760:INFO:plot_model() successfully completed......................................
2025-05-14 12:36:22,760:INFO:Initializing plot_model()
2025-05-14 12:36:22,762:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 12:36:22,762:INFO:Checking exceptions
2025-05-14 12:36:22,770:INFO:Preloading libraries
2025-05-14 12:36:22,773:INFO:Copying training dataset
2025-05-14 12:36:22,773:INFO:Plot type: auc
2025-05-14 12:36:23,042:INFO:Fitting Model
2025-05-14 12:36:23,042:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-14 12:36:23,043:INFO:Scoring test/hold-out set
2025-05-14 12:36:23,161:INFO:Visual Rendered Successfully
2025-05-14 12:36:23,218:INFO:plot_model() successfully completed......................................
2025-05-14 12:36:23,218:INFO:Initializing plot_model()
2025-05-14 12:36:23,218:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326642690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 12:36:23,219:INFO:Checking exceptions
2025-05-14 12:36:23,227:INFO:Preloading libraries
2025-05-14 12:36:23,231:INFO:Copying training dataset
2025-05-14 12:36:23,231:INFO:Plot type: feature
2025-05-14 12:36:23,231:WARNING:No coef_ found. Trying feature_importances_
2025-05-14 12:36:23,318:INFO:Visual Rendered Successfully
2025-05-14 12:36:23,373:INFO:plot_model() successfully completed......................................
2025-05-14 12:43:29,753:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 12:43:29,753:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 12:43:29,753:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 12:43:29,753:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 12:43:30,432:INFO:PyCaret ClassificationExperiment
2025-05-14 12:43:30,432:INFO:Logging name: clf-default-name
2025-05-14 12:43:30,432:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 12:43:30,432:INFO:version 3.3.2
2025-05-14 12:43:30,432:INFO:Initializing setup()
2025-05-14 12:43:30,432:INFO:self.USI: 2599
2025-05-14 12:43:30,432:INFO:self._variable_keys: {'idx', 'memory', 'exp_id', '_ml_usecase', 'log_plots_param', 'exp_name_log', 'X', 'n_jobs_param', 'y_test', '_available_plots', 'target_param', 'fix_imbalance', 'gpu_param', 'gpu_n_jobs_param', 'X_train', 'is_multiclass', 'seed', 'html_param', 'y_train', 'y', 'X_test', 'USI', 'fold_generator', 'fold_shuffle_param', 'fold_groups_param', 'logging_param', 'pipeline', 'data'}
2025-05-14 12:43:30,432:INFO:Checking environment
2025-05-14 12:43:30,432:INFO:python_version: 3.11.0
2025-05-14 12:43:30,432:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-14 12:43:30,432:INFO:machine: arm64
2025-05-14 12:43:30,432:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-14 12:43:30,432:INFO:Memory: svmem(total=17179869184, available=4490608640, percent=73.9, used=6936674304, free=57917440, active=4460363776, inactive=4398563328, wired=2476310528)
2025-05-14 12:43:30,432:INFO:Physical Core: 12
2025-05-14 12:43:30,432:INFO:Logical Core: 12
2025-05-14 12:43:30,432:INFO:Checking libraries
2025-05-14 12:43:30,432:INFO:System:
2025-05-14 12:43:30,432:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-14 12:43:30,432:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-14 12:43:30,432:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-14 12:43:30,433:INFO:PyCaret required dependencies:
2025-05-14 12:43:30,467:INFO:                 pip: 22.3
2025-05-14 12:43:30,467:INFO:          setuptools: 65.5.0
2025-05-14 12:43:30,467:INFO:             pycaret: 3.3.2
2025-05-14 12:43:30,467:INFO:             IPython: 9.2.0
2025-05-14 12:43:30,468:INFO:          ipywidgets: 8.1.7
2025-05-14 12:43:30,468:INFO:                tqdm: 4.67.1
2025-05-14 12:43:30,468:INFO:               numpy: 1.26.4
2025-05-14 12:43:30,468:INFO:              pandas: 2.1.4
2025-05-14 12:43:30,468:INFO:              jinja2: 3.1.6
2025-05-14 12:43:30,468:INFO:               scipy: 1.11.4
2025-05-14 12:43:30,468:INFO:              joblib: 1.3.2
2025-05-14 12:43:30,468:INFO:             sklearn: 1.4.2
2025-05-14 12:43:30,468:INFO:                pyod: 2.0.5
2025-05-14 12:43:30,468:INFO:            imblearn: 0.13.0
2025-05-14 12:43:30,468:INFO:   category_encoders: 2.7.0
2025-05-14 12:43:30,468:INFO:            lightgbm: 4.6.0
2025-05-14 12:43:30,468:INFO:               numba: 0.61.2
2025-05-14 12:43:30,468:INFO:            requests: 2.32.3
2025-05-14 12:43:30,468:INFO:          matplotlib: 3.7.5
2025-05-14 12:43:30,468:INFO:          scikitplot: 0.3.7
2025-05-14 12:43:30,468:INFO:         yellowbrick: 1.5
2025-05-14 12:43:30,468:INFO:              plotly: 5.24.1
2025-05-14 12:43:30,468:INFO:    plotly-resampler: Not installed
2025-05-14 12:43:30,468:INFO:             kaleido: 0.2.1
2025-05-14 12:43:30,468:INFO:           schemdraw: 0.15
2025-05-14 12:43:30,468:INFO:         statsmodels: 0.14.4
2025-05-14 12:43:30,468:INFO:              sktime: 0.26.0
2025-05-14 12:43:30,468:INFO:               tbats: 1.1.3
2025-05-14 12:43:30,468:INFO:            pmdarima: 2.0.4
2025-05-14 12:43:30,468:INFO:              psutil: 7.0.0
2025-05-14 12:43:30,468:INFO:          markupsafe: 3.0.2
2025-05-14 12:43:30,468:INFO:             pickle5: Not installed
2025-05-14 12:43:30,468:INFO:         cloudpickle: 3.1.1
2025-05-14 12:43:30,468:INFO:         deprecation: 2.1.0
2025-05-14 12:43:30,468:INFO:              xxhash: 3.5.0
2025-05-14 12:43:30,468:INFO:           wurlitzer: 3.1.1
2025-05-14 12:43:30,468:INFO:PyCaret optional dependencies:
2025-05-14 12:43:30,475:INFO:                shap: 0.47.2
2025-05-14 12:43:30,476:INFO:           interpret: Not installed
2025-05-14 12:43:30,476:INFO:                umap: Not installed
2025-05-14 12:43:30,476:INFO:     ydata_profiling: Not installed
2025-05-14 12:43:30,476:INFO:  explainerdashboard: Not installed
2025-05-14 12:43:30,476:INFO:             autoviz: Not installed
2025-05-14 12:43:30,476:INFO:           fairlearn: Not installed
2025-05-14 12:43:30,476:INFO:          deepchecks: Not installed
2025-05-14 12:43:30,476:INFO:             xgboost: Not installed
2025-05-14 12:43:30,476:INFO:            catboost: 1.2.8
2025-05-14 12:43:30,476:INFO:              kmodes: Not installed
2025-05-14 12:43:30,476:INFO:             mlxtend: Not installed
2025-05-14 12:43:30,476:INFO:       statsforecast: Not installed
2025-05-14 12:43:30,476:INFO:        tune_sklearn: Not installed
2025-05-14 12:43:30,476:INFO:                 ray: Not installed
2025-05-14 12:43:30,476:INFO:            hyperopt: Not installed
2025-05-14 12:43:30,476:INFO:              optuna: 4.3.0
2025-05-14 12:43:30,476:INFO:               skopt: Not installed
2025-05-14 12:43:30,476:INFO:              mlflow: Not installed
2025-05-14 12:43:30,476:INFO:              gradio: Not installed
2025-05-14 12:43:30,476:INFO:             fastapi: Not installed
2025-05-14 12:43:30,476:INFO:             uvicorn: Not installed
2025-05-14 12:43:30,476:INFO:              m2cgen: Not installed
2025-05-14 12:43:30,476:INFO:           evidently: Not installed
2025-05-14 12:43:30,476:INFO:               fugue: Not installed
2025-05-14 12:43:30,476:INFO:           streamlit: Not installed
2025-05-14 12:43:30,476:INFO:             prophet: Not installed
2025-05-14 12:43:30,476:INFO:None
2025-05-14 12:43:30,476:INFO:Set up data.
2025-05-14 12:43:30,528:INFO:Set up folding strategy.
2025-05-14 12:43:30,528:INFO:Set up train/test split.
2025-05-14 12:43:30,557:INFO:Set up index.
2025-05-14 12:43:30,558:INFO:Assigning column types.
2025-05-14 12:43:30,571:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 12:43:30,589:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 12:43:30,591:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 12:43:30,606:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:43:30,607:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:43:30,644:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 12:43:30,644:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 12:43:30,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:43:30,655:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:43:30,656:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 12:43:30,674:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 12:43:30,685:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:43:30,685:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:43:30,703:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 12:43:30,714:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:43:30,714:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:43:30,714:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 12:43:30,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:43:30,743:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:43:30,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:43:30,773:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:43:30,775:INFO:Preparing preprocessing pipeline...
2025-05-14 12:43:30,778:INFO:Set up simple imputation.
2025-05-14 12:43:30,788:INFO:Set up encoding of ordinal features.
2025-05-14 12:43:30,815:INFO:Set up encoding of categorical features.
2025-05-14 12:43:30,815:INFO:Set up imbalanced handling.
2025-05-14 12:43:30,815:INFO:Set up column transformation.
2025-05-14 12:43:32,729:INFO:Finished creating preprocessing pipeline.
2025-05-14 12:43:32,748:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk',
                                             'TSH_Normal', 'T4_Normal',
                                             'T3_Normal', 'TSH_T4_Ratio',
                                             'T3_T4_Ratio',
                                             'Family_Background_Binary',
                                             'Radiation_Histo...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-14 12:43:32,748:INFO:Creating final display dataframe.
2025-05-14 12:43:33,339:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 30)
4        Transformed data shape      (106821, 43)
5   Transformed train set shape       (85902, 43)
6    Transformed test set shape       (20919, 43)
7              Numeric features                20
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              2599
2025-05-14 12:43:33,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:43:33,372:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:43:33,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 12:43:33,402:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 12:43:33,403:INFO:setup() successfully completed in 2.97s...............
2025-05-14 12:43:33,403:INFO:Initializing compare_models()
2025-05-14 12:43:33,403:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 12:43:33,403:INFO:Checking exceptions
2025-05-14 12:43:33,415:INFO:Preparing display monitor
2025-05-14 12:43:33,450:INFO:Initializing Logistic Regression
2025-05-14 12:43:33,450:INFO:Total runtime is 2.7338663736979167e-06 minutes
2025-05-14 12:43:33,452:INFO:SubProcess create_model() called ==================================
2025-05-14 12:43:33,452:INFO:Initializing create_model()
2025-05-14 12:43:33,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:43:33,452:INFO:Checking exceptions
2025-05-14 12:43:33,453:INFO:Importing libraries
2025-05-14 12:43:33,453:INFO:Copying training dataset
2025-05-14 12:43:33,474:INFO:Defining folds
2025-05-14 12:43:33,475:INFO:Declaring metric variables
2025-05-14 12:43:33,476:INFO:Importing untrained model
2025-05-14 12:43:33,478:INFO:Logistic Regression Imported successfully
2025-05-14 12:43:33,480:INFO:Starting cross validation
2025-05-14 12:43:33,482:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:43:40,597:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 12:43:40,627:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 12:43:40,628:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 12:43:40,629:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 12:43:40,671:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 12:43:40,739:INFO:Calculating mean and std
2025-05-14 12:43:40,743:INFO:Creating metrics dataframe
2025-05-14 12:43:40,746:INFO:Uploading results into container
2025-05-14 12:43:40,746:INFO:Uploading model into container now
2025-05-14 12:43:40,747:INFO:_master_model_container: 1
2025-05-14 12:43:40,747:INFO:_display_container: 2
2025-05-14 12:43:40,747:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 12:43:40,747:INFO:create_model() successfully completed......................................
2025-05-14 12:43:41,058:INFO:SubProcess create_model() end ==================================
2025-05-14 12:43:41,058:INFO:Creating metrics dataframe
2025-05-14 12:43:41,061:INFO:Initializing K Neighbors Classifier
2025-05-14 12:43:41,061:INFO:Total runtime is 0.12684386571248374 minutes
2025-05-14 12:43:41,062:INFO:SubProcess create_model() called ==================================
2025-05-14 12:43:41,062:INFO:Initializing create_model()
2025-05-14 12:43:41,062:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:43:41,062:INFO:Checking exceptions
2025-05-14 12:43:41,062:INFO:Importing libraries
2025-05-14 12:43:41,062:INFO:Copying training dataset
2025-05-14 12:43:41,084:INFO:Defining folds
2025-05-14 12:43:41,084:INFO:Declaring metric variables
2025-05-14 12:43:41,085:INFO:Importing untrained model
2025-05-14 12:43:41,087:INFO:K Neighbors Classifier Imported successfully
2025-05-14 12:43:41,089:INFO:Starting cross validation
2025-05-14 12:43:41,090:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:43:48,365:INFO:Calculating mean and std
2025-05-14 12:43:48,367:INFO:Creating metrics dataframe
2025-05-14 12:43:48,370:INFO:Uploading results into container
2025-05-14 12:43:48,371:INFO:Uploading model into container now
2025-05-14 12:43:48,371:INFO:_master_model_container: 2
2025-05-14 12:43:48,371:INFO:_display_container: 2
2025-05-14 12:43:48,372:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 12:43:48,372:INFO:create_model() successfully completed......................................
2025-05-14 12:43:48,507:INFO:SubProcess create_model() end ==================================
2025-05-14 12:43:48,507:INFO:Creating metrics dataframe
2025-05-14 12:43:48,511:INFO:Initializing Naive Bayes
2025-05-14 12:43:48,511:INFO:Total runtime is 0.25100808540980024 minutes
2025-05-14 12:43:48,512:INFO:SubProcess create_model() called ==================================
2025-05-14 12:43:48,512:INFO:Initializing create_model()
2025-05-14 12:43:48,512:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:43:48,512:INFO:Checking exceptions
2025-05-14 12:43:48,512:INFO:Importing libraries
2025-05-14 12:43:48,512:INFO:Copying training dataset
2025-05-14 12:43:48,543:INFO:Defining folds
2025-05-14 12:43:48,543:INFO:Declaring metric variables
2025-05-14 12:43:48,544:INFO:Importing untrained model
2025-05-14 12:43:48,545:INFO:Naive Bayes Imported successfully
2025-05-14 12:43:48,547:INFO:Starting cross validation
2025-05-14 12:43:48,549:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:43:50,097:INFO:Calculating mean and std
2025-05-14 12:43:50,098:INFO:Creating metrics dataframe
2025-05-14 12:43:50,098:INFO:Uploading results into container
2025-05-14 12:43:50,099:INFO:Uploading model into container now
2025-05-14 12:43:50,099:INFO:_master_model_container: 3
2025-05-14 12:43:50,099:INFO:_display_container: 2
2025-05-14 12:43:50,099:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 12:43:50,099:INFO:create_model() successfully completed......................................
2025-05-14 12:43:50,194:INFO:SubProcess create_model() end ==================================
2025-05-14 12:43:50,194:INFO:Creating metrics dataframe
2025-05-14 12:43:50,197:INFO:Initializing Decision Tree Classifier
2025-05-14 12:43:50,197:INFO:Total runtime is 0.27911320130030315 minutes
2025-05-14 12:43:50,198:INFO:SubProcess create_model() called ==================================
2025-05-14 12:43:50,198:INFO:Initializing create_model()
2025-05-14 12:43:50,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:43:50,198:INFO:Checking exceptions
2025-05-14 12:43:50,198:INFO:Importing libraries
2025-05-14 12:43:50,198:INFO:Copying training dataset
2025-05-14 12:43:50,223:INFO:Defining folds
2025-05-14 12:43:50,223:INFO:Declaring metric variables
2025-05-14 12:43:50,224:INFO:Importing untrained model
2025-05-14 12:43:50,225:INFO:Decision Tree Classifier Imported successfully
2025-05-14 12:43:50,227:INFO:Starting cross validation
2025-05-14 12:43:50,228:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:43:53,779:INFO:Calculating mean and std
2025-05-14 12:43:53,781:INFO:Creating metrics dataframe
2025-05-14 12:43:53,783:INFO:Uploading results into container
2025-05-14 12:43:53,783:INFO:Uploading model into container now
2025-05-14 12:43:53,783:INFO:_master_model_container: 4
2025-05-14 12:43:53,783:INFO:_display_container: 2
2025-05-14 12:43:53,784:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-14 12:43:53,784:INFO:create_model() successfully completed......................................
2025-05-14 12:43:53,919:INFO:SubProcess create_model() end ==================================
2025-05-14 12:43:53,919:INFO:Creating metrics dataframe
2025-05-14 12:43:53,922:INFO:Initializing SVM - Linear Kernel
2025-05-14 12:43:53,922:INFO:Total runtime is 0.34119861523310346 minutes
2025-05-14 12:43:53,923:INFO:SubProcess create_model() called ==================================
2025-05-14 12:43:53,923:INFO:Initializing create_model()
2025-05-14 12:43:53,923:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:43:53,924:INFO:Checking exceptions
2025-05-14 12:43:53,924:INFO:Importing libraries
2025-05-14 12:43:53,924:INFO:Copying training dataset
2025-05-14 12:43:53,943:INFO:Defining folds
2025-05-14 12:43:53,943:INFO:Declaring metric variables
2025-05-14 12:43:53,944:INFO:Importing untrained model
2025-05-14 12:43:53,945:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 12:43:53,947:INFO:Starting cross validation
2025-05-14 12:43:53,948:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:44:00,429:INFO:Calculating mean and std
2025-05-14 12:44:00,431:INFO:Creating metrics dataframe
2025-05-14 12:44:00,432:INFO:Uploading results into container
2025-05-14 12:44:00,433:INFO:Uploading model into container now
2025-05-14 12:44:00,433:INFO:_master_model_container: 5
2025-05-14 12:44:00,433:INFO:_display_container: 2
2025-05-14 12:44:00,433:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 12:44:00,433:INFO:create_model() successfully completed......................................
2025-05-14 12:44:00,572:INFO:SubProcess create_model() end ==================================
2025-05-14 12:44:00,572:INFO:Creating metrics dataframe
2025-05-14 12:44:00,575:INFO:Initializing Ridge Classifier
2025-05-14 12:44:00,576:INFO:Total runtime is 0.4520887176195781 minutes
2025-05-14 12:44:00,577:INFO:SubProcess create_model() called ==================================
2025-05-14 12:44:00,577:INFO:Initializing create_model()
2025-05-14 12:44:00,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:44:00,577:INFO:Checking exceptions
2025-05-14 12:44:00,577:INFO:Importing libraries
2025-05-14 12:44:00,577:INFO:Copying training dataset
2025-05-14 12:44:00,601:INFO:Defining folds
2025-05-14 12:44:00,601:INFO:Declaring metric variables
2025-05-14 12:44:00,603:INFO:Importing untrained model
2025-05-14 12:44:00,604:INFO:Ridge Classifier Imported successfully
2025-05-14 12:44:00,606:INFO:Starting cross validation
2025-05-14 12:44:00,607:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:44:02,267:INFO:Calculating mean and std
2025-05-14 12:44:02,267:INFO:Creating metrics dataframe
2025-05-14 12:44:02,268:INFO:Uploading results into container
2025-05-14 12:44:02,269:INFO:Uploading model into container now
2025-05-14 12:44:02,269:INFO:_master_model_container: 6
2025-05-14 12:44:02,269:INFO:_display_container: 2
2025-05-14 12:44:02,269:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-14 12:44:02,269:INFO:create_model() successfully completed......................................
2025-05-14 12:44:02,368:INFO:SubProcess create_model() end ==================================
2025-05-14 12:44:02,369:INFO:Creating metrics dataframe
2025-05-14 12:44:02,372:INFO:Initializing Random Forest Classifier
2025-05-14 12:44:02,372:INFO:Total runtime is 0.4820282657941183 minutes
2025-05-14 12:44:02,373:INFO:SubProcess create_model() called ==================================
2025-05-14 12:44:02,373:INFO:Initializing create_model()
2025-05-14 12:44:02,373:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:44:02,374:INFO:Checking exceptions
2025-05-14 12:44:02,374:INFO:Importing libraries
2025-05-14 12:44:02,374:INFO:Copying training dataset
2025-05-14 12:44:02,395:INFO:Defining folds
2025-05-14 12:44:02,395:INFO:Declaring metric variables
2025-05-14 12:44:02,396:INFO:Importing untrained model
2025-05-14 12:44:02,398:INFO:Random Forest Classifier Imported successfully
2025-05-14 12:44:02,400:INFO:Starting cross validation
2025-05-14 12:44:02,401:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:44:10,406:INFO:Calculating mean and std
2025-05-14 12:44:10,408:INFO:Creating metrics dataframe
2025-05-14 12:44:10,411:INFO:Uploading results into container
2025-05-14 12:44:10,411:INFO:Uploading model into container now
2025-05-14 12:44:10,411:INFO:_master_model_container: 7
2025-05-14 12:44:10,411:INFO:_display_container: 2
2025-05-14 12:44:10,412:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 12:44:10,412:INFO:create_model() successfully completed......................................
2025-05-14 12:44:10,570:INFO:SubProcess create_model() end ==================================
2025-05-14 12:44:10,570:INFO:Creating metrics dataframe
2025-05-14 12:44:10,574:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 12:44:10,574:INFO:Total runtime is 0.6187281807263693 minutes
2025-05-14 12:44:10,575:INFO:SubProcess create_model() called ==================================
2025-05-14 12:44:10,575:INFO:Initializing create_model()
2025-05-14 12:44:10,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:44:10,575:INFO:Checking exceptions
2025-05-14 12:44:10,575:INFO:Importing libraries
2025-05-14 12:44:10,575:INFO:Copying training dataset
2025-05-14 12:44:10,596:INFO:Defining folds
2025-05-14 12:44:10,596:INFO:Declaring metric variables
2025-05-14 12:44:10,597:INFO:Importing untrained model
2025-05-14 12:44:10,598:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 12:44:10,601:INFO:Starting cross validation
2025-05-14 12:44:10,602:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:44:12,089:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 12:44:12,098:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 12:44:12,181:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 12:44:12,206:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:44:12,287:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:44:13,586:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 12:44:13,604:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 12:44:13,683:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:44:13,701:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:44:13,712:INFO:Calculating mean and std
2025-05-14 12:44:13,713:INFO:Creating metrics dataframe
2025-05-14 12:44:13,718:INFO:Uploading results into container
2025-05-14 12:44:13,718:INFO:Uploading model into container now
2025-05-14 12:44:13,719:INFO:_master_model_container: 8
2025-05-14 12:44:13,719:INFO:_display_container: 2
2025-05-14 12:44:13,719:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 12:44:13,719:INFO:create_model() successfully completed......................................
2025-05-14 12:44:13,848:INFO:SubProcess create_model() end ==================================
2025-05-14 12:44:13,848:INFO:Creating metrics dataframe
2025-05-14 12:44:13,852:INFO:Initializing Ada Boost Classifier
2025-05-14 12:44:13,852:INFO:Total runtime is 0.6733590165774028 minutes
2025-05-14 12:44:13,853:INFO:SubProcess create_model() called ==================================
2025-05-14 12:44:13,853:INFO:Initializing create_model()
2025-05-14 12:44:13,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:44:13,853:INFO:Checking exceptions
2025-05-14 12:44:13,853:INFO:Importing libraries
2025-05-14 12:44:13,854:INFO:Copying training dataset
2025-05-14 12:44:13,877:INFO:Defining folds
2025-05-14 12:44:13,877:INFO:Declaring metric variables
2025-05-14 12:44:13,879:INFO:Importing untrained model
2025-05-14 12:44:13,880:INFO:Ada Boost Classifier Imported successfully
2025-05-14 12:44:13,882:INFO:Starting cross validation
2025-05-14 12:44:13,884:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:44:15,439:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 12:44:15,524:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 12:44:15,541:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 12:44:15,563:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 12:44:15,590:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 12:44:19,968:INFO:Calculating mean and std
2025-05-14 12:44:19,970:INFO:Creating metrics dataframe
2025-05-14 12:44:19,972:INFO:Uploading results into container
2025-05-14 12:44:19,972:INFO:Uploading model into container now
2025-05-14 12:44:19,973:INFO:_master_model_container: 9
2025-05-14 12:44:19,973:INFO:_display_container: 2
2025-05-14 12:44:19,973:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-14 12:44:19,973:INFO:create_model() successfully completed......................................
2025-05-14 12:44:20,130:INFO:SubProcess create_model() end ==================================
2025-05-14 12:44:20,130:INFO:Creating metrics dataframe
2025-05-14 12:44:20,134:INFO:Initializing Gradient Boosting Classifier
2025-05-14 12:44:20,134:INFO:Total runtime is 0.7780683835347494 minutes
2025-05-14 12:44:20,136:INFO:SubProcess create_model() called ==================================
2025-05-14 12:44:20,136:INFO:Initializing create_model()
2025-05-14 12:44:20,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:44:20,136:INFO:Checking exceptions
2025-05-14 12:44:20,136:INFO:Importing libraries
2025-05-14 12:44:20,136:INFO:Copying training dataset
2025-05-14 12:44:20,160:INFO:Defining folds
2025-05-14 12:44:20,160:INFO:Declaring metric variables
2025-05-14 12:44:20,161:INFO:Importing untrained model
2025-05-14 12:44:20,163:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 12:44:20,165:INFO:Starting cross validation
2025-05-14 12:44:20,167:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:44:43,563:INFO:Calculating mean and std
2025-05-14 12:44:43,566:INFO:Creating metrics dataframe
2025-05-14 12:44:43,572:INFO:Uploading results into container
2025-05-14 12:44:43,573:INFO:Uploading model into container now
2025-05-14 12:44:43,573:INFO:_master_model_container: 10
2025-05-14 12:44:43,573:INFO:_display_container: 2
2025-05-14 12:44:43,576:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 12:44:43,576:INFO:create_model() successfully completed......................................
2025-05-14 12:44:43,775:INFO:SubProcess create_model() end ==================================
2025-05-14 12:44:43,775:INFO:Creating metrics dataframe
2025-05-14 12:44:43,779:INFO:Initializing Linear Discriminant Analysis
2025-05-14 12:44:43,779:INFO:Total runtime is 1.1721472501754762 minutes
2025-05-14 12:44:43,780:INFO:SubProcess create_model() called ==================================
2025-05-14 12:44:43,780:INFO:Initializing create_model()
2025-05-14 12:44:43,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:44:43,781:INFO:Checking exceptions
2025-05-14 12:44:43,781:INFO:Importing libraries
2025-05-14 12:44:43,781:INFO:Copying training dataset
2025-05-14 12:44:43,812:INFO:Defining folds
2025-05-14 12:44:43,812:INFO:Declaring metric variables
2025-05-14 12:44:43,814:INFO:Importing untrained model
2025-05-14 12:44:43,819:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 12:44:43,822:INFO:Starting cross validation
2025-05-14 12:44:43,824:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:44:45,637:INFO:Calculating mean and std
2025-05-14 12:44:45,638:INFO:Creating metrics dataframe
2025-05-14 12:44:45,639:INFO:Uploading results into container
2025-05-14 12:44:45,639:INFO:Uploading model into container now
2025-05-14 12:44:45,640:INFO:_master_model_container: 11
2025-05-14 12:44:45,640:INFO:_display_container: 2
2025-05-14 12:44:45,640:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 12:44:45,640:INFO:create_model() successfully completed......................................
2025-05-14 12:44:45,738:INFO:SubProcess create_model() end ==================================
2025-05-14 12:44:45,738:INFO:Creating metrics dataframe
2025-05-14 12:44:45,742:INFO:Initializing Extra Trees Classifier
2025-05-14 12:44:45,742:INFO:Total runtime is 1.2048614184061688 minutes
2025-05-14 12:44:45,743:INFO:SubProcess create_model() called ==================================
2025-05-14 12:44:45,743:INFO:Initializing create_model()
2025-05-14 12:44:45,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:44:45,743:INFO:Checking exceptions
2025-05-14 12:44:45,743:INFO:Importing libraries
2025-05-14 12:44:45,743:INFO:Copying training dataset
2025-05-14 12:44:45,765:INFO:Defining folds
2025-05-14 12:44:45,765:INFO:Declaring metric variables
2025-05-14 12:44:45,766:INFO:Importing untrained model
2025-05-14 12:44:45,768:INFO:Extra Trees Classifier Imported successfully
2025-05-14 12:44:45,770:INFO:Starting cross validation
2025-05-14 12:44:45,771:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:44:51,936:INFO:Calculating mean and std
2025-05-14 12:44:51,939:INFO:Creating metrics dataframe
2025-05-14 12:44:51,945:INFO:Uploading results into container
2025-05-14 12:44:51,947:INFO:Uploading model into container now
2025-05-14 12:44:51,950:INFO:_master_model_container: 12
2025-05-14 12:44:51,950:INFO:_display_container: 2
2025-05-14 12:44:51,951:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-14 12:44:51,952:INFO:create_model() successfully completed......................................
2025-05-14 12:44:52,172:INFO:SubProcess create_model() end ==================================
2025-05-14 12:44:52,172:INFO:Creating metrics dataframe
2025-05-14 12:44:52,177:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 12:44:52,177:INFO:Total runtime is 1.3121189832687379 minutes
2025-05-14 12:44:52,179:INFO:SubProcess create_model() called ==================================
2025-05-14 12:44:52,179:INFO:Initializing create_model()
2025-05-14 12:44:52,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:44:52,179:INFO:Checking exceptions
2025-05-14 12:44:52,179:INFO:Importing libraries
2025-05-14 12:44:52,179:INFO:Copying training dataset
2025-05-14 12:44:52,208:INFO:Defining folds
2025-05-14 12:44:52,208:INFO:Declaring metric variables
2025-05-14 12:44:52,210:INFO:Importing untrained model
2025-05-14 12:44:52,211:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 12:44:52,214:INFO:Starting cross validation
2025-05-14 12:44:52,216:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:44:56,944:INFO:Calculating mean and std
2025-05-14 12:44:56,945:INFO:Creating metrics dataframe
2025-05-14 12:44:56,947:INFO:Uploading results into container
2025-05-14 12:44:56,948:INFO:Uploading model into container now
2025-05-14 12:44:56,948:INFO:_master_model_container: 13
2025-05-14 12:44:56,948:INFO:_display_container: 2
2025-05-14 12:44:56,948:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 12:44:56,948:INFO:create_model() successfully completed......................................
2025-05-14 12:44:57,064:INFO:SubProcess create_model() end ==================================
2025-05-14 12:44:57,064:INFO:Creating metrics dataframe
2025-05-14 12:44:57,068:INFO:Initializing CatBoost Classifier
2025-05-14 12:44:57,068:INFO:Total runtime is 1.3936342358589173 minutes
2025-05-14 12:44:57,070:INFO:SubProcess create_model() called ==================================
2025-05-14 12:44:57,070:INFO:Initializing create_model()
2025-05-14 12:44:57,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:44:57,070:INFO:Checking exceptions
2025-05-14 12:44:57,070:INFO:Importing libraries
2025-05-14 12:44:57,070:INFO:Copying training dataset
2025-05-14 12:44:57,092:INFO:Defining folds
2025-05-14 12:44:57,092:INFO:Declaring metric variables
2025-05-14 12:44:57,094:INFO:Importing untrained model
2025-05-14 12:44:57,095:INFO:CatBoost Classifier Imported successfully
2025-05-14 12:44:57,098:INFO:Starting cross validation
2025-05-14 12:44:57,099:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:45:17,959:INFO:Calculating mean and std
2025-05-14 12:45:17,962:INFO:Creating metrics dataframe
2025-05-14 12:45:17,966:INFO:Uploading results into container
2025-05-14 12:45:17,966:INFO:Uploading model into container now
2025-05-14 12:45:17,966:INFO:_master_model_container: 14
2025-05-14 12:45:17,966:INFO:_display_container: 2
2025-05-14 12:45:17,967:INFO:<catboost.core.CatBoostClassifier object at 0x15ba71550>
2025-05-14 12:45:17,967:INFO:create_model() successfully completed......................................
2025-05-14 12:45:18,185:INFO:SubProcess create_model() end ==================================
2025-05-14 12:45:18,185:INFO:Creating metrics dataframe
2025-05-14 12:45:18,191:INFO:Initializing Dummy Classifier
2025-05-14 12:45:18,191:INFO:Total runtime is 1.7456778168678284 minutes
2025-05-14 12:45:18,192:INFO:SubProcess create_model() called ==================================
2025-05-14 12:45:18,192:INFO:Initializing create_model()
2025-05-14 12:45:18,192:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15e464590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:45:18,193:INFO:Checking exceptions
2025-05-14 12:45:18,193:INFO:Importing libraries
2025-05-14 12:45:18,193:INFO:Copying training dataset
2025-05-14 12:45:18,221:INFO:Defining folds
2025-05-14 12:45:18,221:INFO:Declaring metric variables
2025-05-14 12:45:18,223:INFO:Importing untrained model
2025-05-14 12:45:18,225:INFO:Dummy Classifier Imported successfully
2025-05-14 12:45:18,228:INFO:Starting cross validation
2025-05-14 12:45:18,234:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:45:19,763:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:45:19,781:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:45:19,814:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:45:19,875:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:45:19,918:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 12:45:19,929:INFO:Calculating mean and std
2025-05-14 12:45:19,930:INFO:Creating metrics dataframe
2025-05-14 12:45:19,931:INFO:Uploading results into container
2025-05-14 12:45:19,932:INFO:Uploading model into container now
2025-05-14 12:45:19,932:INFO:_master_model_container: 15
2025-05-14 12:45:19,932:INFO:_display_container: 2
2025-05-14 12:45:19,932:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-14 12:45:19,932:INFO:create_model() successfully completed......................................
2025-05-14 12:45:20,043:INFO:SubProcess create_model() end ==================================
2025-05-14 12:45:20,043:INFO:Creating metrics dataframe
2025-05-14 12:45:20,051:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-14 12:45:20,055:INFO:Initializing create_model()
2025-05-14 12:45:20,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:45:20,055:INFO:Checking exceptions
2025-05-14 12:45:20,056:INFO:Importing libraries
2025-05-14 12:45:20,056:INFO:Copying training dataset
2025-05-14 12:45:20,084:INFO:Defining folds
2025-05-14 12:45:20,084:INFO:Declaring metric variables
2025-05-14 12:45:20,084:INFO:Importing untrained model
2025-05-14 12:45:20,084:INFO:Declaring custom model
2025-05-14 12:45:20,085:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 12:45:20,085:INFO:Cross validation set to False
2025-05-14 12:45:20,086:INFO:Fitting Model
2025-05-14 12:45:47,861:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 12:45:47,861:INFO:create_model() successfully completed......................................
2025-05-14 12:45:48,037:INFO:Initializing create_model()
2025-05-14 12:45:48,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:45:48,037:INFO:Checking exceptions
2025-05-14 12:45:48,038:INFO:Importing libraries
2025-05-14 12:45:48,038:INFO:Copying training dataset
2025-05-14 12:45:48,059:INFO:Defining folds
2025-05-14 12:45:48,059:INFO:Declaring metric variables
2025-05-14 12:45:48,059:INFO:Importing untrained model
2025-05-14 12:45:48,059:INFO:Declaring custom model
2025-05-14 12:45:48,060:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 12:45:48,061:INFO:Cross validation set to False
2025-05-14 12:45:48,061:INFO:Fitting Model
2025-05-14 12:45:49,702:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 12:45:49,715:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006009 seconds.
2025-05-14 12:45:49,715:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 12:45:49,715:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 12:45:49,716:INFO:[LightGBM] [Info] Total Bins 10710
2025-05-14 12:45:49,716:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 42
2025-05-14 12:45:49,716:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 12:45:50,507:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 12:45:50,507:INFO:create_model() successfully completed......................................
2025-05-14 12:45:50,605:INFO:Initializing create_model()
2025-05-14 12:45:50,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=<catboost.core.CatBoostClassifier object at 0x15ba71550>, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:45:50,605:INFO:Checking exceptions
2025-05-14 12:45:50,606:INFO:Importing libraries
2025-05-14 12:45:50,606:INFO:Copying training dataset
2025-05-14 12:45:50,627:INFO:Defining folds
2025-05-14 12:45:50,627:INFO:Declaring metric variables
2025-05-14 12:45:50,627:INFO:Importing untrained model
2025-05-14 12:45:50,627:INFO:Declaring custom model
2025-05-14 12:45:50,628:INFO:CatBoost Classifier Imported successfully
2025-05-14 12:45:50,629:INFO:Cross validation set to False
2025-05-14 12:45:50,629:INFO:Fitting Model
2025-05-14 12:45:58,978:INFO:<catboost.core.CatBoostClassifier object at 0x15cf0a710>
2025-05-14 12:45:58,979:INFO:create_model() successfully completed......................................
2025-05-14 12:45:59,083:INFO:_master_model_container: 15
2025-05-14 12:45:59,083:INFO:_display_container: 2
2025-05-14 12:45:59,084:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x15cf0a710>]
2025-05-14 12:45:59,084:INFO:compare_models() successfully completed......................................
2025-05-14 12:45:59,084:INFO:Initializing evaluate_model()
2025-05-14 12:45:59,085:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 12:45:59,101:INFO:Initializing plot_model()
2025-05-14 12:45:59,101:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 12:45:59,101:INFO:Checking exceptions
2025-05-14 12:45:59,112:INFO:Preloading libraries
2025-05-14 12:45:59,115:INFO:Copying training dataset
2025-05-14 12:45:59,115:INFO:Plot type: pipeline
2025-05-14 12:45:59,198:INFO:Visual Rendered Successfully
2025-05-14 12:45:59,294:INFO:plot_model() successfully completed......................................
2025-05-14 12:45:59,296:INFO:Initializing tune_model()
2025-05-14 12:45:59,296:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 12:45:59,296:INFO:Checking exceptions
2025-05-14 12:45:59,311:INFO:Copying training dataset
2025-05-14 12:45:59,326:INFO:Checking base model
2025-05-14 12:45:59,327:INFO:Base model : Gradient Boosting Classifier
2025-05-14 12:45:59,328:INFO:Declaring metric variables
2025-05-14 12:45:59,329:INFO:Defining Hyperparameters
2025-05-14 12:45:59,429:INFO:Tuning with n_jobs=-1
2025-05-14 12:45:59,430:INFO:Initializing RandomizedSearchCV
2025-05-14 12:46:49,182:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-14 12:46:49,184:INFO:Hyperparameter search completed
2025-05-14 12:46:49,185:INFO:SubProcess create_model() called ==================================
2025-05-14 12:46:49,185:INFO:Initializing create_model()
2025-05-14 12:46:49,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33b4dda50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-14 12:46:49,186:INFO:Checking exceptions
2025-05-14 12:46:49,186:INFO:Importing libraries
2025-05-14 12:46:49,186:INFO:Copying training dataset
2025-05-14 12:46:49,214:INFO:Defining folds
2025-05-14 12:46:49,214:INFO:Declaring metric variables
2025-05-14 12:46:49,218:INFO:Importing untrained model
2025-05-14 12:46:49,218:INFO:Declaring custom model
2025-05-14 12:46:49,220:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 12:46:49,222:INFO:Starting cross validation
2025-05-14 12:46:49,226:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:47:01,402:INFO:Calculating mean and std
2025-05-14 12:47:01,403:INFO:Creating metrics dataframe
2025-05-14 12:47:01,405:INFO:Finalizing model
2025-05-14 12:47:15,364:INFO:Uploading results into container
2025-05-14 12:47:15,365:INFO:Uploading model into container now
2025-05-14 12:47:15,365:INFO:_master_model_container: 16
2025-05-14 12:47:15,365:INFO:_display_container: 3
2025-05-14 12:47:15,365:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 12:47:15,365:INFO:create_model() successfully completed......................................
2025-05-14 12:47:15,574:INFO:SubProcess create_model() end ==================================
2025-05-14 12:47:15,575:INFO:choose_better activated
2025-05-14 12:47:15,577:INFO:SubProcess create_model() called ==================================
2025-05-14 12:47:15,577:INFO:Initializing create_model()
2025-05-14 12:47:15,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:47:15,577:INFO:Checking exceptions
2025-05-14 12:47:15,578:INFO:Importing libraries
2025-05-14 12:47:15,578:INFO:Copying training dataset
2025-05-14 12:47:15,602:INFO:Defining folds
2025-05-14 12:47:15,602:INFO:Declaring metric variables
2025-05-14 12:47:15,602:INFO:Importing untrained model
2025-05-14 12:47:15,602:INFO:Declaring custom model
2025-05-14 12:47:15,602:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 12:47:15,602:INFO:Starting cross validation
2025-05-14 12:47:15,603:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:47:38,863:INFO:Calculating mean and std
2025-05-14 12:47:38,865:INFO:Creating metrics dataframe
2025-05-14 12:47:38,868:INFO:Finalizing model
2025-05-14 12:48:06,967:INFO:Uploading results into container
2025-05-14 12:48:06,969:INFO:Uploading model into container now
2025-05-14 12:48:06,969:INFO:_master_model_container: 17
2025-05-14 12:48:06,969:INFO:_display_container: 4
2025-05-14 12:48:06,970:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 12:48:06,970:INFO:create_model() successfully completed......................................
2025-05-14 12:48:07,152:INFO:SubProcess create_model() end ==================================
2025-05-14 12:48:07,152:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4705
2025-05-14 12:48:07,152:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4907
2025-05-14 12:48:07,152:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-14 12:48:07,152:INFO:choose_better completed
2025-05-14 12:48:07,157:INFO:_master_model_container: 17
2025-05-14 12:48:07,157:INFO:_display_container: 3
2025-05-14 12:48:07,157:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 12:48:07,157:INFO:tune_model() successfully completed......................................
2025-05-14 12:48:07,265:INFO:Initializing evaluate_model()
2025-05-14 12:48:07,265:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 12:48:07,283:INFO:Initializing plot_model()
2025-05-14 12:48:07,283:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 12:48:07,283:INFO:Checking exceptions
2025-05-14 12:48:07,301:INFO:Preloading libraries
2025-05-14 12:48:07,312:INFO:Copying training dataset
2025-05-14 12:48:07,312:INFO:Plot type: pipeline
2025-05-14 12:48:07,381:INFO:Visual Rendered Successfully
2025-05-14 12:48:07,493:INFO:plot_model() successfully completed......................................
2025-05-14 12:48:07,495:INFO:Initializing interpret_model()
2025-05-14 12:48:07,495:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 12:48:07,495:INFO:Checking exceptions
2025-05-14 12:48:07,496:INFO:Soft dependency imported: shap: 0.47.2
2025-05-14 12:48:07,771:INFO:Initializing finalize_model()
2025-05-14 12:48:07,771:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-14 12:48:07,771:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 12:48:07,780:INFO:Initializing create_model()
2025-05-14 12:48:07,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:48:07,780:INFO:Checking exceptions
2025-05-14 12:48:07,781:INFO:Importing libraries
2025-05-14 12:48:07,781:INFO:Copying training dataset
2025-05-14 12:48:07,782:INFO:Defining folds
2025-05-14 12:48:07,782:INFO:Declaring metric variables
2025-05-14 12:48:07,782:INFO:Importing untrained model
2025-05-14 12:48:07,782:INFO:Declaring custom model
2025-05-14 12:48:07,782:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 12:48:07,783:INFO:Cross validation set to False
2025-05-14 12:48:07,783:INFO:Fitting Model
2025-05-14 12:48:28,106:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk',
                                             'TSH_Normal', 'T4_Normal',
                                             'T3_Normal', 'TSH_T4_Ratio',
                                             'T3_T4_Ratio',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabete...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-14 12:48:28,106:INFO:create_model() successfully completed......................................
2025-05-14 12:48:28,227:INFO:_master_model_container: 17
2025-05-14 12:48:28,227:INFO:_display_container: 3
2025-05-14 12:48:28,247:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk',
                                             'TSH_Normal', 'T4_Normal',
                                             'T3_Normal', 'TSH_T4_Ratio',
                                             'T3_T4_Ratio',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabete...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-14 12:48:28,247:INFO:finalize_model() successfully completed......................................
2025-05-14 12:48:28,392:INFO:Initializing save_model()
2025-05-14 12:48:28,392:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk',
                                             'TSH_Normal', 'T4_Normal',
                                             'T3_Normal', 'TSH_T4_Ratio',
                                             'T3_T4_Ratio',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabete...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk',
                                             'TSH_Normal', 'T4_Normal',
                                             'T3_Normal', 'TSH_T4_Ratio',
                                             'T3_T4_Ratio',
                                             'Family_Background_Binary',
                                             'Radiation_Histo...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-14 12:48:28,392:INFO:Adding model into prep_pipe
2025-05-14 12:48:28,392:WARNING:Only Model saved as it was a pipeline.
2025-05-14 12:48:28,414:INFO:final_cancer_model.pkl saved in current working directory
2025-05-14 12:48:28,433:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk',
                                             'TSH_Normal', 'T4_Normal',
                                             'T3_Normal', 'TSH_T4_Ratio',
                                             'T3_T4_Ratio',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabete...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-14 12:48:28,433:INFO:save_model() successfully completed......................................
2025-05-14 12:48:28,570:INFO:Initializing predict_model()
2025-05-14 12:48:28,570:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk',
                                             'TSH_Normal', 'T4_Normal',
                                             'T3_Normal', 'TSH_T4_Ratio',
                                             'T3_T4_Ratio',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabete...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x3533d6020>)
2025-05-14 12:48:28,570:INFO:Checking exceptions
2025-05-14 12:48:28,570:INFO:Preloading libraries
2025-05-14 12:48:28,571:INFO:Set up data.
2025-05-14 12:48:28,592:INFO:Set up index.
2025-05-14 12:48:29,494:INFO:Initializing blend_models()
2025-05-14 12:48:29,494:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x15cf0a710>], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-14 12:48:29,495:INFO:Checking exceptions
2025-05-14 12:48:29,507:INFO:Importing libraries
2025-05-14 12:48:29,507:INFO:Copying training dataset
2025-05-14 12:48:29,509:INFO:Getting model names
2025-05-14 12:48:29,510:INFO:SubProcess create_model() called ==================================
2025-05-14 12:48:29,512:INFO:Initializing create_model()
2025-05-14 12:48:29,512:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x15cf0a710>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x15c73df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 12:48:29,512:INFO:Checking exceptions
2025-05-14 12:48:29,512:INFO:Importing libraries
2025-05-14 12:48:29,512:INFO:Copying training dataset
2025-05-14 12:48:29,533:INFO:Defining folds
2025-05-14 12:48:29,533:INFO:Declaring metric variables
2025-05-14 12:48:29,534:INFO:Importing untrained model
2025-05-14 12:48:29,535:INFO:Declaring custom model
2025-05-14 12:48:29,537:INFO:Voting Classifier Imported successfully
2025-05-14 12:48:29,539:INFO:Starting cross validation
2025-05-14 12:48:29,540:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 12:49:01,022:INFO:Calculating mean and std
2025-05-14 12:49:01,025:INFO:Creating metrics dataframe
2025-05-14 12:49:01,032:INFO:Finalizing model
2025-05-14 12:49:29,749:INFO:Uploading results into container
2025-05-14 12:49:29,750:INFO:Uploading model into container now
2025-05-14 12:49:29,751:INFO:_master_model_container: 18
2025-05-14 12:49:29,751:INFO:_display_container: 4
2025-05-14 12:49:29,754:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x3528c6450>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-14 12:49:29,754:INFO:create_model() successfully completed......................................
2025-05-14 12:49:29,954:INFO:SubProcess create_model() end ==================================
2025-05-14 12:49:29,958:INFO:_master_model_container: 18
2025-05-14 12:49:29,958:INFO:_display_container: 4
2025-05-14 12:49:29,960:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x3528c6450>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-14 12:49:29,960:INFO:blend_models() successfully completed......................................
2025-05-14 12:49:30,066:INFO:Initializing evaluate_model()
2025-05-14 12:49:30,066:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x3528c6450>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 12:49:30,080:INFO:Initializing plot_model()
2025-05-14 12:49:30,080:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x3528c6450>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 12:49:30,080:INFO:Checking exceptions
2025-05-14 12:49:30,088:INFO:Preloading libraries
2025-05-14 12:49:30,095:INFO:Copying training dataset
2025-05-14 12:49:30,095:INFO:Plot type: pipeline
2025-05-14 12:49:30,152:INFO:Visual Rendered Successfully
2025-05-14 12:49:30,258:INFO:plot_model() successfully completed......................................
2025-05-14 12:49:30,261:INFO:Initializing predict_model()
2025-05-14 12:49:30,261:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x3528c6450>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x3533ffce0>)
2025-05-14 12:49:30,261:INFO:Checking exceptions
2025-05-14 12:49:30,261:INFO:Preloading libraries
2025-05-14 12:49:30,262:INFO:Set up data.
2025-05-14 12:49:30,291:INFO:Set up index.
2025-05-14 12:49:30,879:INFO:Initializing plot_model()
2025-05-14 12:49:30,879:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 12:49:30,879:INFO:Checking exceptions
2025-05-14 12:49:30,891:INFO:Preloading libraries
2025-05-14 12:49:30,895:INFO:Copying training dataset
2025-05-14 12:49:30,895:INFO:Plot type: confusion_matrix
2025-05-14 12:49:31,174:INFO:Fitting Model
2025-05-14 12:49:31,175:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-14 12:49:31,176:INFO:Scoring test/hold-out set
2025-05-14 12:49:31,255:INFO:Visual Rendered Successfully
2025-05-14 12:49:31,360:INFO:plot_model() successfully completed......................................
2025-05-14 12:49:31,360:INFO:Initializing plot_model()
2025-05-14 12:49:31,360:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 12:49:31,360:INFO:Checking exceptions
2025-05-14 12:49:31,369:INFO:Preloading libraries
2025-05-14 12:49:31,372:INFO:Copying training dataset
2025-05-14 12:49:31,372:INFO:Plot type: auc
2025-05-14 12:49:31,484:INFO:Fitting Model
2025-05-14 12:49:31,485:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-14 12:49:31,486:INFO:Scoring test/hold-out set
2025-05-14 12:49:31,633:INFO:Visual Rendered Successfully
2025-05-14 12:49:31,746:INFO:plot_model() successfully completed......................................
2025-05-14 12:49:31,746:INFO:Initializing plot_model()
2025-05-14 12:49:31,746:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x158ebcdd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 12:49:31,746:INFO:Checking exceptions
2025-05-14 12:49:31,755:INFO:Preloading libraries
2025-05-14 12:49:31,758:INFO:Copying training dataset
2025-05-14 12:49:31,758:INFO:Plot type: feature
2025-05-14 12:49:31,758:WARNING:No coef_ found. Trying feature_importances_
2025-05-14 12:49:31,844:INFO:Visual Rendered Successfully
2025-05-14 12:49:31,955:INFO:plot_model() successfully completed......................................
2025-05-15 11:13:52,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 11:13:52,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 11:13:52,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 11:13:52,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 11:14:01,704:INFO:PyCaret ClassificationExperiment
2025-05-15 11:14:01,705:INFO:Logging name: clf-default-name
2025-05-15 11:14:01,705:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 11:14:01,705:INFO:version 3.3.2
2025-05-15 11:14:01,705:INFO:Initializing setup()
2025-05-15 11:14:01,705:INFO:self.USI: 7db7
2025-05-15 11:14:01,705:INFO:self._variable_keys: {'_ml_usecase', 'X', 'gpu_param', 'fix_imbalance', 'X_test', '_available_plots', 'n_jobs_param', 'pipeline', 'memory', 'exp_name_log', 'fold_groups_param', 'target_param', 'fold_generator', 'data', 'y', 'exp_id', 'log_plots_param', 'idx', 'USI', 'y_train', 'is_multiclass', 'html_param', 'fold_shuffle_param', 'X_train', 'gpu_n_jobs_param', 'y_test', 'logging_param', 'seed'}
2025-05-15 11:14:01,705:INFO:Checking environment
2025-05-15 11:14:01,705:INFO:python_version: 3.11.0
2025-05-15 11:14:01,705:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 11:14:01,705:INFO:machine: arm64
2025-05-15 11:14:01,705:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 11:14:01,705:INFO:Memory: svmem(total=17179869184, available=2880962560, percent=83.2, used=5663342592, free=69664768, active=2838773760, inactive=2796732416, wired=2824568832)
2025-05-15 11:14:01,705:INFO:Physical Core: 12
2025-05-15 11:14:01,705:INFO:Logical Core: 12
2025-05-15 11:14:01,705:INFO:Checking libraries
2025-05-15 11:14:01,705:INFO:System:
2025-05-15 11:14:01,705:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 11:14:01,705:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 11:14:01,705:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 11:14:01,705:INFO:PyCaret required dependencies:
2025-05-15 11:14:01,739:INFO:                 pip: 22.3
2025-05-15 11:14:01,739:INFO:          setuptools: 65.5.0
2025-05-15 11:14:01,739:INFO:             pycaret: 3.3.2
2025-05-15 11:14:01,739:INFO:             IPython: 9.2.0
2025-05-15 11:14:01,739:INFO:          ipywidgets: 8.1.7
2025-05-15 11:14:01,739:INFO:                tqdm: 4.67.1
2025-05-15 11:14:01,739:INFO:               numpy: 1.26.4
2025-05-15 11:14:01,739:INFO:              pandas: 2.1.4
2025-05-15 11:14:01,739:INFO:              jinja2: 3.1.6
2025-05-15 11:14:01,739:INFO:               scipy: 1.11.4
2025-05-15 11:14:01,739:INFO:              joblib: 1.3.2
2025-05-15 11:14:01,739:INFO:             sklearn: 1.4.2
2025-05-15 11:14:01,739:INFO:                pyod: 2.0.5
2025-05-15 11:14:01,739:INFO:            imblearn: 0.13.0
2025-05-15 11:14:01,739:INFO:   category_encoders: 2.7.0
2025-05-15 11:14:01,739:INFO:            lightgbm: 4.6.0
2025-05-15 11:14:01,739:INFO:               numba: 0.61.2
2025-05-15 11:14:01,739:INFO:            requests: 2.32.3
2025-05-15 11:14:01,739:INFO:          matplotlib: 3.7.5
2025-05-15 11:14:01,739:INFO:          scikitplot: 0.3.7
2025-05-15 11:14:01,739:INFO:         yellowbrick: 1.5
2025-05-15 11:14:01,739:INFO:              plotly: 5.24.1
2025-05-15 11:14:01,739:INFO:    plotly-resampler: Not installed
2025-05-15 11:14:01,739:INFO:             kaleido: 0.2.1
2025-05-15 11:14:01,740:INFO:           schemdraw: 0.15
2025-05-15 11:14:01,740:INFO:         statsmodels: 0.14.4
2025-05-15 11:14:01,740:INFO:              sktime: 0.26.0
2025-05-15 11:14:01,740:INFO:               tbats: 1.1.3
2025-05-15 11:14:01,740:INFO:            pmdarima: 2.0.4
2025-05-15 11:14:01,740:INFO:              psutil: 7.0.0
2025-05-15 11:14:01,740:INFO:          markupsafe: 3.0.2
2025-05-15 11:14:01,740:INFO:             pickle5: Not installed
2025-05-15 11:14:01,740:INFO:         cloudpickle: 3.1.1
2025-05-15 11:14:01,740:INFO:         deprecation: 2.1.0
2025-05-15 11:14:01,740:INFO:              xxhash: 3.5.0
2025-05-15 11:14:01,740:INFO:           wurlitzer: 3.1.1
2025-05-15 11:14:01,740:INFO:PyCaret optional dependencies:
2025-05-15 11:14:01,748:INFO:                shap: 0.47.2
2025-05-15 11:14:01,749:INFO:           interpret: Not installed
2025-05-15 11:14:01,749:INFO:                umap: Not installed
2025-05-15 11:14:01,749:INFO:     ydata_profiling: Not installed
2025-05-15 11:14:01,749:INFO:  explainerdashboard: Not installed
2025-05-15 11:14:01,749:INFO:             autoviz: Not installed
2025-05-15 11:14:01,749:INFO:           fairlearn: Not installed
2025-05-15 11:14:01,749:INFO:          deepchecks: Not installed
2025-05-15 11:14:01,749:INFO:             xgboost: Not installed
2025-05-15 11:14:01,749:INFO:            catboost: 1.2.8
2025-05-15 11:14:01,749:INFO:              kmodes: Not installed
2025-05-15 11:14:01,749:INFO:             mlxtend: Not installed
2025-05-15 11:14:01,749:INFO:       statsforecast: Not installed
2025-05-15 11:14:01,749:INFO:        tune_sklearn: Not installed
2025-05-15 11:14:01,749:INFO:                 ray: Not installed
2025-05-15 11:14:01,749:INFO:            hyperopt: Not installed
2025-05-15 11:14:01,749:INFO:              optuna: 4.3.0
2025-05-15 11:14:01,750:INFO:               skopt: Not installed
2025-05-15 11:14:01,750:INFO:              mlflow: Not installed
2025-05-15 11:14:01,750:INFO:              gradio: Not installed
2025-05-15 11:14:01,750:INFO:             fastapi: Not installed
2025-05-15 11:14:01,750:INFO:             uvicorn: Not installed
2025-05-15 11:14:01,750:INFO:              m2cgen: Not installed
2025-05-15 11:14:01,750:INFO:           evidently: Not installed
2025-05-15 11:14:01,750:INFO:               fugue: Not installed
2025-05-15 11:14:01,750:INFO:           streamlit: Not installed
2025-05-15 11:14:01,750:INFO:             prophet: Not installed
2025-05-15 11:14:01,750:INFO:None
2025-05-15 11:14:01,750:INFO:Set up data.
2025-05-15 11:14:01,825:INFO:Set up folding strategy.
2025-05-15 11:14:01,826:INFO:Set up train/test split.
2025-05-15 11:14:01,850:INFO:Set up index.
2025-05-15 11:14:01,851:INFO:Assigning column types.
2025-05-15 11:14:01,855:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 11:14:01,873:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:14:01,875:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:14:01,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:14:01,891:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:14:01,955:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:14:01,956:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:14:01,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:14:01,967:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:14:01,967:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 11:14:01,985:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:14:01,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:14:01,997:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:14:02,016:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:14:02,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:14:02,028:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:14:02,028:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 11:14:02,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:14:02,059:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:14:02,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:14:02,091:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:14:02,092:INFO:Preparing preprocessing pipeline...
2025-05-15 11:14:02,094:INFO:Set up simple imputation.
2025-05-15 11:14:02,100:INFO:Set up encoding of ordinal features.
2025-05-15 11:14:02,110:INFO:Set up encoding of categorical features.
2025-05-15 11:14:02,110:INFO:Set up imbalanced handling.
2025-05-15 11:14:02,110:INFO:Set up column transformation.
2025-05-15 11:14:02,379:INFO:Finished creating preprocessing pipeline.
2025-05-15 11:14:02,403:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 11:14:02,403:INFO:Creating final display dataframe.
2025-05-15 11:14:02,651:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              7db7
2025-05-15 11:14:02,688:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:14:02,689:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:14:02,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:14:02,726:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:14:02,727:INFO:setup() successfully completed in 1.03s...............
2025-05-15 11:14:02,727:INFO:Initializing compare_models()
2025-05-15 11:14:02,727:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-15 11:14:02,727:INFO:Checking exceptions
2025-05-15 11:14:02,732:INFO:Preparing display monitor
2025-05-15 11:14:02,771:INFO:Initializing Logistic Regression
2025-05-15 11:14:02,771:INFO:Total runtime is 3.314018249511719e-06 minutes
2025-05-15 11:14:02,772:INFO:SubProcess create_model() called ==================================
2025-05-15 11:14:02,772:INFO:Initializing create_model()
2025-05-15 11:14:02,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:14:02,773:INFO:Checking exceptions
2025-05-15 11:14:02,773:INFO:Importing libraries
2025-05-15 11:14:02,773:INFO:Copying training dataset
2025-05-15 11:14:02,785:INFO:Defining folds
2025-05-15 11:14:02,785:INFO:Declaring metric variables
2025-05-15 11:14:02,786:INFO:Importing untrained model
2025-05-15 11:14:02,787:INFO:Logistic Regression Imported successfully
2025-05-15 11:14:02,790:INFO:Starting cross validation
2025-05-15 11:14:02,791:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:14:08,844:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 11:14:08,874:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 11:14:08,907:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 11:14:08,930:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 11:14:08,969:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 11:14:09,044:INFO:Calculating mean and std
2025-05-15 11:14:09,047:INFO:Creating metrics dataframe
2025-05-15 11:14:09,053:INFO:Uploading results into container
2025-05-15 11:14:09,054:INFO:Uploading model into container now
2025-05-15 11:14:09,056:INFO:_master_model_container: 1
2025-05-15 11:14:09,056:INFO:_display_container: 2
2025-05-15 11:14:09,058:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 11:14:09,058:INFO:create_model() successfully completed......................................
2025-05-15 11:14:09,195:INFO:SubProcess create_model() end ==================================
2025-05-15 11:14:09,195:INFO:Creating metrics dataframe
2025-05-15 11:14:09,198:INFO:Initializing K Neighbors Classifier
2025-05-15 11:14:09,198:INFO:Total runtime is 0.10712401469548544 minutes
2025-05-15 11:14:09,199:INFO:SubProcess create_model() called ==================================
2025-05-15 11:14:09,200:INFO:Initializing create_model()
2025-05-15 11:14:09,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:14:09,200:INFO:Checking exceptions
2025-05-15 11:14:09,200:INFO:Importing libraries
2025-05-15 11:14:09,200:INFO:Copying training dataset
2025-05-15 11:14:09,211:INFO:Defining folds
2025-05-15 11:14:09,211:INFO:Declaring metric variables
2025-05-15 11:14:09,212:INFO:Importing untrained model
2025-05-15 11:14:09,214:INFO:K Neighbors Classifier Imported successfully
2025-05-15 11:14:09,216:INFO:Starting cross validation
2025-05-15 11:14:09,217:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:14:15,473:INFO:Calculating mean and std
2025-05-15 11:14:15,475:INFO:Creating metrics dataframe
2025-05-15 11:14:15,477:INFO:Uploading results into container
2025-05-15 11:14:15,477:INFO:Uploading model into container now
2025-05-15 11:14:15,477:INFO:_master_model_container: 2
2025-05-15 11:14:15,477:INFO:_display_container: 2
2025-05-15 11:14:15,478:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-15 11:14:15,478:INFO:create_model() successfully completed......................................
2025-05-15 11:14:15,538:INFO:SubProcess create_model() end ==================================
2025-05-15 11:14:15,538:INFO:Creating metrics dataframe
2025-05-15 11:14:15,542:INFO:Initializing Naive Bayes
2025-05-15 11:14:15,542:INFO:Total runtime is 0.21285738150278727 minutes
2025-05-15 11:14:15,544:INFO:SubProcess create_model() called ==================================
2025-05-15 11:14:15,544:INFO:Initializing create_model()
2025-05-15 11:14:15,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:14:15,544:INFO:Checking exceptions
2025-05-15 11:14:15,544:INFO:Importing libraries
2025-05-15 11:14:15,544:INFO:Copying training dataset
2025-05-15 11:14:15,555:INFO:Defining folds
2025-05-15 11:14:15,556:INFO:Declaring metric variables
2025-05-15 11:14:15,557:INFO:Importing untrained model
2025-05-15 11:14:15,558:INFO:Naive Bayes Imported successfully
2025-05-15 11:14:15,561:INFO:Starting cross validation
2025-05-15 11:14:15,561:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:14:18,138:INFO:Calculating mean and std
2025-05-15 11:14:18,139:INFO:Creating metrics dataframe
2025-05-15 11:14:18,140:INFO:Uploading results into container
2025-05-15 11:14:18,140:INFO:Uploading model into container now
2025-05-15 11:14:18,140:INFO:_master_model_container: 3
2025-05-15 11:14:18,140:INFO:_display_container: 2
2025-05-15 11:14:18,140:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-15 11:14:18,140:INFO:create_model() successfully completed......................................
2025-05-15 11:14:18,197:INFO:SubProcess create_model() end ==================================
2025-05-15 11:14:18,197:INFO:Creating metrics dataframe
2025-05-15 11:14:18,201:INFO:Initializing Decision Tree Classifier
2025-05-15 11:14:18,201:INFO:Total runtime is 0.2571732997894287 minutes
2025-05-15 11:14:18,202:INFO:SubProcess create_model() called ==================================
2025-05-15 11:14:18,202:INFO:Initializing create_model()
2025-05-15 11:14:18,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:14:18,203:INFO:Checking exceptions
2025-05-15 11:14:18,203:INFO:Importing libraries
2025-05-15 11:14:18,203:INFO:Copying training dataset
2025-05-15 11:14:18,219:INFO:Defining folds
2025-05-15 11:14:18,219:INFO:Declaring metric variables
2025-05-15 11:14:18,220:INFO:Importing untrained model
2025-05-15 11:14:18,221:INFO:Decision Tree Classifier Imported successfully
2025-05-15 11:14:18,224:INFO:Starting cross validation
2025-05-15 11:14:18,225:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:14:19,925:INFO:Calculating mean and std
2025-05-15 11:14:19,926:INFO:Creating metrics dataframe
2025-05-15 11:14:19,927:INFO:Uploading results into container
2025-05-15 11:14:19,927:INFO:Uploading model into container now
2025-05-15 11:14:19,927:INFO:_master_model_container: 4
2025-05-15 11:14:19,927:INFO:_display_container: 2
2025-05-15 11:14:19,927:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-15 11:14:19,928:INFO:create_model() successfully completed......................................
2025-05-15 11:14:19,973:INFO:SubProcess create_model() end ==================================
2025-05-15 11:14:19,973:INFO:Creating metrics dataframe
2025-05-15 11:14:19,976:INFO:Initializing SVM - Linear Kernel
2025-05-15 11:14:19,976:INFO:Total runtime is 0.2867598652839661 minutes
2025-05-15 11:14:19,978:INFO:SubProcess create_model() called ==================================
2025-05-15 11:14:19,978:INFO:Initializing create_model()
2025-05-15 11:14:19,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:14:19,978:INFO:Checking exceptions
2025-05-15 11:14:19,978:INFO:Importing libraries
2025-05-15 11:14:19,978:INFO:Copying training dataset
2025-05-15 11:14:19,991:INFO:Defining folds
2025-05-15 11:14:19,991:INFO:Declaring metric variables
2025-05-15 11:14:19,993:INFO:Importing untrained model
2025-05-15 11:14:19,994:INFO:SVM - Linear Kernel Imported successfully
2025-05-15 11:14:19,997:INFO:Starting cross validation
2025-05-15 11:14:19,998:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:14:23,697:INFO:Calculating mean and std
2025-05-15 11:14:23,699:INFO:Creating metrics dataframe
2025-05-15 11:14:23,711:INFO:Uploading results into container
2025-05-15 11:14:23,711:INFO:Uploading model into container now
2025-05-15 11:14:23,712:INFO:_master_model_container: 5
2025-05-15 11:14:23,712:INFO:_display_container: 2
2025-05-15 11:14:23,713:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-15 11:14:23,713:INFO:create_model() successfully completed......................................
2025-05-15 11:14:23,782:INFO:SubProcess create_model() end ==================================
2025-05-15 11:14:23,782:INFO:Creating metrics dataframe
2025-05-15 11:14:23,785:INFO:Initializing Ridge Classifier
2025-05-15 11:14:23,785:INFO:Total runtime is 0.35024444659550985 minutes
2025-05-15 11:14:23,787:INFO:SubProcess create_model() called ==================================
2025-05-15 11:14:23,787:INFO:Initializing create_model()
2025-05-15 11:14:23,787:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:14:23,787:INFO:Checking exceptions
2025-05-15 11:14:23,787:INFO:Importing libraries
2025-05-15 11:14:23,787:INFO:Copying training dataset
2025-05-15 11:14:23,796:INFO:Defining folds
2025-05-15 11:14:23,796:INFO:Declaring metric variables
2025-05-15 11:14:23,797:INFO:Importing untrained model
2025-05-15 11:14:23,798:INFO:Ridge Classifier Imported successfully
2025-05-15 11:14:23,801:INFO:Starting cross validation
2025-05-15 11:14:23,801:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:14:24,935:INFO:Calculating mean and std
2025-05-15 11:14:24,935:INFO:Creating metrics dataframe
2025-05-15 11:14:24,937:INFO:Uploading results into container
2025-05-15 11:14:24,937:INFO:Uploading model into container now
2025-05-15 11:14:24,937:INFO:_master_model_container: 6
2025-05-15 11:14:24,937:INFO:_display_container: 2
2025-05-15 11:14:24,938:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-15 11:14:24,938:INFO:create_model() successfully completed......................................
2025-05-15 11:14:25,032:INFO:SubProcess create_model() end ==================================
2025-05-15 11:14:25,032:INFO:Creating metrics dataframe
2025-05-15 11:14:25,036:INFO:Initializing Random Forest Classifier
2025-05-15 11:14:25,036:INFO:Total runtime is 0.37109346787134806 minutes
2025-05-15 11:14:25,038:INFO:SubProcess create_model() called ==================================
2025-05-15 11:14:25,038:INFO:Initializing create_model()
2025-05-15 11:14:25,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:14:25,038:INFO:Checking exceptions
2025-05-15 11:14:25,038:INFO:Importing libraries
2025-05-15 11:14:25,038:INFO:Copying training dataset
2025-05-15 11:14:25,051:INFO:Defining folds
2025-05-15 11:14:25,051:INFO:Declaring metric variables
2025-05-15 11:14:25,053:INFO:Importing untrained model
2025-05-15 11:14:25,054:INFO:Random Forest Classifier Imported successfully
2025-05-15 11:14:25,057:INFO:Starting cross validation
2025-05-15 11:14:25,058:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:14:31,672:INFO:Calculating mean and std
2025-05-15 11:14:31,676:INFO:Creating metrics dataframe
2025-05-15 11:14:31,682:INFO:Uploading results into container
2025-05-15 11:14:31,683:INFO:Uploading model into container now
2025-05-15 11:14:31,684:INFO:_master_model_container: 7
2025-05-15 11:14:31,684:INFO:_display_container: 2
2025-05-15 11:14:31,684:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 11:14:31,685:INFO:create_model() successfully completed......................................
2025-05-15 11:14:31,839:INFO:SubProcess create_model() end ==================================
2025-05-15 11:14:31,839:INFO:Creating metrics dataframe
2025-05-15 11:14:31,843:INFO:Initializing Quadratic Discriminant Analysis
2025-05-15 11:14:31,843:INFO:Total runtime is 0.48453493118286134 minutes
2025-05-15 11:14:31,844:INFO:SubProcess create_model() called ==================================
2025-05-15 11:14:31,844:INFO:Initializing create_model()
2025-05-15 11:14:31,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:14:31,844:INFO:Checking exceptions
2025-05-15 11:14:31,844:INFO:Importing libraries
2025-05-15 11:14:31,844:INFO:Copying training dataset
2025-05-15 11:14:31,856:INFO:Defining folds
2025-05-15 11:14:31,856:INFO:Declaring metric variables
2025-05-15 11:14:31,858:INFO:Importing untrained model
2025-05-15 11:14:31,859:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 11:14:31,861:INFO:Starting cross validation
2025-05-15 11:14:31,863:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:14:32,984:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 11:14:32,987:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 11:14:33,022:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 11:14:33,064:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:14:33,065:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 11:14:33,076:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:14:33,109:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:14:33,131:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 11:14:33,149:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:14:33,204:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:14:33,215:INFO:Calculating mean and std
2025-05-15 11:14:33,216:INFO:Creating metrics dataframe
2025-05-15 11:14:33,217:INFO:Uploading results into container
2025-05-15 11:14:33,217:INFO:Uploading model into container now
2025-05-15 11:14:33,217:INFO:_master_model_container: 8
2025-05-15 11:14:33,217:INFO:_display_container: 2
2025-05-15 11:14:33,218:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 11:14:33,218:INFO:create_model() successfully completed......................................
2025-05-15 11:14:33,271:INFO:SubProcess create_model() end ==================================
2025-05-15 11:14:33,271:INFO:Creating metrics dataframe
2025-05-15 11:14:33,274:INFO:Initializing Ada Boost Classifier
2025-05-15 11:14:33,274:INFO:Total runtime is 0.5083946784337362 minutes
2025-05-15 11:14:33,276:INFO:SubProcess create_model() called ==================================
2025-05-15 11:14:33,276:INFO:Initializing create_model()
2025-05-15 11:14:33,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:14:33,276:INFO:Checking exceptions
2025-05-15 11:14:33,276:INFO:Importing libraries
2025-05-15 11:14:33,276:INFO:Copying training dataset
2025-05-15 11:14:33,286:INFO:Defining folds
2025-05-15 11:14:33,286:INFO:Declaring metric variables
2025-05-15 11:14:33,288:INFO:Importing untrained model
2025-05-15 11:14:33,289:INFO:Ada Boost Classifier Imported successfully
2025-05-15 11:14:33,292:INFO:Starting cross validation
2025-05-15 11:14:33,293:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:14:34,345:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 11:14:34,365:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 11:14:34,409:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 11:14:34,434:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 11:14:34,465:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 11:14:37,346:INFO:Calculating mean and std
2025-05-15 11:14:37,355:INFO:Creating metrics dataframe
2025-05-15 11:14:37,358:INFO:Uploading results into container
2025-05-15 11:14:37,359:INFO:Uploading model into container now
2025-05-15 11:14:37,359:INFO:_master_model_container: 9
2025-05-15 11:14:37,360:INFO:_display_container: 2
2025-05-15 11:14:37,360:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-15 11:14:37,360:INFO:create_model() successfully completed......................................
2025-05-15 11:14:37,464:INFO:SubProcess create_model() end ==================================
2025-05-15 11:14:37,464:INFO:Creating metrics dataframe
2025-05-15 11:14:37,468:INFO:Initializing Gradient Boosting Classifier
2025-05-15 11:14:37,468:INFO:Total runtime is 0.5782883167266846 minutes
2025-05-15 11:14:37,469:INFO:SubProcess create_model() called ==================================
2025-05-15 11:14:37,469:INFO:Initializing create_model()
2025-05-15 11:14:37,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:14:37,470:INFO:Checking exceptions
2025-05-15 11:14:37,470:INFO:Importing libraries
2025-05-15 11:14:37,470:INFO:Copying training dataset
2025-05-15 11:14:37,482:INFO:Defining folds
2025-05-15 11:14:37,482:INFO:Declaring metric variables
2025-05-15 11:14:37,484:INFO:Importing untrained model
2025-05-15 11:14:37,486:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 11:14:37,488:INFO:Starting cross validation
2025-05-15 11:14:37,489:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:14:51,528:INFO:Calculating mean and std
2025-05-15 11:14:51,531:INFO:Creating metrics dataframe
2025-05-15 11:14:51,534:INFO:Uploading results into container
2025-05-15 11:14:51,534:INFO:Uploading model into container now
2025-05-15 11:14:51,535:INFO:_master_model_container: 10
2025-05-15 11:14:51,535:INFO:_display_container: 2
2025-05-15 11:14:51,536:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 11:14:51,536:INFO:create_model() successfully completed......................................
2025-05-15 11:14:51,615:INFO:SubProcess create_model() end ==================================
2025-05-15 11:14:51,615:INFO:Creating metrics dataframe
2025-05-15 11:14:51,619:INFO:Initializing Linear Discriminant Analysis
2025-05-15 11:14:51,619:INFO:Total runtime is 0.8141427636146545 minutes
2025-05-15 11:14:51,621:INFO:SubProcess create_model() called ==================================
2025-05-15 11:14:51,621:INFO:Initializing create_model()
2025-05-15 11:14:51,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:14:51,621:INFO:Checking exceptions
2025-05-15 11:14:51,621:INFO:Importing libraries
2025-05-15 11:14:51,621:INFO:Copying training dataset
2025-05-15 11:14:51,633:INFO:Defining folds
2025-05-15 11:14:51,633:INFO:Declaring metric variables
2025-05-15 11:14:51,634:INFO:Importing untrained model
2025-05-15 11:14:51,635:INFO:Linear Discriminant Analysis Imported successfully
2025-05-15 11:14:51,637:INFO:Starting cross validation
2025-05-15 11:14:51,638:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:14:52,877:INFO:Calculating mean and std
2025-05-15 11:14:52,877:INFO:Creating metrics dataframe
2025-05-15 11:14:52,878:INFO:Uploading results into container
2025-05-15 11:14:52,878:INFO:Uploading model into container now
2025-05-15 11:14:52,879:INFO:_master_model_container: 11
2025-05-15 11:14:52,879:INFO:_display_container: 2
2025-05-15 11:14:52,879:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-15 11:14:52,879:INFO:create_model() successfully completed......................................
2025-05-15 11:14:52,923:INFO:SubProcess create_model() end ==================================
2025-05-15 11:14:52,923:INFO:Creating metrics dataframe
2025-05-15 11:14:52,927:INFO:Initializing Extra Trees Classifier
2025-05-15 11:14:52,927:INFO:Total runtime is 0.8359413345654806 minutes
2025-05-15 11:14:52,928:INFO:SubProcess create_model() called ==================================
2025-05-15 11:14:52,928:INFO:Initializing create_model()
2025-05-15 11:14:52,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:14:52,929:INFO:Checking exceptions
2025-05-15 11:14:52,929:INFO:Importing libraries
2025-05-15 11:14:52,929:INFO:Copying training dataset
2025-05-15 11:14:52,938:INFO:Defining folds
2025-05-15 11:14:52,938:INFO:Declaring metric variables
2025-05-15 11:14:52,939:INFO:Importing untrained model
2025-05-15 11:14:52,940:INFO:Extra Trees Classifier Imported successfully
2025-05-15 11:14:52,942:INFO:Starting cross validation
2025-05-15 11:14:52,943:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:14:57,572:INFO:Calculating mean and std
2025-05-15 11:14:57,578:INFO:Creating metrics dataframe
2025-05-15 11:14:57,585:INFO:Uploading results into container
2025-05-15 11:14:57,585:INFO:Uploading model into container now
2025-05-15 11:14:57,586:INFO:_master_model_container: 12
2025-05-15 11:14:57,586:INFO:_display_container: 2
2025-05-15 11:14:57,587:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 11:14:57,587:INFO:create_model() successfully completed......................................
2025-05-15 11:14:57,693:INFO:SubProcess create_model() end ==================================
2025-05-15 11:14:57,694:INFO:Creating metrics dataframe
2025-05-15 11:14:57,698:INFO:Initializing Light Gradient Boosting Machine
2025-05-15 11:14:57,698:INFO:Total runtime is 0.9154525836308798 minutes
2025-05-15 11:14:57,699:INFO:SubProcess create_model() called ==================================
2025-05-15 11:14:57,699:INFO:Initializing create_model()
2025-05-15 11:14:57,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:14:57,699:INFO:Checking exceptions
2025-05-15 11:14:57,699:INFO:Importing libraries
2025-05-15 11:14:57,699:INFO:Copying training dataset
2025-05-15 11:14:57,715:INFO:Defining folds
2025-05-15 11:14:57,715:INFO:Declaring metric variables
2025-05-15 11:14:57,716:INFO:Importing untrained model
2025-05-15 11:14:57,718:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 11:14:57,720:INFO:Starting cross validation
2025-05-15 11:14:57,721:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:15:01,876:INFO:Calculating mean and std
2025-05-15 11:15:01,878:INFO:Creating metrics dataframe
2025-05-15 11:15:01,883:INFO:Uploading results into container
2025-05-15 11:15:01,884:INFO:Uploading model into container now
2025-05-15 11:15:01,884:INFO:_master_model_container: 13
2025-05-15 11:15:01,884:INFO:_display_container: 2
2025-05-15 11:15:01,885:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 11:15:01,885:INFO:create_model() successfully completed......................................
2025-05-15 11:15:02,008:INFO:SubProcess create_model() end ==================================
2025-05-15 11:15:02,008:INFO:Creating metrics dataframe
2025-05-15 11:15:02,015:INFO:Initializing CatBoost Classifier
2025-05-15 11:15:02,015:INFO:Total runtime is 0.9874007304509481 minutes
2025-05-15 11:15:02,016:INFO:SubProcess create_model() called ==================================
2025-05-15 11:15:02,016:INFO:Initializing create_model()
2025-05-15 11:15:02,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:15:02,017:INFO:Checking exceptions
2025-05-15 11:15:02,017:INFO:Importing libraries
2025-05-15 11:15:02,017:INFO:Copying training dataset
2025-05-15 11:15:02,032:INFO:Defining folds
2025-05-15 11:15:02,032:INFO:Declaring metric variables
2025-05-15 11:15:02,034:INFO:Importing untrained model
2025-05-15 11:15:02,036:INFO:CatBoost Classifier Imported successfully
2025-05-15 11:15:02,039:INFO:Starting cross validation
2025-05-15 11:15:02,040:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:15:21,440:INFO:Calculating mean and std
2025-05-15 11:15:21,442:INFO:Creating metrics dataframe
2025-05-15 11:15:21,445:INFO:Uploading results into container
2025-05-15 11:15:21,446:INFO:Uploading model into container now
2025-05-15 11:15:21,447:INFO:_master_model_container: 14
2025-05-15 11:15:21,447:INFO:_display_container: 2
2025-05-15 11:15:21,447:INFO:<catboost.core.CatBoostClassifier object at 0x327513d10>
2025-05-15 11:15:21,447:INFO:create_model() successfully completed......................................
2025-05-15 11:15:21,526:INFO:SubProcess create_model() end ==================================
2025-05-15 11:15:21,526:INFO:Creating metrics dataframe
2025-05-15 11:15:21,531:INFO:Initializing Dummy Classifier
2025-05-15 11:15:21,531:INFO:Total runtime is 1.312674661477407 minutes
2025-05-15 11:15:21,533:INFO:SubProcess create_model() called ==================================
2025-05-15 11:15:21,533:INFO:Initializing create_model()
2025-05-15 11:15:21,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331d6e210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:15:21,533:INFO:Checking exceptions
2025-05-15 11:15:21,533:INFO:Importing libraries
2025-05-15 11:15:21,533:INFO:Copying training dataset
2025-05-15 11:15:21,544:INFO:Defining folds
2025-05-15 11:15:21,544:INFO:Declaring metric variables
2025-05-15 11:15:21,546:INFO:Importing untrained model
2025-05-15 11:15:21,547:INFO:Dummy Classifier Imported successfully
2025-05-15 11:15:21,549:INFO:Starting cross validation
2025-05-15 11:15:21,550:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:15:22,613:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:15:22,626:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:15:22,643:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:15:22,655:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:15:22,685:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:15:22,700:INFO:Calculating mean and std
2025-05-15 11:15:22,700:INFO:Creating metrics dataframe
2025-05-15 11:15:22,701:INFO:Uploading results into container
2025-05-15 11:15:22,701:INFO:Uploading model into container now
2025-05-15 11:15:22,702:INFO:_master_model_container: 15
2025-05-15 11:15:22,702:INFO:_display_container: 2
2025-05-15 11:15:22,702:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-15 11:15:22,702:INFO:create_model() successfully completed......................................
2025-05-15 11:15:22,752:INFO:SubProcess create_model() end ==================================
2025-05-15 11:15:22,752:INFO:Creating metrics dataframe
2025-05-15 11:15:22,758:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-15 11:15:22,761:INFO:Initializing create_model()
2025-05-15 11:15:22,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:15:22,761:INFO:Checking exceptions
2025-05-15 11:15:22,762:INFO:Importing libraries
2025-05-15 11:15:22,762:INFO:Copying training dataset
2025-05-15 11:15:22,772:INFO:Defining folds
2025-05-15 11:15:22,772:INFO:Declaring metric variables
2025-05-15 11:15:22,772:INFO:Importing untrained model
2025-05-15 11:15:22,772:INFO:Declaring custom model
2025-05-15 11:15:22,773:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 11:15:22,773:INFO:Cross validation set to False
2025-05-15 11:15:22,773:INFO:Fitting Model
2025-05-15 11:15:24,192:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 11:15:24,202:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004904 seconds.
2025-05-15 11:15:24,203:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 11:15:24,203:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 11:15:24,203:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 11:15:24,203:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 11:15:24,204:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 11:15:24,956:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 11:15:24,956:INFO:create_model() successfully completed......................................
2025-05-15 11:15:25,018:INFO:Initializing create_model()
2025-05-15 11:15:25,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:15:25,018:INFO:Checking exceptions
2025-05-15 11:15:25,019:INFO:Importing libraries
2025-05-15 11:15:25,019:INFO:Copying training dataset
2025-05-15 11:15:25,030:INFO:Defining folds
2025-05-15 11:15:25,030:INFO:Declaring metric variables
2025-05-15 11:15:25,030:INFO:Importing untrained model
2025-05-15 11:15:25,030:INFO:Declaring custom model
2025-05-15 11:15:25,031:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 11:15:25,032:INFO:Cross validation set to False
2025-05-15 11:15:25,032:INFO:Fitting Model
2025-05-15 11:15:41,093:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 11:15:41,094:INFO:create_model() successfully completed......................................
2025-05-15 11:15:41,156:INFO:Initializing create_model()
2025-05-15 11:15:41,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:15:41,156:INFO:Checking exceptions
2025-05-15 11:15:41,157:INFO:Importing libraries
2025-05-15 11:15:41,157:INFO:Copying training dataset
2025-05-15 11:15:41,169:INFO:Defining folds
2025-05-15 11:15:41,169:INFO:Declaring metric variables
2025-05-15 11:15:41,169:INFO:Importing untrained model
2025-05-15 11:15:41,169:INFO:Declaring custom model
2025-05-15 11:15:41,169:INFO:Random Forest Classifier Imported successfully
2025-05-15 11:15:41,170:INFO:Cross validation set to False
2025-05-15 11:15:41,170:INFO:Fitting Model
2025-05-15 11:15:43,478:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 11:15:43,478:INFO:create_model() successfully completed......................................
2025-05-15 11:15:43,540:INFO:_master_model_container: 15
2025-05-15 11:15:43,540:INFO:_display_container: 2
2025-05-15 11:15:43,541:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-15 11:15:43,541:INFO:compare_models() successfully completed......................................
2025-05-15 11:15:43,542:INFO:Initializing evaluate_model()
2025-05-15 11:15:43,542:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 11:15:43,548:INFO:Initializing plot_model()
2025-05-15 11:15:43,548:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 11:15:43,549:INFO:Checking exceptions
2025-05-15 11:15:43,552:INFO:Preloading libraries
2025-05-15 11:15:43,554:INFO:Copying training dataset
2025-05-15 11:15:43,554:INFO:Plot type: pipeline
2025-05-15 11:15:43,642:INFO:Visual Rendered Successfully
2025-05-15 11:15:43,694:INFO:plot_model() successfully completed......................................
2025-05-15 11:15:43,696:INFO:Initializing tune_model()
2025-05-15 11:15:43,696:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-15 11:15:43,696:INFO:Checking exceptions
2025-05-15 11:15:43,705:INFO:Copying training dataset
2025-05-15 11:15:43,712:INFO:Checking base model
2025-05-15 11:15:43,712:INFO:Base model : Light Gradient Boosting Machine
2025-05-15 11:15:43,714:INFO:Declaring metric variables
2025-05-15 11:15:43,715:INFO:Defining Hyperparameters
2025-05-15 11:15:43,766:INFO:Tuning with n_jobs=-1
2025-05-15 11:15:43,766:INFO:Initializing RandomizedSearchCV
2025-05-15 11:16:20,019:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-15 11:16:20,021:INFO:Hyperparameter search completed
2025-05-15 11:16:20,022:INFO:SubProcess create_model() called ==================================
2025-05-15 11:16:20,023:INFO:Initializing create_model()
2025-05-15 11:16:20,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331f05190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-15 11:16:20,023:INFO:Checking exceptions
2025-05-15 11:16:20,024:INFO:Importing libraries
2025-05-15 11:16:20,025:INFO:Copying training dataset
2025-05-15 11:16:20,061:INFO:Defining folds
2025-05-15 11:16:20,061:INFO:Declaring metric variables
2025-05-15 11:16:20,064:INFO:Importing untrained model
2025-05-15 11:16:20,064:INFO:Declaring custom model
2025-05-15 11:16:20,068:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 11:16:20,071:INFO:Starting cross validation
2025-05-15 11:16:20,076:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:16:27,338:INFO:Calculating mean and std
2025-05-15 11:16:27,344:INFO:Creating metrics dataframe
2025-05-15 11:16:27,353:INFO:Finalizing model
2025-05-15 11:16:28,399:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 11:16:28,399:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 11:16:28,399:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 11:16:28,431:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 11:16:28,431:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 11:16:28,431:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 11:16:28,431:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 11:16:28,442:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005248 seconds.
2025-05-15 11:16:28,442:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 11:16:28,442:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 11:16:28,442:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 11:16:28,442:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 11:16:28,442:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 11:16:29,890:INFO:Uploading results into container
2025-05-15 11:16:29,891:INFO:Uploading model into container now
2025-05-15 11:16:29,891:INFO:_master_model_container: 16
2025-05-15 11:16:29,891:INFO:_display_container: 3
2025-05-15 11:16:29,892:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 11:16:29,892:INFO:create_model() successfully completed......................................
2025-05-15 11:16:29,995:INFO:SubProcess create_model() end ==================================
2025-05-15 11:16:29,995:INFO:choose_better activated
2025-05-15 11:16:29,997:INFO:SubProcess create_model() called ==================================
2025-05-15 11:16:29,997:INFO:Initializing create_model()
2025-05-15 11:16:29,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:16:29,997:INFO:Checking exceptions
2025-05-15 11:16:29,999:INFO:Importing libraries
2025-05-15 11:16:29,999:INFO:Copying training dataset
2025-05-15 11:16:30,008:INFO:Defining folds
2025-05-15 11:16:30,008:INFO:Declaring metric variables
2025-05-15 11:16:30,008:INFO:Importing untrained model
2025-05-15 11:16:30,008:INFO:Declaring custom model
2025-05-15 11:16:30,009:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 11:16:30,009:INFO:Starting cross validation
2025-05-15 11:16:30,010:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:16:34,350:INFO:Calculating mean and std
2025-05-15 11:16:34,350:INFO:Creating metrics dataframe
2025-05-15 11:16:34,351:INFO:Finalizing model
2025-05-15 11:16:35,409:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 11:16:35,422:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008638 seconds.
2025-05-15 11:16:35,422:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 11:16:35,422:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 11:16:35,422:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 11:16:35,422:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 11:16:35,423:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 11:16:36,272:INFO:Uploading results into container
2025-05-15 11:16:36,272:INFO:Uploading model into container now
2025-05-15 11:16:36,272:INFO:_master_model_container: 17
2025-05-15 11:16:36,273:INFO:_display_container: 4
2025-05-15 11:16:36,273:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 11:16:36,273:INFO:create_model() successfully completed......................................
2025-05-15 11:16:36,354:INFO:SubProcess create_model() end ==================================
2025-05-15 11:16:36,355:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-15 11:16:36,356:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-15 11:16:36,356:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-15 11:16:36,356:INFO:choose_better completed
2025-05-15 11:16:36,369:INFO:_master_model_container: 17
2025-05-15 11:16:36,369:INFO:_display_container: 3
2025-05-15 11:16:36,369:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 11:16:36,369:INFO:tune_model() successfully completed......................................
2025-05-15 11:16:36,461:INFO:Initializing evaluate_model()
2025-05-15 11:16:36,461:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 11:16:36,476:INFO:Initializing plot_model()
2025-05-15 11:16:36,476:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 11:16:36,476:INFO:Checking exceptions
2025-05-15 11:16:36,486:INFO:Preloading libraries
2025-05-15 11:16:36,490:INFO:Copying training dataset
2025-05-15 11:16:36,490:INFO:Plot type: pipeline
2025-05-15 11:16:36,592:INFO:Visual Rendered Successfully
2025-05-15 11:16:36,661:INFO:plot_model() successfully completed......................................
2025-05-15 11:16:36,663:INFO:Initializing interpret_model()
2025-05-15 11:16:36,663:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325528b10>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-15 11:16:36,663:INFO:Checking exceptions
2025-05-15 11:16:36,663:INFO:Soft dependency imported: shap: 0.47.2
2025-05-15 11:16:37,288:INFO:plot type: summary
2025-05-15 11:16:37,288:INFO:Creating TreeExplainer
2025-05-15 11:16:37,362:INFO:Compiling shap values
2025-05-15 11:16:38,642:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray
  warnings.warn(

2025-05-15 11:16:38,642:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-05-15 11:16:39,951:INFO:Visual Rendered Successfully
2025-05-15 11:16:39,951:INFO:interpret_model() successfully completed......................................
2025-05-15 11:16:40,020:INFO:PyCaret ClassificationExperiment
2025-05-15 11:16:40,020:INFO:Logging name: clf-default-name
2025-05-15 11:16:40,020:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 11:16:40,020:INFO:version 3.3.2
2025-05-15 11:16:40,020:INFO:Initializing setup()
2025-05-15 11:16:40,020:INFO:self.USI: ddc9
2025-05-15 11:16:40,020:INFO:self._variable_keys: {'_ml_usecase', 'X', 'gpu_param', 'fix_imbalance', 'X_test', '_available_plots', 'n_jobs_param', 'pipeline', 'memory', 'exp_name_log', 'fold_groups_param', 'target_param', 'fold_generator', 'data', 'y', 'exp_id', 'log_plots_param', 'idx', 'USI', 'y_train', 'is_multiclass', 'html_param', 'fold_shuffle_param', 'X_train', 'gpu_n_jobs_param', 'y_test', 'logging_param', 'seed'}
2025-05-15 11:16:40,020:INFO:Checking environment
2025-05-15 11:16:40,020:INFO:python_version: 3.11.0
2025-05-15 11:16:40,020:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 11:16:40,020:INFO:machine: arm64
2025-05-15 11:16:40,020:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 11:16:40,020:INFO:Memory: svmem(total=17179869184, available=3279634432, percent=80.9, used=5557026816, free=597819392, active=2707128320, inactive=2664235008, wired=2849898496)
2025-05-15 11:16:40,020:INFO:Physical Core: 12
2025-05-15 11:16:40,020:INFO:Logical Core: 12
2025-05-15 11:16:40,020:INFO:Checking libraries
2025-05-15 11:16:40,020:INFO:System:
2025-05-15 11:16:40,020:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 11:16:40,020:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 11:16:40,020:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 11:16:40,020:INFO:PyCaret required dependencies:
2025-05-15 11:16:40,020:INFO:                 pip: 22.3
2025-05-15 11:16:40,020:INFO:          setuptools: 65.5.0
2025-05-15 11:16:40,020:INFO:             pycaret: 3.3.2
2025-05-15 11:16:40,020:INFO:             IPython: 9.2.0
2025-05-15 11:16:40,020:INFO:          ipywidgets: 8.1.7
2025-05-15 11:16:40,020:INFO:                tqdm: 4.67.1
2025-05-15 11:16:40,020:INFO:               numpy: 1.26.4
2025-05-15 11:16:40,020:INFO:              pandas: 2.1.4
2025-05-15 11:16:40,020:INFO:              jinja2: 3.1.6
2025-05-15 11:16:40,020:INFO:               scipy: 1.11.4
2025-05-15 11:16:40,020:INFO:              joblib: 1.3.2
2025-05-15 11:16:40,020:INFO:             sklearn: 1.4.2
2025-05-15 11:16:40,020:INFO:                pyod: 2.0.5
2025-05-15 11:16:40,020:INFO:            imblearn: 0.13.0
2025-05-15 11:16:40,020:INFO:   category_encoders: 2.7.0
2025-05-15 11:16:40,020:INFO:            lightgbm: 4.6.0
2025-05-15 11:16:40,020:INFO:               numba: 0.61.2
2025-05-15 11:16:40,020:INFO:            requests: 2.32.3
2025-05-15 11:16:40,020:INFO:          matplotlib: 3.7.5
2025-05-15 11:16:40,020:INFO:          scikitplot: 0.3.7
2025-05-15 11:16:40,020:INFO:         yellowbrick: 1.5
2025-05-15 11:16:40,020:INFO:              plotly: 5.24.1
2025-05-15 11:16:40,020:INFO:    plotly-resampler: Not installed
2025-05-15 11:16:40,020:INFO:             kaleido: 0.2.1
2025-05-15 11:16:40,020:INFO:           schemdraw: 0.15
2025-05-15 11:16:40,020:INFO:         statsmodels: 0.14.4
2025-05-15 11:16:40,020:INFO:              sktime: 0.26.0
2025-05-15 11:16:40,020:INFO:               tbats: 1.1.3
2025-05-15 11:16:40,020:INFO:            pmdarima: 2.0.4
2025-05-15 11:16:40,020:INFO:              psutil: 7.0.0
2025-05-15 11:16:40,020:INFO:          markupsafe: 3.0.2
2025-05-15 11:16:40,020:INFO:             pickle5: Not installed
2025-05-15 11:16:40,020:INFO:         cloudpickle: 3.1.1
2025-05-15 11:16:40,020:INFO:         deprecation: 2.1.0
2025-05-15 11:16:40,020:INFO:              xxhash: 3.5.0
2025-05-15 11:16:40,020:INFO:           wurlitzer: 3.1.1
2025-05-15 11:16:40,020:INFO:PyCaret optional dependencies:
2025-05-15 11:16:40,020:INFO:                shap: 0.47.2
2025-05-15 11:16:40,020:INFO:           interpret: Not installed
2025-05-15 11:16:40,020:INFO:                umap: Not installed
2025-05-15 11:16:40,020:INFO:     ydata_profiling: Not installed
2025-05-15 11:16:40,021:INFO:  explainerdashboard: Not installed
2025-05-15 11:16:40,021:INFO:             autoviz: Not installed
2025-05-15 11:16:40,021:INFO:           fairlearn: Not installed
2025-05-15 11:16:40,021:INFO:          deepchecks: Not installed
2025-05-15 11:16:40,021:INFO:             xgboost: Not installed
2025-05-15 11:16:40,021:INFO:            catboost: 1.2.8
2025-05-15 11:16:40,021:INFO:              kmodes: Not installed
2025-05-15 11:16:40,021:INFO:             mlxtend: Not installed
2025-05-15 11:16:40,021:INFO:       statsforecast: Not installed
2025-05-15 11:16:40,021:INFO:        tune_sklearn: Not installed
2025-05-15 11:16:40,021:INFO:                 ray: Not installed
2025-05-15 11:16:40,021:INFO:            hyperopt: Not installed
2025-05-15 11:16:40,021:INFO:              optuna: 4.3.0
2025-05-15 11:16:40,021:INFO:               skopt: Not installed
2025-05-15 11:16:40,021:INFO:              mlflow: Not installed
2025-05-15 11:16:40,021:INFO:              gradio: Not installed
2025-05-15 11:16:40,021:INFO:             fastapi: Not installed
2025-05-15 11:16:40,021:INFO:             uvicorn: Not installed
2025-05-15 11:16:40,021:INFO:              m2cgen: Not installed
2025-05-15 11:16:40,021:INFO:           evidently: Not installed
2025-05-15 11:16:40,021:INFO:               fugue: Not installed
2025-05-15 11:16:40,021:INFO:           streamlit: Not installed
2025-05-15 11:16:40,021:INFO:             prophet: Not installed
2025-05-15 11:16:40,021:INFO:None
2025-05-15 11:16:40,021:INFO:Set up data.
2025-05-15 11:16:40,068:INFO:Set up folding strategy.
2025-05-15 11:16:40,068:INFO:Set up train/test split.
2025-05-15 11:16:40,086:INFO:Set up index.
2025-05-15 11:16:40,086:INFO:Assigning column types.
2025-05-15 11:16:40,091:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 11:16:40,109:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:16:40,109:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:16:40,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:16:40,121:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:16:40,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:16:40,140:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:16:40,152:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:16:40,152:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:16:40,152:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 11:16:40,171:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:16:40,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:16:40,182:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:16:40,200:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:16:40,211:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:16:40,212:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:16:40,212:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 11:16:40,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:16:40,241:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:16:40,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:16:40,271:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:16:40,271:INFO:Preparing preprocessing pipeline...
2025-05-15 11:16:40,273:INFO:Set up simple imputation.
2025-05-15 11:16:40,280:INFO:Set up encoding of ordinal features.
2025-05-15 11:16:40,291:INFO:Set up encoding of categorical features.
2025-05-15 11:16:40,291:INFO:Set up imbalanced handling.
2025-05-15 11:16:40,291:INFO:Set up column transformation.
2025-05-15 11:16:40,619:INFO:Finished creating preprocessing pipeline.
2025-05-15 11:16:40,638:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 11:16:40,638:INFO:Creating final display dataframe.
2025-05-15 11:16:40,882:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (87159, 16)
4        Transformed data shape      (133528, 29)
5   Transformed train set shape      (107380, 29)
6    Transformed test set shape       (26148, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              ddc9
2025-05-15 11:16:40,915:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:16:40,915:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:16:40,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:16:40,947:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:16:40,948:INFO:setup() successfully completed in 0.93s...............
2025-05-15 11:45:10,662:INFO:PyCaret ClassificationExperiment
2025-05-15 11:45:10,662:INFO:Logging name: clf-default-name
2025-05-15 11:45:10,662:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 11:45:10,662:INFO:version 3.3.2
2025-05-15 11:45:10,662:INFO:Initializing setup()
2025-05-15 11:45:10,662:INFO:self.USI: 3d56
2025-05-15 11:45:10,662:INFO:self._variable_keys: {'_ml_usecase', 'X', 'gpu_param', 'fix_imbalance', 'X_test', '_available_plots', 'n_jobs_param', 'pipeline', 'memory', 'exp_name_log', 'fold_groups_param', 'target_param', 'fold_generator', 'data', 'y', 'exp_id', 'log_plots_param', 'idx', 'USI', 'y_train', 'is_multiclass', 'html_param', 'fold_shuffle_param', 'X_train', 'gpu_n_jobs_param', 'y_test', 'logging_param', 'seed'}
2025-05-15 11:45:10,662:INFO:Checking environment
2025-05-15 11:45:10,662:INFO:python_version: 3.11.0
2025-05-15 11:45:10,662:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 11:45:10,662:INFO:machine: arm64
2025-05-15 11:45:10,662:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 11:45:10,662:INFO:Memory: svmem(total=17179869184, available=4232773632, percent=75.4, used=7031537664, free=71385088, active=4180934656, inactive=4154425344, wired=2850603008)
2025-05-15 11:45:10,662:INFO:Physical Core: 12
2025-05-15 11:45:10,662:INFO:Logical Core: 12
2025-05-15 11:45:10,662:INFO:Checking libraries
2025-05-15 11:45:10,662:INFO:System:
2025-05-15 11:45:10,662:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 11:45:10,662:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 11:45:10,662:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 11:45:10,662:INFO:PyCaret required dependencies:
2025-05-15 11:45:10,663:INFO:                 pip: 22.3
2025-05-15 11:45:10,663:INFO:          setuptools: 65.5.0
2025-05-15 11:45:10,663:INFO:             pycaret: 3.3.2
2025-05-15 11:45:10,663:INFO:             IPython: 9.2.0
2025-05-15 11:45:10,663:INFO:          ipywidgets: 8.1.7
2025-05-15 11:45:10,663:INFO:                tqdm: 4.67.1
2025-05-15 11:45:10,663:INFO:               numpy: 1.26.4
2025-05-15 11:45:10,663:INFO:              pandas: 2.1.4
2025-05-15 11:45:10,663:INFO:              jinja2: 3.1.6
2025-05-15 11:45:10,663:INFO:               scipy: 1.11.4
2025-05-15 11:45:10,663:INFO:              joblib: 1.3.2
2025-05-15 11:45:10,663:INFO:             sklearn: 1.4.2
2025-05-15 11:45:10,663:INFO:                pyod: 2.0.5
2025-05-15 11:45:10,663:INFO:            imblearn: 0.13.0
2025-05-15 11:45:10,663:INFO:   category_encoders: 2.7.0
2025-05-15 11:45:10,663:INFO:            lightgbm: 4.6.0
2025-05-15 11:45:10,663:INFO:               numba: 0.61.2
2025-05-15 11:45:10,663:INFO:            requests: 2.32.3
2025-05-15 11:45:10,663:INFO:          matplotlib: 3.7.5
2025-05-15 11:45:10,663:INFO:          scikitplot: 0.3.7
2025-05-15 11:45:10,663:INFO:         yellowbrick: 1.5
2025-05-15 11:45:10,663:INFO:              plotly: 5.24.1
2025-05-15 11:45:10,663:INFO:    plotly-resampler: Not installed
2025-05-15 11:45:10,663:INFO:             kaleido: 0.2.1
2025-05-15 11:45:10,663:INFO:           schemdraw: 0.15
2025-05-15 11:45:10,663:INFO:         statsmodels: 0.14.4
2025-05-15 11:45:10,663:INFO:              sktime: 0.26.0
2025-05-15 11:45:10,663:INFO:               tbats: 1.1.3
2025-05-15 11:45:10,663:INFO:            pmdarima: 2.0.4
2025-05-15 11:45:10,663:INFO:              psutil: 7.0.0
2025-05-15 11:45:10,663:INFO:          markupsafe: 3.0.2
2025-05-15 11:45:10,663:INFO:             pickle5: Not installed
2025-05-15 11:45:10,663:INFO:         cloudpickle: 3.1.1
2025-05-15 11:45:10,663:INFO:         deprecation: 2.1.0
2025-05-15 11:45:10,663:INFO:              xxhash: 3.5.0
2025-05-15 11:45:10,663:INFO:           wurlitzer: 3.1.1
2025-05-15 11:45:10,663:INFO:PyCaret optional dependencies:
2025-05-15 11:45:10,663:INFO:                shap: 0.47.2
2025-05-15 11:45:10,663:INFO:           interpret: Not installed
2025-05-15 11:45:10,663:INFO:                umap: Not installed
2025-05-15 11:45:10,663:INFO:     ydata_profiling: Not installed
2025-05-15 11:45:10,663:INFO:  explainerdashboard: Not installed
2025-05-15 11:45:10,663:INFO:             autoviz: Not installed
2025-05-15 11:45:10,663:INFO:           fairlearn: Not installed
2025-05-15 11:45:10,663:INFO:          deepchecks: Not installed
2025-05-15 11:45:10,663:INFO:             xgboost: Not installed
2025-05-15 11:45:10,663:INFO:            catboost: 1.2.8
2025-05-15 11:45:10,663:INFO:              kmodes: Not installed
2025-05-15 11:45:10,663:INFO:             mlxtend: Not installed
2025-05-15 11:45:10,663:INFO:       statsforecast: Not installed
2025-05-15 11:45:10,663:INFO:        tune_sklearn: Not installed
2025-05-15 11:45:10,663:INFO:                 ray: Not installed
2025-05-15 11:45:10,663:INFO:            hyperopt: Not installed
2025-05-15 11:45:10,663:INFO:              optuna: 4.3.0
2025-05-15 11:45:10,663:INFO:               skopt: Not installed
2025-05-15 11:45:10,663:INFO:              mlflow: Not installed
2025-05-15 11:45:10,663:INFO:              gradio: Not installed
2025-05-15 11:45:10,663:INFO:             fastapi: Not installed
2025-05-15 11:45:10,663:INFO:             uvicorn: Not installed
2025-05-15 11:45:10,663:INFO:              m2cgen: Not installed
2025-05-15 11:45:10,663:INFO:           evidently: Not installed
2025-05-15 11:45:10,663:INFO:               fugue: Not installed
2025-05-15 11:45:10,663:INFO:           streamlit: Not installed
2025-05-15 11:45:10,663:INFO:             prophet: Not installed
2025-05-15 11:45:10,663:INFO:None
2025-05-15 11:45:10,663:INFO:Set up data.
2025-05-15 11:45:10,701:INFO:Set up folding strategy.
2025-05-15 11:45:10,701:INFO:Set up train/test split.
2025-05-15 11:45:10,716:INFO:Set up index.
2025-05-15 11:45:10,718:INFO:Assigning column types.
2025-05-15 11:45:10,722:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 11:45:10,739:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:45:10,740:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:45:10,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:45:10,751:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:45:10,769:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:45:10,770:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:45:10,781:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:45:10,782:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:45:10,782:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 11:45:10,802:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:45:10,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:45:10,814:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:45:10,834:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:45:10,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:45:10,846:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:45:10,847:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 11:45:10,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:45:10,878:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:45:10,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:45:10,910:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:45:10,911:INFO:Preparing preprocessing pipeline...
2025-05-15 11:45:10,912:INFO:Set up simple imputation.
2025-05-15 11:45:10,919:INFO:Set up encoding of ordinal features.
2025-05-15 11:45:10,931:INFO:Set up encoding of categorical features.
2025-05-15 11:45:10,931:INFO:Set up imbalanced handling.
2025-05-15 11:45:10,931:INFO:Set up column transformation.
2025-05-15 11:45:11,281:INFO:Finished creating preprocessing pipeline.
2025-05-15 11:45:11,301:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 11:45:11,301:INFO:Creating final display dataframe.
2025-05-15 11:45:11,567:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              3d56
2025-05-15 11:45:11,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:45:11,602:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:45:11,635:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:45:11,636:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:45:11,637:INFO:setup() successfully completed in 0.98s...............
2025-05-15 11:45:11,637:INFO:Initializing compare_models()
2025-05-15 11:45:11,637:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-15 11:45:11,637:INFO:Checking exceptions
2025-05-15 11:45:11,642:INFO:Preparing display monitor
2025-05-15 11:45:11,651:INFO:Initializing Logistic Regression
2025-05-15 11:45:11,651:INFO:Total runtime is 1.8318494160970053e-06 minutes
2025-05-15 11:45:11,652:INFO:SubProcess create_model() called ==================================
2025-05-15 11:45:11,653:INFO:Initializing create_model()
2025-05-15 11:45:11,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:45:11,653:INFO:Checking exceptions
2025-05-15 11:45:11,653:INFO:Importing libraries
2025-05-15 11:45:11,653:INFO:Copying training dataset
2025-05-15 11:45:11,664:INFO:Defining folds
2025-05-15 11:45:11,665:INFO:Declaring metric variables
2025-05-15 11:45:11,666:INFO:Importing untrained model
2025-05-15 11:45:11,667:INFO:Logistic Regression Imported successfully
2025-05-15 11:45:11,669:INFO:Starting cross validation
2025-05-15 11:45:11,671:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:45:17,755:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 11:45:17,761:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 11:45:17,763:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 11:45:17,794:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 11:45:17,807:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 11:45:17,865:INFO:Calculating mean and std
2025-05-15 11:45:17,867:INFO:Creating metrics dataframe
2025-05-15 11:45:17,872:INFO:Uploading results into container
2025-05-15 11:45:17,872:INFO:Uploading model into container now
2025-05-15 11:45:17,873:INFO:_master_model_container: 1
2025-05-15 11:45:17,873:INFO:_display_container: 2
2025-05-15 11:45:17,874:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 11:45:17,874:INFO:create_model() successfully completed......................................
2025-05-15 11:45:18,007:INFO:SubProcess create_model() end ==================================
2025-05-15 11:45:18,007:INFO:Creating metrics dataframe
2025-05-15 11:45:18,010:INFO:Initializing K Neighbors Classifier
2025-05-15 11:45:18,010:INFO:Total runtime is 0.10598678191502889 minutes
2025-05-15 11:45:18,012:INFO:SubProcess create_model() called ==================================
2025-05-15 11:45:18,012:INFO:Initializing create_model()
2025-05-15 11:45:18,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:45:18,012:INFO:Checking exceptions
2025-05-15 11:45:18,012:INFO:Importing libraries
2025-05-15 11:45:18,012:INFO:Copying training dataset
2025-05-15 11:45:18,023:INFO:Defining folds
2025-05-15 11:45:18,023:INFO:Declaring metric variables
2025-05-15 11:45:18,025:INFO:Importing untrained model
2025-05-15 11:45:18,026:INFO:K Neighbors Classifier Imported successfully
2025-05-15 11:45:18,028:INFO:Starting cross validation
2025-05-15 11:45:18,029:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:45:23,981:INFO:Calculating mean and std
2025-05-15 11:45:23,982:INFO:Creating metrics dataframe
2025-05-15 11:45:23,983:INFO:Uploading results into container
2025-05-15 11:45:23,983:INFO:Uploading model into container now
2025-05-15 11:45:23,983:INFO:_master_model_container: 2
2025-05-15 11:45:23,983:INFO:_display_container: 2
2025-05-15 11:45:23,984:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-15 11:45:23,984:INFO:create_model() successfully completed......................................
2025-05-15 11:45:24,064:INFO:SubProcess create_model() end ==================================
2025-05-15 11:45:24,064:INFO:Creating metrics dataframe
2025-05-15 11:45:24,068:INFO:Initializing Naive Bayes
2025-05-15 11:45:24,068:INFO:Total runtime is 0.20694033304850262 minutes
2025-05-15 11:45:24,069:INFO:SubProcess create_model() called ==================================
2025-05-15 11:45:24,069:INFO:Initializing create_model()
2025-05-15 11:45:24,069:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:45:24,069:INFO:Checking exceptions
2025-05-15 11:45:24,069:INFO:Importing libraries
2025-05-15 11:45:24,069:INFO:Copying training dataset
2025-05-15 11:45:24,081:INFO:Defining folds
2025-05-15 11:45:24,081:INFO:Declaring metric variables
2025-05-15 11:45:24,082:INFO:Importing untrained model
2025-05-15 11:45:24,083:INFO:Naive Bayes Imported successfully
2025-05-15 11:45:24,086:INFO:Starting cross validation
2025-05-15 11:45:24,087:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:45:26,381:INFO:Calculating mean and std
2025-05-15 11:45:26,381:INFO:Creating metrics dataframe
2025-05-15 11:45:26,382:INFO:Uploading results into container
2025-05-15 11:45:26,382:INFO:Uploading model into container now
2025-05-15 11:45:26,383:INFO:_master_model_container: 3
2025-05-15 11:45:26,383:INFO:_display_container: 2
2025-05-15 11:45:26,383:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-15 11:45:26,383:INFO:create_model() successfully completed......................................
2025-05-15 11:45:26,448:INFO:SubProcess create_model() end ==================================
2025-05-15 11:45:26,448:INFO:Creating metrics dataframe
2025-05-15 11:45:26,452:INFO:Initializing Decision Tree Classifier
2025-05-15 11:45:26,452:INFO:Total runtime is 0.24667373100916545 minutes
2025-05-15 11:45:26,453:INFO:SubProcess create_model() called ==================================
2025-05-15 11:45:26,453:INFO:Initializing create_model()
2025-05-15 11:45:26,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:45:26,453:INFO:Checking exceptions
2025-05-15 11:45:26,453:INFO:Importing libraries
2025-05-15 11:45:26,453:INFO:Copying training dataset
2025-05-15 11:45:26,464:INFO:Defining folds
2025-05-15 11:45:26,464:INFO:Declaring metric variables
2025-05-15 11:45:26,465:INFO:Importing untrained model
2025-05-15 11:45:26,466:INFO:Decision Tree Classifier Imported successfully
2025-05-15 11:45:26,469:INFO:Starting cross validation
2025-05-15 11:45:26,470:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:45:29,268:INFO:Calculating mean and std
2025-05-15 11:45:29,271:INFO:Creating metrics dataframe
2025-05-15 11:45:29,281:INFO:Uploading results into container
2025-05-15 11:45:29,282:INFO:Uploading model into container now
2025-05-15 11:45:29,283:INFO:_master_model_container: 4
2025-05-15 11:45:29,283:INFO:_display_container: 2
2025-05-15 11:45:29,283:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-15 11:45:29,283:INFO:create_model() successfully completed......................................
2025-05-15 11:45:29,393:INFO:SubProcess create_model() end ==================================
2025-05-15 11:45:29,393:INFO:Creating metrics dataframe
2025-05-15 11:45:29,396:INFO:Initializing SVM - Linear Kernel
2025-05-15 11:45:29,396:INFO:Total runtime is 0.2957514802614848 minutes
2025-05-15 11:45:29,397:INFO:SubProcess create_model() called ==================================
2025-05-15 11:45:29,398:INFO:Initializing create_model()
2025-05-15 11:45:29,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:45:29,398:INFO:Checking exceptions
2025-05-15 11:45:29,398:INFO:Importing libraries
2025-05-15 11:45:29,398:INFO:Copying training dataset
2025-05-15 11:45:29,407:INFO:Defining folds
2025-05-15 11:45:29,407:INFO:Declaring metric variables
2025-05-15 11:45:29,409:INFO:Importing untrained model
2025-05-15 11:45:29,410:INFO:SVM - Linear Kernel Imported successfully
2025-05-15 11:45:29,412:INFO:Starting cross validation
2025-05-15 11:45:29,413:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:45:33,321:INFO:Calculating mean and std
2025-05-15 11:45:33,322:INFO:Creating metrics dataframe
2025-05-15 11:45:33,323:INFO:Uploading results into container
2025-05-15 11:45:33,323:INFO:Uploading model into container now
2025-05-15 11:45:33,323:INFO:_master_model_container: 5
2025-05-15 11:45:33,323:INFO:_display_container: 2
2025-05-15 11:45:33,323:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-15 11:45:33,324:INFO:create_model() successfully completed......................................
2025-05-15 11:45:33,384:INFO:SubProcess create_model() end ==================================
2025-05-15 11:45:33,384:INFO:Creating metrics dataframe
2025-05-15 11:45:33,387:INFO:Initializing Ridge Classifier
2025-05-15 11:45:33,387:INFO:Total runtime is 0.36226476430892945 minutes
2025-05-15 11:45:33,388:INFO:SubProcess create_model() called ==================================
2025-05-15 11:45:33,388:INFO:Initializing create_model()
2025-05-15 11:45:33,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:45:33,389:INFO:Checking exceptions
2025-05-15 11:45:33,389:INFO:Importing libraries
2025-05-15 11:45:33,389:INFO:Copying training dataset
2025-05-15 11:45:33,398:INFO:Defining folds
2025-05-15 11:45:33,398:INFO:Declaring metric variables
2025-05-15 11:45:33,400:INFO:Importing untrained model
2025-05-15 11:45:33,401:INFO:Ridge Classifier Imported successfully
2025-05-15 11:45:33,403:INFO:Starting cross validation
2025-05-15 11:45:33,404:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:45:35,584:INFO:Calculating mean and std
2025-05-15 11:45:35,585:INFO:Creating metrics dataframe
2025-05-15 11:45:35,585:INFO:Uploading results into container
2025-05-15 11:45:35,586:INFO:Uploading model into container now
2025-05-15 11:45:35,586:INFO:_master_model_container: 6
2025-05-15 11:45:35,586:INFO:_display_container: 2
2025-05-15 11:45:35,586:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-15 11:45:35,586:INFO:create_model() successfully completed......................................
2025-05-15 11:45:35,644:INFO:SubProcess create_model() end ==================================
2025-05-15 11:45:35,644:INFO:Creating metrics dataframe
2025-05-15 11:45:35,647:INFO:Initializing Random Forest Classifier
2025-05-15 11:45:35,647:INFO:Total runtime is 0.3999316175778707 minutes
2025-05-15 11:45:35,648:INFO:SubProcess create_model() called ==================================
2025-05-15 11:45:35,648:INFO:Initializing create_model()
2025-05-15 11:45:35,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:45:35,648:INFO:Checking exceptions
2025-05-15 11:45:35,648:INFO:Importing libraries
2025-05-15 11:45:35,648:INFO:Copying training dataset
2025-05-15 11:45:35,658:INFO:Defining folds
2025-05-15 11:45:35,658:INFO:Declaring metric variables
2025-05-15 11:45:35,659:INFO:Importing untrained model
2025-05-15 11:45:35,660:INFO:Random Forest Classifier Imported successfully
2025-05-15 11:45:35,663:INFO:Starting cross validation
2025-05-15 11:45:35,664:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:45:41,550:INFO:Calculating mean and std
2025-05-15 11:45:41,551:INFO:Creating metrics dataframe
2025-05-15 11:45:41,553:INFO:Uploading results into container
2025-05-15 11:45:41,553:INFO:Uploading model into container now
2025-05-15 11:45:41,553:INFO:_master_model_container: 7
2025-05-15 11:45:41,553:INFO:_display_container: 2
2025-05-15 11:45:41,554:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 11:45:41,554:INFO:create_model() successfully completed......................................
2025-05-15 11:45:41,621:INFO:SubProcess create_model() end ==================================
2025-05-15 11:45:41,621:INFO:Creating metrics dataframe
2025-05-15 11:45:41,625:INFO:Initializing Quadratic Discriminant Analysis
2025-05-15 11:45:41,625:INFO:Total runtime is 0.4995576659838359 minutes
2025-05-15 11:45:41,626:INFO:SubProcess create_model() called ==================================
2025-05-15 11:45:41,626:INFO:Initializing create_model()
2025-05-15 11:45:41,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:45:41,626:INFO:Checking exceptions
2025-05-15 11:45:41,626:INFO:Importing libraries
2025-05-15 11:45:41,626:INFO:Copying training dataset
2025-05-15 11:45:41,637:INFO:Defining folds
2025-05-15 11:45:41,637:INFO:Declaring metric variables
2025-05-15 11:45:41,639:INFO:Importing untrained model
2025-05-15 11:45:41,640:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 11:45:41,642:INFO:Starting cross validation
2025-05-15 11:45:41,643:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:45:42,701:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 11:45:42,707:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 11:45:42,708:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 11:45:42,772:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 11:45:42,795:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 11:45:42,798:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:45:42,798:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:45:42,800:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:45:42,851:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:45:42,875:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:45:42,888:INFO:Calculating mean and std
2025-05-15 11:45:42,889:INFO:Creating metrics dataframe
2025-05-15 11:45:42,890:INFO:Uploading results into container
2025-05-15 11:45:42,890:INFO:Uploading model into container now
2025-05-15 11:45:42,890:INFO:_master_model_container: 8
2025-05-15 11:45:42,890:INFO:_display_container: 2
2025-05-15 11:45:42,890:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 11:45:42,890:INFO:create_model() successfully completed......................................
2025-05-15 11:45:42,949:INFO:SubProcess create_model() end ==================================
2025-05-15 11:45:42,949:INFO:Creating metrics dataframe
2025-05-15 11:45:42,953:INFO:Initializing Ada Boost Classifier
2025-05-15 11:45:42,953:INFO:Total runtime is 0.5217005014419556 minutes
2025-05-15 11:45:42,954:INFO:SubProcess create_model() called ==================================
2025-05-15 11:45:42,955:INFO:Initializing create_model()
2025-05-15 11:45:42,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:45:42,955:INFO:Checking exceptions
2025-05-15 11:45:42,955:INFO:Importing libraries
2025-05-15 11:45:42,955:INFO:Copying training dataset
2025-05-15 11:45:42,966:INFO:Defining folds
2025-05-15 11:45:42,966:INFO:Declaring metric variables
2025-05-15 11:45:42,967:INFO:Importing untrained model
2025-05-15 11:45:42,968:INFO:Ada Boost Classifier Imported successfully
2025-05-15 11:45:42,970:INFO:Starting cross validation
2025-05-15 11:45:42,971:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:45:44,036:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 11:45:44,058:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 11:45:44,085:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 11:45:44,093:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 11:45:44,167:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 11:45:46,901:INFO:Calculating mean and std
2025-05-15 11:45:46,901:INFO:Creating metrics dataframe
2025-05-15 11:45:46,902:INFO:Uploading results into container
2025-05-15 11:45:46,902:INFO:Uploading model into container now
2025-05-15 11:45:46,903:INFO:_master_model_container: 9
2025-05-15 11:45:46,903:INFO:_display_container: 2
2025-05-15 11:45:46,903:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-15 11:45:46,903:INFO:create_model() successfully completed......................................
2025-05-15 11:45:46,965:INFO:SubProcess create_model() end ==================================
2025-05-15 11:45:46,965:INFO:Creating metrics dataframe
2025-05-15 11:45:46,969:INFO:Initializing Gradient Boosting Classifier
2025-05-15 11:45:46,969:INFO:Total runtime is 0.5886262814203898 minutes
2025-05-15 11:45:46,970:INFO:SubProcess create_model() called ==================================
2025-05-15 11:45:46,970:INFO:Initializing create_model()
2025-05-15 11:45:46,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:45:46,971:INFO:Checking exceptions
2025-05-15 11:45:46,971:INFO:Importing libraries
2025-05-15 11:45:46,971:INFO:Copying training dataset
2025-05-15 11:45:46,980:INFO:Defining folds
2025-05-15 11:45:46,980:INFO:Declaring metric variables
2025-05-15 11:45:46,981:INFO:Importing untrained model
2025-05-15 11:45:46,982:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 11:45:46,984:INFO:Starting cross validation
2025-05-15 11:45:46,985:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:46:00,580:INFO:Calculating mean and std
2025-05-15 11:46:00,581:INFO:Creating metrics dataframe
2025-05-15 11:46:00,582:INFO:Uploading results into container
2025-05-15 11:46:00,583:INFO:Uploading model into container now
2025-05-15 11:46:00,583:INFO:_master_model_container: 10
2025-05-15 11:46:00,583:INFO:_display_container: 2
2025-05-15 11:46:00,583:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 11:46:00,583:INFO:create_model() successfully completed......................................
2025-05-15 11:46:00,647:INFO:SubProcess create_model() end ==================================
2025-05-15 11:46:00,647:INFO:Creating metrics dataframe
2025-05-15 11:46:00,650:INFO:Initializing Linear Discriminant Analysis
2025-05-15 11:46:00,650:INFO:Total runtime is 0.8166511138280232 minutes
2025-05-15 11:46:00,651:INFO:SubProcess create_model() called ==================================
2025-05-15 11:46:00,652:INFO:Initializing create_model()
2025-05-15 11:46:00,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:46:00,652:INFO:Checking exceptions
2025-05-15 11:46:00,652:INFO:Importing libraries
2025-05-15 11:46:00,652:INFO:Copying training dataset
2025-05-15 11:46:00,661:INFO:Defining folds
2025-05-15 11:46:00,661:INFO:Declaring metric variables
2025-05-15 11:46:00,662:INFO:Importing untrained model
2025-05-15 11:46:00,664:INFO:Linear Discriminant Analysis Imported successfully
2025-05-15 11:46:00,666:INFO:Starting cross validation
2025-05-15 11:46:00,667:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:46:01,866:INFO:Calculating mean and std
2025-05-15 11:46:01,866:INFO:Creating metrics dataframe
2025-05-15 11:46:01,867:INFO:Uploading results into container
2025-05-15 11:46:01,868:INFO:Uploading model into container now
2025-05-15 11:46:01,868:INFO:_master_model_container: 11
2025-05-15 11:46:01,868:INFO:_display_container: 2
2025-05-15 11:46:01,868:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-15 11:46:01,868:INFO:create_model() successfully completed......................................
2025-05-15 11:46:01,922:INFO:SubProcess create_model() end ==================================
2025-05-15 11:46:01,922:INFO:Creating metrics dataframe
2025-05-15 11:46:01,926:INFO:Initializing Extra Trees Classifier
2025-05-15 11:46:01,926:INFO:Total runtime is 0.8379168152809143 minutes
2025-05-15 11:46:01,927:INFO:SubProcess create_model() called ==================================
2025-05-15 11:46:01,928:INFO:Initializing create_model()
2025-05-15 11:46:01,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:46:01,928:INFO:Checking exceptions
2025-05-15 11:46:01,928:INFO:Importing libraries
2025-05-15 11:46:01,928:INFO:Copying training dataset
2025-05-15 11:46:01,937:INFO:Defining folds
2025-05-15 11:46:01,937:INFO:Declaring metric variables
2025-05-15 11:46:01,938:INFO:Importing untrained model
2025-05-15 11:46:01,939:INFO:Extra Trees Classifier Imported successfully
2025-05-15 11:46:01,941:INFO:Starting cross validation
2025-05-15 11:46:01,942:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:46:06,539:INFO:Calculating mean and std
2025-05-15 11:46:06,545:INFO:Creating metrics dataframe
2025-05-15 11:46:06,549:INFO:Uploading results into container
2025-05-15 11:46:06,550:INFO:Uploading model into container now
2025-05-15 11:46:06,551:INFO:_master_model_container: 12
2025-05-15 11:46:06,551:INFO:_display_container: 2
2025-05-15 11:46:06,552:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 11:46:06,552:INFO:create_model() successfully completed......................................
2025-05-15 11:46:06,663:INFO:SubProcess create_model() end ==================================
2025-05-15 11:46:06,663:INFO:Creating metrics dataframe
2025-05-15 11:46:06,668:INFO:Initializing Light Gradient Boosting Machine
2025-05-15 11:46:06,668:INFO:Total runtime is 0.916941777865092 minutes
2025-05-15 11:46:06,669:INFO:SubProcess create_model() called ==================================
2025-05-15 11:46:06,669:INFO:Initializing create_model()
2025-05-15 11:46:06,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:46:06,669:INFO:Checking exceptions
2025-05-15 11:46:06,669:INFO:Importing libraries
2025-05-15 11:46:06,669:INFO:Copying training dataset
2025-05-15 11:46:06,687:INFO:Defining folds
2025-05-15 11:46:06,687:INFO:Declaring metric variables
2025-05-15 11:46:06,688:INFO:Importing untrained model
2025-05-15 11:46:06,689:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 11:46:06,691:INFO:Starting cross validation
2025-05-15 11:46:06,692:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:46:10,825:INFO:Calculating mean and std
2025-05-15 11:46:10,826:INFO:Creating metrics dataframe
2025-05-15 11:46:10,827:INFO:Uploading results into container
2025-05-15 11:46:10,827:INFO:Uploading model into container now
2025-05-15 11:46:10,827:INFO:_master_model_container: 13
2025-05-15 11:46:10,827:INFO:_display_container: 2
2025-05-15 11:46:10,828:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 11:46:10,828:INFO:create_model() successfully completed......................................
2025-05-15 11:46:10,887:INFO:SubProcess create_model() end ==================================
2025-05-15 11:46:10,887:INFO:Creating metrics dataframe
2025-05-15 11:46:10,891:INFO:Initializing CatBoost Classifier
2025-05-15 11:46:10,891:INFO:Total runtime is 0.9873282790184021 minutes
2025-05-15 11:46:10,892:INFO:SubProcess create_model() called ==================================
2025-05-15 11:46:10,892:INFO:Initializing create_model()
2025-05-15 11:46:10,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:46:10,892:INFO:Checking exceptions
2025-05-15 11:46:10,892:INFO:Importing libraries
2025-05-15 11:46:10,892:INFO:Copying training dataset
2025-05-15 11:46:10,902:INFO:Defining folds
2025-05-15 11:46:10,902:INFO:Declaring metric variables
2025-05-15 11:46:10,903:INFO:Importing untrained model
2025-05-15 11:46:10,904:INFO:CatBoost Classifier Imported successfully
2025-05-15 11:46:10,906:INFO:Starting cross validation
2025-05-15 11:46:10,907:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:46:28,321:INFO:Calculating mean and std
2025-05-15 11:46:28,324:INFO:Creating metrics dataframe
2025-05-15 11:46:28,330:INFO:Uploading results into container
2025-05-15 11:46:28,332:INFO:Uploading model into container now
2025-05-15 11:46:28,333:INFO:_master_model_container: 14
2025-05-15 11:46:28,333:INFO:_display_container: 2
2025-05-15 11:46:28,333:INFO:<catboost.core.CatBoostClassifier object at 0x110f91a50>
2025-05-15 11:46:28,333:INFO:create_model() successfully completed......................................
2025-05-15 11:46:28,409:INFO:SubProcess create_model() end ==================================
2025-05-15 11:46:28,409:INFO:Creating metrics dataframe
2025-05-15 11:46:28,414:INFO:Initializing Dummy Classifier
2025-05-15 11:46:28,414:INFO:Total runtime is 1.279381815592448 minutes
2025-05-15 11:46:28,415:INFO:SubProcess create_model() called ==================================
2025-05-15 11:46:28,416:INFO:Initializing create_model()
2025-05-15 11:46:28,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327f79b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:46:28,416:INFO:Checking exceptions
2025-05-15 11:46:28,416:INFO:Importing libraries
2025-05-15 11:46:28,416:INFO:Copying training dataset
2025-05-15 11:46:28,427:INFO:Defining folds
2025-05-15 11:46:28,427:INFO:Declaring metric variables
2025-05-15 11:46:28,429:INFO:Importing untrained model
2025-05-15 11:46:28,430:INFO:Dummy Classifier Imported successfully
2025-05-15 11:46:28,432:INFO:Starting cross validation
2025-05-15 11:46:28,433:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:46:29,510:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:46:29,523:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:46:29,554:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:46:29,570:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:46:29,627:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 11:46:29,635:INFO:Calculating mean and std
2025-05-15 11:46:29,636:INFO:Creating metrics dataframe
2025-05-15 11:46:29,637:INFO:Uploading results into container
2025-05-15 11:46:29,637:INFO:Uploading model into container now
2025-05-15 11:46:29,637:INFO:_master_model_container: 15
2025-05-15 11:46:29,637:INFO:_display_container: 2
2025-05-15 11:46:29,637:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-15 11:46:29,638:INFO:create_model() successfully completed......................................
2025-05-15 11:46:29,705:INFO:SubProcess create_model() end ==================================
2025-05-15 11:46:29,705:INFO:Creating metrics dataframe
2025-05-15 11:46:29,710:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-15 11:46:29,713:INFO:Initializing create_model()
2025-05-15 11:46:29,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:46:29,713:INFO:Checking exceptions
2025-05-15 11:46:29,714:INFO:Importing libraries
2025-05-15 11:46:29,714:INFO:Copying training dataset
2025-05-15 11:46:29,725:INFO:Defining folds
2025-05-15 11:46:29,725:INFO:Declaring metric variables
2025-05-15 11:46:29,725:INFO:Importing untrained model
2025-05-15 11:46:29,725:INFO:Declaring custom model
2025-05-15 11:46:29,726:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 11:46:29,727:INFO:Cross validation set to False
2025-05-15 11:46:29,727:INFO:Fitting Model
2025-05-15 11:46:31,084:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 11:46:31,095:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005291 seconds.
2025-05-15 11:46:31,095:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 11:46:31,095:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 11:46:31,095:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 11:46:31,095:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 11:46:31,096:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 11:46:31,874:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 11:46:31,874:INFO:create_model() successfully completed......................................
2025-05-15 11:46:31,940:INFO:Initializing create_model()
2025-05-15 11:46:31,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:46:31,941:INFO:Checking exceptions
2025-05-15 11:46:31,941:INFO:Importing libraries
2025-05-15 11:46:31,941:INFO:Copying training dataset
2025-05-15 11:46:31,951:INFO:Defining folds
2025-05-15 11:46:31,951:INFO:Declaring metric variables
2025-05-15 11:46:31,951:INFO:Importing untrained model
2025-05-15 11:46:31,951:INFO:Declaring custom model
2025-05-15 11:46:31,951:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 11:46:31,952:INFO:Cross validation set to False
2025-05-15 11:46:31,952:INFO:Fitting Model
2025-05-15 11:46:48,110:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 11:46:48,110:INFO:create_model() successfully completed......................................
2025-05-15 11:46:48,179:INFO:Initializing create_model()
2025-05-15 11:46:48,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:46:48,179:INFO:Checking exceptions
2025-05-15 11:46:48,180:INFO:Importing libraries
2025-05-15 11:46:48,180:INFO:Copying training dataset
2025-05-15 11:46:48,190:INFO:Defining folds
2025-05-15 11:46:48,190:INFO:Declaring metric variables
2025-05-15 11:46:48,190:INFO:Importing untrained model
2025-05-15 11:46:48,190:INFO:Declaring custom model
2025-05-15 11:46:48,191:INFO:Random Forest Classifier Imported successfully
2025-05-15 11:46:48,192:INFO:Cross validation set to False
2025-05-15 11:46:48,192:INFO:Fitting Model
2025-05-15 11:46:50,516:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 11:46:50,516:INFO:create_model() successfully completed......................................
2025-05-15 11:46:50,597:INFO:_master_model_container: 15
2025-05-15 11:46:50,597:INFO:_display_container: 2
2025-05-15 11:46:50,597:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-15 11:46:50,598:INFO:compare_models() successfully completed......................................
2025-05-15 11:46:50,608:INFO:Initializing evaluate_model()
2025-05-15 11:46:50,608:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 11:46:50,615:INFO:Initializing plot_model()
2025-05-15 11:46:50,615:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 11:46:50,615:INFO:Checking exceptions
2025-05-15 11:46:50,619:INFO:Preloading libraries
2025-05-15 11:46:50,621:INFO:Copying training dataset
2025-05-15 11:46:50,621:INFO:Plot type: pipeline
2025-05-15 11:46:50,683:INFO:Visual Rendered Successfully
2025-05-15 11:46:50,744:INFO:plot_model() successfully completed......................................
2025-05-15 11:46:50,745:INFO:Initializing tune_model()
2025-05-15 11:46:50,746:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-15 11:46:50,746:INFO:Checking exceptions
2025-05-15 11:46:50,754:INFO:Copying training dataset
2025-05-15 11:46:50,762:INFO:Checking base model
2025-05-15 11:46:50,762:INFO:Base model : Light Gradient Boosting Machine
2025-05-15 11:46:50,763:INFO:Declaring metric variables
2025-05-15 11:46:50,764:INFO:Defining Hyperparameters
2025-05-15 11:46:50,823:INFO:Tuning with n_jobs=-1
2025-05-15 11:46:50,823:INFO:Initializing RandomizedSearchCV
2025-05-15 11:47:27,283:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-15 11:47:27,286:INFO:Hyperparameter search completed
2025-05-15 11:47:27,287:INFO:SubProcess create_model() called ==================================
2025-05-15 11:47:27,288:INFO:Initializing create_model()
2025-05-15 11:47:27,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3232c8f50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-15 11:47:27,288:INFO:Checking exceptions
2025-05-15 11:47:27,288:INFO:Importing libraries
2025-05-15 11:47:27,288:INFO:Copying training dataset
2025-05-15 11:47:27,306:INFO:Defining folds
2025-05-15 11:47:27,306:INFO:Declaring metric variables
2025-05-15 11:47:27,310:INFO:Importing untrained model
2025-05-15 11:47:27,310:INFO:Declaring custom model
2025-05-15 11:47:27,312:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 11:47:27,315:INFO:Starting cross validation
2025-05-15 11:47:27,317:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:47:34,852:INFO:Calculating mean and std
2025-05-15 11:47:34,855:INFO:Creating metrics dataframe
2025-05-15 11:47:34,863:INFO:Finalizing model
2025-05-15 11:47:35,943:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 11:47:35,943:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 11:47:35,943:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 11:47:35,978:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 11:47:35,979:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 11:47:35,979:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 11:47:35,979:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 11:47:35,993:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005118 seconds.
2025-05-15 11:47:35,993:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 11:47:35,993:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 11:47:35,993:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 11:47:35,994:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 11:47:35,994:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 11:47:37,483:INFO:Uploading results into container
2025-05-15 11:47:37,484:INFO:Uploading model into container now
2025-05-15 11:47:37,484:INFO:_master_model_container: 16
2025-05-15 11:47:37,484:INFO:_display_container: 3
2025-05-15 11:47:37,485:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 11:47:37,485:INFO:create_model() successfully completed......................................
2025-05-15 11:47:37,605:INFO:SubProcess create_model() end ==================================
2025-05-15 11:47:37,605:INFO:choose_better activated
2025-05-15 11:47:37,607:INFO:SubProcess create_model() called ==================================
2025-05-15 11:47:37,607:INFO:Initializing create_model()
2025-05-15 11:47:37,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:47:37,607:INFO:Checking exceptions
2025-05-15 11:47:37,608:INFO:Importing libraries
2025-05-15 11:47:37,608:INFO:Copying training dataset
2025-05-15 11:47:37,619:INFO:Defining folds
2025-05-15 11:47:37,619:INFO:Declaring metric variables
2025-05-15 11:47:37,619:INFO:Importing untrained model
2025-05-15 11:47:37,619:INFO:Declaring custom model
2025-05-15 11:47:37,619:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 11:47:37,619:INFO:Starting cross validation
2025-05-15 11:47:37,620:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:47:41,535:INFO:Calculating mean and std
2025-05-15 11:47:41,535:INFO:Creating metrics dataframe
2025-05-15 11:47:41,536:INFO:Finalizing model
2025-05-15 11:47:42,583:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 11:47:42,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008742 seconds.
2025-05-15 11:47:42,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 11:47:42,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 11:47:42,596:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 11:47:42,596:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 11:47:42,596:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 11:47:43,538:INFO:Uploading results into container
2025-05-15 11:47:43,539:INFO:Uploading model into container now
2025-05-15 11:47:43,539:INFO:_master_model_container: 17
2025-05-15 11:47:43,539:INFO:_display_container: 4
2025-05-15 11:47:43,540:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 11:47:43,540:INFO:create_model() successfully completed......................................
2025-05-15 11:47:43,614:INFO:SubProcess create_model() end ==================================
2025-05-15 11:47:43,614:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-15 11:47:43,614:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-15 11:47:43,615:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-15 11:47:43,615:INFO:choose_better completed
2025-05-15 11:47:43,619:INFO:_master_model_container: 17
2025-05-15 11:47:43,619:INFO:_display_container: 3
2025-05-15 11:47:43,619:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 11:47:43,620:INFO:tune_model() successfully completed......................................
2025-05-15 11:47:43,708:INFO:Initializing evaluate_model()
2025-05-15 11:47:43,709:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 11:47:43,718:INFO:Initializing plot_model()
2025-05-15 11:47:43,718:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 11:47:43,718:INFO:Checking exceptions
2025-05-15 11:47:43,722:INFO:Preloading libraries
2025-05-15 11:47:43,725:INFO:Copying training dataset
2025-05-15 11:47:43,725:INFO:Plot type: pipeline
2025-05-15 11:47:43,791:INFO:Visual Rendered Successfully
2025-05-15 11:47:43,865:INFO:plot_model() successfully completed......................................
2025-05-15 11:47:43,867:INFO:Initializing interpret_model()
2025-05-15 11:47:43,868:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3318f7690>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-15 11:47:43,868:INFO:Checking exceptions
2025-05-15 11:47:43,868:INFO:Soft dependency imported: shap: 0.47.2
2025-05-15 11:47:43,974:INFO:plot type: summary
2025-05-15 11:47:43,975:INFO:Creating TreeExplainer
2025-05-15 11:47:44,052:INFO:Compiling shap values
2025-05-15 11:47:45,444:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray
  warnings.warn(

2025-05-15 11:47:45,444:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-05-15 11:47:46,741:INFO:Visual Rendered Successfully
2025-05-15 11:47:46,741:INFO:interpret_model() successfully completed......................................
2025-05-15 11:47:46,807:INFO:PyCaret ClassificationExperiment
2025-05-15 11:47:46,807:INFO:Logging name: clf-default-name
2025-05-15 11:47:46,807:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 11:47:46,807:INFO:version 3.3.2
2025-05-15 11:47:46,807:INFO:Initializing setup()
2025-05-15 11:47:46,807:INFO:self.USI: feff
2025-05-15 11:47:46,807:INFO:self._variable_keys: {'_ml_usecase', 'X', 'gpu_param', 'fix_imbalance', 'X_test', '_available_plots', 'n_jobs_param', 'pipeline', 'memory', 'exp_name_log', 'fold_groups_param', 'target_param', 'fold_generator', 'data', 'y', 'exp_id', 'log_plots_param', 'idx', 'USI', 'y_train', 'is_multiclass', 'html_param', 'fold_shuffle_param', 'X_train', 'gpu_n_jobs_param', 'y_test', 'logging_param', 'seed'}
2025-05-15 11:47:46,807:INFO:Checking environment
2025-05-15 11:47:46,807:INFO:python_version: 3.11.0
2025-05-15 11:47:46,807:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 11:47:46,807:INFO:machine: arm64
2025-05-15 11:47:46,807:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 11:47:46,807:INFO:Memory: svmem(total=17179869184, available=3488317440, percent=79.7, used=6076481536, free=64585728, active=3444867072, inactive=3364831232, wired=2631614464)
2025-05-15 11:47:46,808:INFO:Physical Core: 12
2025-05-15 11:47:46,808:INFO:Logical Core: 12
2025-05-15 11:47:46,808:INFO:Checking libraries
2025-05-15 11:47:46,808:INFO:System:
2025-05-15 11:47:46,808:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 11:47:46,808:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 11:47:46,808:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 11:47:46,808:INFO:PyCaret required dependencies:
2025-05-15 11:47:46,808:INFO:                 pip: 22.3
2025-05-15 11:47:46,808:INFO:          setuptools: 65.5.0
2025-05-15 11:47:46,808:INFO:             pycaret: 3.3.2
2025-05-15 11:47:46,808:INFO:             IPython: 9.2.0
2025-05-15 11:47:46,808:INFO:          ipywidgets: 8.1.7
2025-05-15 11:47:46,808:INFO:                tqdm: 4.67.1
2025-05-15 11:47:46,808:INFO:               numpy: 1.26.4
2025-05-15 11:47:46,808:INFO:              pandas: 2.1.4
2025-05-15 11:47:46,808:INFO:              jinja2: 3.1.6
2025-05-15 11:47:46,808:INFO:               scipy: 1.11.4
2025-05-15 11:47:46,808:INFO:              joblib: 1.3.2
2025-05-15 11:47:46,808:INFO:             sklearn: 1.4.2
2025-05-15 11:47:46,808:INFO:                pyod: 2.0.5
2025-05-15 11:47:46,808:INFO:            imblearn: 0.13.0
2025-05-15 11:47:46,808:INFO:   category_encoders: 2.7.0
2025-05-15 11:47:46,808:INFO:            lightgbm: 4.6.0
2025-05-15 11:47:46,808:INFO:               numba: 0.61.2
2025-05-15 11:47:46,808:INFO:            requests: 2.32.3
2025-05-15 11:47:46,808:INFO:          matplotlib: 3.7.5
2025-05-15 11:47:46,808:INFO:          scikitplot: 0.3.7
2025-05-15 11:47:46,808:INFO:         yellowbrick: 1.5
2025-05-15 11:47:46,808:INFO:              plotly: 5.24.1
2025-05-15 11:47:46,808:INFO:    plotly-resampler: Not installed
2025-05-15 11:47:46,808:INFO:             kaleido: 0.2.1
2025-05-15 11:47:46,808:INFO:           schemdraw: 0.15
2025-05-15 11:47:46,808:INFO:         statsmodels: 0.14.4
2025-05-15 11:47:46,808:INFO:              sktime: 0.26.0
2025-05-15 11:47:46,808:INFO:               tbats: 1.1.3
2025-05-15 11:47:46,808:INFO:            pmdarima: 2.0.4
2025-05-15 11:47:46,808:INFO:              psutil: 7.0.0
2025-05-15 11:47:46,808:INFO:          markupsafe: 3.0.2
2025-05-15 11:47:46,808:INFO:             pickle5: Not installed
2025-05-15 11:47:46,808:INFO:         cloudpickle: 3.1.1
2025-05-15 11:47:46,808:INFO:         deprecation: 2.1.0
2025-05-15 11:47:46,808:INFO:              xxhash: 3.5.0
2025-05-15 11:47:46,808:INFO:           wurlitzer: 3.1.1
2025-05-15 11:47:46,808:INFO:PyCaret optional dependencies:
2025-05-15 11:47:46,808:INFO:                shap: 0.47.2
2025-05-15 11:47:46,808:INFO:           interpret: Not installed
2025-05-15 11:47:46,808:INFO:                umap: Not installed
2025-05-15 11:47:46,808:INFO:     ydata_profiling: Not installed
2025-05-15 11:47:46,808:INFO:  explainerdashboard: Not installed
2025-05-15 11:47:46,808:INFO:             autoviz: Not installed
2025-05-15 11:47:46,808:INFO:           fairlearn: Not installed
2025-05-15 11:47:46,808:INFO:          deepchecks: Not installed
2025-05-15 11:47:46,808:INFO:             xgboost: Not installed
2025-05-15 11:47:46,808:INFO:            catboost: 1.2.8
2025-05-15 11:47:46,808:INFO:              kmodes: Not installed
2025-05-15 11:47:46,808:INFO:             mlxtend: Not installed
2025-05-15 11:47:46,808:INFO:       statsforecast: Not installed
2025-05-15 11:47:46,808:INFO:        tune_sklearn: Not installed
2025-05-15 11:47:46,808:INFO:                 ray: Not installed
2025-05-15 11:47:46,808:INFO:            hyperopt: Not installed
2025-05-15 11:47:46,808:INFO:              optuna: 4.3.0
2025-05-15 11:47:46,808:INFO:               skopt: Not installed
2025-05-15 11:47:46,808:INFO:              mlflow: Not installed
2025-05-15 11:47:46,808:INFO:              gradio: Not installed
2025-05-15 11:47:46,808:INFO:             fastapi: Not installed
2025-05-15 11:47:46,808:INFO:             uvicorn: Not installed
2025-05-15 11:47:46,808:INFO:              m2cgen: Not installed
2025-05-15 11:47:46,808:INFO:           evidently: Not installed
2025-05-15 11:47:46,808:INFO:               fugue: Not installed
2025-05-15 11:47:46,808:INFO:           streamlit: Not installed
2025-05-15 11:47:46,808:INFO:             prophet: Not installed
2025-05-15 11:47:46,808:INFO:None
2025-05-15 11:47:46,808:INFO:Set up data.
2025-05-15 11:47:46,855:INFO:Set up folding strategy.
2025-05-15 11:47:46,855:INFO:Set up train/test split.
2025-05-15 11:47:46,871:INFO:Set up index.
2025-05-15 11:47:46,872:INFO:Assigning column types.
2025-05-15 11:47:46,876:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 11:47:46,894:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:47:46,895:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:47:46,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:46,906:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:47:46,925:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:47:46,925:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:47:46,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:46,936:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:47:46,937:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 11:47:46,955:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:47:46,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:46,966:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:47:46,985:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:47:46,996:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:46,997:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:47:46,997:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 11:47:47,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:47,026:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:47:47,056:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:47,056:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:47:47,056:INFO:Preparing preprocessing pipeline...
2025-05-15 11:47:47,057:INFO:Set up simple imputation.
2025-05-15 11:47:47,064:INFO:Set up encoding of ordinal features.
2025-05-15 11:47:47,075:INFO:Set up encoding of categorical features.
2025-05-15 11:47:47,075:INFO:Set up imbalanced handling.
2025-05-15 11:47:47,075:INFO:Set up column transformation.
2025-05-15 11:47:47,426:INFO:Finished creating preprocessing pipeline.
2025-05-15 11:47:47,447:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 11:47:47,447:INFO:Creating final display dataframe.
2025-05-15 11:47:47,693:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (87159, 16)
4        Transformed data shape      (133528, 29)
5   Transformed train set shape      (107380, 29)
6    Transformed test set shape       (26148, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              feff
2025-05-15 11:47:47,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:47,726:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:47:47,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:47,756:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:47:47,757:INFO:setup() successfully completed in 0.95s...............
2025-05-15 11:47:47,761:INFO:Initializing create_model()
2025-05-15 11:47:47,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x324dc1150>, estimator=LGBMClassifier, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:47:47,761:INFO:Checking exceptions
2025-05-15 11:47:47,761:INFO:Initializing create_model()
2025-05-15 11:47:47,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x324dc1150>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:47:47,761:INFO:Checking exceptions
2025-05-15 11:47:47,766:INFO:Importing libraries
2025-05-15 11:47:47,766:INFO:Copying training dataset
2025-05-15 11:47:47,778:INFO:Defining folds
2025-05-15 11:47:47,778:INFO:Declaring metric variables
2025-05-15 11:47:47,779:INFO:Importing untrained model
2025-05-15 11:47:47,780:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 11:47:47,782:INFO:Starting cross validation
2025-05-15 11:47:47,783:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 11:47:56,503:INFO:Calculating mean and std
2025-05-15 11:47:56,506:INFO:Creating metrics dataframe
2025-05-15 11:47:56,512:INFO:Finalizing model
2025-05-15 11:47:57,833:INFO:[LightGBM] [Info] Number of positive: 53690, number of negative: 53690
2025-05-15 11:47:57,850:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010736 seconds.
2025-05-15 11:47:57,850:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 11:47:57,850:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 11:47:57,850:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 11:47:57,850:INFO:[LightGBM] [Info] Number of data points in the train set: 107380, number of used features: 28
2025-05-15 11:47:57,850:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 11:47:58,631:INFO:Uploading results into container
2025-05-15 11:47:58,631:INFO:Uploading model into container now
2025-05-15 11:47:58,635:INFO:_master_model_container: 1
2025-05-15 11:47:58,635:INFO:_display_container: 2
2025-05-15 11:47:58,636:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 11:47:58,636:INFO:create_model() successfully completed......................................
2025-05-15 11:47:58,771:INFO:Initializing save_model()
2025-05-15 11:47:58,771:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-15 11:47:58,771:INFO:Adding model into prep_pipe
2025-05-15 11:47:58,777:INFO:final_cancer_model.pkl saved in current working directory
2025-05-15 11:47:58,797:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 11:47:58,797:INFO:save_model() successfully completed......................................
2025-05-15 11:47:58,852:INFO:Initializing predict_model()
2025-05-15 11:47:58,852:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x324dc1150>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x331f47f60>)
2025-05-15 11:47:58,852:INFO:Checking exceptions
2025-05-15 11:47:58,852:INFO:Preloading libraries
2025-05-15 11:47:58,853:INFO:Set up data.
2025-05-15 11:47:58,878:INFO:Set up index.
2025-05-15 11:47:59,087:INFO:PyCaret ClassificationExperiment
2025-05-15 11:47:59,087:INFO:Logging name: clf-default-name
2025-05-15 11:47:59,087:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 11:47:59,087:INFO:version 3.3.2
2025-05-15 11:47:59,087:INFO:Initializing setup()
2025-05-15 11:47:59,087:INFO:self.USI: 0569
2025-05-15 11:47:59,087:INFO:self._variable_keys: {'_ml_usecase', 'X', 'gpu_param', 'fix_imbalance', 'X_test', '_available_plots', 'n_jobs_param', 'pipeline', 'memory', 'exp_name_log', 'fold_groups_param', 'target_param', 'fold_generator', 'data', 'y', 'exp_id', 'log_plots_param', 'idx', 'USI', 'y_train', 'is_multiclass', 'html_param', 'fold_shuffle_param', 'X_train', 'gpu_n_jobs_param', 'y_test', 'logging_param', 'seed'}
2025-05-15 11:47:59,087:INFO:Checking environment
2025-05-15 11:47:59,087:INFO:python_version: 3.11.0
2025-05-15 11:47:59,087:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 11:47:59,087:INFO:machine: arm64
2025-05-15 11:47:59,087:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 11:47:59,087:INFO:Memory: svmem(total=17179869184, available=3321577472, percent=80.7, used=5861670912, free=57884672, active=3284647936, inactive=3258892288, wired=2577022976)
2025-05-15 11:47:59,087:INFO:Physical Core: 12
2025-05-15 11:47:59,087:INFO:Logical Core: 12
2025-05-15 11:47:59,087:INFO:Checking libraries
2025-05-15 11:47:59,087:INFO:System:
2025-05-15 11:47:59,087:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 11:47:59,087:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 11:47:59,087:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 11:47:59,087:INFO:PyCaret required dependencies:
2025-05-15 11:47:59,088:INFO:                 pip: 22.3
2025-05-15 11:47:59,088:INFO:          setuptools: 65.5.0
2025-05-15 11:47:59,088:INFO:             pycaret: 3.3.2
2025-05-15 11:47:59,088:INFO:             IPython: 9.2.0
2025-05-15 11:47:59,088:INFO:          ipywidgets: 8.1.7
2025-05-15 11:47:59,088:INFO:                tqdm: 4.67.1
2025-05-15 11:47:59,088:INFO:               numpy: 1.26.4
2025-05-15 11:47:59,088:INFO:              pandas: 2.1.4
2025-05-15 11:47:59,088:INFO:              jinja2: 3.1.6
2025-05-15 11:47:59,088:INFO:               scipy: 1.11.4
2025-05-15 11:47:59,088:INFO:              joblib: 1.3.2
2025-05-15 11:47:59,088:INFO:             sklearn: 1.4.2
2025-05-15 11:47:59,088:INFO:                pyod: 2.0.5
2025-05-15 11:47:59,088:INFO:            imblearn: 0.13.0
2025-05-15 11:47:59,088:INFO:   category_encoders: 2.7.0
2025-05-15 11:47:59,088:INFO:            lightgbm: 4.6.0
2025-05-15 11:47:59,088:INFO:               numba: 0.61.2
2025-05-15 11:47:59,088:INFO:            requests: 2.32.3
2025-05-15 11:47:59,088:INFO:          matplotlib: 3.7.5
2025-05-15 11:47:59,088:INFO:          scikitplot: 0.3.7
2025-05-15 11:47:59,088:INFO:         yellowbrick: 1.5
2025-05-15 11:47:59,088:INFO:              plotly: 5.24.1
2025-05-15 11:47:59,088:INFO:    plotly-resampler: Not installed
2025-05-15 11:47:59,088:INFO:             kaleido: 0.2.1
2025-05-15 11:47:59,088:INFO:           schemdraw: 0.15
2025-05-15 11:47:59,088:INFO:         statsmodels: 0.14.4
2025-05-15 11:47:59,088:INFO:              sktime: 0.26.0
2025-05-15 11:47:59,088:INFO:               tbats: 1.1.3
2025-05-15 11:47:59,088:INFO:            pmdarima: 2.0.4
2025-05-15 11:47:59,088:INFO:              psutil: 7.0.0
2025-05-15 11:47:59,088:INFO:          markupsafe: 3.0.2
2025-05-15 11:47:59,088:INFO:             pickle5: Not installed
2025-05-15 11:47:59,088:INFO:         cloudpickle: 3.1.1
2025-05-15 11:47:59,088:INFO:         deprecation: 2.1.0
2025-05-15 11:47:59,088:INFO:              xxhash: 3.5.0
2025-05-15 11:47:59,088:INFO:           wurlitzer: 3.1.1
2025-05-15 11:47:59,088:INFO:PyCaret optional dependencies:
2025-05-15 11:47:59,088:INFO:                shap: 0.47.2
2025-05-15 11:47:59,088:INFO:           interpret: Not installed
2025-05-15 11:47:59,088:INFO:                umap: Not installed
2025-05-15 11:47:59,088:INFO:     ydata_profiling: Not installed
2025-05-15 11:47:59,088:INFO:  explainerdashboard: Not installed
2025-05-15 11:47:59,088:INFO:             autoviz: Not installed
2025-05-15 11:47:59,088:INFO:           fairlearn: Not installed
2025-05-15 11:47:59,088:INFO:          deepchecks: Not installed
2025-05-15 11:47:59,088:INFO:             xgboost: Not installed
2025-05-15 11:47:59,088:INFO:            catboost: 1.2.8
2025-05-15 11:47:59,088:INFO:              kmodes: Not installed
2025-05-15 11:47:59,088:INFO:             mlxtend: Not installed
2025-05-15 11:47:59,088:INFO:       statsforecast: Not installed
2025-05-15 11:47:59,088:INFO:        tune_sklearn: Not installed
2025-05-15 11:47:59,088:INFO:                 ray: Not installed
2025-05-15 11:47:59,088:INFO:            hyperopt: Not installed
2025-05-15 11:47:59,088:INFO:              optuna: 4.3.0
2025-05-15 11:47:59,088:INFO:               skopt: Not installed
2025-05-15 11:47:59,088:INFO:              mlflow: Not installed
2025-05-15 11:47:59,088:INFO:              gradio: Not installed
2025-05-15 11:47:59,088:INFO:             fastapi: Not installed
2025-05-15 11:47:59,088:INFO:             uvicorn: Not installed
2025-05-15 11:47:59,088:INFO:              m2cgen: Not installed
2025-05-15 11:47:59,088:INFO:           evidently: Not installed
2025-05-15 11:47:59,088:INFO:               fugue: Not installed
2025-05-15 11:47:59,088:INFO:           streamlit: Not installed
2025-05-15 11:47:59,088:INFO:             prophet: Not installed
2025-05-15 11:47:59,088:INFO:None
2025-05-15 11:47:59,088:INFO:Set up data.
2025-05-15 11:47:59,142:INFO:Set up folding strategy.
2025-05-15 11:47:59,142:INFO:Set up train/test split.
2025-05-15 11:47:59,161:INFO:Set up index.
2025-05-15 11:47:59,161:INFO:Assigning column types.
2025-05-15 11:47:59,166:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 11:47:59,184:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:47:59,184:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:47:59,196:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:59,196:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:47:59,214:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:47:59,214:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:47:59,225:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:59,225:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:47:59,226:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 11:47:59,244:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:47:59,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:59,255:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:47:59,274:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:47:59,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:59,285:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:47:59,285:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 11:47:59,315:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:59,315:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:47:59,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:59,346:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:47:59,346:INFO:Preparing preprocessing pipeline...
2025-05-15 11:47:59,347:INFO:Set up simple imputation.
2025-05-15 11:47:59,355:INFO:Set up encoding of ordinal features.
2025-05-15 11:47:59,367:INFO:Set up encoding of categorical features.
2025-05-15 11:47:59,367:INFO:Set up imbalanced handling.
2025-05-15 11:47:59,367:INFO:Set up column transformation.
2025-05-15 11:47:59,701:INFO:Finished creating preprocessing pipeline.
2025-05-15 11:47:59,720:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 11:47:59,720:INFO:Creating final display dataframe.
2025-05-15 11:47:59,953:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (87159, 16)
4        Transformed data shape      (133528, 29)
5   Transformed train set shape      (107380, 29)
6    Transformed test set shape       (26148, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              0569
2025-05-15 11:47:59,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:47:59,986:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:48:00,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:48:00,017:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 11:48:00,018:INFO:setup() successfully completed in 0.93s...............
2025-05-15 11:48:00,018:INFO:Initializing create_model()
2025-05-15 11:48:00,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32750fad0>, estimator=LGBMClassifier, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:48:00,018:INFO:Checking exceptions
2025-05-15 11:48:00,018:INFO:Initializing create_model()
2025-05-15 11:48:00,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32750fad0>, estimator=GradientBoostingClassifier, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:48:00,019:INFO:Checking exceptions
2025-05-15 11:48:00,019:INFO:Initializing create_model()
2025-05-15 11:48:00,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32750fad0>, estimator=DecisionTreeClassifier, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 11:48:00,019:INFO:Checking exceptions
2025-05-15 11:48:00,019:INFO:Initializing predict_model()
2025-05-15 11:48:00,019:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32750fad0>, estimator=<function ensemble_model at 0x326a58860>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x33c4102c0>)
2025-05-15 11:48:00,019:INFO:Checking exceptions
2025-05-15 11:48:00,019:INFO:Preloading libraries
2025-05-15 11:48:00,020:INFO:Set up data.
2025-05-15 11:48:00,037:INFO:Set up index.
2025-05-15 12:52:49,085:INFO:PyCaret ClassificationExperiment
2025-05-15 12:52:49,086:INFO:Logging name: clf-default-name
2025-05-15 12:52:49,086:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 12:52:49,086:INFO:version 3.3.2
2025-05-15 12:52:49,086:INFO:Initializing setup()
2025-05-15 12:52:49,086:INFO:self.USI: a980
2025-05-15 12:52:49,086:INFO:self._variable_keys: {'_ml_usecase', 'X', 'gpu_param', 'fix_imbalance', 'X_test', '_available_plots', 'n_jobs_param', 'pipeline', 'memory', 'exp_name_log', 'fold_groups_param', 'target_param', 'fold_generator', 'data', 'y', 'exp_id', 'log_plots_param', 'idx', 'USI', 'y_train', 'is_multiclass', 'html_param', 'fold_shuffle_param', 'X_train', 'gpu_n_jobs_param', 'y_test', 'logging_param', 'seed'}
2025-05-15 12:52:49,086:INFO:Checking environment
2025-05-15 12:52:49,086:INFO:python_version: 3.11.0
2025-05-15 12:52:49,086:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 12:52:49,086:INFO:machine: arm64
2025-05-15 12:52:49,086:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 12:52:49,086:INFO:Memory: svmem(total=17179869184, available=3721265152, percent=78.3, used=6537543680, free=64176128, active=3671080960, inactive=3420733440, wired=2866462720)
2025-05-15 12:52:49,086:INFO:Physical Core: 12
2025-05-15 12:52:49,086:INFO:Logical Core: 12
2025-05-15 12:52:49,086:INFO:Checking libraries
2025-05-15 12:52:49,086:INFO:System:
2025-05-15 12:52:49,086:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 12:52:49,086:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 12:52:49,086:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 12:52:49,086:INFO:PyCaret required dependencies:
2025-05-15 12:52:49,086:INFO:                 pip: 22.3
2025-05-15 12:52:49,086:INFO:          setuptools: 65.5.0
2025-05-15 12:52:49,086:INFO:             pycaret: 3.3.2
2025-05-15 12:52:49,086:INFO:             IPython: 9.2.0
2025-05-15 12:52:49,086:INFO:          ipywidgets: 8.1.7
2025-05-15 12:52:49,086:INFO:                tqdm: 4.67.1
2025-05-15 12:52:49,086:INFO:               numpy: 1.26.4
2025-05-15 12:52:49,086:INFO:              pandas: 2.1.4
2025-05-15 12:52:49,086:INFO:              jinja2: 3.1.6
2025-05-15 12:52:49,086:INFO:               scipy: 1.11.4
2025-05-15 12:52:49,086:INFO:              joblib: 1.3.2
2025-05-15 12:52:49,086:INFO:             sklearn: 1.4.2
2025-05-15 12:52:49,086:INFO:                pyod: 2.0.5
2025-05-15 12:52:49,086:INFO:            imblearn: 0.13.0
2025-05-15 12:52:49,086:INFO:   category_encoders: 2.7.0
2025-05-15 12:52:49,086:INFO:            lightgbm: 4.6.0
2025-05-15 12:52:49,086:INFO:               numba: 0.61.2
2025-05-15 12:52:49,086:INFO:            requests: 2.32.3
2025-05-15 12:52:49,086:INFO:          matplotlib: 3.7.5
2025-05-15 12:52:49,086:INFO:          scikitplot: 0.3.7
2025-05-15 12:52:49,086:INFO:         yellowbrick: 1.5
2025-05-15 12:52:49,086:INFO:              plotly: 5.24.1
2025-05-15 12:52:49,086:INFO:    plotly-resampler: Not installed
2025-05-15 12:52:49,086:INFO:             kaleido: 0.2.1
2025-05-15 12:52:49,086:INFO:           schemdraw: 0.15
2025-05-15 12:52:49,086:INFO:         statsmodels: 0.14.4
2025-05-15 12:52:49,086:INFO:              sktime: 0.26.0
2025-05-15 12:52:49,086:INFO:               tbats: 1.1.3
2025-05-15 12:52:49,086:INFO:            pmdarima: 2.0.4
2025-05-15 12:52:49,086:INFO:              psutil: 7.0.0
2025-05-15 12:52:49,086:INFO:          markupsafe: 3.0.2
2025-05-15 12:52:49,086:INFO:             pickle5: Not installed
2025-05-15 12:52:49,086:INFO:         cloudpickle: 3.1.1
2025-05-15 12:52:49,086:INFO:         deprecation: 2.1.0
2025-05-15 12:52:49,086:INFO:              xxhash: 3.5.0
2025-05-15 12:52:49,086:INFO:           wurlitzer: 3.1.1
2025-05-15 12:52:49,086:INFO:PyCaret optional dependencies:
2025-05-15 12:52:49,086:INFO:                shap: 0.47.2
2025-05-15 12:52:49,086:INFO:           interpret: Not installed
2025-05-15 12:52:49,086:INFO:                umap: Not installed
2025-05-15 12:52:49,086:INFO:     ydata_profiling: Not installed
2025-05-15 12:52:49,086:INFO:  explainerdashboard: Not installed
2025-05-15 12:52:49,086:INFO:             autoviz: Not installed
2025-05-15 12:52:49,086:INFO:           fairlearn: Not installed
2025-05-15 12:52:49,086:INFO:          deepchecks: Not installed
2025-05-15 12:52:49,086:INFO:             xgboost: Not installed
2025-05-15 12:52:49,086:INFO:            catboost: 1.2.8
2025-05-15 12:52:49,086:INFO:              kmodes: Not installed
2025-05-15 12:52:49,086:INFO:             mlxtend: Not installed
2025-05-15 12:52:49,087:INFO:       statsforecast: Not installed
2025-05-15 12:52:49,087:INFO:        tune_sklearn: Not installed
2025-05-15 12:52:49,087:INFO:                 ray: Not installed
2025-05-15 12:52:49,087:INFO:            hyperopt: Not installed
2025-05-15 12:52:49,087:INFO:              optuna: 4.3.0
2025-05-15 12:52:49,087:INFO:               skopt: Not installed
2025-05-15 12:52:49,087:INFO:              mlflow: Not installed
2025-05-15 12:52:49,087:INFO:              gradio: Not installed
2025-05-15 12:52:49,087:INFO:             fastapi: Not installed
2025-05-15 12:52:49,087:INFO:             uvicorn: Not installed
2025-05-15 12:52:49,087:INFO:              m2cgen: Not installed
2025-05-15 12:52:49,087:INFO:           evidently: Not installed
2025-05-15 12:52:49,087:INFO:               fugue: Not installed
2025-05-15 12:52:49,087:INFO:           streamlit: Not installed
2025-05-15 12:52:49,087:INFO:             prophet: Not installed
2025-05-15 12:52:49,087:INFO:None
2025-05-15 12:52:49,087:INFO:Set up data.
2025-05-15 12:52:49,118:INFO:Set up folding strategy.
2025-05-15 12:52:49,118:INFO:Set up train/test split.
2025-05-15 12:52:49,134:INFO:Set up index.
2025-05-15 12:52:49,134:INFO:Assigning column types.
2025-05-15 12:52:49,138:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 12:52:49,155:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:52:49,156:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:52:49,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:52:49,168:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:52:49,187:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:52:49,187:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:52:49,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:52:49,199:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:52:49,199:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 12:52:49,218:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:52:49,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:52:49,231:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:52:49,252:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:52:49,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:52:49,268:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:52:49,268:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 12:52:49,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:52:49,298:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:52:49,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:52:49,329:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:52:49,329:INFO:Preparing preprocessing pipeline...
2025-05-15 12:52:49,331:INFO:Set up simple imputation.
2025-05-15 12:52:49,337:INFO:Set up encoding of ordinal features.
2025-05-15 12:52:49,348:INFO:Set up encoding of categorical features.
2025-05-15 12:52:49,348:INFO:Set up imbalanced handling.
2025-05-15 12:52:49,348:INFO:Set up column transformation.
2025-05-15 12:52:49,639:INFO:Finished creating preprocessing pipeline.
2025-05-15 12:52:49,659:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 12:52:49,659:INFO:Creating final display dataframe.
2025-05-15 12:52:49,889:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              a980
2025-05-15 12:52:49,922:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:52:49,923:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:52:49,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:52:49,954:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:52:49,955:INFO:setup() successfully completed in 0.88s...............
2025-05-15 12:52:49,956:INFO:Initializing compare_models()
2025-05-15 12:52:49,956:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-15 12:52:49,956:INFO:Checking exceptions
2025-05-15 12:52:49,961:INFO:Preparing display monitor
2025-05-15 12:52:49,970:INFO:Initializing Logistic Regression
2025-05-15 12:52:49,971:INFO:Total runtime is 1.5656153361002604e-06 minutes
2025-05-15 12:52:49,972:INFO:SubProcess create_model() called ==================================
2025-05-15 12:52:49,972:INFO:Initializing create_model()
2025-05-15 12:52:49,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:52:49,972:INFO:Checking exceptions
2025-05-15 12:52:49,972:INFO:Importing libraries
2025-05-15 12:52:49,972:INFO:Copying training dataset
2025-05-15 12:52:49,984:INFO:Defining folds
2025-05-15 12:52:49,984:INFO:Declaring metric variables
2025-05-15 12:52:49,985:INFO:Importing untrained model
2025-05-15 12:52:49,986:INFO:Logistic Regression Imported successfully
2025-05-15 12:52:49,989:INFO:Starting cross validation
2025-05-15 12:52:49,990:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:52:56,321:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 12:52:56,371:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 12:52:56,403:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 12:52:56,412:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 12:52:56,476:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 12:52:56,552:INFO:Calculating mean and std
2025-05-15 12:52:56,556:INFO:Creating metrics dataframe
2025-05-15 12:52:56,561:INFO:Uploading results into container
2025-05-15 12:52:56,561:INFO:Uploading model into container now
2025-05-15 12:52:56,562:INFO:_master_model_container: 1
2025-05-15 12:52:56,562:INFO:_display_container: 2
2025-05-15 12:52:56,563:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 12:52:56,563:INFO:create_model() successfully completed......................................
2025-05-15 12:52:56,689:INFO:SubProcess create_model() end ==================================
2025-05-15 12:52:56,689:INFO:Creating metrics dataframe
2025-05-15 12:52:56,692:INFO:Initializing K Neighbors Classifier
2025-05-15 12:52:56,692:INFO:Total runtime is 0.11203213135401408 minutes
2025-05-15 12:52:56,694:INFO:SubProcess create_model() called ==================================
2025-05-15 12:52:56,694:INFO:Initializing create_model()
2025-05-15 12:52:56,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:52:56,694:INFO:Checking exceptions
2025-05-15 12:52:56,694:INFO:Importing libraries
2025-05-15 12:52:56,694:INFO:Copying training dataset
2025-05-15 12:52:56,705:INFO:Defining folds
2025-05-15 12:52:56,705:INFO:Declaring metric variables
2025-05-15 12:52:56,706:INFO:Importing untrained model
2025-05-15 12:52:56,707:INFO:K Neighbors Classifier Imported successfully
2025-05-15 12:52:56,709:INFO:Starting cross validation
2025-05-15 12:52:56,710:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:53:02,699:INFO:Calculating mean and std
2025-05-15 12:53:02,702:INFO:Creating metrics dataframe
2025-05-15 12:53:02,703:INFO:Uploading results into container
2025-05-15 12:53:02,703:INFO:Uploading model into container now
2025-05-15 12:53:02,704:INFO:_master_model_container: 2
2025-05-15 12:53:02,704:INFO:_display_container: 2
2025-05-15 12:53:02,704:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-15 12:53:02,704:INFO:create_model() successfully completed......................................
2025-05-15 12:53:02,776:INFO:SubProcess create_model() end ==================================
2025-05-15 12:53:02,776:INFO:Creating metrics dataframe
2025-05-15 12:53:02,778:INFO:Initializing Naive Bayes
2025-05-15 12:53:02,778:INFO:Total runtime is 0.2134672522544861 minutes
2025-05-15 12:53:02,780:INFO:SubProcess create_model() called ==================================
2025-05-15 12:53:02,780:INFO:Initializing create_model()
2025-05-15 12:53:02,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:53:02,780:INFO:Checking exceptions
2025-05-15 12:53:02,780:INFO:Importing libraries
2025-05-15 12:53:02,780:INFO:Copying training dataset
2025-05-15 12:53:02,790:INFO:Defining folds
2025-05-15 12:53:02,790:INFO:Declaring metric variables
2025-05-15 12:53:02,791:INFO:Importing untrained model
2025-05-15 12:53:02,792:INFO:Naive Bayes Imported successfully
2025-05-15 12:53:02,794:INFO:Starting cross validation
2025-05-15 12:53:02,795:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:53:05,026:INFO:Calculating mean and std
2025-05-15 12:53:05,026:INFO:Creating metrics dataframe
2025-05-15 12:53:05,028:INFO:Uploading results into container
2025-05-15 12:53:05,028:INFO:Uploading model into container now
2025-05-15 12:53:05,028:INFO:_master_model_container: 3
2025-05-15 12:53:05,028:INFO:_display_container: 2
2025-05-15 12:53:05,028:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-15 12:53:05,028:INFO:create_model() successfully completed......................................
2025-05-15 12:53:05,100:INFO:SubProcess create_model() end ==================================
2025-05-15 12:53:05,100:INFO:Creating metrics dataframe
2025-05-15 12:53:05,103:INFO:Initializing Decision Tree Classifier
2025-05-15 12:53:05,103:INFO:Total runtime is 0.2522163987159729 minutes
2025-05-15 12:53:05,105:INFO:SubProcess create_model() called ==================================
2025-05-15 12:53:05,105:INFO:Initializing create_model()
2025-05-15 12:53:05,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:53:05,105:INFO:Checking exceptions
2025-05-15 12:53:05,105:INFO:Importing libraries
2025-05-15 12:53:05,105:INFO:Copying training dataset
2025-05-15 12:53:05,113:INFO:Defining folds
2025-05-15 12:53:05,113:INFO:Declaring metric variables
2025-05-15 12:53:05,114:INFO:Importing untrained model
2025-05-15 12:53:05,116:INFO:Decision Tree Classifier Imported successfully
2025-05-15 12:53:05,118:INFO:Starting cross validation
2025-05-15 12:53:05,119:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:53:07,951:INFO:Calculating mean and std
2025-05-15 12:53:07,954:INFO:Creating metrics dataframe
2025-05-15 12:53:07,957:INFO:Uploading results into container
2025-05-15 12:53:07,957:INFO:Uploading model into container now
2025-05-15 12:53:07,958:INFO:_master_model_container: 4
2025-05-15 12:53:07,958:INFO:_display_container: 2
2025-05-15 12:53:07,958:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-15 12:53:07,959:INFO:create_model() successfully completed......................................
2025-05-15 12:53:08,083:INFO:SubProcess create_model() end ==================================
2025-05-15 12:53:08,083:INFO:Creating metrics dataframe
2025-05-15 12:53:08,087:INFO:Initializing SVM - Linear Kernel
2025-05-15 12:53:08,087:INFO:Total runtime is 0.30193753242492677 minutes
2025-05-15 12:53:08,088:INFO:SubProcess create_model() called ==================================
2025-05-15 12:53:08,088:INFO:Initializing create_model()
2025-05-15 12:53:08,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:53:08,088:INFO:Checking exceptions
2025-05-15 12:53:08,088:INFO:Importing libraries
2025-05-15 12:53:08,089:INFO:Copying training dataset
2025-05-15 12:53:08,103:INFO:Defining folds
2025-05-15 12:53:08,103:INFO:Declaring metric variables
2025-05-15 12:53:08,104:INFO:Importing untrained model
2025-05-15 12:53:08,106:INFO:SVM - Linear Kernel Imported successfully
2025-05-15 12:53:08,108:INFO:Starting cross validation
2025-05-15 12:53:08,109:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:53:11,833:INFO:Calculating mean and std
2025-05-15 12:53:11,834:INFO:Creating metrics dataframe
2025-05-15 12:53:11,835:INFO:Uploading results into container
2025-05-15 12:53:11,835:INFO:Uploading model into container now
2025-05-15 12:53:11,835:INFO:_master_model_container: 5
2025-05-15 12:53:11,835:INFO:_display_container: 2
2025-05-15 12:53:11,835:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-15 12:53:11,835:INFO:create_model() successfully completed......................................
2025-05-15 12:53:11,909:INFO:SubProcess create_model() end ==================================
2025-05-15 12:53:11,909:INFO:Creating metrics dataframe
2025-05-15 12:53:11,912:INFO:Initializing Ridge Classifier
2025-05-15 12:53:11,912:INFO:Total runtime is 0.3656974991162618 minutes
2025-05-15 12:53:11,913:INFO:SubProcess create_model() called ==================================
2025-05-15 12:53:11,914:INFO:Initializing create_model()
2025-05-15 12:53:11,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:53:11,914:INFO:Checking exceptions
2025-05-15 12:53:11,914:INFO:Importing libraries
2025-05-15 12:53:11,914:INFO:Copying training dataset
2025-05-15 12:53:11,928:INFO:Defining folds
2025-05-15 12:53:11,928:INFO:Declaring metric variables
2025-05-15 12:53:11,930:INFO:Importing untrained model
2025-05-15 12:53:11,932:INFO:Ridge Classifier Imported successfully
2025-05-15 12:53:11,934:INFO:Starting cross validation
2025-05-15 12:53:11,935:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:53:13,139:INFO:Calculating mean and std
2025-05-15 12:53:13,143:INFO:Creating metrics dataframe
2025-05-15 12:53:13,146:INFO:Uploading results into container
2025-05-15 12:53:13,146:INFO:Uploading model into container now
2025-05-15 12:53:13,148:INFO:_master_model_container: 6
2025-05-15 12:53:13,148:INFO:_display_container: 2
2025-05-15 12:53:13,149:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-15 12:53:13,149:INFO:create_model() successfully completed......................................
2025-05-15 12:53:13,287:INFO:SubProcess create_model() end ==================================
2025-05-15 12:53:13,288:INFO:Creating metrics dataframe
2025-05-15 12:53:13,291:INFO:Initializing Random Forest Classifier
2025-05-15 12:53:13,291:INFO:Total runtime is 0.388681968053182 minutes
2025-05-15 12:53:13,292:INFO:SubProcess create_model() called ==================================
2025-05-15 12:53:13,293:INFO:Initializing create_model()
2025-05-15 12:53:13,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:53:13,293:INFO:Checking exceptions
2025-05-15 12:53:13,293:INFO:Importing libraries
2025-05-15 12:53:13,293:INFO:Copying training dataset
2025-05-15 12:53:13,309:INFO:Defining folds
2025-05-15 12:53:13,310:INFO:Declaring metric variables
2025-05-15 12:53:13,312:INFO:Importing untrained model
2025-05-15 12:53:13,313:INFO:Random Forest Classifier Imported successfully
2025-05-15 12:53:13,316:INFO:Starting cross validation
2025-05-15 12:53:13,317:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:53:19,750:INFO:Calculating mean and std
2025-05-15 12:53:19,754:INFO:Creating metrics dataframe
2025-05-15 12:53:19,758:INFO:Uploading results into container
2025-05-15 12:53:19,758:INFO:Uploading model into container now
2025-05-15 12:53:19,759:INFO:_master_model_container: 7
2025-05-15 12:53:19,759:INFO:_display_container: 2
2025-05-15 12:53:19,759:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 12:53:19,759:INFO:create_model() successfully completed......................................
2025-05-15 12:53:19,904:INFO:SubProcess create_model() end ==================================
2025-05-15 12:53:19,904:INFO:Creating metrics dataframe
2025-05-15 12:53:19,908:INFO:Initializing Quadratic Discriminant Analysis
2025-05-15 12:53:19,908:INFO:Total runtime is 0.4989558339118958 minutes
2025-05-15 12:53:19,909:INFO:SubProcess create_model() called ==================================
2025-05-15 12:53:19,909:INFO:Initializing create_model()
2025-05-15 12:53:19,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:53:19,909:INFO:Checking exceptions
2025-05-15 12:53:19,909:INFO:Importing libraries
2025-05-15 12:53:19,909:INFO:Copying training dataset
2025-05-15 12:53:19,929:INFO:Defining folds
2025-05-15 12:53:19,929:INFO:Declaring metric variables
2025-05-15 12:53:19,930:INFO:Importing untrained model
2025-05-15 12:53:19,932:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 12:53:19,934:INFO:Starting cross validation
2025-05-15 12:53:19,935:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:53:20,922:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 12:53:21,009:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 12:53:21,019:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 12:53:21,042:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 12:53:21,073:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 12:53:21,104:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 12:53:21,124:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 12:53:21,150:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 12:53:22,432:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 12:53:22,499:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 12:53:22,508:INFO:Calculating mean and std
2025-05-15 12:53:22,508:INFO:Creating metrics dataframe
2025-05-15 12:53:22,509:INFO:Uploading results into container
2025-05-15 12:53:22,509:INFO:Uploading model into container now
2025-05-15 12:53:22,510:INFO:_master_model_container: 8
2025-05-15 12:53:22,510:INFO:_display_container: 2
2025-05-15 12:53:22,510:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 12:53:22,510:INFO:create_model() successfully completed......................................
2025-05-15 12:53:22,585:INFO:SubProcess create_model() end ==================================
2025-05-15 12:53:22,585:INFO:Creating metrics dataframe
2025-05-15 12:53:22,588:INFO:Initializing Ada Boost Classifier
2025-05-15 12:53:22,588:INFO:Total runtime is 0.5436333179473878 minutes
2025-05-15 12:53:22,590:INFO:SubProcess create_model() called ==================================
2025-05-15 12:53:22,590:INFO:Initializing create_model()
2025-05-15 12:53:22,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:53:22,590:INFO:Checking exceptions
2025-05-15 12:53:22,590:INFO:Importing libraries
2025-05-15 12:53:22,590:INFO:Copying training dataset
2025-05-15 12:53:22,599:INFO:Defining folds
2025-05-15 12:53:22,599:INFO:Declaring metric variables
2025-05-15 12:53:22,600:INFO:Importing untrained model
2025-05-15 12:53:22,601:INFO:Ada Boost Classifier Imported successfully
2025-05-15 12:53:22,603:INFO:Starting cross validation
2025-05-15 12:53:22,604:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:53:23,601:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 12:53:23,647:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 12:53:23,652:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 12:53:23,670:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 12:53:23,717:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 12:53:26,559:INFO:Calculating mean and std
2025-05-15 12:53:26,564:INFO:Creating metrics dataframe
2025-05-15 12:53:26,574:INFO:Uploading results into container
2025-05-15 12:53:26,575:INFO:Uploading model into container now
2025-05-15 12:53:26,575:INFO:_master_model_container: 9
2025-05-15 12:53:26,576:INFO:_display_container: 2
2025-05-15 12:53:26,576:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-15 12:53:26,576:INFO:create_model() successfully completed......................................
2025-05-15 12:53:26,713:INFO:SubProcess create_model() end ==================================
2025-05-15 12:53:26,713:INFO:Creating metrics dataframe
2025-05-15 12:53:26,717:INFO:Initializing Gradient Boosting Classifier
2025-05-15 12:53:26,717:INFO:Total runtime is 0.6124423344930015 minutes
2025-05-15 12:53:26,718:INFO:SubProcess create_model() called ==================================
2025-05-15 12:53:26,718:INFO:Initializing create_model()
2025-05-15 12:53:26,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:53:26,718:INFO:Checking exceptions
2025-05-15 12:53:26,718:INFO:Importing libraries
2025-05-15 12:53:26,718:INFO:Copying training dataset
2025-05-15 12:53:26,736:INFO:Defining folds
2025-05-15 12:53:26,736:INFO:Declaring metric variables
2025-05-15 12:53:26,738:INFO:Importing untrained model
2025-05-15 12:53:26,739:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 12:53:26,742:INFO:Starting cross validation
2025-05-15 12:53:26,743:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:53:40,414:INFO:Calculating mean and std
2025-05-15 12:53:40,416:INFO:Creating metrics dataframe
2025-05-15 12:53:40,417:INFO:Uploading results into container
2025-05-15 12:53:40,417:INFO:Uploading model into container now
2025-05-15 12:53:40,418:INFO:_master_model_container: 10
2025-05-15 12:53:40,418:INFO:_display_container: 2
2025-05-15 12:53:40,418:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 12:53:40,418:INFO:create_model() successfully completed......................................
2025-05-15 12:53:40,488:INFO:SubProcess create_model() end ==================================
2025-05-15 12:53:40,488:INFO:Creating metrics dataframe
2025-05-15 12:53:40,491:INFO:Initializing Linear Discriminant Analysis
2025-05-15 12:53:40,491:INFO:Total runtime is 0.8420174479484559 minutes
2025-05-15 12:53:40,493:INFO:SubProcess create_model() called ==================================
2025-05-15 12:53:40,493:INFO:Initializing create_model()
2025-05-15 12:53:40,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:53:40,493:INFO:Checking exceptions
2025-05-15 12:53:40,493:INFO:Importing libraries
2025-05-15 12:53:40,493:INFO:Copying training dataset
2025-05-15 12:53:40,504:INFO:Defining folds
2025-05-15 12:53:40,504:INFO:Declaring metric variables
2025-05-15 12:53:40,506:INFO:Importing untrained model
2025-05-15 12:53:40,507:INFO:Linear Discriminant Analysis Imported successfully
2025-05-15 12:53:40,510:INFO:Starting cross validation
2025-05-15 12:53:40,511:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:53:41,735:INFO:Calculating mean and std
2025-05-15 12:53:41,735:INFO:Creating metrics dataframe
2025-05-15 12:53:41,736:INFO:Uploading results into container
2025-05-15 12:53:41,736:INFO:Uploading model into container now
2025-05-15 12:53:41,736:INFO:_master_model_container: 11
2025-05-15 12:53:41,737:INFO:_display_container: 2
2025-05-15 12:53:41,737:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-15 12:53:41,737:INFO:create_model() successfully completed......................................
2025-05-15 12:53:41,829:INFO:SubProcess create_model() end ==================================
2025-05-15 12:53:41,829:INFO:Creating metrics dataframe
2025-05-15 12:53:41,833:INFO:Initializing Extra Trees Classifier
2025-05-15 12:53:41,833:INFO:Total runtime is 0.8643770654996237 minutes
2025-05-15 12:53:41,834:INFO:SubProcess create_model() called ==================================
2025-05-15 12:53:41,834:INFO:Initializing create_model()
2025-05-15 12:53:41,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:53:41,834:INFO:Checking exceptions
2025-05-15 12:53:41,834:INFO:Importing libraries
2025-05-15 12:53:41,834:INFO:Copying training dataset
2025-05-15 12:53:41,847:INFO:Defining folds
2025-05-15 12:53:41,847:INFO:Declaring metric variables
2025-05-15 12:53:41,848:INFO:Importing untrained model
2025-05-15 12:53:41,849:INFO:Extra Trees Classifier Imported successfully
2025-05-15 12:53:41,851:INFO:Starting cross validation
2025-05-15 12:53:41,852:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:53:46,382:INFO:Calculating mean and std
2025-05-15 12:53:46,386:INFO:Creating metrics dataframe
2025-05-15 12:53:46,390:INFO:Uploading results into container
2025-05-15 12:53:46,390:INFO:Uploading model into container now
2025-05-15 12:53:46,391:INFO:_master_model_container: 12
2025-05-15 12:53:46,391:INFO:_display_container: 2
2025-05-15 12:53:46,392:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 12:53:46,393:INFO:create_model() successfully completed......................................
2025-05-15 12:53:46,541:INFO:SubProcess create_model() end ==================================
2025-05-15 12:53:46,541:INFO:Creating metrics dataframe
2025-05-15 12:53:46,546:INFO:Initializing Light Gradient Boosting Machine
2025-05-15 12:53:46,546:INFO:Total runtime is 0.9429239511489869 minutes
2025-05-15 12:53:46,547:INFO:SubProcess create_model() called ==================================
2025-05-15 12:53:46,547:INFO:Initializing create_model()
2025-05-15 12:53:46,547:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:53:46,547:INFO:Checking exceptions
2025-05-15 12:53:46,547:INFO:Importing libraries
2025-05-15 12:53:46,548:INFO:Copying training dataset
2025-05-15 12:53:46,574:INFO:Defining folds
2025-05-15 12:53:46,574:INFO:Declaring metric variables
2025-05-15 12:53:46,576:INFO:Importing untrained model
2025-05-15 12:53:46,577:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 12:53:46,580:INFO:Starting cross validation
2025-05-15 12:53:46,581:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:53:50,837:INFO:Calculating mean and std
2025-05-15 12:53:50,838:INFO:Creating metrics dataframe
2025-05-15 12:53:50,838:INFO:Uploading results into container
2025-05-15 12:53:50,839:INFO:Uploading model into container now
2025-05-15 12:53:50,839:INFO:_master_model_container: 13
2025-05-15 12:53:50,839:INFO:_display_container: 2
2025-05-15 12:53:50,840:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 12:53:50,840:INFO:create_model() successfully completed......................................
2025-05-15 12:53:50,916:INFO:SubProcess create_model() end ==================================
2025-05-15 12:53:50,916:INFO:Creating metrics dataframe
2025-05-15 12:53:50,921:INFO:Initializing CatBoost Classifier
2025-05-15 12:53:50,921:INFO:Total runtime is 1.015843951702118 minutes
2025-05-15 12:53:50,922:INFO:SubProcess create_model() called ==================================
2025-05-15 12:53:50,923:INFO:Initializing create_model()
2025-05-15 12:53:50,923:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:53:50,923:INFO:Checking exceptions
2025-05-15 12:53:50,923:INFO:Importing libraries
2025-05-15 12:53:50,923:INFO:Copying training dataset
2025-05-15 12:53:50,932:INFO:Defining folds
2025-05-15 12:53:50,932:INFO:Declaring metric variables
2025-05-15 12:53:50,933:INFO:Importing untrained model
2025-05-15 12:53:50,935:INFO:CatBoost Classifier Imported successfully
2025-05-15 12:53:50,937:INFO:Starting cross validation
2025-05-15 12:53:50,938:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:54:07,377:INFO:Calculating mean and std
2025-05-15 12:54:07,380:INFO:Creating metrics dataframe
2025-05-15 12:54:07,384:INFO:Uploading results into container
2025-05-15 12:54:07,384:INFO:Uploading model into container now
2025-05-15 12:54:07,385:INFO:_master_model_container: 14
2025-05-15 12:54:07,385:INFO:_display_container: 2
2025-05-15 12:54:07,386:INFO:<catboost.core.CatBoostClassifier object at 0x3305230d0>
2025-05-15 12:54:07,386:INFO:create_model() successfully completed......................................
2025-05-15 12:54:07,513:INFO:SubProcess create_model() end ==================================
2025-05-15 12:54:07,513:INFO:Creating metrics dataframe
2025-05-15 12:54:07,518:INFO:Initializing Dummy Classifier
2025-05-15 12:54:07,518:INFO:Total runtime is 1.292463000615438 minutes
2025-05-15 12:54:07,520:INFO:SubProcess create_model() called ==================================
2025-05-15 12:54:07,520:INFO:Initializing create_model()
2025-05-15 12:54:07,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330479550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:54:07,520:INFO:Checking exceptions
2025-05-15 12:54:07,520:INFO:Importing libraries
2025-05-15 12:54:07,520:INFO:Copying training dataset
2025-05-15 12:54:07,532:INFO:Defining folds
2025-05-15 12:54:07,532:INFO:Declaring metric variables
2025-05-15 12:54:07,534:INFO:Importing untrained model
2025-05-15 12:54:07,535:INFO:Dummy Classifier Imported successfully
2025-05-15 12:54:07,537:INFO:Starting cross validation
2025-05-15 12:54:07,538:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:54:08,598:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 12:54:08,638:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 12:54:08,690:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 12:54:08,715:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 12:54:08,719:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 12:54:08,729:INFO:Calculating mean and std
2025-05-15 12:54:08,730:INFO:Creating metrics dataframe
2025-05-15 12:54:08,730:INFO:Uploading results into container
2025-05-15 12:54:08,731:INFO:Uploading model into container now
2025-05-15 12:54:08,731:INFO:_master_model_container: 15
2025-05-15 12:54:08,731:INFO:_display_container: 2
2025-05-15 12:54:08,731:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-15 12:54:08,731:INFO:create_model() successfully completed......................................
2025-05-15 12:54:08,798:INFO:SubProcess create_model() end ==================================
2025-05-15 12:54:08,798:INFO:Creating metrics dataframe
2025-05-15 12:54:08,802:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-15 12:54:08,805:INFO:Initializing create_model()
2025-05-15 12:54:08,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:54:08,805:INFO:Checking exceptions
2025-05-15 12:54:08,806:INFO:Importing libraries
2025-05-15 12:54:08,806:INFO:Copying training dataset
2025-05-15 12:54:08,816:INFO:Defining folds
2025-05-15 12:54:08,816:INFO:Declaring metric variables
2025-05-15 12:54:08,816:INFO:Importing untrained model
2025-05-15 12:54:08,816:INFO:Declaring custom model
2025-05-15 12:54:08,816:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 12:54:08,817:INFO:Cross validation set to False
2025-05-15 12:54:08,817:INFO:Fitting Model
2025-05-15 12:54:10,128:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 12:54:10,138:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005049 seconds.
2025-05-15 12:54:10,138:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 12:54:10,138:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 12:54:10,138:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 12:54:10,138:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 12:54:10,139:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 12:54:10,901:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 12:54:10,901:INFO:create_model() successfully completed......................................
2025-05-15 12:54:10,976:INFO:Initializing create_model()
2025-05-15 12:54:10,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:54:10,976:INFO:Checking exceptions
2025-05-15 12:54:10,977:INFO:Importing libraries
2025-05-15 12:54:10,977:INFO:Copying training dataset
2025-05-15 12:54:10,986:INFO:Defining folds
2025-05-15 12:54:10,986:INFO:Declaring metric variables
2025-05-15 12:54:10,986:INFO:Importing untrained model
2025-05-15 12:54:10,986:INFO:Declaring custom model
2025-05-15 12:54:10,986:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 12:54:10,987:INFO:Cross validation set to False
2025-05-15 12:54:10,987:INFO:Fitting Model
2025-05-15 12:54:27,174:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 12:54:27,174:INFO:create_model() successfully completed......................................
2025-05-15 12:54:27,289:INFO:Initializing create_model()
2025-05-15 12:54:27,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:54:27,289:INFO:Checking exceptions
2025-05-15 12:54:27,290:INFO:Importing libraries
2025-05-15 12:54:27,290:INFO:Copying training dataset
2025-05-15 12:54:27,300:INFO:Defining folds
2025-05-15 12:54:27,300:INFO:Declaring metric variables
2025-05-15 12:54:27,300:INFO:Importing untrained model
2025-05-15 12:54:27,300:INFO:Declaring custom model
2025-05-15 12:54:27,300:INFO:Random Forest Classifier Imported successfully
2025-05-15 12:54:27,301:INFO:Cross validation set to False
2025-05-15 12:54:27,301:INFO:Fitting Model
2025-05-15 12:54:29,585:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 12:54:29,585:INFO:create_model() successfully completed......................................
2025-05-15 12:54:29,667:INFO:_master_model_container: 15
2025-05-15 12:54:29,667:INFO:_display_container: 2
2025-05-15 12:54:29,667:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-15 12:54:29,668:INFO:compare_models() successfully completed......................................
2025-05-15 12:54:29,669:INFO:Initializing evaluate_model()
2025-05-15 12:54:29,669:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 12:54:29,676:INFO:Initializing plot_model()
2025-05-15 12:54:29,676:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 12:54:29,676:INFO:Checking exceptions
2025-05-15 12:54:29,680:INFO:Preloading libraries
2025-05-15 12:54:29,681:INFO:Copying training dataset
2025-05-15 12:54:29,681:INFO:Plot type: pipeline
2025-05-15 12:54:29,742:INFO:Visual Rendered Successfully
2025-05-15 12:54:29,819:INFO:plot_model() successfully completed......................................
2025-05-15 12:54:29,821:INFO:Initializing tune_model()
2025-05-15 12:54:29,821:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-15 12:54:29,821:INFO:Checking exceptions
2025-05-15 12:54:29,831:INFO:Copying training dataset
2025-05-15 12:54:29,838:INFO:Checking base model
2025-05-15 12:54:29,838:INFO:Base model : Light Gradient Boosting Machine
2025-05-15 12:54:29,840:INFO:Declaring metric variables
2025-05-15 12:54:29,841:INFO:Defining Hyperparameters
2025-05-15 12:54:29,922:INFO:Tuning with n_jobs=-1
2025-05-15 12:54:29,922:INFO:Initializing RandomizedSearchCV
2025-05-15 12:55:07,135:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-15 12:55:07,137:INFO:Hyperparameter search completed
2025-05-15 12:55:07,138:INFO:SubProcess create_model() called ==================================
2025-05-15 12:55:07,139:INFO:Initializing create_model()
2025-05-15 12:55:07,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33c029b90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-15 12:55:07,139:INFO:Checking exceptions
2025-05-15 12:55:07,139:INFO:Importing libraries
2025-05-15 12:55:07,139:INFO:Copying training dataset
2025-05-15 12:55:07,155:INFO:Defining folds
2025-05-15 12:55:07,155:INFO:Declaring metric variables
2025-05-15 12:55:07,158:INFO:Importing untrained model
2025-05-15 12:55:07,159:INFO:Declaring custom model
2025-05-15 12:55:07,161:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 12:55:07,164:INFO:Starting cross validation
2025-05-15 12:55:07,166:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:55:14,494:INFO:Calculating mean and std
2025-05-15 12:55:14,497:INFO:Creating metrics dataframe
2025-05-15 12:55:14,504:INFO:Finalizing model
2025-05-15 12:55:15,673:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 12:55:15,673:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 12:55:15,673:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 12:55:15,726:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 12:55:15,726:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 12:55:15,726:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 12:55:15,726:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 12:55:15,737:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005643 seconds.
2025-05-15 12:55:15,737:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 12:55:15,737:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 12:55:15,737:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 12:55:15,737:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 12:55:15,738:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 12:55:17,414:INFO:Uploading results into container
2025-05-15 12:55:17,418:INFO:Uploading model into container now
2025-05-15 12:55:17,419:INFO:_master_model_container: 16
2025-05-15 12:55:17,420:INFO:_display_container: 3
2025-05-15 12:55:17,420:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 12:55:17,420:INFO:create_model() successfully completed......................................
2025-05-15 12:55:17,567:INFO:SubProcess create_model() end ==================================
2025-05-15 12:55:17,567:INFO:choose_better activated
2025-05-15 12:55:17,569:INFO:SubProcess create_model() called ==================================
2025-05-15 12:55:17,569:INFO:Initializing create_model()
2025-05-15 12:55:17,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:55:17,569:INFO:Checking exceptions
2025-05-15 12:55:17,570:INFO:Importing libraries
2025-05-15 12:55:17,570:INFO:Copying training dataset
2025-05-15 12:55:17,589:INFO:Defining folds
2025-05-15 12:55:17,589:INFO:Declaring metric variables
2025-05-15 12:55:17,589:INFO:Importing untrained model
2025-05-15 12:55:17,589:INFO:Declaring custom model
2025-05-15 12:55:17,590:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 12:55:17,590:INFO:Starting cross validation
2025-05-15 12:55:17,591:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:55:22,107:INFO:Calculating mean and std
2025-05-15 12:55:22,108:INFO:Creating metrics dataframe
2025-05-15 12:55:22,109:INFO:Finalizing model
2025-05-15 12:55:23,213:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 12:55:23,222:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004640 seconds.
2025-05-15 12:55:23,222:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 12:55:23,222:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 12:55:23,222:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 12:55:23,222:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 12:55:23,222:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 12:55:23,999:INFO:Uploading results into container
2025-05-15 12:55:24,000:INFO:Uploading model into container now
2025-05-15 12:55:24,000:INFO:_master_model_container: 17
2025-05-15 12:55:24,000:INFO:_display_container: 4
2025-05-15 12:55:24,000:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 12:55:24,000:INFO:create_model() successfully completed......................................
2025-05-15 12:55:24,076:INFO:SubProcess create_model() end ==================================
2025-05-15 12:55:24,077:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-15 12:55:24,077:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-15 12:55:24,077:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-15 12:55:24,077:INFO:choose_better completed
2025-05-15 12:55:24,081:INFO:_master_model_container: 17
2025-05-15 12:55:24,081:INFO:_display_container: 3
2025-05-15 12:55:24,082:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 12:55:24,082:INFO:tune_model() successfully completed......................................
2025-05-15 12:55:24,156:INFO:Initializing evaluate_model()
2025-05-15 12:55:24,156:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 12:55:24,164:INFO:Initializing plot_model()
2025-05-15 12:55:24,164:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 12:55:24,164:INFO:Checking exceptions
2025-05-15 12:55:24,168:INFO:Preloading libraries
2025-05-15 12:55:24,171:INFO:Copying training dataset
2025-05-15 12:55:24,171:INFO:Plot type: pipeline
2025-05-15 12:55:24,233:INFO:Visual Rendered Successfully
2025-05-15 12:55:24,321:INFO:plot_model() successfully completed......................................
2025-05-15 12:55:24,323:INFO:Initializing interpret_model()
2025-05-15 12:55:24,323:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e1c950>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-15 12:55:24,323:INFO:Checking exceptions
2025-05-15 12:55:24,323:INFO:Soft dependency imported: shap: 0.47.2
2025-05-15 12:55:24,414:INFO:plot type: summary
2025-05-15 12:55:24,414:INFO:Creating TreeExplainer
2025-05-15 12:55:24,492:INFO:Compiling shap values
2025-05-15 12:55:25,782:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray
  warnings.warn(

2025-05-15 12:55:25,782:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-05-15 12:55:27,070:INFO:Visual Rendered Successfully
2025-05-15 12:55:27,070:INFO:interpret_model() successfully completed......................................
2025-05-15 12:55:27,151:INFO:PyCaret ClassificationExperiment
2025-05-15 12:55:27,151:INFO:Logging name: clf-default-name
2025-05-15 12:55:27,151:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 12:55:27,151:INFO:version 3.3.2
2025-05-15 12:55:27,151:INFO:Initializing setup()
2025-05-15 12:55:27,151:INFO:self.USI: 181a
2025-05-15 12:55:27,151:INFO:self._variable_keys: {'_ml_usecase', 'X', 'gpu_param', 'fix_imbalance', 'X_test', '_available_plots', 'n_jobs_param', 'pipeline', 'memory', 'exp_name_log', 'fold_groups_param', 'target_param', 'fold_generator', 'data', 'y', 'exp_id', 'log_plots_param', 'idx', 'USI', 'y_train', 'is_multiclass', 'html_param', 'fold_shuffle_param', 'X_train', 'gpu_n_jobs_param', 'y_test', 'logging_param', 'seed'}
2025-05-15 12:55:27,151:INFO:Checking environment
2025-05-15 12:55:27,151:INFO:python_version: 3.11.0
2025-05-15 12:55:27,151:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 12:55:27,151:INFO:machine: arm64
2025-05-15 12:55:27,151:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 12:55:27,152:INFO:Memory: svmem(total=17179869184, available=3164553216, percent=81.6, used=5848694784, free=74432512, active=3103883264, inactive=3082698752, wired=2744811520)
2025-05-15 12:55:27,152:INFO:Physical Core: 12
2025-05-15 12:55:27,152:INFO:Logical Core: 12
2025-05-15 12:55:27,152:INFO:Checking libraries
2025-05-15 12:55:27,152:INFO:System:
2025-05-15 12:55:27,152:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 12:55:27,152:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 12:55:27,152:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 12:55:27,152:INFO:PyCaret required dependencies:
2025-05-15 12:55:27,152:INFO:                 pip: 22.3
2025-05-15 12:55:27,152:INFO:          setuptools: 65.5.0
2025-05-15 12:55:27,152:INFO:             pycaret: 3.3.2
2025-05-15 12:55:27,152:INFO:             IPython: 9.2.0
2025-05-15 12:55:27,152:INFO:          ipywidgets: 8.1.7
2025-05-15 12:55:27,152:INFO:                tqdm: 4.67.1
2025-05-15 12:55:27,152:INFO:               numpy: 1.26.4
2025-05-15 12:55:27,152:INFO:              pandas: 2.1.4
2025-05-15 12:55:27,152:INFO:              jinja2: 3.1.6
2025-05-15 12:55:27,152:INFO:               scipy: 1.11.4
2025-05-15 12:55:27,152:INFO:              joblib: 1.3.2
2025-05-15 12:55:27,152:INFO:             sklearn: 1.4.2
2025-05-15 12:55:27,152:INFO:                pyod: 2.0.5
2025-05-15 12:55:27,152:INFO:            imblearn: 0.13.0
2025-05-15 12:55:27,152:INFO:   category_encoders: 2.7.0
2025-05-15 12:55:27,152:INFO:            lightgbm: 4.6.0
2025-05-15 12:55:27,152:INFO:               numba: 0.61.2
2025-05-15 12:55:27,152:INFO:            requests: 2.32.3
2025-05-15 12:55:27,152:INFO:          matplotlib: 3.7.5
2025-05-15 12:55:27,152:INFO:          scikitplot: 0.3.7
2025-05-15 12:55:27,152:INFO:         yellowbrick: 1.5
2025-05-15 12:55:27,152:INFO:              plotly: 5.24.1
2025-05-15 12:55:27,152:INFO:    plotly-resampler: Not installed
2025-05-15 12:55:27,152:INFO:             kaleido: 0.2.1
2025-05-15 12:55:27,152:INFO:           schemdraw: 0.15
2025-05-15 12:55:27,152:INFO:         statsmodels: 0.14.4
2025-05-15 12:55:27,152:INFO:              sktime: 0.26.0
2025-05-15 12:55:27,152:INFO:               tbats: 1.1.3
2025-05-15 12:55:27,152:INFO:            pmdarima: 2.0.4
2025-05-15 12:55:27,152:INFO:              psutil: 7.0.0
2025-05-15 12:55:27,152:INFO:          markupsafe: 3.0.2
2025-05-15 12:55:27,152:INFO:             pickle5: Not installed
2025-05-15 12:55:27,152:INFO:         cloudpickle: 3.1.1
2025-05-15 12:55:27,152:INFO:         deprecation: 2.1.0
2025-05-15 12:55:27,152:INFO:              xxhash: 3.5.0
2025-05-15 12:55:27,152:INFO:           wurlitzer: 3.1.1
2025-05-15 12:55:27,152:INFO:PyCaret optional dependencies:
2025-05-15 12:55:27,152:INFO:                shap: 0.47.2
2025-05-15 12:55:27,152:INFO:           interpret: Not installed
2025-05-15 12:55:27,152:INFO:                umap: Not installed
2025-05-15 12:55:27,152:INFO:     ydata_profiling: Not installed
2025-05-15 12:55:27,152:INFO:  explainerdashboard: Not installed
2025-05-15 12:55:27,152:INFO:             autoviz: Not installed
2025-05-15 12:55:27,152:INFO:           fairlearn: Not installed
2025-05-15 12:55:27,152:INFO:          deepchecks: Not installed
2025-05-15 12:55:27,152:INFO:             xgboost: Not installed
2025-05-15 12:55:27,152:INFO:            catboost: 1.2.8
2025-05-15 12:55:27,152:INFO:              kmodes: Not installed
2025-05-15 12:55:27,152:INFO:             mlxtend: Not installed
2025-05-15 12:55:27,152:INFO:       statsforecast: Not installed
2025-05-15 12:55:27,152:INFO:        tune_sklearn: Not installed
2025-05-15 12:55:27,152:INFO:                 ray: Not installed
2025-05-15 12:55:27,152:INFO:            hyperopt: Not installed
2025-05-15 12:55:27,152:INFO:              optuna: 4.3.0
2025-05-15 12:55:27,152:INFO:               skopt: Not installed
2025-05-15 12:55:27,152:INFO:              mlflow: Not installed
2025-05-15 12:55:27,152:INFO:              gradio: Not installed
2025-05-15 12:55:27,152:INFO:             fastapi: Not installed
2025-05-15 12:55:27,152:INFO:             uvicorn: Not installed
2025-05-15 12:55:27,152:INFO:              m2cgen: Not installed
2025-05-15 12:55:27,152:INFO:           evidently: Not installed
2025-05-15 12:55:27,152:INFO:               fugue: Not installed
2025-05-15 12:55:27,152:INFO:           streamlit: Not installed
2025-05-15 12:55:27,152:INFO:             prophet: Not installed
2025-05-15 12:55:27,152:INFO:None
2025-05-15 12:55:27,152:INFO:Set up data.
2025-05-15 12:55:27,197:INFO:Set up folding strategy.
2025-05-15 12:55:27,197:INFO:Set up train/test split.
2025-05-15 12:55:27,213:INFO:Set up index.
2025-05-15 12:55:27,213:INFO:Assigning column types.
2025-05-15 12:55:27,218:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 12:55:27,236:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:55:27,236:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:55:27,247:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:27,247:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:27,266:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:55:27,266:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:55:27,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:27,278:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:27,278:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 12:55:27,296:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:55:27,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:27,308:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:27,326:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:55:27,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:27,338:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:27,338:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 12:55:27,367:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:27,368:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:27,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:27,398:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:27,398:INFO:Preparing preprocessing pipeline...
2025-05-15 12:55:27,400:INFO:Set up simple imputation.
2025-05-15 12:55:27,407:INFO:Set up encoding of ordinal features.
2025-05-15 12:55:27,420:INFO:Set up encoding of categorical features.
2025-05-15 12:55:27,421:INFO:Set up imbalanced handling.
2025-05-15 12:55:27,421:INFO:Set up column transformation.
2025-05-15 12:55:27,755:INFO:Finished creating preprocessing pipeline.
2025-05-15 12:55:27,774:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 12:55:27,774:INFO:Creating final display dataframe.
2025-05-15 12:55:28,040:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (87159, 16)
4        Transformed data shape      (133528, 29)
5   Transformed train set shape      (107380, 29)
6    Transformed test set shape       (26148, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              181a
2025-05-15 12:55:28,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:28,074:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:28,105:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:28,105:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:28,106:INFO:setup() successfully completed in 0.96s...............
2025-05-15 12:55:28,108:INFO:Initializing create_model()
2025-05-15 12:55:28,108:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32494ded0>, estimator=LGBMClassifier, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:55:28,108:INFO:Checking exceptions
2025-05-15 12:55:28,109:INFO:Initializing create_model()
2025-05-15 12:55:28,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32494ded0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:55:28,109:INFO:Checking exceptions
2025-05-15 12:55:28,114:INFO:Importing libraries
2025-05-15 12:55:28,114:INFO:Copying training dataset
2025-05-15 12:55:28,126:INFO:Defining folds
2025-05-15 12:55:28,126:INFO:Declaring metric variables
2025-05-15 12:55:28,127:INFO:Importing untrained model
2025-05-15 12:55:28,129:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 12:55:28,131:INFO:Starting cross validation
2025-05-15 12:55:28,132:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 12:55:36,815:INFO:Calculating mean and std
2025-05-15 12:55:36,818:INFO:Creating metrics dataframe
2025-05-15 12:55:36,826:INFO:Finalizing model
2025-05-15 12:55:38,183:INFO:[LightGBM] [Info] Number of positive: 53690, number of negative: 53690
2025-05-15 12:55:38,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005949 seconds.
2025-05-15 12:55:38,195:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 12:55:38,195:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 12:55:38,195:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 12:55:38,195:INFO:[LightGBM] [Info] Number of data points in the train set: 107380, number of used features: 28
2025-05-15 12:55:38,195:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 12:55:38,976:INFO:Uploading results into container
2025-05-15 12:55:38,977:INFO:Uploading model into container now
2025-05-15 12:55:38,981:INFO:_master_model_container: 1
2025-05-15 12:55:38,981:INFO:_display_container: 2
2025-05-15 12:55:38,981:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 12:55:38,982:INFO:create_model() successfully completed......................................
2025-05-15 12:55:39,133:INFO:Initializing save_model()
2025-05-15 12:55:39,133:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-15 12:55:39,133:INFO:Adding model into prep_pipe
2025-05-15 12:55:39,142:INFO:final_cancer_model.pkl saved in current working directory
2025-05-15 12:55:39,163:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 12:55:39,163:INFO:save_model() successfully completed......................................
2025-05-15 12:55:39,229:INFO:Initializing predict_model()
2025-05-15 12:55:39,230:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32494ded0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x331f47f60>)
2025-05-15 12:55:39,230:INFO:Checking exceptions
2025-05-15 12:55:39,230:INFO:Preloading libraries
2025-05-15 12:55:39,231:INFO:Set up data.
2025-05-15 12:55:39,249:INFO:Set up index.
2025-05-15 12:55:39,471:INFO:PyCaret ClassificationExperiment
2025-05-15 12:55:39,471:INFO:Logging name: clf-default-name
2025-05-15 12:55:39,471:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 12:55:39,471:INFO:version 3.3.2
2025-05-15 12:55:39,471:INFO:Initializing setup()
2025-05-15 12:55:39,471:INFO:self.USI: 1297
2025-05-15 12:55:39,471:INFO:self._variable_keys: {'_ml_usecase', 'X', 'gpu_param', 'fix_imbalance', 'X_test', '_available_plots', 'n_jobs_param', 'pipeline', 'memory', 'exp_name_log', 'fold_groups_param', 'target_param', 'fold_generator', 'data', 'y', 'exp_id', 'log_plots_param', 'idx', 'USI', 'y_train', 'is_multiclass', 'html_param', 'fold_shuffle_param', 'X_train', 'gpu_n_jobs_param', 'y_test', 'logging_param', 'seed'}
2025-05-15 12:55:39,471:INFO:Checking environment
2025-05-15 12:55:39,471:INFO:python_version: 3.11.0
2025-05-15 12:55:39,471:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 12:55:39,471:INFO:machine: arm64
2025-05-15 12:55:39,471:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 12:55:39,471:INFO:Memory: svmem(total=17179869184, available=3313729536, percent=80.7, used=5924814848, free=64225280, active=3260563456, inactive=3243245568, wired=2664251392)
2025-05-15 12:55:39,471:INFO:Physical Core: 12
2025-05-15 12:55:39,471:INFO:Logical Core: 12
2025-05-15 12:55:39,471:INFO:Checking libraries
2025-05-15 12:55:39,471:INFO:System:
2025-05-15 12:55:39,471:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 12:55:39,471:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 12:55:39,471:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 12:55:39,471:INFO:PyCaret required dependencies:
2025-05-15 12:55:39,471:INFO:                 pip: 22.3
2025-05-15 12:55:39,471:INFO:          setuptools: 65.5.0
2025-05-15 12:55:39,471:INFO:             pycaret: 3.3.2
2025-05-15 12:55:39,471:INFO:             IPython: 9.2.0
2025-05-15 12:55:39,471:INFO:          ipywidgets: 8.1.7
2025-05-15 12:55:39,471:INFO:                tqdm: 4.67.1
2025-05-15 12:55:39,471:INFO:               numpy: 1.26.4
2025-05-15 12:55:39,471:INFO:              pandas: 2.1.4
2025-05-15 12:55:39,471:INFO:              jinja2: 3.1.6
2025-05-15 12:55:39,471:INFO:               scipy: 1.11.4
2025-05-15 12:55:39,471:INFO:              joblib: 1.3.2
2025-05-15 12:55:39,471:INFO:             sklearn: 1.4.2
2025-05-15 12:55:39,471:INFO:                pyod: 2.0.5
2025-05-15 12:55:39,471:INFO:            imblearn: 0.13.0
2025-05-15 12:55:39,471:INFO:   category_encoders: 2.7.0
2025-05-15 12:55:39,471:INFO:            lightgbm: 4.6.0
2025-05-15 12:55:39,471:INFO:               numba: 0.61.2
2025-05-15 12:55:39,471:INFO:            requests: 2.32.3
2025-05-15 12:55:39,471:INFO:          matplotlib: 3.7.5
2025-05-15 12:55:39,471:INFO:          scikitplot: 0.3.7
2025-05-15 12:55:39,471:INFO:         yellowbrick: 1.5
2025-05-15 12:55:39,471:INFO:              plotly: 5.24.1
2025-05-15 12:55:39,471:INFO:    plotly-resampler: Not installed
2025-05-15 12:55:39,471:INFO:             kaleido: 0.2.1
2025-05-15 12:55:39,471:INFO:           schemdraw: 0.15
2025-05-15 12:55:39,471:INFO:         statsmodels: 0.14.4
2025-05-15 12:55:39,471:INFO:              sktime: 0.26.0
2025-05-15 12:55:39,471:INFO:               tbats: 1.1.3
2025-05-15 12:55:39,471:INFO:            pmdarima: 2.0.4
2025-05-15 12:55:39,471:INFO:              psutil: 7.0.0
2025-05-15 12:55:39,471:INFO:          markupsafe: 3.0.2
2025-05-15 12:55:39,471:INFO:             pickle5: Not installed
2025-05-15 12:55:39,471:INFO:         cloudpickle: 3.1.1
2025-05-15 12:55:39,471:INFO:         deprecation: 2.1.0
2025-05-15 12:55:39,471:INFO:              xxhash: 3.5.0
2025-05-15 12:55:39,471:INFO:           wurlitzer: 3.1.1
2025-05-15 12:55:39,471:INFO:PyCaret optional dependencies:
2025-05-15 12:55:39,471:INFO:                shap: 0.47.2
2025-05-15 12:55:39,471:INFO:           interpret: Not installed
2025-05-15 12:55:39,471:INFO:                umap: Not installed
2025-05-15 12:55:39,471:INFO:     ydata_profiling: Not installed
2025-05-15 12:55:39,471:INFO:  explainerdashboard: Not installed
2025-05-15 12:55:39,471:INFO:             autoviz: Not installed
2025-05-15 12:55:39,471:INFO:           fairlearn: Not installed
2025-05-15 12:55:39,471:INFO:          deepchecks: Not installed
2025-05-15 12:55:39,471:INFO:             xgboost: Not installed
2025-05-15 12:55:39,471:INFO:            catboost: 1.2.8
2025-05-15 12:55:39,471:INFO:              kmodes: Not installed
2025-05-15 12:55:39,471:INFO:             mlxtend: Not installed
2025-05-15 12:55:39,471:INFO:       statsforecast: Not installed
2025-05-15 12:55:39,471:INFO:        tune_sklearn: Not installed
2025-05-15 12:55:39,471:INFO:                 ray: Not installed
2025-05-15 12:55:39,471:INFO:            hyperopt: Not installed
2025-05-15 12:55:39,471:INFO:              optuna: 4.3.0
2025-05-15 12:55:39,471:INFO:               skopt: Not installed
2025-05-15 12:55:39,472:INFO:              mlflow: Not installed
2025-05-15 12:55:39,472:INFO:              gradio: Not installed
2025-05-15 12:55:39,472:INFO:             fastapi: Not installed
2025-05-15 12:55:39,472:INFO:             uvicorn: Not installed
2025-05-15 12:55:39,472:INFO:              m2cgen: Not installed
2025-05-15 12:55:39,472:INFO:           evidently: Not installed
2025-05-15 12:55:39,472:INFO:               fugue: Not installed
2025-05-15 12:55:39,472:INFO:           streamlit: Not installed
2025-05-15 12:55:39,472:INFO:             prophet: Not installed
2025-05-15 12:55:39,472:INFO:None
2025-05-15 12:55:39,472:INFO:Set up data.
2025-05-15 12:55:39,519:INFO:Set up folding strategy.
2025-05-15 12:55:39,519:INFO:Set up train/test split.
2025-05-15 12:55:39,535:INFO:Set up index.
2025-05-15 12:55:39,535:INFO:Assigning column types.
2025-05-15 12:55:39,540:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 12:55:39,558:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:55:39,558:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:55:39,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:39,570:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:39,589:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:55:39,589:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:55:39,600:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:39,600:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:39,601:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 12:55:39,619:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:55:39,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:39,630:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:39,649:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:55:39,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:39,660:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:39,661:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 12:55:39,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:39,690:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:39,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:39,720:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:39,720:INFO:Preparing preprocessing pipeline...
2025-05-15 12:55:39,721:INFO:Set up simple imputation.
2025-05-15 12:55:39,729:INFO:Set up encoding of ordinal features.
2025-05-15 12:55:39,741:INFO:Set up encoding of categorical features.
2025-05-15 12:55:39,741:INFO:Set up imbalanced handling.
2025-05-15 12:55:39,741:INFO:Set up column transformation.
2025-05-15 12:55:40,077:INFO:Finished creating preprocessing pipeline.
2025-05-15 12:55:40,097:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 12:55:40,097:INFO:Creating final display dataframe.
2025-05-15 12:55:40,330:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (87159, 16)
4        Transformed data shape      (133528, 29)
5   Transformed train set shape      (107380, 29)
6    Transformed test set shape       (26148, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              1297
2025-05-15 12:55:40,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:40,363:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:40,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:55:40,394:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:55:40,395:INFO:setup() successfully completed in 0.93s...............
2025-05-15 12:55:40,417:INFO:Initializing create_model()
2025-05-15 12:55:40,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x110fb59d0>, estimator=LGBMClassifier, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:55:40,417:INFO:Checking exceptions
2025-05-15 12:55:40,417:INFO:Initializing create_model()
2025-05-15 12:55:40,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x110fb59d0>, estimator=GradientBoostingClassifier, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:55:40,417:INFO:Checking exceptions
2025-05-15 12:55:40,417:INFO:Initializing create_model()
2025-05-15 12:55:40,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x110fb59d0>, estimator=DecisionTreeClassifier, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:55:40,417:INFO:Checking exceptions
2025-05-15 12:55:40,417:INFO:Initializing predict_model()
2025-05-15 12:55:40,417:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x110fb59d0>, estimator=<function ensemble_model at 0x326a58860>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x327bdeac0>)
2025-05-15 12:55:40,417:INFO:Checking exceptions
2025-05-15 12:55:40,417:INFO:Preloading libraries
2025-05-15 12:55:40,418:INFO:Set up data.
2025-05-15 12:55:40,437:INFO:Set up index.
2025-05-15 12:59:58,402:INFO:PyCaret ClassificationExperiment
2025-05-15 12:59:58,402:INFO:Logging name: clf-default-name
2025-05-15 12:59:58,402:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 12:59:58,402:INFO:version 3.3.2
2025-05-15 12:59:58,402:INFO:Initializing setup()
2025-05-15 12:59:58,402:INFO:self.USI: 2ccc
2025-05-15 12:59:58,402:INFO:self._variable_keys: {'_ml_usecase', 'X', 'gpu_param', 'fix_imbalance', 'X_test', '_available_plots', 'n_jobs_param', 'pipeline', 'memory', 'exp_name_log', 'fold_groups_param', 'target_param', 'fold_generator', 'data', 'y', 'exp_id', 'log_plots_param', 'idx', 'USI', 'y_train', 'is_multiclass', 'html_param', 'fold_shuffle_param', 'X_train', 'gpu_n_jobs_param', 'y_test', 'logging_param', 'seed'}
2025-05-15 12:59:58,402:INFO:Checking environment
2025-05-15 12:59:58,402:INFO:python_version: 3.11.0
2025-05-15 12:59:58,402:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 12:59:58,402:INFO:machine: arm64
2025-05-15 12:59:58,402:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 12:59:58,402:INFO:Memory: svmem(total=17179869184, available=3139207168, percent=81.7, used=6023446528, free=61538304, active=3097919488, inactive=3052240896, wired=2925527040)
2025-05-15 12:59:58,402:INFO:Physical Core: 12
2025-05-15 12:59:58,402:INFO:Logical Core: 12
2025-05-15 12:59:58,402:INFO:Checking libraries
2025-05-15 12:59:58,403:INFO:System:
2025-05-15 12:59:58,403:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 12:59:58,403:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 12:59:58,403:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 12:59:58,403:INFO:PyCaret required dependencies:
2025-05-15 12:59:58,403:INFO:                 pip: 22.3
2025-05-15 12:59:58,403:INFO:          setuptools: 65.5.0
2025-05-15 12:59:58,403:INFO:             pycaret: 3.3.2
2025-05-15 12:59:58,403:INFO:             IPython: 9.2.0
2025-05-15 12:59:58,403:INFO:          ipywidgets: 8.1.7
2025-05-15 12:59:58,403:INFO:                tqdm: 4.67.1
2025-05-15 12:59:58,403:INFO:               numpy: 1.26.4
2025-05-15 12:59:58,403:INFO:              pandas: 2.1.4
2025-05-15 12:59:58,403:INFO:              jinja2: 3.1.6
2025-05-15 12:59:58,403:INFO:               scipy: 1.11.4
2025-05-15 12:59:58,403:INFO:              joblib: 1.3.2
2025-05-15 12:59:58,403:INFO:             sklearn: 1.4.2
2025-05-15 12:59:58,403:INFO:                pyod: 2.0.5
2025-05-15 12:59:58,403:INFO:            imblearn: 0.13.0
2025-05-15 12:59:58,403:INFO:   category_encoders: 2.7.0
2025-05-15 12:59:58,403:INFO:            lightgbm: 4.6.0
2025-05-15 12:59:58,403:INFO:               numba: 0.61.2
2025-05-15 12:59:58,403:INFO:            requests: 2.32.3
2025-05-15 12:59:58,403:INFO:          matplotlib: 3.7.5
2025-05-15 12:59:58,403:INFO:          scikitplot: 0.3.7
2025-05-15 12:59:58,403:INFO:         yellowbrick: 1.5
2025-05-15 12:59:58,403:INFO:              plotly: 5.24.1
2025-05-15 12:59:58,403:INFO:    plotly-resampler: Not installed
2025-05-15 12:59:58,403:INFO:             kaleido: 0.2.1
2025-05-15 12:59:58,403:INFO:           schemdraw: 0.15
2025-05-15 12:59:58,403:INFO:         statsmodels: 0.14.4
2025-05-15 12:59:58,403:INFO:              sktime: 0.26.0
2025-05-15 12:59:58,403:INFO:               tbats: 1.1.3
2025-05-15 12:59:58,403:INFO:            pmdarima: 2.0.4
2025-05-15 12:59:58,403:INFO:              psutil: 7.0.0
2025-05-15 12:59:58,403:INFO:          markupsafe: 3.0.2
2025-05-15 12:59:58,403:INFO:             pickle5: Not installed
2025-05-15 12:59:58,403:INFO:         cloudpickle: 3.1.1
2025-05-15 12:59:58,403:INFO:         deprecation: 2.1.0
2025-05-15 12:59:58,403:INFO:              xxhash: 3.5.0
2025-05-15 12:59:58,403:INFO:           wurlitzer: 3.1.1
2025-05-15 12:59:58,403:INFO:PyCaret optional dependencies:
2025-05-15 12:59:58,403:INFO:                shap: 0.47.2
2025-05-15 12:59:58,403:INFO:           interpret: Not installed
2025-05-15 12:59:58,403:INFO:                umap: Not installed
2025-05-15 12:59:58,403:INFO:     ydata_profiling: Not installed
2025-05-15 12:59:58,403:INFO:  explainerdashboard: Not installed
2025-05-15 12:59:58,403:INFO:             autoviz: Not installed
2025-05-15 12:59:58,403:INFO:           fairlearn: Not installed
2025-05-15 12:59:58,403:INFO:          deepchecks: Not installed
2025-05-15 12:59:58,403:INFO:             xgboost: Not installed
2025-05-15 12:59:58,403:INFO:            catboost: 1.2.8
2025-05-15 12:59:58,403:INFO:              kmodes: Not installed
2025-05-15 12:59:58,403:INFO:             mlxtend: Not installed
2025-05-15 12:59:58,404:INFO:       statsforecast: Not installed
2025-05-15 12:59:58,404:INFO:        tune_sklearn: Not installed
2025-05-15 12:59:58,404:INFO:                 ray: Not installed
2025-05-15 12:59:58,404:INFO:            hyperopt: Not installed
2025-05-15 12:59:58,404:INFO:              optuna: 4.3.0
2025-05-15 12:59:58,404:INFO:               skopt: Not installed
2025-05-15 12:59:58,404:INFO:              mlflow: Not installed
2025-05-15 12:59:58,404:INFO:              gradio: Not installed
2025-05-15 12:59:58,404:INFO:             fastapi: Not installed
2025-05-15 12:59:58,404:INFO:             uvicorn: Not installed
2025-05-15 12:59:58,404:INFO:              m2cgen: Not installed
2025-05-15 12:59:58,404:INFO:           evidently: Not installed
2025-05-15 12:59:58,404:INFO:               fugue: Not installed
2025-05-15 12:59:58,404:INFO:           streamlit: Not installed
2025-05-15 12:59:58,404:INFO:             prophet: Not installed
2025-05-15 12:59:58,404:INFO:None
2025-05-15 12:59:58,404:INFO:Set up data.
2025-05-15 12:59:58,454:INFO:Set up folding strategy.
2025-05-15 12:59:58,454:INFO:Set up train/test split.
2025-05-15 12:59:58,469:INFO:Set up index.
2025-05-15 12:59:58,470:INFO:Assigning column types.
2025-05-15 12:59:58,475:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 12:59:58,495:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:59:58,497:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:59:58,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:59:58,509:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:59:58,528:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:59:58,528:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:59:58,539:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:59:58,539:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:59:58,540:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 12:59:58,558:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:59:58,569:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:59:58,569:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:59:58,587:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:59:58,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:59:58,598:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:59:58,599:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 12:59:58,629:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:59:58,629:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:59:58,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:59:58,659:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:59:58,660:INFO:Preparing preprocessing pipeline...
2025-05-15 12:59:58,661:INFO:Set up simple imputation.
2025-05-15 12:59:58,668:INFO:Set up encoding of ordinal features.
2025-05-15 12:59:58,679:INFO:Set up encoding of categorical features.
2025-05-15 12:59:58,680:INFO:Set up imbalanced handling.
2025-05-15 12:59:58,680:INFO:Set up column transformation.
2025-05-15 12:59:58,981:INFO:Finished creating preprocessing pipeline.
2025-05-15 12:59:59,000:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 12:59:59,000:INFO:Creating final display dataframe.
2025-05-15 12:59:59,203:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              2ccc
2025-05-15 12:59:59,239:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:59:59,239:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:59:59,270:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:59:59,271:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 12:59:59,272:INFO:setup() successfully completed in 0.88s...............
2025-05-15 12:59:59,272:INFO:Initializing compare_models()
2025-05-15 12:59:59,273:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-15 12:59:59,273:INFO:Checking exceptions
2025-05-15 12:59:59,278:INFO:Preparing display monitor
2025-05-15 12:59:59,287:INFO:Initializing Logistic Regression
2025-05-15 12:59:59,287:INFO:Total runtime is 1.5894571940104167e-06 minutes
2025-05-15 12:59:59,289:INFO:SubProcess create_model() called ==================================
2025-05-15 12:59:59,289:INFO:Initializing create_model()
2025-05-15 12:59:59,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 12:59:59,289:INFO:Checking exceptions
2025-05-15 12:59:59,289:INFO:Importing libraries
2025-05-15 12:59:59,289:INFO:Copying training dataset
2025-05-15 12:59:59,300:INFO:Defining folds
2025-05-15 12:59:59,300:INFO:Declaring metric variables
2025-05-15 12:59:59,301:INFO:Importing untrained model
2025-05-15 12:59:59,303:INFO:Logistic Regression Imported successfully
2025-05-15 12:59:59,305:INFO:Starting cross validation
2025-05-15 12:59:59,306:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:00:03,335:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:00:03,361:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:00:03,401:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:00:03,412:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:00:03,420:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:00:03,521:INFO:Calculating mean and std
2025-05-15 13:00:03,522:INFO:Creating metrics dataframe
2025-05-15 13:00:03,523:INFO:Uploading results into container
2025-05-15 13:00:03,524:INFO:Uploading model into container now
2025-05-15 13:00:03,524:INFO:_master_model_container: 1
2025-05-15 13:00:03,524:INFO:_display_container: 2
2025-05-15 13:00:03,524:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 13:00:03,524:INFO:create_model() successfully completed......................................
2025-05-15 13:00:03,666:INFO:SubProcess create_model() end ==================================
2025-05-15 13:00:03,666:INFO:Creating metrics dataframe
2025-05-15 13:00:03,669:INFO:Initializing K Neighbors Classifier
2025-05-15 13:00:03,669:INFO:Total runtime is 0.07302956978480021 minutes
2025-05-15 13:00:03,670:INFO:SubProcess create_model() called ==================================
2025-05-15 13:00:03,670:INFO:Initializing create_model()
2025-05-15 13:00:03,670:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:00:03,670:INFO:Checking exceptions
2025-05-15 13:00:03,670:INFO:Importing libraries
2025-05-15 13:00:03,670:INFO:Copying training dataset
2025-05-15 13:00:03,681:INFO:Defining folds
2025-05-15 13:00:03,681:INFO:Declaring metric variables
2025-05-15 13:00:03,682:INFO:Importing untrained model
2025-05-15 13:00:03,683:INFO:K Neighbors Classifier Imported successfully
2025-05-15 13:00:03,685:INFO:Starting cross validation
2025-05-15 13:00:03,686:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:00:08,481:INFO:Calculating mean and std
2025-05-15 13:00:08,481:INFO:Creating metrics dataframe
2025-05-15 13:00:08,483:INFO:Uploading results into container
2025-05-15 13:00:08,483:INFO:Uploading model into container now
2025-05-15 13:00:08,483:INFO:_master_model_container: 2
2025-05-15 13:00:08,483:INFO:_display_container: 2
2025-05-15 13:00:08,483:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-15 13:00:08,483:INFO:create_model() successfully completed......................................
2025-05-15 13:00:08,565:INFO:SubProcess create_model() end ==================================
2025-05-15 13:00:08,565:INFO:Creating metrics dataframe
2025-05-15 13:00:08,568:INFO:Initializing Naive Bayes
2025-05-15 13:00:08,568:INFO:Total runtime is 0.15467883745829264 minutes
2025-05-15 13:00:08,569:INFO:SubProcess create_model() called ==================================
2025-05-15 13:00:08,569:INFO:Initializing create_model()
2025-05-15 13:00:08,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:00:08,569:INFO:Checking exceptions
2025-05-15 13:00:08,569:INFO:Importing libraries
2025-05-15 13:00:08,570:INFO:Copying training dataset
2025-05-15 13:00:08,583:INFO:Defining folds
2025-05-15 13:00:08,584:INFO:Declaring metric variables
2025-05-15 13:00:08,585:INFO:Importing untrained model
2025-05-15 13:00:08,586:INFO:Naive Bayes Imported successfully
2025-05-15 13:00:08,588:INFO:Starting cross validation
2025-05-15 13:00:08,589:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:00:09,800:INFO:Calculating mean and std
2025-05-15 13:00:09,801:INFO:Creating metrics dataframe
2025-05-15 13:00:09,802:INFO:Uploading results into container
2025-05-15 13:00:09,802:INFO:Uploading model into container now
2025-05-15 13:00:09,802:INFO:_master_model_container: 3
2025-05-15 13:00:09,803:INFO:_display_container: 2
2025-05-15 13:00:09,803:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-15 13:00:09,803:INFO:create_model() successfully completed......................................
2025-05-15 13:00:09,873:INFO:SubProcess create_model() end ==================================
2025-05-15 13:00:09,873:INFO:Creating metrics dataframe
2025-05-15 13:00:09,876:INFO:Initializing Decision Tree Classifier
2025-05-15 13:00:09,876:INFO:Total runtime is 0.17647680044174194 minutes
2025-05-15 13:00:09,877:INFO:SubProcess create_model() called ==================================
2025-05-15 13:00:09,877:INFO:Initializing create_model()
2025-05-15 13:00:09,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:00:09,877:INFO:Checking exceptions
2025-05-15 13:00:09,877:INFO:Importing libraries
2025-05-15 13:00:09,878:INFO:Copying training dataset
2025-05-15 13:00:09,887:INFO:Defining folds
2025-05-15 13:00:09,887:INFO:Declaring metric variables
2025-05-15 13:00:09,888:INFO:Importing untrained model
2025-05-15 13:00:09,890:INFO:Decision Tree Classifier Imported successfully
2025-05-15 13:00:09,892:INFO:Starting cross validation
2025-05-15 13:00:09,893:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:00:11,610:INFO:Calculating mean and std
2025-05-15 13:00:11,611:INFO:Creating metrics dataframe
2025-05-15 13:00:11,612:INFO:Uploading results into container
2025-05-15 13:00:11,612:INFO:Uploading model into container now
2025-05-15 13:00:11,612:INFO:_master_model_container: 4
2025-05-15 13:00:11,612:INFO:_display_container: 2
2025-05-15 13:00:11,612:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-15 13:00:11,613:INFO:create_model() successfully completed......................................
2025-05-15 13:00:11,687:INFO:SubProcess create_model() end ==================================
2025-05-15 13:00:11,687:INFO:Creating metrics dataframe
2025-05-15 13:00:11,690:INFO:Initializing SVM - Linear Kernel
2025-05-15 13:00:11,690:INFO:Total runtime is 0.20672170321146646 minutes
2025-05-15 13:00:11,692:INFO:SubProcess create_model() called ==================================
2025-05-15 13:00:11,692:INFO:Initializing create_model()
2025-05-15 13:00:11,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:00:11,692:INFO:Checking exceptions
2025-05-15 13:00:11,692:INFO:Importing libraries
2025-05-15 13:00:11,692:INFO:Copying training dataset
2025-05-15 13:00:11,704:INFO:Defining folds
2025-05-15 13:00:11,704:INFO:Declaring metric variables
2025-05-15 13:00:11,705:INFO:Importing untrained model
2025-05-15 13:00:11,706:INFO:SVM - Linear Kernel Imported successfully
2025-05-15 13:00:11,709:INFO:Starting cross validation
2025-05-15 13:00:11,710:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:00:15,430:INFO:Calculating mean and std
2025-05-15 13:00:15,432:INFO:Creating metrics dataframe
2025-05-15 13:00:15,435:INFO:Uploading results into container
2025-05-15 13:00:15,435:INFO:Uploading model into container now
2025-05-15 13:00:15,436:INFO:_master_model_container: 5
2025-05-15 13:00:15,436:INFO:_display_container: 2
2025-05-15 13:00:15,436:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-15 13:00:15,436:INFO:create_model() successfully completed......................................
2025-05-15 13:00:15,561:INFO:SubProcess create_model() end ==================================
2025-05-15 13:00:15,562:INFO:Creating metrics dataframe
2025-05-15 13:00:15,565:INFO:Initializing Ridge Classifier
2025-05-15 13:00:15,565:INFO:Total runtime is 0.27130228678385415 minutes
2025-05-15 13:00:15,566:INFO:SubProcess create_model() called ==================================
2025-05-15 13:00:15,567:INFO:Initializing create_model()
2025-05-15 13:00:15,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:00:15,567:INFO:Checking exceptions
2025-05-15 13:00:15,567:INFO:Importing libraries
2025-05-15 13:00:15,567:INFO:Copying training dataset
2025-05-15 13:00:15,586:INFO:Defining folds
2025-05-15 13:00:15,586:INFO:Declaring metric variables
2025-05-15 13:00:15,588:INFO:Importing untrained model
2025-05-15 13:00:15,589:INFO:Ridge Classifier Imported successfully
2025-05-15 13:00:15,592:INFO:Starting cross validation
2025-05-15 13:00:15,593:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:00:16,721:INFO:Calculating mean and std
2025-05-15 13:00:16,722:INFO:Creating metrics dataframe
2025-05-15 13:00:16,723:INFO:Uploading results into container
2025-05-15 13:00:16,723:INFO:Uploading model into container now
2025-05-15 13:00:16,723:INFO:_master_model_container: 6
2025-05-15 13:00:16,723:INFO:_display_container: 2
2025-05-15 13:00:16,723:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-15 13:00:16,723:INFO:create_model() successfully completed......................................
2025-05-15 13:00:16,792:INFO:SubProcess create_model() end ==================================
2025-05-15 13:00:16,792:INFO:Creating metrics dataframe
2025-05-15 13:00:16,795:INFO:Initializing Random Forest Classifier
2025-05-15 13:00:16,795:INFO:Total runtime is 0.2918028513590495 minutes
2025-05-15 13:00:16,796:INFO:SubProcess create_model() called ==================================
2025-05-15 13:00:16,797:INFO:Initializing create_model()
2025-05-15 13:00:16,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:00:16,797:INFO:Checking exceptions
2025-05-15 13:00:16,797:INFO:Importing libraries
2025-05-15 13:00:16,797:INFO:Copying training dataset
2025-05-15 13:00:16,806:INFO:Defining folds
2025-05-15 13:00:16,806:INFO:Declaring metric variables
2025-05-15 13:00:16,807:INFO:Importing untrained model
2025-05-15 13:00:16,809:INFO:Random Forest Classifier Imported successfully
2025-05-15 13:00:16,811:INFO:Starting cross validation
2025-05-15 13:00:16,812:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:00:22,475:INFO:Calculating mean and std
2025-05-15 13:00:22,476:INFO:Creating metrics dataframe
2025-05-15 13:00:22,477:INFO:Uploading results into container
2025-05-15 13:00:22,477:INFO:Uploading model into container now
2025-05-15 13:00:22,477:INFO:_master_model_container: 7
2025-05-15 13:00:22,477:INFO:_display_container: 2
2025-05-15 13:00:22,477:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 13:00:22,477:INFO:create_model() successfully completed......................................
2025-05-15 13:00:22,553:INFO:SubProcess create_model() end ==================================
2025-05-15 13:00:22,553:INFO:Creating metrics dataframe
2025-05-15 13:00:22,556:INFO:Initializing Quadratic Discriminant Analysis
2025-05-15 13:00:22,556:INFO:Total runtime is 0.38781798680623375 minutes
2025-05-15 13:00:22,557:INFO:SubProcess create_model() called ==================================
2025-05-15 13:00:22,558:INFO:Initializing create_model()
2025-05-15 13:00:22,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:00:22,558:INFO:Checking exceptions
2025-05-15 13:00:22,558:INFO:Importing libraries
2025-05-15 13:00:22,558:INFO:Copying training dataset
2025-05-15 13:00:22,567:INFO:Defining folds
2025-05-15 13:00:22,568:INFO:Declaring metric variables
2025-05-15 13:00:22,569:INFO:Importing untrained model
2025-05-15 13:00:22,570:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 13:00:22,572:INFO:Starting cross validation
2025-05-15 13:00:22,573:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:00:23,651:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:00:23,677:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:00:23,734:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:00:23,738:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:00:23,754:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:00:23,764:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:00:23,771:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:00:23,817:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:00:23,831:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:00:23,833:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:00:23,842:INFO:Calculating mean and std
2025-05-15 13:00:23,843:INFO:Creating metrics dataframe
2025-05-15 13:00:23,845:INFO:Uploading results into container
2025-05-15 13:00:23,845:INFO:Uploading model into container now
2025-05-15 13:00:23,845:INFO:_master_model_container: 8
2025-05-15 13:00:23,845:INFO:_display_container: 2
2025-05-15 13:00:23,845:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 13:00:23,846:INFO:create_model() successfully completed......................................
2025-05-15 13:00:23,979:INFO:SubProcess create_model() end ==================================
2025-05-15 13:00:23,979:INFO:Creating metrics dataframe
2025-05-15 13:00:23,983:INFO:Initializing Ada Boost Classifier
2025-05-15 13:00:23,984:INFO:Total runtime is 0.41160773833592734 minutes
2025-05-15 13:00:23,985:INFO:SubProcess create_model() called ==================================
2025-05-15 13:00:23,985:INFO:Initializing create_model()
2025-05-15 13:00:23,985:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:00:23,985:INFO:Checking exceptions
2025-05-15 13:00:23,985:INFO:Importing libraries
2025-05-15 13:00:23,985:INFO:Copying training dataset
2025-05-15 13:00:24,001:INFO:Defining folds
2025-05-15 13:00:24,001:INFO:Declaring metric variables
2025-05-15 13:00:24,003:INFO:Importing untrained model
2025-05-15 13:00:24,004:INFO:Ada Boost Classifier Imported successfully
2025-05-15 13:00:24,007:INFO:Starting cross validation
2025-05-15 13:00:24,008:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:00:25,012:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:00:25,041:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:00:25,053:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:00:25,063:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:00:25,079:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:00:27,754:INFO:Calculating mean and std
2025-05-15 13:00:27,754:INFO:Creating metrics dataframe
2025-05-15 13:00:27,755:INFO:Uploading results into container
2025-05-15 13:00:27,756:INFO:Uploading model into container now
2025-05-15 13:00:27,756:INFO:_master_model_container: 9
2025-05-15 13:00:27,756:INFO:_display_container: 2
2025-05-15 13:00:27,756:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-15 13:00:27,756:INFO:create_model() successfully completed......................................
2025-05-15 13:00:27,825:INFO:SubProcess create_model() end ==================================
2025-05-15 13:00:27,825:INFO:Creating metrics dataframe
2025-05-15 13:00:27,829:INFO:Initializing Gradient Boosting Classifier
2025-05-15 13:00:27,829:INFO:Total runtime is 0.4756986657778422 minutes
2025-05-15 13:00:27,830:INFO:SubProcess create_model() called ==================================
2025-05-15 13:00:27,830:INFO:Initializing create_model()
2025-05-15 13:00:27,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:00:27,830:INFO:Checking exceptions
2025-05-15 13:00:27,831:INFO:Importing libraries
2025-05-15 13:00:27,831:INFO:Copying training dataset
2025-05-15 13:00:27,839:INFO:Defining folds
2025-05-15 13:00:27,839:INFO:Declaring metric variables
2025-05-15 13:00:27,840:INFO:Importing untrained model
2025-05-15 13:00:27,842:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 13:00:27,844:INFO:Starting cross validation
2025-05-15 13:00:27,845:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:00:41,399:INFO:Calculating mean and std
2025-05-15 13:00:41,401:INFO:Creating metrics dataframe
2025-05-15 13:00:41,402:INFO:Uploading results into container
2025-05-15 13:00:41,402:INFO:Uploading model into container now
2025-05-15 13:00:41,403:INFO:_master_model_container: 10
2025-05-15 13:00:41,403:INFO:_display_container: 2
2025-05-15 13:00:41,403:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 13:00:41,403:INFO:create_model() successfully completed......................................
2025-05-15 13:00:41,470:INFO:SubProcess create_model() end ==================================
2025-05-15 13:00:41,470:INFO:Creating metrics dataframe
2025-05-15 13:00:41,474:INFO:Initializing Linear Discriminant Analysis
2025-05-15 13:00:41,474:INFO:Total runtime is 0.7031104365984598 minutes
2025-05-15 13:00:41,475:INFO:SubProcess create_model() called ==================================
2025-05-15 13:00:41,475:INFO:Initializing create_model()
2025-05-15 13:00:41,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:00:41,475:INFO:Checking exceptions
2025-05-15 13:00:41,475:INFO:Importing libraries
2025-05-15 13:00:41,475:INFO:Copying training dataset
2025-05-15 13:00:41,485:INFO:Defining folds
2025-05-15 13:00:41,485:INFO:Declaring metric variables
2025-05-15 13:00:41,486:INFO:Importing untrained model
2025-05-15 13:00:41,488:INFO:Linear Discriminant Analysis Imported successfully
2025-05-15 13:00:41,490:INFO:Starting cross validation
2025-05-15 13:00:41,491:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:00:42,706:INFO:Calculating mean and std
2025-05-15 13:00:42,707:INFO:Creating metrics dataframe
2025-05-15 13:00:42,708:INFO:Uploading results into container
2025-05-15 13:00:42,708:INFO:Uploading model into container now
2025-05-15 13:00:42,708:INFO:_master_model_container: 11
2025-05-15 13:00:42,708:INFO:_display_container: 2
2025-05-15 13:00:42,709:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-15 13:00:42,709:INFO:create_model() successfully completed......................................
2025-05-15 13:00:42,780:INFO:SubProcess create_model() end ==================================
2025-05-15 13:00:42,781:INFO:Creating metrics dataframe
2025-05-15 13:00:42,785:INFO:Initializing Extra Trees Classifier
2025-05-15 13:00:42,785:INFO:Total runtime is 0.7249626676241556 minutes
2025-05-15 13:00:42,786:INFO:SubProcess create_model() called ==================================
2025-05-15 13:00:42,786:INFO:Initializing create_model()
2025-05-15 13:00:42,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:00:42,786:INFO:Checking exceptions
2025-05-15 13:00:42,786:INFO:Importing libraries
2025-05-15 13:00:42,786:INFO:Copying training dataset
2025-05-15 13:00:42,796:INFO:Defining folds
2025-05-15 13:00:42,796:INFO:Declaring metric variables
2025-05-15 13:00:42,797:INFO:Importing untrained model
2025-05-15 13:00:42,798:INFO:Extra Trees Classifier Imported successfully
2025-05-15 13:00:42,801:INFO:Starting cross validation
2025-05-15 13:00:42,801:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:00:47,358:INFO:Calculating mean and std
2025-05-15 13:00:47,366:INFO:Creating metrics dataframe
2025-05-15 13:00:47,372:INFO:Uploading results into container
2025-05-15 13:00:47,372:INFO:Uploading model into container now
2025-05-15 13:00:47,373:INFO:_master_model_container: 12
2025-05-15 13:00:47,374:INFO:_display_container: 2
2025-05-15 13:00:47,375:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 13:00:47,376:INFO:create_model() successfully completed......................................
2025-05-15 13:00:47,519:INFO:SubProcess create_model() end ==================================
2025-05-15 13:00:47,519:INFO:Creating metrics dataframe
2025-05-15 13:00:47,524:INFO:Initializing Light Gradient Boosting Machine
2025-05-15 13:00:47,524:INFO:Total runtime is 0.8039518674214681 minutes
2025-05-15 13:00:47,526:INFO:SubProcess create_model() called ==================================
2025-05-15 13:00:47,526:INFO:Initializing create_model()
2025-05-15 13:00:47,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:00:47,526:INFO:Checking exceptions
2025-05-15 13:00:47,526:INFO:Importing libraries
2025-05-15 13:00:47,526:INFO:Copying training dataset
2025-05-15 13:00:47,538:INFO:Defining folds
2025-05-15 13:00:47,538:INFO:Declaring metric variables
2025-05-15 13:00:47,540:INFO:Importing untrained model
2025-05-15 13:00:47,542:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:00:47,544:INFO:Starting cross validation
2025-05-15 13:00:47,545:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:00:51,649:INFO:Calculating mean and std
2025-05-15 13:00:51,649:INFO:Creating metrics dataframe
2025-05-15 13:00:51,650:INFO:Uploading results into container
2025-05-15 13:00:51,650:INFO:Uploading model into container now
2025-05-15 13:00:51,650:INFO:_master_model_container: 13
2025-05-15 13:00:51,651:INFO:_display_container: 2
2025-05-15 13:00:51,651:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:00:51,651:INFO:create_model() successfully completed......................................
2025-05-15 13:00:51,727:INFO:SubProcess create_model() end ==================================
2025-05-15 13:00:51,727:INFO:Creating metrics dataframe
2025-05-15 13:00:51,732:INFO:Initializing CatBoost Classifier
2025-05-15 13:00:51,732:INFO:Total runtime is 0.8740819692611694 minutes
2025-05-15 13:00:51,733:INFO:SubProcess create_model() called ==================================
2025-05-15 13:00:51,733:INFO:Initializing create_model()
2025-05-15 13:00:51,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:00:51,734:INFO:Checking exceptions
2025-05-15 13:00:51,734:INFO:Importing libraries
2025-05-15 13:00:51,734:INFO:Copying training dataset
2025-05-15 13:00:51,744:INFO:Defining folds
2025-05-15 13:00:51,744:INFO:Declaring metric variables
2025-05-15 13:00:51,745:INFO:Importing untrained model
2025-05-15 13:00:51,746:INFO:CatBoost Classifier Imported successfully
2025-05-15 13:00:51,749:INFO:Starting cross validation
2025-05-15 13:00:51,750:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:01:10,232:INFO:Calculating mean and std
2025-05-15 13:01:10,236:INFO:Creating metrics dataframe
2025-05-15 13:01:10,241:INFO:Uploading results into container
2025-05-15 13:01:10,241:INFO:Uploading model into container now
2025-05-15 13:01:10,242:INFO:_master_model_container: 14
2025-05-15 13:01:10,242:INFO:_display_container: 2
2025-05-15 13:01:10,242:INFO:<catboost.core.CatBoostClassifier object at 0x33355a510>
2025-05-15 13:01:10,242:INFO:create_model() successfully completed......................................
2025-05-15 13:01:10,388:INFO:SubProcess create_model() end ==================================
2025-05-15 13:01:10,388:INFO:Creating metrics dataframe
2025-05-15 13:01:10,393:INFO:Initializing Dummy Classifier
2025-05-15 13:01:10,393:INFO:Total runtime is 1.1851020495096842 minutes
2025-05-15 13:01:10,395:INFO:SubProcess create_model() called ==================================
2025-05-15 13:01:10,395:INFO:Initializing create_model()
2025-05-15 13:01:10,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32751df10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:01:10,395:INFO:Checking exceptions
2025-05-15 13:01:10,395:INFO:Importing libraries
2025-05-15 13:01:10,395:INFO:Copying training dataset
2025-05-15 13:01:10,409:INFO:Defining folds
2025-05-15 13:01:10,409:INFO:Declaring metric variables
2025-05-15 13:01:10,411:INFO:Importing untrained model
2025-05-15 13:01:10,412:INFO:Dummy Classifier Imported successfully
2025-05-15 13:01:10,414:INFO:Starting cross validation
2025-05-15 13:01:10,415:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:01:11,693:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:01:11,711:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:01:11,716:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:01:11,763:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:01:11,819:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:01:11,831:INFO:Calculating mean and std
2025-05-15 13:01:11,832:INFO:Creating metrics dataframe
2025-05-15 13:01:11,833:INFO:Uploading results into container
2025-05-15 13:01:11,833:INFO:Uploading model into container now
2025-05-15 13:01:11,833:INFO:_master_model_container: 15
2025-05-15 13:01:11,833:INFO:_display_container: 2
2025-05-15 13:01:11,834:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-15 13:01:11,834:INFO:create_model() successfully completed......................................
2025-05-15 13:01:11,928:INFO:SubProcess create_model() end ==================================
2025-05-15 13:01:11,928:INFO:Creating metrics dataframe
2025-05-15 13:01:11,944:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-15 13:01:11,956:INFO:Initializing create_model()
2025-05-15 13:01:11,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:01:11,957:INFO:Checking exceptions
2025-05-15 13:01:11,960:INFO:Importing libraries
2025-05-15 13:01:11,960:INFO:Copying training dataset
2025-05-15 13:01:12,079:INFO:Defining folds
2025-05-15 13:01:12,079:INFO:Declaring metric variables
2025-05-15 13:01:12,079:INFO:Importing untrained model
2025-05-15 13:01:12,079:INFO:Declaring custom model
2025-05-15 13:01:12,080:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:01:12,081:INFO:Cross validation set to False
2025-05-15 13:01:12,081:INFO:Fitting Model
2025-05-15 13:01:13,194:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 13:01:13,204:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004826 seconds.
2025-05-15 13:01:13,204:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 13:01:13,204:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 13:01:13,204:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 13:01:13,204:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 13:01:13,204:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 13:01:13,978:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:01:13,978:INFO:create_model() successfully completed......................................
2025-05-15 13:01:14,092:INFO:Initializing create_model()
2025-05-15 13:01:14,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:01:14,093:INFO:Checking exceptions
2025-05-15 13:01:14,094:INFO:Importing libraries
2025-05-15 13:01:14,094:INFO:Copying training dataset
2025-05-15 13:01:14,105:INFO:Defining folds
2025-05-15 13:01:14,105:INFO:Declaring metric variables
2025-05-15 13:01:14,105:INFO:Importing untrained model
2025-05-15 13:01:14,105:INFO:Declaring custom model
2025-05-15 13:01:14,106:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 13:01:14,107:INFO:Cross validation set to False
2025-05-15 13:01:14,107:INFO:Fitting Model
2025-05-15 13:01:30,305:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 13:01:30,305:INFO:create_model() successfully completed......................................
2025-05-15 13:01:30,386:INFO:Initializing create_model()
2025-05-15 13:01:30,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:01:30,387:INFO:Checking exceptions
2025-05-15 13:01:30,387:INFO:Importing libraries
2025-05-15 13:01:30,387:INFO:Copying training dataset
2025-05-15 13:01:30,397:INFO:Defining folds
2025-05-15 13:01:30,397:INFO:Declaring metric variables
2025-05-15 13:01:30,397:INFO:Importing untrained model
2025-05-15 13:01:30,397:INFO:Declaring custom model
2025-05-15 13:01:30,398:INFO:Random Forest Classifier Imported successfully
2025-05-15 13:01:30,398:INFO:Cross validation set to False
2025-05-15 13:01:30,398:INFO:Fitting Model
2025-05-15 13:01:32,669:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 13:01:32,669:INFO:create_model() successfully completed......................................
2025-05-15 13:01:32,753:INFO:_master_model_container: 15
2025-05-15 13:01:32,753:INFO:_display_container: 2
2025-05-15 13:01:32,754:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-15 13:01:32,754:INFO:compare_models() successfully completed......................................
2025-05-15 13:01:32,755:INFO:Initializing evaluate_model()
2025-05-15 13:01:32,755:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 13:01:32,761:INFO:Initializing plot_model()
2025-05-15 13:01:32,761:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 13:01:32,761:INFO:Checking exceptions
2025-05-15 13:01:32,766:INFO:Preloading libraries
2025-05-15 13:01:32,771:INFO:Copying training dataset
2025-05-15 13:01:32,771:INFO:Plot type: pipeline
2025-05-15 13:01:32,843:INFO:Visual Rendered Successfully
2025-05-15 13:01:32,922:INFO:plot_model() successfully completed......................................
2025-05-15 13:01:32,923:INFO:Initializing tune_model()
2025-05-15 13:01:32,923:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-15 13:01:32,923:INFO:Checking exceptions
2025-05-15 13:01:32,935:INFO:Copying training dataset
2025-05-15 13:01:32,945:INFO:Checking base model
2025-05-15 13:01:32,945:INFO:Base model : Light Gradient Boosting Machine
2025-05-15 13:01:32,948:INFO:Declaring metric variables
2025-05-15 13:01:32,949:INFO:Defining Hyperparameters
2025-05-15 13:01:33,027:INFO:Tuning with n_jobs=-1
2025-05-15 13:01:33,027:INFO:Initializing RandomizedSearchCV
2025-05-15 13:02:11,043:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-15 13:02:11,050:INFO:Hyperparameter search completed
2025-05-15 13:02:11,050:INFO:SubProcess create_model() called ==================================
2025-05-15 13:02:11,055:INFO:Initializing create_model()
2025-05-15 13:02:11,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33bdbad10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-15 13:02:11,055:INFO:Checking exceptions
2025-05-15 13:02:11,055:INFO:Importing libraries
2025-05-15 13:02:11,055:INFO:Copying training dataset
2025-05-15 13:02:11,085:INFO:Defining folds
2025-05-15 13:02:11,085:INFO:Declaring metric variables
2025-05-15 13:02:11,091:INFO:Importing untrained model
2025-05-15 13:02:11,091:INFO:Declaring custom model
2025-05-15 13:02:11,096:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:02:11,099:INFO:Starting cross validation
2025-05-15 13:02:11,104:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:02:17,867:INFO:Calculating mean and std
2025-05-15 13:02:17,868:INFO:Creating metrics dataframe
2025-05-15 13:02:17,872:INFO:Finalizing model
2025-05-15 13:02:18,931:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 13:02:18,931:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 13:02:18,931:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 13:02:18,965:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 13:02:18,965:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 13:02:18,965:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 13:02:18,965:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 13:02:18,975:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005406 seconds.
2025-05-15 13:02:18,976:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 13:02:18,976:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 13:02:18,976:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 13:02:18,976:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 13:02:18,976:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 13:02:20,422:INFO:Uploading results into container
2025-05-15 13:02:20,423:INFO:Uploading model into container now
2025-05-15 13:02:20,423:INFO:_master_model_container: 16
2025-05-15 13:02:20,424:INFO:_display_container: 3
2025-05-15 13:02:20,424:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:02:20,424:INFO:create_model() successfully completed......................................
2025-05-15 13:02:20,578:INFO:SubProcess create_model() end ==================================
2025-05-15 13:02:20,578:INFO:choose_better activated
2025-05-15 13:02:20,580:INFO:SubProcess create_model() called ==================================
2025-05-15 13:02:20,581:INFO:Initializing create_model()
2025-05-15 13:02:20,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:02:20,581:INFO:Checking exceptions
2025-05-15 13:02:20,582:INFO:Importing libraries
2025-05-15 13:02:20,582:INFO:Copying training dataset
2025-05-15 13:02:20,595:INFO:Defining folds
2025-05-15 13:02:20,595:INFO:Declaring metric variables
2025-05-15 13:02:20,595:INFO:Importing untrained model
2025-05-15 13:02:20,595:INFO:Declaring custom model
2025-05-15 13:02:20,595:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:02:20,596:INFO:Starting cross validation
2025-05-15 13:02:20,596:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:02:25,039:INFO:Calculating mean and std
2025-05-15 13:02:25,040:INFO:Creating metrics dataframe
2025-05-15 13:02:25,041:INFO:Finalizing model
2025-05-15 13:02:26,089:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 13:02:26,099:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004804 seconds.
2025-05-15 13:02:26,099:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 13:02:26,099:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 13:02:26,100:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 13:02:26,100:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 13:02:26,100:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 13:02:26,852:INFO:Uploading results into container
2025-05-15 13:02:26,853:INFO:Uploading model into container now
2025-05-15 13:02:26,853:INFO:_master_model_container: 17
2025-05-15 13:02:26,853:INFO:_display_container: 4
2025-05-15 13:02:26,853:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:02:26,853:INFO:create_model() successfully completed......................................
2025-05-15 13:02:26,930:INFO:SubProcess create_model() end ==================================
2025-05-15 13:02:26,931:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-15 13:02:26,931:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-15 13:02:26,931:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-15 13:02:26,931:INFO:choose_better completed
2025-05-15 13:02:26,935:INFO:_master_model_container: 17
2025-05-15 13:02:26,935:INFO:_display_container: 3
2025-05-15 13:02:26,936:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:02:26,936:INFO:tune_model() successfully completed......................................
2025-05-15 13:02:27,015:INFO:Initializing evaluate_model()
2025-05-15 13:02:27,016:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 13:02:27,023:INFO:Initializing plot_model()
2025-05-15 13:02:27,023:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 13:02:27,023:INFO:Checking exceptions
2025-05-15 13:02:27,027:INFO:Preloading libraries
2025-05-15 13:02:27,030:INFO:Copying training dataset
2025-05-15 13:02:27,030:INFO:Plot type: pipeline
2025-05-15 13:02:27,090:INFO:Visual Rendered Successfully
2025-05-15 13:02:27,165:INFO:plot_model() successfully completed......................................
2025-05-15 13:02:27,167:INFO:Initializing interpret_model()
2025-05-15 13:02:27,167:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c5f73d0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-15 13:02:27,167:INFO:Checking exceptions
2025-05-15 13:02:27,167:INFO:Soft dependency imported: shap: 0.47.2
2025-05-15 13:02:27,257:INFO:plot type: summary
2025-05-15 13:02:27,258:INFO:Creating TreeExplainer
2025-05-15 13:02:27,335:INFO:Compiling shap values
2025-05-15 13:02:28,602:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray
  warnings.warn(

2025-05-15 13:02:28,602:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-05-15 13:02:29,886:INFO:Visual Rendered Successfully
2025-05-15 13:02:29,886:INFO:interpret_model() successfully completed......................................
2025-05-15 13:02:29,977:INFO:PyCaret ClassificationExperiment
2025-05-15 13:02:29,977:INFO:Logging name: clf-default-name
2025-05-15 13:02:29,977:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 13:02:29,977:INFO:version 3.3.2
2025-05-15 13:02:29,977:INFO:Initializing setup()
2025-05-15 13:02:29,977:INFO:self.USI: 2cdc
2025-05-15 13:02:29,977:INFO:self._variable_keys: {'_ml_usecase', 'X', 'gpu_param', 'fix_imbalance', 'X_test', '_available_plots', 'n_jobs_param', 'pipeline', 'memory', 'exp_name_log', 'fold_groups_param', 'target_param', 'fold_generator', 'data', 'y', 'exp_id', 'log_plots_param', 'idx', 'USI', 'y_train', 'is_multiclass', 'html_param', 'fold_shuffle_param', 'X_train', 'gpu_n_jobs_param', 'y_test', 'logging_param', 'seed'}
2025-05-15 13:02:29,977:INFO:Checking environment
2025-05-15 13:02:29,977:INFO:python_version: 3.11.0
2025-05-15 13:02:29,977:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 13:02:29,977:INFO:machine: arm64
2025-05-15 13:02:29,977:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 13:02:29,977:INFO:Memory: svmem(total=17179869184, available=3472080896, percent=79.8, used=6096863232, free=71073792, active=3418587136, inactive=3393716224, wired=2678276096)
2025-05-15 13:02:29,977:INFO:Physical Core: 12
2025-05-15 13:02:29,977:INFO:Logical Core: 12
2025-05-15 13:02:29,977:INFO:Checking libraries
2025-05-15 13:02:29,977:INFO:System:
2025-05-15 13:02:29,977:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 13:02:29,977:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 13:02:29,977:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 13:02:29,977:INFO:PyCaret required dependencies:
2025-05-15 13:02:29,977:INFO:                 pip: 22.3
2025-05-15 13:02:29,977:INFO:          setuptools: 65.5.0
2025-05-15 13:02:29,977:INFO:             pycaret: 3.3.2
2025-05-15 13:02:29,977:INFO:             IPython: 9.2.0
2025-05-15 13:02:29,977:INFO:          ipywidgets: 8.1.7
2025-05-15 13:02:29,977:INFO:                tqdm: 4.67.1
2025-05-15 13:02:29,977:INFO:               numpy: 1.26.4
2025-05-15 13:02:29,977:INFO:              pandas: 2.1.4
2025-05-15 13:02:29,977:INFO:              jinja2: 3.1.6
2025-05-15 13:02:29,977:INFO:               scipy: 1.11.4
2025-05-15 13:02:29,977:INFO:              joblib: 1.3.2
2025-05-15 13:02:29,977:INFO:             sklearn: 1.4.2
2025-05-15 13:02:29,977:INFO:                pyod: 2.0.5
2025-05-15 13:02:29,977:INFO:            imblearn: 0.13.0
2025-05-15 13:02:29,977:INFO:   category_encoders: 2.7.0
2025-05-15 13:02:29,977:INFO:            lightgbm: 4.6.0
2025-05-15 13:02:29,977:INFO:               numba: 0.61.2
2025-05-15 13:02:29,977:INFO:            requests: 2.32.3
2025-05-15 13:02:29,977:INFO:          matplotlib: 3.7.5
2025-05-15 13:02:29,977:INFO:          scikitplot: 0.3.7
2025-05-15 13:02:29,977:INFO:         yellowbrick: 1.5
2025-05-15 13:02:29,977:INFO:              plotly: 5.24.1
2025-05-15 13:02:29,977:INFO:    plotly-resampler: Not installed
2025-05-15 13:02:29,977:INFO:             kaleido: 0.2.1
2025-05-15 13:02:29,977:INFO:           schemdraw: 0.15
2025-05-15 13:02:29,977:INFO:         statsmodels: 0.14.4
2025-05-15 13:02:29,977:INFO:              sktime: 0.26.0
2025-05-15 13:02:29,977:INFO:               tbats: 1.1.3
2025-05-15 13:02:29,977:INFO:            pmdarima: 2.0.4
2025-05-15 13:02:29,977:INFO:              psutil: 7.0.0
2025-05-15 13:02:29,977:INFO:          markupsafe: 3.0.2
2025-05-15 13:02:29,977:INFO:             pickle5: Not installed
2025-05-15 13:02:29,977:INFO:         cloudpickle: 3.1.1
2025-05-15 13:02:29,977:INFO:         deprecation: 2.1.0
2025-05-15 13:02:29,977:INFO:              xxhash: 3.5.0
2025-05-15 13:02:29,977:INFO:           wurlitzer: 3.1.1
2025-05-15 13:02:29,977:INFO:PyCaret optional dependencies:
2025-05-15 13:02:29,977:INFO:                shap: 0.47.2
2025-05-15 13:02:29,977:INFO:           interpret: Not installed
2025-05-15 13:02:29,977:INFO:                umap: Not installed
2025-05-15 13:02:29,977:INFO:     ydata_profiling: Not installed
2025-05-15 13:02:29,977:INFO:  explainerdashboard: Not installed
2025-05-15 13:02:29,977:INFO:             autoviz: Not installed
2025-05-15 13:02:29,977:INFO:           fairlearn: Not installed
2025-05-15 13:02:29,977:INFO:          deepchecks: Not installed
2025-05-15 13:02:29,977:INFO:             xgboost: Not installed
2025-05-15 13:02:29,978:INFO:            catboost: 1.2.8
2025-05-15 13:02:29,978:INFO:              kmodes: Not installed
2025-05-15 13:02:29,978:INFO:             mlxtend: Not installed
2025-05-15 13:02:29,978:INFO:       statsforecast: Not installed
2025-05-15 13:02:29,978:INFO:        tune_sklearn: Not installed
2025-05-15 13:02:29,978:INFO:                 ray: Not installed
2025-05-15 13:02:29,978:INFO:            hyperopt: Not installed
2025-05-15 13:02:29,978:INFO:              optuna: 4.3.0
2025-05-15 13:02:29,978:INFO:               skopt: Not installed
2025-05-15 13:02:29,978:INFO:              mlflow: Not installed
2025-05-15 13:02:29,978:INFO:              gradio: Not installed
2025-05-15 13:02:29,978:INFO:             fastapi: Not installed
2025-05-15 13:02:29,978:INFO:             uvicorn: Not installed
2025-05-15 13:02:29,978:INFO:              m2cgen: Not installed
2025-05-15 13:02:29,978:INFO:           evidently: Not installed
2025-05-15 13:02:29,978:INFO:               fugue: Not installed
2025-05-15 13:02:29,978:INFO:           streamlit: Not installed
2025-05-15 13:02:29,978:INFO:             prophet: Not installed
2025-05-15 13:02:29,978:INFO:None
2025-05-15 13:02:29,978:INFO:Set up data.
2025-05-15 13:02:30,021:INFO:Set up folding strategy.
2025-05-15 13:02:30,021:INFO:Set up train/test split.
2025-05-15 13:02:30,038:INFO:Set up index.
2025-05-15 13:02:30,038:INFO:Assigning column types.
2025-05-15 13:02:30,043:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 13:02:30,061:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 13:02:30,062:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:02:30,073:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:30,073:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:30,092:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 13:02:30,092:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:02:30,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:30,103:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:30,104:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 13:02:30,122:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:02:30,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:30,133:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:30,152:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:02:30,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:30,163:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:30,163:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 13:02:30,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:30,196:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:30,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:30,227:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:30,228:INFO:Preparing preprocessing pipeline...
2025-05-15 13:02:30,229:INFO:Set up simple imputation.
2025-05-15 13:02:30,237:INFO:Set up encoding of ordinal features.
2025-05-15 13:02:30,250:INFO:Set up encoding of categorical features.
2025-05-15 13:02:30,250:INFO:Set up imbalanced handling.
2025-05-15 13:02:30,250:INFO:Set up column transformation.
2025-05-15 13:02:30,600:INFO:Finished creating preprocessing pipeline.
2025-05-15 13:02:30,620:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 13:02:30,620:INFO:Creating final display dataframe.
2025-05-15 13:02:30,881:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (87159, 16)
4        Transformed data shape      (133528, 29)
5   Transformed train set shape      (107380, 29)
6    Transformed test set shape       (26148, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              2cdc
2025-05-15 13:02:30,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:30,915:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:30,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:30,947:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:30,947:INFO:setup() successfully completed in 0.97s...............
2025-05-15 13:02:30,949:INFO:Initializing create_model()
2025-05-15 13:02:30,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326a31810>, estimator=LGBMClassifier, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:02:30,949:INFO:Checking exceptions
2025-05-15 13:02:30,949:INFO:Initializing create_model()
2025-05-15 13:02:30,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326a31810>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:02:30,949:INFO:Checking exceptions
2025-05-15 13:02:30,954:INFO:Importing libraries
2025-05-15 13:02:30,955:INFO:Copying training dataset
2025-05-15 13:02:30,967:INFO:Defining folds
2025-05-15 13:02:30,967:INFO:Declaring metric variables
2025-05-15 13:02:30,968:INFO:Importing untrained model
2025-05-15 13:02:30,970:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:02:30,972:INFO:Starting cross validation
2025-05-15 13:02:30,973:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:02:40,077:INFO:Calculating mean and std
2025-05-15 13:02:40,080:INFO:Creating metrics dataframe
2025-05-15 13:02:40,089:INFO:Finalizing model
2025-05-15 13:02:41,481:INFO:[LightGBM] [Info] Number of positive: 53690, number of negative: 53690
2025-05-15 13:02:41,492:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005063 seconds.
2025-05-15 13:02:41,492:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 13:02:41,492:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 13:02:41,492:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 13:02:41,492:INFO:[LightGBM] [Info] Number of data points in the train set: 107380, number of used features: 28
2025-05-15 13:02:41,493:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 13:02:42,286:INFO:Uploading results into container
2025-05-15 13:02:42,287:INFO:Uploading model into container now
2025-05-15 13:02:42,291:INFO:_master_model_container: 1
2025-05-15 13:02:42,291:INFO:_display_container: 2
2025-05-15 13:02:42,291:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:02:42,291:INFO:create_model() successfully completed......................................
2025-05-15 13:02:42,435:INFO:Initializing save_model()
2025-05-15 13:02:42,435:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-15 13:02:42,436:INFO:Adding model into prep_pipe
2025-05-15 13:02:42,442:INFO:final_cancer_model.pkl saved in current working directory
2025-05-15 13:02:42,462:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 13:02:42,462:INFO:save_model() successfully completed......................................
2025-05-15 13:02:42,533:INFO:Initializing predict_model()
2025-05-15 13:02:42,533:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326a31810>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x331faf920>)
2025-05-15 13:02:42,533:INFO:Checking exceptions
2025-05-15 13:02:42,533:INFO:Preloading libraries
2025-05-15 13:02:42,534:INFO:Set up data.
2025-05-15 13:02:42,552:INFO:Set up index.
2025-05-15 13:02:42,785:INFO:PyCaret ClassificationExperiment
2025-05-15 13:02:42,785:INFO:Logging name: clf-default-name
2025-05-15 13:02:42,785:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 13:02:42,785:INFO:version 3.3.2
2025-05-15 13:02:42,785:INFO:Initializing setup()
2025-05-15 13:02:42,785:INFO:self.USI: 699e
2025-05-15 13:02:42,785:INFO:self._variable_keys: {'_ml_usecase', 'X', 'gpu_param', 'fix_imbalance', 'X_test', '_available_plots', 'n_jobs_param', 'pipeline', 'memory', 'exp_name_log', 'fold_groups_param', 'target_param', 'fold_generator', 'data', 'y', 'exp_id', 'log_plots_param', 'idx', 'USI', 'y_train', 'is_multiclass', 'html_param', 'fold_shuffle_param', 'X_train', 'gpu_n_jobs_param', 'y_test', 'logging_param', 'seed'}
2025-05-15 13:02:42,785:INFO:Checking environment
2025-05-15 13:02:42,785:INFO:python_version: 3.11.0
2025-05-15 13:02:42,785:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 13:02:42,785:INFO:machine: arm64
2025-05-15 13:02:42,785:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 13:02:42,785:INFO:Memory: svmem(total=17179869184, available=3379855360, percent=80.3, used=5875630080, free=65650688, active=3328131072, inactive=3284385792, wired=2547499008)
2025-05-15 13:02:42,785:INFO:Physical Core: 12
2025-05-15 13:02:42,785:INFO:Logical Core: 12
2025-05-15 13:02:42,785:INFO:Checking libraries
2025-05-15 13:02:42,785:INFO:System:
2025-05-15 13:02:42,785:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 13:02:42,785:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 13:02:42,785:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 13:02:42,785:INFO:PyCaret required dependencies:
2025-05-15 13:02:42,785:INFO:                 pip: 22.3
2025-05-15 13:02:42,785:INFO:          setuptools: 65.5.0
2025-05-15 13:02:42,785:INFO:             pycaret: 3.3.2
2025-05-15 13:02:42,785:INFO:             IPython: 9.2.0
2025-05-15 13:02:42,785:INFO:          ipywidgets: 8.1.7
2025-05-15 13:02:42,785:INFO:                tqdm: 4.67.1
2025-05-15 13:02:42,785:INFO:               numpy: 1.26.4
2025-05-15 13:02:42,785:INFO:              pandas: 2.1.4
2025-05-15 13:02:42,785:INFO:              jinja2: 3.1.6
2025-05-15 13:02:42,785:INFO:               scipy: 1.11.4
2025-05-15 13:02:42,785:INFO:              joblib: 1.3.2
2025-05-15 13:02:42,785:INFO:             sklearn: 1.4.2
2025-05-15 13:02:42,785:INFO:                pyod: 2.0.5
2025-05-15 13:02:42,785:INFO:            imblearn: 0.13.0
2025-05-15 13:02:42,785:INFO:   category_encoders: 2.7.0
2025-05-15 13:02:42,785:INFO:            lightgbm: 4.6.0
2025-05-15 13:02:42,785:INFO:               numba: 0.61.2
2025-05-15 13:02:42,785:INFO:            requests: 2.32.3
2025-05-15 13:02:42,785:INFO:          matplotlib: 3.7.5
2025-05-15 13:02:42,785:INFO:          scikitplot: 0.3.7
2025-05-15 13:02:42,785:INFO:         yellowbrick: 1.5
2025-05-15 13:02:42,785:INFO:              plotly: 5.24.1
2025-05-15 13:02:42,785:INFO:    plotly-resampler: Not installed
2025-05-15 13:02:42,785:INFO:             kaleido: 0.2.1
2025-05-15 13:02:42,785:INFO:           schemdraw: 0.15
2025-05-15 13:02:42,785:INFO:         statsmodels: 0.14.4
2025-05-15 13:02:42,785:INFO:              sktime: 0.26.0
2025-05-15 13:02:42,785:INFO:               tbats: 1.1.3
2025-05-15 13:02:42,785:INFO:            pmdarima: 2.0.4
2025-05-15 13:02:42,785:INFO:              psutil: 7.0.0
2025-05-15 13:02:42,785:INFO:          markupsafe: 3.0.2
2025-05-15 13:02:42,785:INFO:             pickle5: Not installed
2025-05-15 13:02:42,785:INFO:         cloudpickle: 3.1.1
2025-05-15 13:02:42,785:INFO:         deprecation: 2.1.0
2025-05-15 13:02:42,785:INFO:              xxhash: 3.5.0
2025-05-15 13:02:42,785:INFO:           wurlitzer: 3.1.1
2025-05-15 13:02:42,785:INFO:PyCaret optional dependencies:
2025-05-15 13:02:42,785:INFO:                shap: 0.47.2
2025-05-15 13:02:42,785:INFO:           interpret: Not installed
2025-05-15 13:02:42,785:INFO:                umap: Not installed
2025-05-15 13:02:42,785:INFO:     ydata_profiling: Not installed
2025-05-15 13:02:42,785:INFO:  explainerdashboard: Not installed
2025-05-15 13:02:42,785:INFO:             autoviz: Not installed
2025-05-15 13:02:42,785:INFO:           fairlearn: Not installed
2025-05-15 13:02:42,785:INFO:          deepchecks: Not installed
2025-05-15 13:02:42,785:INFO:             xgboost: Not installed
2025-05-15 13:02:42,785:INFO:            catboost: 1.2.8
2025-05-15 13:02:42,785:INFO:              kmodes: Not installed
2025-05-15 13:02:42,785:INFO:             mlxtend: Not installed
2025-05-15 13:02:42,785:INFO:       statsforecast: Not installed
2025-05-15 13:02:42,786:INFO:        tune_sklearn: Not installed
2025-05-15 13:02:42,786:INFO:                 ray: Not installed
2025-05-15 13:02:42,786:INFO:            hyperopt: Not installed
2025-05-15 13:02:42,786:INFO:              optuna: 4.3.0
2025-05-15 13:02:42,786:INFO:               skopt: Not installed
2025-05-15 13:02:42,786:INFO:              mlflow: Not installed
2025-05-15 13:02:42,786:INFO:              gradio: Not installed
2025-05-15 13:02:42,786:INFO:             fastapi: Not installed
2025-05-15 13:02:42,786:INFO:             uvicorn: Not installed
2025-05-15 13:02:42,786:INFO:              m2cgen: Not installed
2025-05-15 13:02:42,786:INFO:           evidently: Not installed
2025-05-15 13:02:42,786:INFO:               fugue: Not installed
2025-05-15 13:02:42,786:INFO:           streamlit: Not installed
2025-05-15 13:02:42,786:INFO:             prophet: Not installed
2025-05-15 13:02:42,786:INFO:None
2025-05-15 13:02:42,786:INFO:Set up data.
2025-05-15 13:02:42,832:INFO:Set up folding strategy.
2025-05-15 13:02:42,832:INFO:Set up train/test split.
2025-05-15 13:02:42,848:INFO:Set up index.
2025-05-15 13:02:42,849:INFO:Assigning column types.
2025-05-15 13:02:42,854:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 13:02:42,872:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 13:02:42,873:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:02:42,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:42,884:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:42,903:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 13:02:42,903:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:02:42,915:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:42,915:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:42,916:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 13:02:42,935:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:02:42,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:42,947:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:42,965:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:02:42,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:42,977:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:42,977:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 13:02:43,006:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:43,006:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:43,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:43,036:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:43,036:INFO:Preparing preprocessing pipeline...
2025-05-15 13:02:43,038:INFO:Set up simple imputation.
2025-05-15 13:02:43,045:INFO:Set up encoding of ordinal features.
2025-05-15 13:02:43,058:INFO:Set up encoding of categorical features.
2025-05-15 13:02:43,058:INFO:Set up imbalanced handling.
2025-05-15 13:02:43,058:INFO:Set up column transformation.
2025-05-15 13:02:43,400:INFO:Finished creating preprocessing pipeline.
2025-05-15 13:02:43,421:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 13:02:43,421:INFO:Creating final display dataframe.
2025-05-15 13:02:43,682:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (87159, 16)
4        Transformed data shape      (133528, 29)
5   Transformed train set shape      (107380, 29)
6    Transformed test set shape       (26148, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              699e
2025-05-15 13:02:43,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:43,715:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:43,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:02:43,746:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:02:43,746:INFO:setup() successfully completed in 0.96s...............
2025-05-15 13:02:43,760:INFO:Initializing create_model()
2025-05-15 13:02:43,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e5c590>, estimator=LGBMClassifier, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:02:43,760:INFO:Checking exceptions
2025-05-15 13:02:43,760:INFO:Initializing create_model()
2025-05-15 13:02:43,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e5c590>, estimator=GradientBoostingClassifier, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:02:43,760:INFO:Checking exceptions
2025-05-15 13:02:43,760:INFO:Initializing create_model()
2025-05-15 13:02:43,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e5c590>, estimator=DecisionTreeClassifier, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:02:43,760:INFO:Checking exceptions
2025-05-15 13:02:43,760:INFO:Initializing predict_model()
2025-05-15 13:02:43,760:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x327e5c590>, estimator=<function ensemble_model at 0x326a58860>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x33354d6c0>)
2025-05-15 13:02:43,760:INFO:Checking exceptions
2025-05-15 13:02:43,760:INFO:Preloading libraries
2025-05-15 13:02:43,761:INFO:Set up data.
2025-05-15 13:02:43,778:INFO:Set up index.
2025-05-15 13:07:19,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 13:07:19,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 13:07:19,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 13:07:19,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 13:07:28,619:INFO:PyCaret ClassificationExperiment
2025-05-15 13:07:28,619:INFO:Logging name: clf-default-name
2025-05-15 13:07:28,619:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 13:07:28,619:INFO:version 3.3.2
2025-05-15 13:07:28,619:INFO:Initializing setup()
2025-05-15 13:07:28,619:INFO:self.USI: 047f
2025-05-15 13:07:28,619:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-15 13:07:28,619:INFO:Checking environment
2025-05-15 13:07:28,619:INFO:python_version: 3.11.0
2025-05-15 13:07:28,619:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 13:07:28,619:INFO:machine: arm64
2025-05-15 13:07:28,619:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 13:07:28,619:INFO:Memory: svmem(total=17179869184, available=2975547392, percent=82.7, used=5697814528, free=79609856, active=2916204544, inactive=2891972608, wired=2781609984)
2025-05-15 13:07:28,619:INFO:Physical Core: 12
2025-05-15 13:07:28,619:INFO:Logical Core: 12
2025-05-15 13:07:28,619:INFO:Checking libraries
2025-05-15 13:07:28,619:INFO:System:
2025-05-15 13:07:28,619:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 13:07:28,619:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 13:07:28,619:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 13:07:28,619:INFO:PyCaret required dependencies:
2025-05-15 13:07:28,651:INFO:                 pip: 22.3
2025-05-15 13:07:28,651:INFO:          setuptools: 65.5.0
2025-05-15 13:07:28,651:INFO:             pycaret: 3.3.2
2025-05-15 13:07:28,651:INFO:             IPython: 9.2.0
2025-05-15 13:07:28,651:INFO:          ipywidgets: 8.1.7
2025-05-15 13:07:28,651:INFO:                tqdm: 4.67.1
2025-05-15 13:07:28,651:INFO:               numpy: 1.26.4
2025-05-15 13:07:28,651:INFO:              pandas: 2.1.4
2025-05-15 13:07:28,651:INFO:              jinja2: 3.1.6
2025-05-15 13:07:28,651:INFO:               scipy: 1.11.4
2025-05-15 13:07:28,651:INFO:              joblib: 1.3.2
2025-05-15 13:07:28,651:INFO:             sklearn: 1.4.2
2025-05-15 13:07:28,651:INFO:                pyod: 2.0.5
2025-05-15 13:07:28,651:INFO:            imblearn: 0.13.0
2025-05-15 13:07:28,651:INFO:   category_encoders: 2.7.0
2025-05-15 13:07:28,651:INFO:            lightgbm: 4.6.0
2025-05-15 13:07:28,651:INFO:               numba: 0.61.2
2025-05-15 13:07:28,651:INFO:            requests: 2.32.3
2025-05-15 13:07:28,651:INFO:          matplotlib: 3.7.5
2025-05-15 13:07:28,651:INFO:          scikitplot: 0.3.7
2025-05-15 13:07:28,651:INFO:         yellowbrick: 1.5
2025-05-15 13:07:28,651:INFO:              plotly: 5.24.1
2025-05-15 13:07:28,651:INFO:    plotly-resampler: Not installed
2025-05-15 13:07:28,651:INFO:             kaleido: 0.2.1
2025-05-15 13:07:28,651:INFO:           schemdraw: 0.15
2025-05-15 13:07:28,651:INFO:         statsmodels: 0.14.4
2025-05-15 13:07:28,651:INFO:              sktime: 0.26.0
2025-05-15 13:07:28,651:INFO:               tbats: 1.1.3
2025-05-15 13:07:28,651:INFO:            pmdarima: 2.0.4
2025-05-15 13:07:28,651:INFO:              psutil: 7.0.0
2025-05-15 13:07:28,651:INFO:          markupsafe: 3.0.2
2025-05-15 13:07:28,651:INFO:             pickle5: Not installed
2025-05-15 13:07:28,651:INFO:         cloudpickle: 3.1.1
2025-05-15 13:07:28,651:INFO:         deprecation: 2.1.0
2025-05-15 13:07:28,651:INFO:              xxhash: 3.5.0
2025-05-15 13:07:28,651:INFO:           wurlitzer: 3.1.1
2025-05-15 13:07:28,651:INFO:PyCaret optional dependencies:
2025-05-15 13:07:28,656:INFO:                shap: 0.47.2
2025-05-15 13:07:28,656:INFO:           interpret: Not installed
2025-05-15 13:07:28,656:INFO:                umap: Not installed
2025-05-15 13:07:28,656:INFO:     ydata_profiling: Not installed
2025-05-15 13:07:28,656:INFO:  explainerdashboard: Not installed
2025-05-15 13:07:28,656:INFO:             autoviz: Not installed
2025-05-15 13:07:28,656:INFO:           fairlearn: Not installed
2025-05-15 13:07:28,656:INFO:          deepchecks: Not installed
2025-05-15 13:07:28,656:INFO:             xgboost: Not installed
2025-05-15 13:07:28,656:INFO:            catboost: 1.2.8
2025-05-15 13:07:28,656:INFO:              kmodes: Not installed
2025-05-15 13:07:28,656:INFO:             mlxtend: Not installed
2025-05-15 13:07:28,656:INFO:       statsforecast: Not installed
2025-05-15 13:07:28,656:INFO:        tune_sklearn: Not installed
2025-05-15 13:07:28,656:INFO:                 ray: Not installed
2025-05-15 13:07:28,656:INFO:            hyperopt: Not installed
2025-05-15 13:07:28,656:INFO:              optuna: 4.3.0
2025-05-15 13:07:28,656:INFO:               skopt: Not installed
2025-05-15 13:07:28,656:INFO:              mlflow: Not installed
2025-05-15 13:07:28,656:INFO:              gradio: Not installed
2025-05-15 13:07:28,656:INFO:             fastapi: Not installed
2025-05-15 13:07:28,656:INFO:             uvicorn: Not installed
2025-05-15 13:07:28,656:INFO:              m2cgen: Not installed
2025-05-15 13:07:28,656:INFO:           evidently: Not installed
2025-05-15 13:07:28,656:INFO:               fugue: Not installed
2025-05-15 13:07:28,656:INFO:           streamlit: Not installed
2025-05-15 13:07:28,656:INFO:             prophet: Not installed
2025-05-15 13:07:28,656:INFO:None
2025-05-15 13:07:28,656:INFO:Set up data.
2025-05-15 13:07:28,686:INFO:Set up folding strategy.
2025-05-15 13:07:28,686:INFO:Set up train/test split.
2025-05-15 13:07:28,705:INFO:Set up index.
2025-05-15 13:07:28,705:INFO:Assigning column types.
2025-05-15 13:07:28,708:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 13:07:28,726:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 13:07:28,727:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:07:28,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:07:28,742:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:07:28,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 13:07:28,793:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:07:28,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:07:28,804:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:07:28,804:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 13:07:28,822:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:07:28,833:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:07:28,833:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:07:28,851:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:07:28,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:07:28,862:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:07:28,862:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 13:07:28,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:07:28,892:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:07:28,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:07:28,923:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:07:28,924:INFO:Preparing preprocessing pipeline...
2025-05-15 13:07:28,925:INFO:Set up simple imputation.
2025-05-15 13:07:28,932:INFO:Set up encoding of ordinal features.
2025-05-15 13:07:28,943:INFO:Set up encoding of categorical features.
2025-05-15 13:07:28,943:INFO:Set up imbalanced handling.
2025-05-15 13:07:28,943:INFO:Set up column transformation.
2025-05-15 13:07:30,293:INFO:Finished creating preprocessing pipeline.
2025-05-15 13:07:30,312:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 13:07:30,312:INFO:Creating final display dataframe.
2025-05-15 13:07:30,783:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 15)
4        Transformed data shape      (106821, 28)
5   Transformed train set shape       (85902, 28)
6    Transformed test set shape       (20919, 28)
7              Numeric features                 5
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              047f
2025-05-15 13:07:30,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:07:30,818:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:07:30,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:07:30,850:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:07:30,851:INFO:setup() successfully completed in 2.24s...............
2025-05-15 13:07:30,851:INFO:Initializing compare_models()
2025-05-15 13:07:30,851:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-15 13:07:30,851:INFO:Checking exceptions
2025-05-15 13:07:30,856:INFO:Preparing display monitor
2025-05-15 13:07:30,889:INFO:Initializing Logistic Regression
2025-05-15 13:07:30,890:INFO:Total runtime is 3.612041473388672e-06 minutes
2025-05-15 13:07:30,891:INFO:SubProcess create_model() called ==================================
2025-05-15 13:07:30,891:INFO:Initializing create_model()
2025-05-15 13:07:30,891:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:07:30,891:INFO:Checking exceptions
2025-05-15 13:07:30,891:INFO:Importing libraries
2025-05-15 13:07:30,891:INFO:Copying training dataset
2025-05-15 13:07:30,903:INFO:Defining folds
2025-05-15 13:07:30,903:INFO:Declaring metric variables
2025-05-15 13:07:30,904:INFO:Importing untrained model
2025-05-15 13:07:30,906:INFO:Logistic Regression Imported successfully
2025-05-15 13:07:30,909:INFO:Starting cross validation
2025-05-15 13:07:30,911:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:07:36,475:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:07:36,657:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:07:36,772:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:07:36,784:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:07:36,792:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:07:36,851:INFO:Calculating mean and std
2025-05-15 13:07:36,860:INFO:Creating metrics dataframe
2025-05-15 13:07:36,865:INFO:Uploading results into container
2025-05-15 13:07:36,866:INFO:Uploading model into container now
2025-05-15 13:07:36,867:INFO:_master_model_container: 1
2025-05-15 13:07:36,867:INFO:_display_container: 2
2025-05-15 13:07:36,867:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 13:07:36,867:INFO:create_model() successfully completed......................................
2025-05-15 13:07:36,961:INFO:SubProcess create_model() end ==================================
2025-05-15 13:07:36,961:INFO:Creating metrics dataframe
2025-05-15 13:07:36,963:INFO:Initializing K Neighbors Classifier
2025-05-15 13:07:36,964:INFO:Total runtime is 0.10123656590779623 minutes
2025-05-15 13:07:36,965:INFO:SubProcess create_model() called ==================================
2025-05-15 13:07:36,965:INFO:Initializing create_model()
2025-05-15 13:07:36,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:07:36,965:INFO:Checking exceptions
2025-05-15 13:07:36,965:INFO:Importing libraries
2025-05-15 13:07:36,965:INFO:Copying training dataset
2025-05-15 13:07:36,974:INFO:Defining folds
2025-05-15 13:07:36,974:INFO:Declaring metric variables
2025-05-15 13:07:36,976:INFO:Importing untrained model
2025-05-15 13:07:36,977:INFO:K Neighbors Classifier Imported successfully
2025-05-15 13:07:36,980:INFO:Starting cross validation
2025-05-15 13:07:36,981:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:07:42,877:INFO:Calculating mean and std
2025-05-15 13:07:42,878:INFO:Creating metrics dataframe
2025-05-15 13:07:42,880:INFO:Uploading results into container
2025-05-15 13:07:42,880:INFO:Uploading model into container now
2025-05-15 13:07:42,881:INFO:_master_model_container: 2
2025-05-15 13:07:42,881:INFO:_display_container: 2
2025-05-15 13:07:42,881:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-15 13:07:42,881:INFO:create_model() successfully completed......................................
2025-05-15 13:07:42,938:INFO:SubProcess create_model() end ==================================
2025-05-15 13:07:42,939:INFO:Creating metrics dataframe
2025-05-15 13:07:42,942:INFO:Initializing Naive Bayes
2025-05-15 13:07:42,942:INFO:Total runtime is 0.2008727788925171 minutes
2025-05-15 13:07:42,943:INFO:SubProcess create_model() called ==================================
2025-05-15 13:07:42,943:INFO:Initializing create_model()
2025-05-15 13:07:42,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:07:42,943:INFO:Checking exceptions
2025-05-15 13:07:42,943:INFO:Importing libraries
2025-05-15 13:07:42,943:INFO:Copying training dataset
2025-05-15 13:07:42,953:INFO:Defining folds
2025-05-15 13:07:42,954:INFO:Declaring metric variables
2025-05-15 13:07:42,955:INFO:Importing untrained model
2025-05-15 13:07:42,956:INFO:Naive Bayes Imported successfully
2025-05-15 13:07:42,959:INFO:Starting cross validation
2025-05-15 13:07:42,960:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:07:45,121:INFO:Calculating mean and std
2025-05-15 13:07:45,122:INFO:Creating metrics dataframe
2025-05-15 13:07:45,123:INFO:Uploading results into container
2025-05-15 13:07:45,123:INFO:Uploading model into container now
2025-05-15 13:07:45,123:INFO:_master_model_container: 3
2025-05-15 13:07:45,123:INFO:_display_container: 2
2025-05-15 13:07:45,123:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-15 13:07:45,123:INFO:create_model() successfully completed......................................
2025-05-15 13:07:45,175:INFO:SubProcess create_model() end ==================================
2025-05-15 13:07:45,175:INFO:Creating metrics dataframe
2025-05-15 13:07:45,178:INFO:Initializing Decision Tree Classifier
2025-05-15 13:07:45,178:INFO:Total runtime is 0.23815009593963624 minutes
2025-05-15 13:07:45,180:INFO:SubProcess create_model() called ==================================
2025-05-15 13:07:45,180:INFO:Initializing create_model()
2025-05-15 13:07:45,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:07:45,180:INFO:Checking exceptions
2025-05-15 13:07:45,180:INFO:Importing libraries
2025-05-15 13:07:45,180:INFO:Copying training dataset
2025-05-15 13:07:45,189:INFO:Defining folds
2025-05-15 13:07:45,189:INFO:Declaring metric variables
2025-05-15 13:07:45,190:INFO:Importing untrained model
2025-05-15 13:07:45,191:INFO:Decision Tree Classifier Imported successfully
2025-05-15 13:07:45,194:INFO:Starting cross validation
2025-05-15 13:07:45,195:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:07:46,727:INFO:Calculating mean and std
2025-05-15 13:07:46,728:INFO:Creating metrics dataframe
2025-05-15 13:07:46,729:INFO:Uploading results into container
2025-05-15 13:07:46,729:INFO:Uploading model into container now
2025-05-15 13:07:46,729:INFO:_master_model_container: 4
2025-05-15 13:07:46,729:INFO:_display_container: 2
2025-05-15 13:07:46,729:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-15 13:07:46,729:INFO:create_model() successfully completed......................................
2025-05-15 13:07:46,778:INFO:SubProcess create_model() end ==================================
2025-05-15 13:07:46,778:INFO:Creating metrics dataframe
2025-05-15 13:07:46,782:INFO:Initializing SVM - Linear Kernel
2025-05-15 13:07:46,782:INFO:Total runtime is 0.26487212975819907 minutes
2025-05-15 13:07:46,783:INFO:SubProcess create_model() called ==================================
2025-05-15 13:07:46,783:INFO:Initializing create_model()
2025-05-15 13:07:46,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:07:46,783:INFO:Checking exceptions
2025-05-15 13:07:46,783:INFO:Importing libraries
2025-05-15 13:07:46,783:INFO:Copying training dataset
2025-05-15 13:07:46,793:INFO:Defining folds
2025-05-15 13:07:46,793:INFO:Declaring metric variables
2025-05-15 13:07:46,794:INFO:Importing untrained model
2025-05-15 13:07:46,795:INFO:SVM - Linear Kernel Imported successfully
2025-05-15 13:07:46,798:INFO:Starting cross validation
2025-05-15 13:07:46,799:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:07:49,762:INFO:Calculating mean and std
2025-05-15 13:07:49,763:INFO:Creating metrics dataframe
2025-05-15 13:07:49,764:INFO:Uploading results into container
2025-05-15 13:07:49,765:INFO:Uploading model into container now
2025-05-15 13:07:49,765:INFO:_master_model_container: 5
2025-05-15 13:07:49,765:INFO:_display_container: 2
2025-05-15 13:07:49,765:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-15 13:07:49,765:INFO:create_model() successfully completed......................................
2025-05-15 13:07:49,820:INFO:SubProcess create_model() end ==================================
2025-05-15 13:07:49,820:INFO:Creating metrics dataframe
2025-05-15 13:07:49,823:INFO:Initializing Ridge Classifier
2025-05-15 13:07:49,823:INFO:Total runtime is 0.3155694961547852 minutes
2025-05-15 13:07:49,825:INFO:SubProcess create_model() called ==================================
2025-05-15 13:07:49,825:INFO:Initializing create_model()
2025-05-15 13:07:49,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:07:49,825:INFO:Checking exceptions
2025-05-15 13:07:49,825:INFO:Importing libraries
2025-05-15 13:07:49,825:INFO:Copying training dataset
2025-05-15 13:07:49,834:INFO:Defining folds
2025-05-15 13:07:49,834:INFO:Declaring metric variables
2025-05-15 13:07:49,835:INFO:Importing untrained model
2025-05-15 13:07:49,837:INFO:Ridge Classifier Imported successfully
2025-05-15 13:07:49,839:INFO:Starting cross validation
2025-05-15 13:07:49,841:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:07:52,027:INFO:Calculating mean and std
2025-05-15 13:07:52,028:INFO:Creating metrics dataframe
2025-05-15 13:07:52,029:INFO:Uploading results into container
2025-05-15 13:07:52,029:INFO:Uploading model into container now
2025-05-15 13:07:52,029:INFO:_master_model_container: 6
2025-05-15 13:07:52,029:INFO:_display_container: 2
2025-05-15 13:07:52,030:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-15 13:07:52,030:INFO:create_model() successfully completed......................................
2025-05-15 13:07:52,082:INFO:SubProcess create_model() end ==================================
2025-05-15 13:07:52,082:INFO:Creating metrics dataframe
2025-05-15 13:07:52,085:INFO:Initializing Random Forest Classifier
2025-05-15 13:07:52,085:INFO:Total runtime is 0.3532652775446574 minutes
2025-05-15 13:07:52,086:INFO:SubProcess create_model() called ==================================
2025-05-15 13:07:52,087:INFO:Initializing create_model()
2025-05-15 13:07:52,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:07:52,087:INFO:Checking exceptions
2025-05-15 13:07:52,087:INFO:Importing libraries
2025-05-15 13:07:52,087:INFO:Copying training dataset
2025-05-15 13:07:52,096:INFO:Defining folds
2025-05-15 13:07:52,096:INFO:Declaring metric variables
2025-05-15 13:07:52,097:INFO:Importing untrained model
2025-05-15 13:07:52,098:INFO:Random Forest Classifier Imported successfully
2025-05-15 13:07:52,101:INFO:Starting cross validation
2025-05-15 13:07:52,102:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:07:57,721:INFO:Calculating mean and std
2025-05-15 13:07:57,722:INFO:Creating metrics dataframe
2025-05-15 13:07:57,723:INFO:Uploading results into container
2025-05-15 13:07:57,723:INFO:Uploading model into container now
2025-05-15 13:07:57,724:INFO:_master_model_container: 7
2025-05-15 13:07:57,724:INFO:_display_container: 2
2025-05-15 13:07:57,724:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 13:07:57,724:INFO:create_model() successfully completed......................................
2025-05-15 13:07:57,775:INFO:SubProcess create_model() end ==================================
2025-05-15 13:07:57,775:INFO:Creating metrics dataframe
2025-05-15 13:07:57,778:INFO:Initializing Quadratic Discriminant Analysis
2025-05-15 13:07:57,778:INFO:Total runtime is 0.4481493433316549 minutes
2025-05-15 13:07:57,779:INFO:SubProcess create_model() called ==================================
2025-05-15 13:07:57,780:INFO:Initializing create_model()
2025-05-15 13:07:57,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:07:57,780:INFO:Checking exceptions
2025-05-15 13:07:57,780:INFO:Importing libraries
2025-05-15 13:07:57,780:INFO:Copying training dataset
2025-05-15 13:07:57,791:INFO:Defining folds
2025-05-15 13:07:57,791:INFO:Declaring metric variables
2025-05-15 13:07:57,792:INFO:Importing untrained model
2025-05-15 13:07:57,793:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 13:07:57,796:INFO:Starting cross validation
2025-05-15 13:07:57,798:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:07:58,754:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:07:58,776:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:07:58,810:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:07:58,830:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:07:58,834:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:07:58,848:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:07:58,869:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:07:58,882:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:07:58,905:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:07:58,942:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:07:58,948:INFO:Calculating mean and std
2025-05-15 13:07:58,949:INFO:Creating metrics dataframe
2025-05-15 13:07:58,950:INFO:Uploading results into container
2025-05-15 13:07:58,950:INFO:Uploading model into container now
2025-05-15 13:07:58,950:INFO:_master_model_container: 8
2025-05-15 13:07:58,950:INFO:_display_container: 2
2025-05-15 13:07:58,950:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 13:07:58,950:INFO:create_model() successfully completed......................................
2025-05-15 13:07:58,998:INFO:SubProcess create_model() end ==================================
2025-05-15 13:07:58,998:INFO:Creating metrics dataframe
2025-05-15 13:07:59,002:INFO:Initializing Ada Boost Classifier
2025-05-15 13:07:59,002:INFO:Total runtime is 0.4685437997182211 minutes
2025-05-15 13:07:59,003:INFO:SubProcess create_model() called ==================================
2025-05-15 13:07:59,003:INFO:Initializing create_model()
2025-05-15 13:07:59,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:07:59,003:INFO:Checking exceptions
2025-05-15 13:07:59,004:INFO:Importing libraries
2025-05-15 13:07:59,004:INFO:Copying training dataset
2025-05-15 13:07:59,013:INFO:Defining folds
2025-05-15 13:07:59,013:INFO:Declaring metric variables
2025-05-15 13:07:59,014:INFO:Importing untrained model
2025-05-15 13:07:59,016:INFO:Ada Boost Classifier Imported successfully
2025-05-15 13:07:59,018:INFO:Starting cross validation
2025-05-15 13:07:59,020:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:07:59,935:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:07:59,936:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:07:59,956:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:07:59,994:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:08:00,019:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:08:02,634:INFO:Calculating mean and std
2025-05-15 13:08:02,635:INFO:Creating metrics dataframe
2025-05-15 13:08:02,636:INFO:Uploading results into container
2025-05-15 13:08:02,636:INFO:Uploading model into container now
2025-05-15 13:08:02,636:INFO:_master_model_container: 9
2025-05-15 13:08:02,637:INFO:_display_container: 2
2025-05-15 13:08:02,637:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-15 13:08:02,637:INFO:create_model() successfully completed......................................
2025-05-15 13:08:02,695:INFO:SubProcess create_model() end ==================================
2025-05-15 13:08:02,695:INFO:Creating metrics dataframe
2025-05-15 13:08:02,698:INFO:Initializing Gradient Boosting Classifier
2025-05-15 13:08:02,698:INFO:Total runtime is 0.530151363213857 minutes
2025-05-15 13:08:02,700:INFO:SubProcess create_model() called ==================================
2025-05-15 13:08:02,700:INFO:Initializing create_model()
2025-05-15 13:08:02,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:08:02,700:INFO:Checking exceptions
2025-05-15 13:08:02,700:INFO:Importing libraries
2025-05-15 13:08:02,700:INFO:Copying training dataset
2025-05-15 13:08:02,709:INFO:Defining folds
2025-05-15 13:08:02,709:INFO:Declaring metric variables
2025-05-15 13:08:02,710:INFO:Importing untrained model
2025-05-15 13:08:02,711:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 13:08:02,714:INFO:Starting cross validation
2025-05-15 13:08:02,715:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:08:16,191:INFO:Calculating mean and std
2025-05-15 13:08:16,192:INFO:Creating metrics dataframe
2025-05-15 13:08:16,193:INFO:Uploading results into container
2025-05-15 13:08:16,193:INFO:Uploading model into container now
2025-05-15 13:08:16,193:INFO:_master_model_container: 10
2025-05-15 13:08:16,193:INFO:_display_container: 2
2025-05-15 13:08:16,193:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 13:08:16,193:INFO:create_model() successfully completed......................................
2025-05-15 13:08:16,243:INFO:SubProcess create_model() end ==================================
2025-05-15 13:08:16,243:INFO:Creating metrics dataframe
2025-05-15 13:08:16,246:INFO:Initializing Linear Discriminant Analysis
2025-05-15 13:08:16,246:INFO:Total runtime is 0.7559482494990031 minutes
2025-05-15 13:08:16,247:INFO:SubProcess create_model() called ==================================
2025-05-15 13:08:16,247:INFO:Initializing create_model()
2025-05-15 13:08:16,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:08:16,248:INFO:Checking exceptions
2025-05-15 13:08:16,248:INFO:Importing libraries
2025-05-15 13:08:16,248:INFO:Copying training dataset
2025-05-15 13:08:16,256:INFO:Defining folds
2025-05-15 13:08:16,256:INFO:Declaring metric variables
2025-05-15 13:08:16,258:INFO:Importing untrained model
2025-05-15 13:08:16,259:INFO:Linear Discriminant Analysis Imported successfully
2025-05-15 13:08:16,261:INFO:Starting cross validation
2025-05-15 13:08:16,262:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:08:17,439:INFO:Calculating mean and std
2025-05-15 13:08:17,440:INFO:Creating metrics dataframe
2025-05-15 13:08:17,441:INFO:Uploading results into container
2025-05-15 13:08:17,441:INFO:Uploading model into container now
2025-05-15 13:08:17,441:INFO:_master_model_container: 11
2025-05-15 13:08:17,441:INFO:_display_container: 2
2025-05-15 13:08:17,441:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-15 13:08:17,441:INFO:create_model() successfully completed......................................
2025-05-15 13:08:17,489:INFO:SubProcess create_model() end ==================================
2025-05-15 13:08:17,489:INFO:Creating metrics dataframe
2025-05-15 13:08:17,493:INFO:Initializing Extra Trees Classifier
2025-05-15 13:08:17,493:INFO:Total runtime is 0.7767340779304505 minutes
2025-05-15 13:08:17,495:INFO:SubProcess create_model() called ==================================
2025-05-15 13:08:17,495:INFO:Initializing create_model()
2025-05-15 13:08:17,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:08:17,495:INFO:Checking exceptions
2025-05-15 13:08:17,495:INFO:Importing libraries
2025-05-15 13:08:17,495:INFO:Copying training dataset
2025-05-15 13:08:17,505:INFO:Defining folds
2025-05-15 13:08:17,505:INFO:Declaring metric variables
2025-05-15 13:08:17,507:INFO:Importing untrained model
2025-05-15 13:08:17,508:INFO:Extra Trees Classifier Imported successfully
2025-05-15 13:08:17,510:INFO:Starting cross validation
2025-05-15 13:08:17,511:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:08:21,866:INFO:Calculating mean and std
2025-05-15 13:08:21,871:INFO:Creating metrics dataframe
2025-05-15 13:08:21,880:INFO:Uploading results into container
2025-05-15 13:08:21,880:INFO:Uploading model into container now
2025-05-15 13:08:21,881:INFO:_master_model_container: 12
2025-05-15 13:08:21,881:INFO:_display_container: 2
2025-05-15 13:08:21,881:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 13:08:21,881:INFO:create_model() successfully completed......................................
2025-05-15 13:08:22,015:INFO:SubProcess create_model() end ==================================
2025-05-15 13:08:22,015:INFO:Creating metrics dataframe
2025-05-15 13:08:22,020:INFO:Initializing Light Gradient Boosting Machine
2025-05-15 13:08:22,020:INFO:Total runtime is 0.8521717151006063 minutes
2025-05-15 13:08:22,021:INFO:SubProcess create_model() called ==================================
2025-05-15 13:08:22,021:INFO:Initializing create_model()
2025-05-15 13:08:22,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:08:22,021:INFO:Checking exceptions
2025-05-15 13:08:22,021:INFO:Importing libraries
2025-05-15 13:08:22,021:INFO:Copying training dataset
2025-05-15 13:08:22,039:INFO:Defining folds
2025-05-15 13:08:22,039:INFO:Declaring metric variables
2025-05-15 13:08:22,040:INFO:Importing untrained model
2025-05-15 13:08:22,042:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:08:22,045:INFO:Starting cross validation
2025-05-15 13:08:22,048:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:08:26,108:INFO:Calculating mean and std
2025-05-15 13:08:26,108:INFO:Creating metrics dataframe
2025-05-15 13:08:26,109:INFO:Uploading results into container
2025-05-15 13:08:26,109:INFO:Uploading model into container now
2025-05-15 13:08:26,109:INFO:_master_model_container: 13
2025-05-15 13:08:26,110:INFO:_display_container: 2
2025-05-15 13:08:26,110:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:08:26,110:INFO:create_model() successfully completed......................................
2025-05-15 13:08:26,160:INFO:SubProcess create_model() end ==================================
2025-05-15 13:08:26,160:INFO:Creating metrics dataframe
2025-05-15 13:08:26,164:INFO:Initializing CatBoost Classifier
2025-05-15 13:08:26,164:INFO:Total runtime is 0.9212422966957092 minutes
2025-05-15 13:08:26,165:INFO:SubProcess create_model() called ==================================
2025-05-15 13:08:26,165:INFO:Initializing create_model()
2025-05-15 13:08:26,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:08:26,165:INFO:Checking exceptions
2025-05-15 13:08:26,165:INFO:Importing libraries
2025-05-15 13:08:26,166:INFO:Copying training dataset
2025-05-15 13:08:26,174:INFO:Defining folds
2025-05-15 13:08:26,174:INFO:Declaring metric variables
2025-05-15 13:08:26,175:INFO:Importing untrained model
2025-05-15 13:08:26,176:INFO:CatBoost Classifier Imported successfully
2025-05-15 13:08:26,179:INFO:Starting cross validation
2025-05-15 13:08:26,180:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:08:42,702:INFO:Calculating mean and std
2025-05-15 13:08:42,704:INFO:Creating metrics dataframe
2025-05-15 13:08:42,706:INFO:Uploading results into container
2025-05-15 13:08:42,706:INFO:Uploading model into container now
2025-05-15 13:08:42,706:INFO:_master_model_container: 14
2025-05-15 13:08:42,706:INFO:_display_container: 2
2025-05-15 13:08:42,706:INFO:<catboost.core.CatBoostClassifier object at 0x3308b2950>
2025-05-15 13:08:42,706:INFO:create_model() successfully completed......................................
2025-05-15 13:08:42,773:INFO:SubProcess create_model() end ==================================
2025-05-15 13:08:42,773:INFO:Creating metrics dataframe
2025-05-15 13:08:42,778:INFO:Initializing Dummy Classifier
2025-05-15 13:08:42,778:INFO:Total runtime is 1.1981388131777446 minutes
2025-05-15 13:08:42,779:INFO:SubProcess create_model() called ==================================
2025-05-15 13:08:42,779:INFO:Initializing create_model()
2025-05-15 13:08:42,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33072bd10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:08:42,779:INFO:Checking exceptions
2025-05-15 13:08:42,779:INFO:Importing libraries
2025-05-15 13:08:42,779:INFO:Copying training dataset
2025-05-15 13:08:42,789:INFO:Defining folds
2025-05-15 13:08:42,790:INFO:Declaring metric variables
2025-05-15 13:08:42,791:INFO:Importing untrained model
2025-05-15 13:08:42,792:INFO:Dummy Classifier Imported successfully
2025-05-15 13:08:42,794:INFO:Starting cross validation
2025-05-15 13:08:42,796:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:08:43,827:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:08:43,879:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:08:43,880:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:08:43,890:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:08:43,894:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:08:43,912:INFO:Calculating mean and std
2025-05-15 13:08:43,912:INFO:Creating metrics dataframe
2025-05-15 13:08:43,913:INFO:Uploading results into container
2025-05-15 13:08:43,913:INFO:Uploading model into container now
2025-05-15 13:08:43,914:INFO:_master_model_container: 15
2025-05-15 13:08:43,914:INFO:_display_container: 2
2025-05-15 13:08:43,914:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-15 13:08:43,914:INFO:create_model() successfully completed......................................
2025-05-15 13:08:43,968:INFO:SubProcess create_model() end ==================================
2025-05-15 13:08:43,968:INFO:Creating metrics dataframe
2025-05-15 13:08:43,975:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-15 13:08:43,978:INFO:Initializing create_model()
2025-05-15 13:08:43,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:08:43,978:INFO:Checking exceptions
2025-05-15 13:08:43,979:INFO:Importing libraries
2025-05-15 13:08:43,979:INFO:Copying training dataset
2025-05-15 13:08:43,988:INFO:Defining folds
2025-05-15 13:08:43,988:INFO:Declaring metric variables
2025-05-15 13:08:43,988:INFO:Importing untrained model
2025-05-15 13:08:43,988:INFO:Declaring custom model
2025-05-15 13:08:43,988:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:08:43,989:INFO:Cross validation set to False
2025-05-15 13:08:43,989:INFO:Fitting Model
2025-05-15 13:08:45,325:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 13:08:45,341:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005423 seconds.
2025-05-15 13:08:45,341:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 13:08:45,341:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 13:08:45,341:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-15 13:08:45,341:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 27
2025-05-15 13:08:45,342:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 13:08:46,101:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:08:46,101:INFO:create_model() successfully completed......................................
2025-05-15 13:08:46,152:INFO:Initializing create_model()
2025-05-15 13:08:46,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:08:46,152:INFO:Checking exceptions
2025-05-15 13:08:46,153:INFO:Importing libraries
2025-05-15 13:08:46,153:INFO:Copying training dataset
2025-05-15 13:08:46,162:INFO:Defining folds
2025-05-15 13:08:46,162:INFO:Declaring metric variables
2025-05-15 13:08:46,163:INFO:Importing untrained model
2025-05-15 13:08:46,163:INFO:Declaring custom model
2025-05-15 13:08:46,163:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 13:08:46,164:INFO:Cross validation set to False
2025-05-15 13:08:46,164:INFO:Fitting Model
2025-05-15 13:09:02,205:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 13:09:02,206:INFO:create_model() successfully completed......................................
2025-05-15 13:09:02,266:INFO:Initializing create_model()
2025-05-15 13:09:02,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=<catboost.core.CatBoostClassifier object at 0x3308b2950>, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:09:02,266:INFO:Checking exceptions
2025-05-15 13:09:02,267:INFO:Importing libraries
2025-05-15 13:09:02,267:INFO:Copying training dataset
2025-05-15 13:09:02,276:INFO:Defining folds
2025-05-15 13:09:02,276:INFO:Declaring metric variables
2025-05-15 13:09:02,276:INFO:Importing untrained model
2025-05-15 13:09:02,276:INFO:Declaring custom model
2025-05-15 13:09:02,276:INFO:CatBoost Classifier Imported successfully
2025-05-15 13:09:02,277:INFO:Cross validation set to False
2025-05-15 13:09:02,277:INFO:Fitting Model
2025-05-15 13:09:09,460:INFO:<catboost.core.CatBoostClassifier object at 0x33073ce90>
2025-05-15 13:09:09,461:INFO:create_model() successfully completed......................................
2025-05-15 13:09:09,514:INFO:_master_model_container: 15
2025-05-15 13:09:09,515:INFO:_display_container: 2
2025-05-15 13:09:09,515:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), <catboost.core.CatBoostClassifier object at 0x33073ce90>]
2025-05-15 13:09:09,515:INFO:compare_models() successfully completed......................................
2025-05-15 13:09:09,516:INFO:Initializing evaluate_model()
2025-05-15 13:09:09,516:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 13:09:09,523:INFO:Initializing plot_model()
2025-05-15 13:09:09,523:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 13:09:09,523:INFO:Checking exceptions
2025-05-15 13:09:09,526:INFO:Preloading libraries
2025-05-15 13:09:09,529:INFO:Copying training dataset
2025-05-15 13:09:09,529:INFO:Plot type: pipeline
2025-05-15 13:09:09,613:INFO:Visual Rendered Successfully
2025-05-15 13:09:09,665:INFO:plot_model() successfully completed......................................
2025-05-15 13:09:09,667:INFO:Initializing tune_model()
2025-05-15 13:09:09,667:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-15 13:09:09,667:INFO:Checking exceptions
2025-05-15 13:09:09,676:INFO:Copying training dataset
2025-05-15 13:09:09,683:INFO:Checking base model
2025-05-15 13:09:09,683:INFO:Base model : Light Gradient Boosting Machine
2025-05-15 13:09:09,685:INFO:Declaring metric variables
2025-05-15 13:09:09,686:INFO:Defining Hyperparameters
2025-05-15 13:09:09,738:INFO:Tuning with n_jobs=-1
2025-05-15 13:09:09,738:INFO:Initializing RandomizedSearchCV
2025-05-15 13:09:44,912:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-15 13:09:44,914:INFO:Hyperparameter search completed
2025-05-15 13:09:44,915:INFO:SubProcess create_model() called ==================================
2025-05-15 13:09:44,916:INFO:Initializing create_model()
2025-05-15 13:09:44,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32b322550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-15 13:09:44,916:INFO:Checking exceptions
2025-05-15 13:09:44,916:INFO:Importing libraries
2025-05-15 13:09:44,916:INFO:Copying training dataset
2025-05-15 13:09:44,931:INFO:Defining folds
2025-05-15 13:09:44,931:INFO:Declaring metric variables
2025-05-15 13:09:44,935:INFO:Importing untrained model
2025-05-15 13:09:44,935:INFO:Declaring custom model
2025-05-15 13:09:44,937:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:09:44,941:INFO:Starting cross validation
2025-05-15 13:09:44,945:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:09:51,651:INFO:Calculating mean and std
2025-05-15 13:09:51,652:INFO:Creating metrics dataframe
2025-05-15 13:09:51,654:INFO:Finalizing model
2025-05-15 13:09:52,686:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 13:09:52,686:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 13:09:52,686:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 13:09:52,716:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 13:09:52,716:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 13:09:52,716:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 13:09:52,716:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 13:09:52,730:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008513 seconds.
2025-05-15 13:09:52,730:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 13:09:52,730:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 13:09:52,730:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-15 13:09:52,730:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 27
2025-05-15 13:09:52,731:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 13:09:54,170:INFO:Uploading results into container
2025-05-15 13:09:54,171:INFO:Uploading model into container now
2025-05-15 13:09:54,171:INFO:_master_model_container: 16
2025-05-15 13:09:54,171:INFO:_display_container: 3
2025-05-15 13:09:54,172:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:09:54,172:INFO:create_model() successfully completed......................................
2025-05-15 13:09:54,246:INFO:SubProcess create_model() end ==================================
2025-05-15 13:09:54,247:INFO:choose_better activated
2025-05-15 13:09:54,248:INFO:SubProcess create_model() called ==================================
2025-05-15 13:09:54,248:INFO:Initializing create_model()
2025-05-15 13:09:54,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:09:54,248:INFO:Checking exceptions
2025-05-15 13:09:54,249:INFO:Importing libraries
2025-05-15 13:09:54,249:INFO:Copying training dataset
2025-05-15 13:09:54,258:INFO:Defining folds
2025-05-15 13:09:54,258:INFO:Declaring metric variables
2025-05-15 13:09:54,258:INFO:Importing untrained model
2025-05-15 13:09:54,258:INFO:Declaring custom model
2025-05-15 13:09:54,259:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:09:54,259:INFO:Starting cross validation
2025-05-15 13:09:54,260:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:09:58,099:INFO:Calculating mean and std
2025-05-15 13:09:58,099:INFO:Creating metrics dataframe
2025-05-15 13:09:58,100:INFO:Finalizing model
2025-05-15 13:09:59,142:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 13:09:59,156:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004920 seconds.
2025-05-15 13:09:59,156:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 13:09:59,156:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 13:09:59,156:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-15 13:09:59,157:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 27
2025-05-15 13:09:59,157:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 13:09:59,914:INFO:Uploading results into container
2025-05-15 13:09:59,914:INFO:Uploading model into container now
2025-05-15 13:09:59,915:INFO:_master_model_container: 17
2025-05-15 13:09:59,915:INFO:_display_container: 4
2025-05-15 13:09:59,915:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:09:59,915:INFO:create_model() successfully completed......................................
2025-05-15 13:09:59,970:INFO:SubProcess create_model() end ==================================
2025-05-15 13:09:59,971:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4636
2025-05-15 13:09:59,971:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4903
2025-05-15 13:09:59,971:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-15 13:09:59,971:INFO:choose_better completed
2025-05-15 13:09:59,975:INFO:_master_model_container: 17
2025-05-15 13:09:59,975:INFO:_display_container: 3
2025-05-15 13:09:59,976:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:09:59,976:INFO:tune_model() successfully completed......................................
2025-05-15 13:10:00,027:INFO:Initializing evaluate_model()
2025-05-15 13:10:00,027:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 13:10:00,033:INFO:Initializing plot_model()
2025-05-15 13:10:00,033:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 13:10:00,033:INFO:Checking exceptions
2025-05-15 13:10:00,037:INFO:Preloading libraries
2025-05-15 13:10:00,039:INFO:Copying training dataset
2025-05-15 13:10:00,039:INFO:Plot type: pipeline
2025-05-15 13:10:00,102:INFO:Visual Rendered Successfully
2025-05-15 13:10:00,153:INFO:plot_model() successfully completed......................................
2025-05-15 13:10:00,155:INFO:Initializing interpret_model()
2025-05-15 13:10:00,155:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-15 13:10:00,155:INFO:Checking exceptions
2025-05-15 13:10:00,156:INFO:Soft dependency imported: shap: 0.47.2
2025-05-15 13:10:00,537:INFO:plot type: summary
2025-05-15 13:10:00,537:INFO:Creating TreeExplainer
2025-05-15 13:10:00,609:INFO:Compiling shap values
2025-05-15 13:10:01,584:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray
  warnings.warn(

2025-05-15 13:10:01,584:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-05-15 13:10:02,856:INFO:Visual Rendered Successfully
2025-05-15 13:10:02,856:INFO:interpret_model() successfully completed......................................
2025-05-15 13:10:02,920:INFO:Initializing finalize_model()
2025-05-15 13:10:02,920:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-15 13:10:02,921:INFO:Finalizing LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:10:02,925:INFO:Initializing create_model()
2025-05-15 13:10:02,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:10:02,925:INFO:Checking exceptions
2025-05-15 13:10:02,926:INFO:Importing libraries
2025-05-15 13:10:02,926:INFO:Copying training dataset
2025-05-15 13:10:02,926:INFO:Defining folds
2025-05-15 13:10:02,926:INFO:Declaring metric variables
2025-05-15 13:10:02,926:INFO:Importing untrained model
2025-05-15 13:10:02,926:INFO:Declaring custom model
2025-05-15 13:10:02,927:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:10:02,927:INFO:Cross validation set to False
2025-05-15 13:10:02,927:INFO:Fitting Model
2025-05-15 13:10:04,309:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 13:10:04,309:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 13:10:04,309:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 13:10:04,352:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 13:10:04,352:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 13:10:04,352:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 13:10:04,353:INFO:[LightGBM] [Info] Number of positive: 61360, number of negative: 61360
2025-05-15 13:10:04,372:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011225 seconds.
2025-05-15 13:10:04,372:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 13:10:04,372:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 13:10:04,372:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-15 13:10:04,372:INFO:[LightGBM] [Info] Number of data points in the train set: 122720, number of used features: 27
2025-05-15 13:10:04,372:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 13:10:05,915:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 13:10:05,915:INFO:create_model() successfully completed......................................
2025-05-15 13:10:05,969:INFO:_master_model_container: 17
2025-05-15 13:10:05,969:INFO:_display_container: 3
2025-05-15 13:10:05,989:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 13:10:05,990:INFO:finalize_model() successfully completed......................................
2025-05-15 13:10:06,076:INFO:Initializing save_model()
2025-05-15 13:10:06,076:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-15 13:10:06,076:INFO:Adding model into prep_pipe
2025-05-15 13:10:06,076:WARNING:Only Model saved as it was a pipeline.
2025-05-15 13:10:06,083:INFO:final_cancer_model.pkl saved in current working directory
2025-05-15 13:10:06,104:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 13:10:06,104:INFO:save_model() successfully completed......................................
2025-05-15 13:10:06,179:INFO:Initializing predict_model()
2025-05-15 13:10:06,179:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x3636d3ec0>)
2025-05-15 13:10:06,179:INFO:Checking exceptions
2025-05-15 13:10:06,179:INFO:Preloading libraries
2025-05-15 13:10:06,180:INFO:Set up data.
2025-05-15 13:10:06,199:INFO:Set up index.
2025-05-15 13:10:06,520:INFO:Initializing blend_models()
2025-05-15 13:10:06,520:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), <catboost.core.CatBoostClassifier object at 0x33073ce90>], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-15 13:10:06,520:INFO:Checking exceptions
2025-05-15 13:10:06,529:INFO:Importing libraries
2025-05-15 13:10:06,529:INFO:Copying training dataset
2025-05-15 13:10:06,530:INFO:Getting model names
2025-05-15 13:10:06,531:INFO:SubProcess create_model() called ==================================
2025-05-15 13:10:06,533:INFO:Initializing create_model()
2025-05-15 13:10:06,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=42,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x33073ce90>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33050bd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:10:06,533:INFO:Checking exceptions
2025-05-15 13:10:06,533:INFO:Importing libraries
2025-05-15 13:10:06,533:INFO:Copying training dataset
2025-05-15 13:10:06,542:INFO:Defining folds
2025-05-15 13:10:06,542:INFO:Declaring metric variables
2025-05-15 13:10:06,544:INFO:Importing untrained model
2025-05-15 13:10:06,544:INFO:Declaring custom model
2025-05-15 13:10:06,546:INFO:Voting Classifier Imported successfully
2025-05-15 13:10:06,548:INFO:Starting cross validation
2025-05-15 13:10:06,549:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:10:29,550:INFO:Calculating mean and std
2025-05-15 13:10:29,552:INFO:Creating metrics dataframe
2025-05-15 13:10:29,560:INFO:Finalizing model
2025-05-15 13:10:46,353:INFO:Uploading results into container
2025-05-15 13:10:46,354:INFO:Uploading model into container now
2025-05-15 13:10:46,355:INFO:_master_model_container: 18
2025-05-15 13:10:46,355:INFO:_display_container: 4
2025-05-15 13:10:46,358:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=42,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x36316c750>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-15 13:10:46,358:INFO:create_model() successfully completed......................................
2025-05-15 13:10:46,479:INFO:SubProcess create_model() end ==================================
2025-05-15 13:10:46,483:INFO:_master_model_container: 18
2025-05-15 13:10:46,483:INFO:_display_container: 4
2025-05-15 13:10:46,484:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=42,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x36316c750>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-15 13:10:46,484:INFO:blend_models() successfully completed......................................
2025-05-15 13:10:46,539:INFO:Initializing evaluate_model()
2025-05-15 13:10:46,539:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=42,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x36316c750>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 13:10:46,548:INFO:Initializing plot_model()
2025-05-15 13:10:46,548:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=42,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x36316c750>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 13:10:46,548:INFO:Checking exceptions
2025-05-15 13:10:46,551:INFO:Preloading libraries
2025-05-15 13:10:46,557:INFO:Copying training dataset
2025-05-15 13:10:46,558:INFO:Plot type: pipeline
2025-05-15 13:10:46,617:INFO:Visual Rendered Successfully
2025-05-15 13:10:46,674:INFO:plot_model() successfully completed......................................
2025-05-15 13:10:46,677:INFO:Initializing predict_model()
2025-05-15 13:10:46,677:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=42,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x36316c750>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x3636d3e20>)
2025-05-15 13:10:46,677:INFO:Checking exceptions
2025-05-15 13:10:46,677:INFO:Preloading libraries
2025-05-15 13:10:46,678:INFO:Set up data.
2025-05-15 13:10:46,696:INFO:Set up index.
2025-05-15 13:10:47,161:INFO:Initializing plot_model()
2025-05-15 13:10:47,161:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 13:10:47,161:INFO:Checking exceptions
2025-05-15 13:10:47,166:INFO:Preloading libraries
2025-05-15 13:10:47,167:INFO:Copying training dataset
2025-05-15 13:10:47,167:INFO:Plot type: confusion_matrix
2025-05-15 13:10:47,378:INFO:Fitting Model
2025-05-15 13:10:47,379:INFO:Scoring test/hold-out set
2025-05-15 13:10:47,507:INFO:Visual Rendered Successfully
2025-05-15 13:10:47,573:INFO:plot_model() successfully completed......................................
2025-05-15 13:10:47,574:INFO:Initializing plot_model()
2025-05-15 13:10:47,574:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 13:10:47,574:INFO:Checking exceptions
2025-05-15 13:10:47,581:INFO:Preloading libraries
2025-05-15 13:10:47,583:INFO:Copying training dataset
2025-05-15 13:10:47,583:INFO:Plot type: auc
2025-05-15 13:10:47,793:INFO:Fitting Model
2025-05-15 13:10:47,795:INFO:Scoring test/hold-out set
2025-05-15 13:10:47,923:INFO:Visual Rendered Successfully
2025-05-15 13:10:47,981:INFO:plot_model() successfully completed......................................
2025-05-15 13:10:47,982:INFO:Initializing plot_model()
2025-05-15 13:10:47,982:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32e1ed510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 13:10:47,982:INFO:Checking exceptions
2025-05-15 13:10:47,987:INFO:Preloading libraries
2025-05-15 13:10:47,989:INFO:Copying training dataset
2025-05-15 13:10:47,989:INFO:Plot type: feature
2025-05-15 13:10:47,989:WARNING:No coef_ found. Trying feature_importances_
2025-05-15 13:10:48,062:INFO:Visual Rendered Successfully
2025-05-15 13:10:48,117:INFO:plot_model() successfully completed......................................
2025-05-15 13:15:04,350:INFO:PyCaret ClassificationExperiment
2025-05-15 13:15:04,350:INFO:Logging name: clf-default-name
2025-05-15 13:15:04,350:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 13:15:04,350:INFO:version 3.3.2
2025-05-15 13:15:04,350:INFO:Initializing setup()
2025-05-15 13:15:04,350:INFO:self.USI: 05a5
2025-05-15 13:15:04,350:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-15 13:15:04,350:INFO:Checking environment
2025-05-15 13:15:04,350:INFO:python_version: 3.11.0
2025-05-15 13:15:04,350:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 13:15:04,350:INFO:machine: arm64
2025-05-15 13:15:04,350:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 13:15:04,350:INFO:Memory: svmem(total=17179869184, available=3324706816, percent=80.6, used=5975195648, free=147357696, active=3198533632, inactive=3129868288, wired=2776662016)
2025-05-15 13:15:04,350:INFO:Physical Core: 12
2025-05-15 13:15:04,350:INFO:Logical Core: 12
2025-05-15 13:15:04,350:INFO:Checking libraries
2025-05-15 13:15:04,350:INFO:System:
2025-05-15 13:15:04,350:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 13:15:04,350:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 13:15:04,350:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 13:15:04,350:INFO:PyCaret required dependencies:
2025-05-15 13:15:04,350:INFO:                 pip: 22.3
2025-05-15 13:15:04,350:INFO:          setuptools: 65.5.0
2025-05-15 13:15:04,350:INFO:             pycaret: 3.3.2
2025-05-15 13:15:04,350:INFO:             IPython: 9.2.0
2025-05-15 13:15:04,350:INFO:          ipywidgets: 8.1.7
2025-05-15 13:15:04,350:INFO:                tqdm: 4.67.1
2025-05-15 13:15:04,350:INFO:               numpy: 1.26.4
2025-05-15 13:15:04,350:INFO:              pandas: 2.1.4
2025-05-15 13:15:04,350:INFO:              jinja2: 3.1.6
2025-05-15 13:15:04,350:INFO:               scipy: 1.11.4
2025-05-15 13:15:04,350:INFO:              joblib: 1.3.2
2025-05-15 13:15:04,350:INFO:             sklearn: 1.4.2
2025-05-15 13:15:04,350:INFO:                pyod: 2.0.5
2025-05-15 13:15:04,350:INFO:            imblearn: 0.13.0
2025-05-15 13:15:04,350:INFO:   category_encoders: 2.7.0
2025-05-15 13:15:04,350:INFO:            lightgbm: 4.6.0
2025-05-15 13:15:04,350:INFO:               numba: 0.61.2
2025-05-15 13:15:04,350:INFO:            requests: 2.32.3
2025-05-15 13:15:04,350:INFO:          matplotlib: 3.7.5
2025-05-15 13:15:04,350:INFO:          scikitplot: 0.3.7
2025-05-15 13:15:04,350:INFO:         yellowbrick: 1.5
2025-05-15 13:15:04,350:INFO:              plotly: 5.24.1
2025-05-15 13:15:04,350:INFO:    plotly-resampler: Not installed
2025-05-15 13:15:04,350:INFO:             kaleido: 0.2.1
2025-05-15 13:15:04,350:INFO:           schemdraw: 0.15
2025-05-15 13:15:04,350:INFO:         statsmodels: 0.14.4
2025-05-15 13:15:04,350:INFO:              sktime: 0.26.0
2025-05-15 13:15:04,350:INFO:               tbats: 1.1.3
2025-05-15 13:15:04,350:INFO:            pmdarima: 2.0.4
2025-05-15 13:15:04,350:INFO:              psutil: 7.0.0
2025-05-15 13:15:04,350:INFO:          markupsafe: 3.0.2
2025-05-15 13:15:04,350:INFO:             pickle5: Not installed
2025-05-15 13:15:04,350:INFO:         cloudpickle: 3.1.1
2025-05-15 13:15:04,350:INFO:         deprecation: 2.1.0
2025-05-15 13:15:04,350:INFO:              xxhash: 3.5.0
2025-05-15 13:15:04,350:INFO:           wurlitzer: 3.1.1
2025-05-15 13:15:04,350:INFO:PyCaret optional dependencies:
2025-05-15 13:15:04,350:INFO:                shap: 0.47.2
2025-05-15 13:15:04,350:INFO:           interpret: Not installed
2025-05-15 13:15:04,350:INFO:                umap: Not installed
2025-05-15 13:15:04,350:INFO:     ydata_profiling: Not installed
2025-05-15 13:15:04,350:INFO:  explainerdashboard: Not installed
2025-05-15 13:15:04,351:INFO:             autoviz: Not installed
2025-05-15 13:15:04,351:INFO:           fairlearn: Not installed
2025-05-15 13:15:04,351:INFO:          deepchecks: Not installed
2025-05-15 13:15:04,351:INFO:             xgboost: Not installed
2025-05-15 13:15:04,351:INFO:            catboost: 1.2.8
2025-05-15 13:15:04,351:INFO:              kmodes: Not installed
2025-05-15 13:15:04,351:INFO:             mlxtend: Not installed
2025-05-15 13:15:04,351:INFO:       statsforecast: Not installed
2025-05-15 13:15:04,351:INFO:        tune_sklearn: Not installed
2025-05-15 13:15:04,351:INFO:                 ray: Not installed
2025-05-15 13:15:04,351:INFO:            hyperopt: Not installed
2025-05-15 13:15:04,351:INFO:              optuna: 4.3.0
2025-05-15 13:15:04,351:INFO:               skopt: Not installed
2025-05-15 13:15:04,351:INFO:              mlflow: Not installed
2025-05-15 13:15:04,351:INFO:              gradio: Not installed
2025-05-15 13:15:04,351:INFO:             fastapi: Not installed
2025-05-15 13:15:04,351:INFO:             uvicorn: Not installed
2025-05-15 13:15:04,351:INFO:              m2cgen: Not installed
2025-05-15 13:15:04,351:INFO:           evidently: Not installed
2025-05-15 13:15:04,351:INFO:               fugue: Not installed
2025-05-15 13:15:04,351:INFO:           streamlit: Not installed
2025-05-15 13:15:04,351:INFO:             prophet: Not installed
2025-05-15 13:15:04,351:INFO:None
2025-05-15 13:15:04,351:INFO:Set up data.
2025-05-15 13:15:04,382:INFO:Set up folding strategy.
2025-05-15 13:15:04,382:INFO:Set up train/test split.
2025-05-15 13:15:04,395:INFO:Set up index.
2025-05-15 13:15:04,396:INFO:Assigning column types.
2025-05-15 13:15:04,399:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 13:15:04,417:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 13:15:04,417:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:15:04,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:15:04,429:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:15:04,447:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 13:15:04,447:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:15:04,459:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:15:04,459:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:15:04,459:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 13:15:04,477:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:15:04,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:15:04,488:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:15:04,506:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 13:15:04,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:15:04,517:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:15:04,517:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 13:15:04,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:15:04,546:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:15:04,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:15:04,576:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:15:04,576:INFO:Preparing preprocessing pipeline...
2025-05-15 13:15:04,577:INFO:Set up simple imputation.
2025-05-15 13:15:04,583:INFO:Set up encoding of ordinal features.
2025-05-15 13:15:04,593:INFO:Set up encoding of categorical features.
2025-05-15 13:15:04,593:INFO:Set up imbalanced handling.
2025-05-15 13:15:04,593:INFO:Set up column transformation.
2025-05-15 13:15:05,607:INFO:Finished creating preprocessing pipeline.
2025-05-15 13:15:05,627:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 13:15:05,627:INFO:Creating final display dataframe.
2025-05-15 13:15:06,123:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              05a5
2025-05-15 13:15:06,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:15:06,157:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:15:06,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 13:15:06,187:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 13:15:06,188:INFO:setup() successfully completed in 1.84s...............
2025-05-15 13:15:06,189:INFO:Initializing compare_models()
2025-05-15 13:15:06,189:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-15 13:15:06,189:INFO:Checking exceptions
2025-05-15 13:15:06,193:INFO:Preparing display monitor
2025-05-15 13:15:06,202:INFO:Initializing Logistic Regression
2025-05-15 13:15:06,202:INFO:Total runtime is 1.71661376953125e-06 minutes
2025-05-15 13:15:06,204:INFO:SubProcess create_model() called ==================================
2025-05-15 13:15:06,204:INFO:Initializing create_model()
2025-05-15 13:15:06,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:15:06,204:INFO:Checking exceptions
2025-05-15 13:15:06,204:INFO:Importing libraries
2025-05-15 13:15:06,204:INFO:Copying training dataset
2025-05-15 13:15:06,217:INFO:Defining folds
2025-05-15 13:15:06,217:INFO:Declaring metric variables
2025-05-15 13:15:06,219:INFO:Importing untrained model
2025-05-15 13:15:06,220:INFO:Logistic Regression Imported successfully
2025-05-15 13:15:06,222:INFO:Starting cross validation
2025-05-15 13:15:06,223:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:15:09,994:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:15:10,170:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:15:10,217:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:15:10,272:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:15:10,407:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 13:15:10,461:INFO:Calculating mean and std
2025-05-15 13:15:10,462:INFO:Creating metrics dataframe
2025-05-15 13:15:10,464:INFO:Uploading results into container
2025-05-15 13:15:10,464:INFO:Uploading model into container now
2025-05-15 13:15:10,465:INFO:_master_model_container: 1
2025-05-15 13:15:10,465:INFO:_display_container: 2
2025-05-15 13:15:10,465:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 13:15:10,465:INFO:create_model() successfully completed......................................
2025-05-15 13:15:10,550:INFO:SubProcess create_model() end ==================================
2025-05-15 13:15:10,550:INFO:Creating metrics dataframe
2025-05-15 13:15:10,553:INFO:Initializing K Neighbors Classifier
2025-05-15 13:15:10,553:INFO:Total runtime is 0.07252256472905477 minutes
2025-05-15 13:15:10,555:INFO:SubProcess create_model() called ==================================
2025-05-15 13:15:10,555:INFO:Initializing create_model()
2025-05-15 13:15:10,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:15:10,555:INFO:Checking exceptions
2025-05-15 13:15:10,555:INFO:Importing libraries
2025-05-15 13:15:10,555:INFO:Copying training dataset
2025-05-15 13:15:10,566:INFO:Defining folds
2025-05-15 13:15:10,566:INFO:Declaring metric variables
2025-05-15 13:15:10,567:INFO:Importing untrained model
2025-05-15 13:15:10,568:INFO:K Neighbors Classifier Imported successfully
2025-05-15 13:15:10,571:INFO:Starting cross validation
2025-05-15 13:15:10,572:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:15:16,758:INFO:Calculating mean and std
2025-05-15 13:15:16,760:INFO:Creating metrics dataframe
2025-05-15 13:15:16,762:INFO:Uploading results into container
2025-05-15 13:15:16,762:INFO:Uploading model into container now
2025-05-15 13:15:16,762:INFO:_master_model_container: 2
2025-05-15 13:15:16,762:INFO:_display_container: 2
2025-05-15 13:15:16,763:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-15 13:15:16,763:INFO:create_model() successfully completed......................................
2025-05-15 13:15:16,830:INFO:SubProcess create_model() end ==================================
2025-05-15 13:15:16,830:INFO:Creating metrics dataframe
2025-05-15 13:15:16,833:INFO:Initializing Naive Bayes
2025-05-15 13:15:16,833:INFO:Total runtime is 0.17717726627985636 minutes
2025-05-15 13:15:16,834:INFO:SubProcess create_model() called ==================================
2025-05-15 13:15:16,834:INFO:Initializing create_model()
2025-05-15 13:15:16,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:15:16,834:INFO:Checking exceptions
2025-05-15 13:15:16,834:INFO:Importing libraries
2025-05-15 13:15:16,834:INFO:Copying training dataset
2025-05-15 13:15:16,843:INFO:Defining folds
2025-05-15 13:15:16,844:INFO:Declaring metric variables
2025-05-15 13:15:16,845:INFO:Importing untrained model
2025-05-15 13:15:16,846:INFO:Naive Bayes Imported successfully
2025-05-15 13:15:16,849:INFO:Starting cross validation
2025-05-15 13:15:16,850:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:15:19,027:INFO:Calculating mean and std
2025-05-15 13:15:19,028:INFO:Creating metrics dataframe
2025-05-15 13:15:19,030:INFO:Uploading results into container
2025-05-15 13:15:19,031:INFO:Uploading model into container now
2025-05-15 13:15:19,031:INFO:_master_model_container: 3
2025-05-15 13:15:19,031:INFO:_display_container: 2
2025-05-15 13:15:19,031:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-15 13:15:19,031:INFO:create_model() successfully completed......................................
2025-05-15 13:15:19,104:INFO:SubProcess create_model() end ==================================
2025-05-15 13:15:19,105:INFO:Creating metrics dataframe
2025-05-15 13:15:19,108:INFO:Initializing Decision Tree Classifier
2025-05-15 13:15:19,108:INFO:Total runtime is 0.21509466568628946 minutes
2025-05-15 13:15:19,109:INFO:SubProcess create_model() called ==================================
2025-05-15 13:15:19,109:INFO:Initializing create_model()
2025-05-15 13:15:19,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:15:19,109:INFO:Checking exceptions
2025-05-15 13:15:19,109:INFO:Importing libraries
2025-05-15 13:15:19,109:INFO:Copying training dataset
2025-05-15 13:15:19,121:INFO:Defining folds
2025-05-15 13:15:19,121:INFO:Declaring metric variables
2025-05-15 13:15:19,122:INFO:Importing untrained model
2025-05-15 13:15:19,123:INFO:Decision Tree Classifier Imported successfully
2025-05-15 13:15:19,126:INFO:Starting cross validation
2025-05-15 13:15:19,127:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:15:20,747:INFO:Calculating mean and std
2025-05-15 13:15:20,748:INFO:Creating metrics dataframe
2025-05-15 13:15:20,750:INFO:Uploading results into container
2025-05-15 13:15:20,750:INFO:Uploading model into container now
2025-05-15 13:15:20,751:INFO:_master_model_container: 4
2025-05-15 13:15:20,751:INFO:_display_container: 2
2025-05-15 13:15:20,751:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-15 13:15:20,751:INFO:create_model() successfully completed......................................
2025-05-15 13:15:20,812:INFO:SubProcess create_model() end ==================================
2025-05-15 13:15:20,812:INFO:Creating metrics dataframe
2025-05-15 13:15:20,815:INFO:Initializing SVM - Linear Kernel
2025-05-15 13:15:20,815:INFO:Total runtime is 0.24355258146921793 minutes
2025-05-15 13:15:20,817:INFO:SubProcess create_model() called ==================================
2025-05-15 13:15:20,817:INFO:Initializing create_model()
2025-05-15 13:15:20,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:15:20,817:INFO:Checking exceptions
2025-05-15 13:15:20,817:INFO:Importing libraries
2025-05-15 13:15:20,817:INFO:Copying training dataset
2025-05-15 13:15:20,828:INFO:Defining folds
2025-05-15 13:15:20,828:INFO:Declaring metric variables
2025-05-15 13:15:20,829:INFO:Importing untrained model
2025-05-15 13:15:20,830:INFO:SVM - Linear Kernel Imported successfully
2025-05-15 13:15:20,833:INFO:Starting cross validation
2025-05-15 13:15:20,834:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:15:24,370:INFO:Calculating mean and std
2025-05-15 13:15:24,371:INFO:Creating metrics dataframe
2025-05-15 13:15:24,372:INFO:Uploading results into container
2025-05-15 13:15:24,372:INFO:Uploading model into container now
2025-05-15 13:15:24,372:INFO:_master_model_container: 5
2025-05-15 13:15:24,373:INFO:_display_container: 2
2025-05-15 13:15:24,373:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-15 13:15:24,373:INFO:create_model() successfully completed......................................
2025-05-15 13:15:24,461:INFO:SubProcess create_model() end ==================================
2025-05-15 13:15:24,461:INFO:Creating metrics dataframe
2025-05-15 13:15:24,465:INFO:Initializing Ridge Classifier
2025-05-15 13:15:24,465:INFO:Total runtime is 0.30437636772791543 minutes
2025-05-15 13:15:24,466:INFO:SubProcess create_model() called ==================================
2025-05-15 13:15:24,466:INFO:Initializing create_model()
2025-05-15 13:15:24,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:15:24,466:INFO:Checking exceptions
2025-05-15 13:15:24,466:INFO:Importing libraries
2025-05-15 13:15:24,466:INFO:Copying training dataset
2025-05-15 13:15:24,478:INFO:Defining folds
2025-05-15 13:15:24,478:INFO:Declaring metric variables
2025-05-15 13:15:24,479:INFO:Importing untrained model
2025-05-15 13:15:24,481:INFO:Ridge Classifier Imported successfully
2025-05-15 13:15:24,483:INFO:Starting cross validation
2025-05-15 13:15:24,484:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:15:25,613:INFO:Calculating mean and std
2025-05-15 13:15:25,614:INFO:Creating metrics dataframe
2025-05-15 13:15:25,615:INFO:Uploading results into container
2025-05-15 13:15:25,615:INFO:Uploading model into container now
2025-05-15 13:15:25,615:INFO:_master_model_container: 6
2025-05-15 13:15:25,615:INFO:_display_container: 2
2025-05-15 13:15:25,615:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-15 13:15:25,615:INFO:create_model() successfully completed......................................
2025-05-15 13:15:25,669:INFO:SubProcess create_model() end ==================================
2025-05-15 13:15:25,670:INFO:Creating metrics dataframe
2025-05-15 13:15:25,673:INFO:Initializing Random Forest Classifier
2025-05-15 13:15:25,673:INFO:Total runtime is 0.32451576391855874 minutes
2025-05-15 13:15:25,674:INFO:SubProcess create_model() called ==================================
2025-05-15 13:15:25,674:INFO:Initializing create_model()
2025-05-15 13:15:25,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:15:25,674:INFO:Checking exceptions
2025-05-15 13:15:25,674:INFO:Importing libraries
2025-05-15 13:15:25,674:INFO:Copying training dataset
2025-05-15 13:15:25,683:INFO:Defining folds
2025-05-15 13:15:25,683:INFO:Declaring metric variables
2025-05-15 13:15:25,685:INFO:Importing untrained model
2025-05-15 13:15:25,686:INFO:Random Forest Classifier Imported successfully
2025-05-15 13:15:25,688:INFO:Starting cross validation
2025-05-15 13:15:25,689:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:15:31,538:INFO:Calculating mean and std
2025-05-15 13:15:31,540:INFO:Creating metrics dataframe
2025-05-15 13:15:31,544:INFO:Uploading results into container
2025-05-15 13:15:31,544:INFO:Uploading model into container now
2025-05-15 13:15:31,545:INFO:_master_model_container: 7
2025-05-15 13:15:31,545:INFO:_display_container: 2
2025-05-15 13:15:31,547:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 13:15:31,548:INFO:create_model() successfully completed......................................
2025-05-15 13:15:31,640:INFO:SubProcess create_model() end ==================================
2025-05-15 13:15:31,641:INFO:Creating metrics dataframe
2025-05-15 13:15:31,644:INFO:Initializing Quadratic Discriminant Analysis
2025-05-15 13:15:31,644:INFO:Total runtime is 0.4240373969078064 minutes
2025-05-15 13:15:31,646:INFO:SubProcess create_model() called ==================================
2025-05-15 13:15:31,646:INFO:Initializing create_model()
2025-05-15 13:15:31,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:15:31,646:INFO:Checking exceptions
2025-05-15 13:15:31,646:INFO:Importing libraries
2025-05-15 13:15:31,646:INFO:Copying training dataset
2025-05-15 13:15:31,658:INFO:Defining folds
2025-05-15 13:15:31,658:INFO:Declaring metric variables
2025-05-15 13:15:31,660:INFO:Importing untrained model
2025-05-15 13:15:31,661:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 13:15:31,664:INFO:Starting cross validation
2025-05-15 13:15:31,665:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:15:32,693:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:15:32,708:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:15:32,726:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:15:32,763:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:15:32,770:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 13:15:32,788:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:15:32,794:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:15:32,814:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:15:32,851:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:15:32,862:INFO:Calculating mean and std
2025-05-15 13:15:32,863:INFO:Creating metrics dataframe
2025-05-15 13:15:32,864:INFO:Uploading results into container
2025-05-15 13:15:32,864:INFO:Uploading model into container now
2025-05-15 13:15:32,864:INFO:_master_model_container: 8
2025-05-15 13:15:32,865:INFO:_display_container: 2
2025-05-15 13:15:32,865:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 13:15:32,865:INFO:create_model() successfully completed......................................
2025-05-15 13:15:32,965:INFO:SubProcess create_model() end ==================================
2025-05-15 13:15:32,965:INFO:Creating metrics dataframe
2025-05-15 13:15:32,969:INFO:Initializing Ada Boost Classifier
2025-05-15 13:15:32,969:INFO:Total runtime is 0.4461135149002075 minutes
2025-05-15 13:15:32,970:INFO:SubProcess create_model() called ==================================
2025-05-15 13:15:32,970:INFO:Initializing create_model()
2025-05-15 13:15:32,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:15:32,971:INFO:Checking exceptions
2025-05-15 13:15:32,971:INFO:Importing libraries
2025-05-15 13:15:32,971:INFO:Copying training dataset
2025-05-15 13:15:32,982:INFO:Defining folds
2025-05-15 13:15:32,982:INFO:Declaring metric variables
2025-05-15 13:15:32,983:INFO:Importing untrained model
2025-05-15 13:15:32,985:INFO:Ada Boost Classifier Imported successfully
2025-05-15 13:15:32,987:INFO:Starting cross validation
2025-05-15 13:15:32,988:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:15:33,963:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:15:33,982:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:15:34,000:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:15:34,075:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:15:34,095:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 13:15:36,757:INFO:Calculating mean and std
2025-05-15 13:15:36,758:INFO:Creating metrics dataframe
2025-05-15 13:15:36,759:INFO:Uploading results into container
2025-05-15 13:15:36,759:INFO:Uploading model into container now
2025-05-15 13:15:36,759:INFO:_master_model_container: 9
2025-05-15 13:15:36,759:INFO:_display_container: 2
2025-05-15 13:15:36,759:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-15 13:15:36,759:INFO:create_model() successfully completed......................................
2025-05-15 13:15:36,818:INFO:SubProcess create_model() end ==================================
2025-05-15 13:15:36,819:INFO:Creating metrics dataframe
2025-05-15 13:15:36,822:INFO:Initializing Gradient Boosting Classifier
2025-05-15 13:15:36,823:INFO:Total runtime is 0.5103411674499512 minutes
2025-05-15 13:15:36,824:INFO:SubProcess create_model() called ==================================
2025-05-15 13:15:36,824:INFO:Initializing create_model()
2025-05-15 13:15:36,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:15:36,824:INFO:Checking exceptions
2025-05-15 13:15:36,824:INFO:Importing libraries
2025-05-15 13:15:36,824:INFO:Copying training dataset
2025-05-15 13:15:36,834:INFO:Defining folds
2025-05-15 13:15:36,834:INFO:Declaring metric variables
2025-05-15 13:15:36,835:INFO:Importing untrained model
2025-05-15 13:15:36,836:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 13:15:36,838:INFO:Starting cross validation
2025-05-15 13:15:36,839:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:15:51,362:INFO:Calculating mean and std
2025-05-15 13:15:51,363:INFO:Creating metrics dataframe
2025-05-15 13:15:51,365:INFO:Uploading results into container
2025-05-15 13:15:51,366:INFO:Uploading model into container now
2025-05-15 13:15:51,366:INFO:_master_model_container: 10
2025-05-15 13:15:51,366:INFO:_display_container: 2
2025-05-15 13:15:51,366:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 13:15:51,366:INFO:create_model() successfully completed......................................
2025-05-15 13:15:51,432:INFO:SubProcess create_model() end ==================================
2025-05-15 13:15:51,432:INFO:Creating metrics dataframe
2025-05-15 13:15:51,436:INFO:Initializing Linear Discriminant Analysis
2025-05-15 13:15:51,436:INFO:Total runtime is 0.7538973331451416 minutes
2025-05-15 13:15:51,437:INFO:SubProcess create_model() called ==================================
2025-05-15 13:15:51,437:INFO:Initializing create_model()
2025-05-15 13:15:51,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:15:51,437:INFO:Checking exceptions
2025-05-15 13:15:51,437:INFO:Importing libraries
2025-05-15 13:15:51,438:INFO:Copying training dataset
2025-05-15 13:15:51,447:INFO:Defining folds
2025-05-15 13:15:51,447:INFO:Declaring metric variables
2025-05-15 13:15:51,448:INFO:Importing untrained model
2025-05-15 13:15:51,449:INFO:Linear Discriminant Analysis Imported successfully
2025-05-15 13:15:51,451:INFO:Starting cross validation
2025-05-15 13:15:51,452:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:15:52,660:INFO:Calculating mean and std
2025-05-15 13:15:52,661:INFO:Creating metrics dataframe
2025-05-15 13:15:52,662:INFO:Uploading results into container
2025-05-15 13:15:52,662:INFO:Uploading model into container now
2025-05-15 13:15:52,662:INFO:_master_model_container: 11
2025-05-15 13:15:52,662:INFO:_display_container: 2
2025-05-15 13:15:52,663:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-15 13:15:52,663:INFO:create_model() successfully completed......................................
2025-05-15 13:15:52,748:INFO:SubProcess create_model() end ==================================
2025-05-15 13:15:52,748:INFO:Creating metrics dataframe
2025-05-15 13:15:52,752:INFO:Initializing Extra Trees Classifier
2025-05-15 13:15:52,752:INFO:Total runtime is 0.7758310675621033 minutes
2025-05-15 13:15:52,753:INFO:SubProcess create_model() called ==================================
2025-05-15 13:15:52,753:INFO:Initializing create_model()
2025-05-15 13:15:52,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:15:52,753:INFO:Checking exceptions
2025-05-15 13:15:52,753:INFO:Importing libraries
2025-05-15 13:15:52,754:INFO:Copying training dataset
2025-05-15 13:15:52,763:INFO:Defining folds
2025-05-15 13:15:52,763:INFO:Declaring metric variables
2025-05-15 13:15:52,765:INFO:Importing untrained model
2025-05-15 13:15:52,766:INFO:Extra Trees Classifier Imported successfully
2025-05-15 13:15:52,769:INFO:Starting cross validation
2025-05-15 13:15:52,770:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:15:57,210:INFO:Calculating mean and std
2025-05-15 13:15:57,214:INFO:Creating metrics dataframe
2025-05-15 13:15:57,217:INFO:Uploading results into container
2025-05-15 13:15:57,218:INFO:Uploading model into container now
2025-05-15 13:15:57,218:INFO:_master_model_container: 12
2025-05-15 13:15:57,218:INFO:_display_container: 2
2025-05-15 13:15:57,219:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 13:15:57,219:INFO:create_model() successfully completed......................................
2025-05-15 13:15:57,337:INFO:SubProcess create_model() end ==================================
2025-05-15 13:15:57,337:INFO:Creating metrics dataframe
2025-05-15 13:15:57,341:INFO:Initializing Light Gradient Boosting Machine
2025-05-15 13:15:57,342:INFO:Total runtime is 0.852324899037679 minutes
2025-05-15 13:15:57,343:INFO:SubProcess create_model() called ==================================
2025-05-15 13:15:57,343:INFO:Initializing create_model()
2025-05-15 13:15:57,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:15:57,343:INFO:Checking exceptions
2025-05-15 13:15:57,343:INFO:Importing libraries
2025-05-15 13:15:57,343:INFO:Copying training dataset
2025-05-15 13:15:57,360:INFO:Defining folds
2025-05-15 13:15:57,360:INFO:Declaring metric variables
2025-05-15 13:15:57,362:INFO:Importing untrained model
2025-05-15 13:15:57,363:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:15:57,366:INFO:Starting cross validation
2025-05-15 13:15:57,369:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:16:01,283:INFO:Calculating mean and std
2025-05-15 13:16:01,283:INFO:Creating metrics dataframe
2025-05-15 13:16:01,284:INFO:Uploading results into container
2025-05-15 13:16:01,284:INFO:Uploading model into container now
2025-05-15 13:16:01,284:INFO:_master_model_container: 13
2025-05-15 13:16:01,285:INFO:_display_container: 2
2025-05-15 13:16:01,285:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:16:01,285:INFO:create_model() successfully completed......................................
2025-05-15 13:16:01,344:INFO:SubProcess create_model() end ==================================
2025-05-15 13:16:01,344:INFO:Creating metrics dataframe
2025-05-15 13:16:01,348:INFO:Initializing CatBoost Classifier
2025-05-15 13:16:01,349:INFO:Total runtime is 0.9191080848375957 minutes
2025-05-15 13:16:01,350:INFO:SubProcess create_model() called ==================================
2025-05-15 13:16:01,350:INFO:Initializing create_model()
2025-05-15 13:16:01,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:16:01,350:INFO:Checking exceptions
2025-05-15 13:16:01,350:INFO:Importing libraries
2025-05-15 13:16:01,350:INFO:Copying training dataset
2025-05-15 13:16:01,360:INFO:Defining folds
2025-05-15 13:16:01,360:INFO:Declaring metric variables
2025-05-15 13:16:01,361:INFO:Importing untrained model
2025-05-15 13:16:01,362:INFO:CatBoost Classifier Imported successfully
2025-05-15 13:16:01,365:INFO:Starting cross validation
2025-05-15 13:16:01,366:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:16:17,580:INFO:Calculating mean and std
2025-05-15 13:16:17,582:INFO:Creating metrics dataframe
2025-05-15 13:16:17,583:INFO:Uploading results into container
2025-05-15 13:16:17,584:INFO:Uploading model into container now
2025-05-15 13:16:17,584:INFO:_master_model_container: 14
2025-05-15 13:16:17,584:INFO:_display_container: 2
2025-05-15 13:16:17,584:INFO:<catboost.core.CatBoostClassifier object at 0x36313e510>
2025-05-15 13:16:17,584:INFO:create_model() successfully completed......................................
2025-05-15 13:16:17,650:INFO:SubProcess create_model() end ==================================
2025-05-15 13:16:17,650:INFO:Creating metrics dataframe
2025-05-15 13:16:17,654:INFO:Initializing Dummy Classifier
2025-05-15 13:16:17,654:INFO:Total runtime is 1.1908743182818096 minutes
2025-05-15 13:16:17,656:INFO:SubProcess create_model() called ==================================
2025-05-15 13:16:17,656:INFO:Initializing create_model()
2025-05-15 13:16:17,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32e106890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:16:17,656:INFO:Checking exceptions
2025-05-15 13:16:17,656:INFO:Importing libraries
2025-05-15 13:16:17,656:INFO:Copying training dataset
2025-05-15 13:16:17,665:INFO:Defining folds
2025-05-15 13:16:17,665:INFO:Declaring metric variables
2025-05-15 13:16:17,666:INFO:Importing untrained model
2025-05-15 13:16:17,667:INFO:Dummy Classifier Imported successfully
2025-05-15 13:16:17,670:INFO:Starting cross validation
2025-05-15 13:16:17,671:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:16:18,681:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:16:18,699:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:16:18,725:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:16:18,746:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:16:18,748:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 13:16:18,764:INFO:Calculating mean and std
2025-05-15 13:16:18,765:INFO:Creating metrics dataframe
2025-05-15 13:16:18,766:INFO:Uploading results into container
2025-05-15 13:16:18,766:INFO:Uploading model into container now
2025-05-15 13:16:18,766:INFO:_master_model_container: 15
2025-05-15 13:16:18,766:INFO:_display_container: 2
2025-05-15 13:16:18,766:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-15 13:16:18,766:INFO:create_model() successfully completed......................................
2025-05-15 13:16:18,836:INFO:SubProcess create_model() end ==================================
2025-05-15 13:16:18,837:INFO:Creating metrics dataframe
2025-05-15 13:16:18,841:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-15 13:16:18,844:INFO:Initializing create_model()
2025-05-15 13:16:18,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:16:18,844:INFO:Checking exceptions
2025-05-15 13:16:18,845:INFO:Importing libraries
2025-05-15 13:16:18,845:INFO:Copying training dataset
2025-05-15 13:16:18,856:INFO:Defining folds
2025-05-15 13:16:18,856:INFO:Declaring metric variables
2025-05-15 13:16:18,856:INFO:Importing untrained model
2025-05-15 13:16:18,856:INFO:Declaring custom model
2025-05-15 13:16:18,856:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:16:18,858:INFO:Cross validation set to False
2025-05-15 13:16:18,858:INFO:Fitting Model
2025-05-15 13:16:20,170:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 13:16:20,180:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004480 seconds.
2025-05-15 13:16:20,180:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 13:16:20,180:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 13:16:20,180:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 13:16:20,180:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 13:16:20,180:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 13:16:20,946:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:16:20,946:INFO:create_model() successfully completed......................................
2025-05-15 13:16:21,006:INFO:Initializing create_model()
2025-05-15 13:16:21,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:16:21,006:INFO:Checking exceptions
2025-05-15 13:16:21,007:INFO:Importing libraries
2025-05-15 13:16:21,007:INFO:Copying training dataset
2025-05-15 13:16:21,016:INFO:Defining folds
2025-05-15 13:16:21,016:INFO:Declaring metric variables
2025-05-15 13:16:21,016:INFO:Importing untrained model
2025-05-15 13:16:21,016:INFO:Declaring custom model
2025-05-15 13:16:21,016:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 13:16:21,017:INFO:Cross validation set to False
2025-05-15 13:16:21,017:INFO:Fitting Model
2025-05-15 13:16:36,919:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 13:16:36,919:INFO:create_model() successfully completed......................................
2025-05-15 13:16:36,976:INFO:Initializing create_model()
2025-05-15 13:16:36,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:16:36,976:INFO:Checking exceptions
2025-05-15 13:16:36,977:INFO:Importing libraries
2025-05-15 13:16:36,977:INFO:Copying training dataset
2025-05-15 13:16:36,987:INFO:Defining folds
2025-05-15 13:16:36,987:INFO:Declaring metric variables
2025-05-15 13:16:36,987:INFO:Importing untrained model
2025-05-15 13:16:36,987:INFO:Declaring custom model
2025-05-15 13:16:36,987:INFO:Random Forest Classifier Imported successfully
2025-05-15 13:16:36,988:INFO:Cross validation set to False
2025-05-15 13:16:36,988:INFO:Fitting Model
2025-05-15 13:16:39,170:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 13:16:39,170:INFO:create_model() successfully completed......................................
2025-05-15 13:16:39,232:INFO:_master_model_container: 15
2025-05-15 13:16:39,232:INFO:_display_container: 2
2025-05-15 13:16:39,232:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-15 13:16:39,232:INFO:compare_models() successfully completed......................................
2025-05-15 13:16:39,234:INFO:Initializing evaluate_model()
2025-05-15 13:16:39,234:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 13:16:39,241:INFO:Initializing plot_model()
2025-05-15 13:16:39,241:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 13:16:39,241:INFO:Checking exceptions
2025-05-15 13:16:39,245:INFO:Preloading libraries
2025-05-15 13:16:39,247:INFO:Copying training dataset
2025-05-15 13:16:39,247:INFO:Plot type: pipeline
2025-05-15 13:16:39,314:INFO:Visual Rendered Successfully
2025-05-15 13:16:39,371:INFO:plot_model() successfully completed......................................
2025-05-15 13:16:39,373:INFO:Initializing tune_model()
2025-05-15 13:16:39,373:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-15 13:16:39,373:INFO:Checking exceptions
2025-05-15 13:16:39,382:INFO:Copying training dataset
2025-05-15 13:16:39,392:INFO:Checking base model
2025-05-15 13:16:39,392:INFO:Base model : Light Gradient Boosting Machine
2025-05-15 13:16:39,393:INFO:Declaring metric variables
2025-05-15 13:16:39,395:INFO:Defining Hyperparameters
2025-05-15 13:16:39,458:INFO:Tuning with n_jobs=-1
2025-05-15 13:16:39,458:INFO:Initializing RandomizedSearchCV
2025-05-15 13:17:15,451:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-15 13:17:15,454:INFO:Hyperparameter search completed
2025-05-15 13:17:15,454:INFO:SubProcess create_model() called ==================================
2025-05-15 13:17:15,455:INFO:Initializing create_model()
2025-05-15 13:17:15,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33098bbd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-15 13:17:15,455:INFO:Checking exceptions
2025-05-15 13:17:15,455:INFO:Importing libraries
2025-05-15 13:17:15,455:INFO:Copying training dataset
2025-05-15 13:17:15,475:INFO:Defining folds
2025-05-15 13:17:15,475:INFO:Declaring metric variables
2025-05-15 13:17:15,483:INFO:Importing untrained model
2025-05-15 13:17:15,484:INFO:Declaring custom model
2025-05-15 13:17:15,487:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:17:15,490:INFO:Starting cross validation
2025-05-15 13:17:15,492:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:17:22,045:INFO:Calculating mean and std
2025-05-15 13:17:22,047:INFO:Creating metrics dataframe
2025-05-15 13:17:22,049:INFO:Finalizing model
2025-05-15 13:17:23,009:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 13:17:23,009:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 13:17:23,009:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 13:17:23,041:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 13:17:23,041:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 13:17:23,041:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 13:17:23,042:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 13:17:23,051:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004963 seconds.
2025-05-15 13:17:23,051:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 13:17:23,051:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 13:17:23,051:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 13:17:23,052:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 13:17:23,052:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 13:17:24,509:INFO:Uploading results into container
2025-05-15 13:17:24,510:INFO:Uploading model into container now
2025-05-15 13:17:24,510:INFO:_master_model_container: 16
2025-05-15 13:17:24,510:INFO:_display_container: 3
2025-05-15 13:17:24,510:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:17:24,510:INFO:create_model() successfully completed......................................
2025-05-15 13:17:24,618:INFO:SubProcess create_model() end ==================================
2025-05-15 13:17:24,619:INFO:choose_better activated
2025-05-15 13:17:24,621:INFO:SubProcess create_model() called ==================================
2025-05-15 13:17:24,621:INFO:Initializing create_model()
2025-05-15 13:17:24,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:17:24,621:INFO:Checking exceptions
2025-05-15 13:17:24,622:INFO:Importing libraries
2025-05-15 13:17:24,622:INFO:Copying training dataset
2025-05-15 13:17:24,632:INFO:Defining folds
2025-05-15 13:17:24,632:INFO:Declaring metric variables
2025-05-15 13:17:24,633:INFO:Importing untrained model
2025-05-15 13:17:24,633:INFO:Declaring custom model
2025-05-15 13:17:24,633:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:17:24,633:INFO:Starting cross validation
2025-05-15 13:17:24,634:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:17:28,833:INFO:Calculating mean and std
2025-05-15 13:17:28,834:INFO:Creating metrics dataframe
2025-05-15 13:17:28,837:INFO:Finalizing model
2025-05-15 13:17:29,830:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 13:17:29,840:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005070 seconds.
2025-05-15 13:17:29,840:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 13:17:29,840:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 13:17:29,840:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 13:17:29,840:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-15 13:17:29,840:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 13:17:30,609:INFO:Uploading results into container
2025-05-15 13:17:30,610:INFO:Uploading model into container now
2025-05-15 13:17:30,610:INFO:_master_model_container: 17
2025-05-15 13:17:30,610:INFO:_display_container: 4
2025-05-15 13:17:30,610:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:17:30,611:INFO:create_model() successfully completed......................................
2025-05-15 13:17:30,672:INFO:SubProcess create_model() end ==================================
2025-05-15 13:17:30,672:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4709
2025-05-15 13:17:30,672:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-15 13:17:30,673:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-15 13:17:30,673:INFO:choose_better completed
2025-05-15 13:17:30,677:INFO:_master_model_container: 17
2025-05-15 13:17:30,677:INFO:_display_container: 3
2025-05-15 13:17:30,677:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:17:30,677:INFO:tune_model() successfully completed......................................
2025-05-15 13:17:30,741:INFO:Initializing evaluate_model()
2025-05-15 13:17:30,742:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 13:17:30,757:INFO:Initializing plot_model()
2025-05-15 13:17:30,757:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 13:17:30,757:INFO:Checking exceptions
2025-05-15 13:17:30,762:INFO:Preloading libraries
2025-05-15 13:17:30,765:INFO:Copying training dataset
2025-05-15 13:17:30,765:INFO:Plot type: pipeline
2025-05-15 13:17:30,826:INFO:Visual Rendered Successfully
2025-05-15 13:17:30,886:INFO:plot_model() successfully completed......................................
2025-05-15 13:17:30,888:INFO:Initializing interpret_model()
2025-05-15 13:17:30,888:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-15 13:17:30,888:INFO:Checking exceptions
2025-05-15 13:17:30,888:INFO:Soft dependency imported: shap: 0.47.2
2025-05-15 13:17:30,981:INFO:plot type: summary
2025-05-15 13:17:30,981:INFO:Creating TreeExplainer
2025-05-15 13:17:31,057:INFO:Compiling shap values
2025-05-15 13:17:32,305:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray
  warnings.warn(

2025-05-15 13:17:32,305:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-05-15 13:17:33,570:INFO:Visual Rendered Successfully
2025-05-15 13:17:33,570:INFO:interpret_model() successfully completed......................................
2025-05-15 13:17:33,635:INFO:Initializing finalize_model()
2025-05-15 13:17:33,635:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-15 13:17:33,635:INFO:Finalizing LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 13:17:33,639:INFO:Initializing create_model()
2025-05-15 13:17:33,639:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:17:33,639:INFO:Checking exceptions
2025-05-15 13:17:33,639:INFO:Importing libraries
2025-05-15 13:17:33,639:INFO:Copying training dataset
2025-05-15 13:17:33,640:INFO:Defining folds
2025-05-15 13:17:33,640:INFO:Declaring metric variables
2025-05-15 13:17:33,640:INFO:Importing untrained model
2025-05-15 13:17:33,640:INFO:Declaring custom model
2025-05-15 13:17:33,640:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 13:17:33,641:INFO:Cross validation set to False
2025-05-15 13:17:33,641:INFO:Fitting Model
2025-05-15 13:17:35,059:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 13:17:35,059:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 13:17:35,059:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 13:17:35,102:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 13:17:35,102:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 13:17:35,103:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 13:17:35,103:INFO:[LightGBM] [Info] Number of positive: 61360, number of negative: 61360
2025-05-15 13:17:35,115:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006004 seconds.
2025-05-15 13:17:35,115:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 13:17:35,115:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 13:17:35,115:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-15 13:17:35,115:INFO:[LightGBM] [Info] Number of data points in the train set: 122720, number of used features: 28
2025-05-15 13:17:35,116:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 13:17:36,719:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 13:17:36,719:INFO:create_model() successfully completed......................................
2025-05-15 13:17:36,775:INFO:_master_model_container: 17
2025-05-15 13:17:36,775:INFO:_display_container: 3
2025-05-15 13:17:36,796:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 13:17:36,796:INFO:finalize_model() successfully completed......................................
2025-05-15 13:17:36,893:INFO:Initializing save_model()
2025-05-15 13:17:36,893:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-15 13:17:36,893:INFO:Adding model into prep_pipe
2025-05-15 13:17:36,893:WARNING:Only Model saved as it was a pipeline.
2025-05-15 13:17:36,902:INFO:final_cancer_model.pkl saved in current working directory
2025-05-15 13:17:36,923:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 13:17:36,923:INFO:save_model() successfully completed......................................
2025-05-15 13:17:37,009:INFO:Initializing predict_model()
2025-05-15 13:17:37,010:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x3288d4fe0>)
2025-05-15 13:17:37,010:INFO:Checking exceptions
2025-05-15 13:17:37,010:INFO:Preloading libraries
2025-05-15 13:17:37,011:INFO:Set up data.
2025-05-15 13:17:37,029:INFO:Set up index.
2025-05-15 13:17:37,381:INFO:Initializing blend_models()
2025-05-15 13:17:37,381:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-15 13:17:37,381:INFO:Checking exceptions
2025-05-15 13:17:37,390:INFO:Importing libraries
2025-05-15 13:17:37,390:INFO:Copying training dataset
2025-05-15 13:17:37,391:INFO:Getting model names
2025-05-15 13:17:37,392:INFO:SubProcess create_model() called ==================================
2025-05-15 13:17:37,395:INFO:Initializing create_model()
2025-05-15 13:17:37,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x330739510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 13:17:37,395:INFO:Checking exceptions
2025-05-15 13:17:37,395:INFO:Importing libraries
2025-05-15 13:17:37,395:INFO:Copying training dataset
2025-05-15 13:17:37,406:INFO:Defining folds
2025-05-15 13:17:37,406:INFO:Declaring metric variables
2025-05-15 13:17:37,408:INFO:Importing untrained model
2025-05-15 13:17:37,408:INFO:Declaring custom model
2025-05-15 13:17:37,410:INFO:Voting Classifier Imported successfully
2025-05-15 13:17:37,412:INFO:Starting cross validation
2025-05-15 13:17:37,414:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 13:17:53,429:INFO:Calculating mean and std
2025-05-15 13:17:53,431:INFO:Creating metrics dataframe
2025-05-15 13:17:53,434:INFO:Finalizing model
2025-05-15 13:18:10,285:INFO:Uploading results into container
2025-05-15 13:18:10,287:INFO:Uploading model into container now
2025-05-15 13:18:10,287:INFO:_master_model_container: 18
2025-05-15 13:18:10,288:INFO:_display_container: 4
2025-05-15 13:18:10,291:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-15 13:18:10,291:INFO:create_model() successfully completed......................................
2025-05-15 13:18:10,399:INFO:SubProcess create_model() end ==================================
2025-05-15 13:18:10,402:INFO:_master_model_container: 18
2025-05-15 13:18:10,402:INFO:_display_container: 4
2025-05-15 13:18:10,405:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-15 13:18:10,405:INFO:blend_models() successfully completed......................................
2025-05-15 13:18:10,472:INFO:Initializing evaluate_model()
2025-05-15 13:18:10,472:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 13:18:10,483:INFO:Initializing plot_model()
2025-05-15 13:18:10,483:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 13:18:10,483:INFO:Checking exceptions
2025-05-15 13:18:10,487:INFO:Preloading libraries
2025-05-15 13:18:10,616:INFO:Copying training dataset
2025-05-15 13:18:10,617:INFO:Plot type: pipeline
2025-05-15 13:18:10,676:INFO:Visual Rendered Successfully
2025-05-15 13:18:10,733:INFO:plot_model() successfully completed......................................
2025-05-15 13:18:10,741:INFO:Initializing predict_model()
2025-05-15 13:18:10,741:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x363647b00>)
2025-05-15 13:18:10,741:INFO:Checking exceptions
2025-05-15 13:18:10,741:INFO:Preloading libraries
2025-05-15 13:18:10,742:INFO:Set up data.
2025-05-15 13:18:10,769:INFO:Set up index.
2025-05-15 13:18:11,359:INFO:Initializing plot_model()
2025-05-15 13:18:11,359:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 13:18:11,359:INFO:Checking exceptions
2025-05-15 13:18:11,363:INFO:Preloading libraries
2025-05-15 13:18:11,365:INFO:Copying training dataset
2025-05-15 13:18:11,365:INFO:Plot type: confusion_matrix
2025-05-15 13:18:11,580:INFO:Fitting Model
2025-05-15 13:18:11,581:INFO:Scoring test/hold-out set
2025-05-15 13:18:11,660:INFO:Visual Rendered Successfully
2025-05-15 13:18:11,721:INFO:plot_model() successfully completed......................................
2025-05-15 13:18:11,721:INFO:Initializing plot_model()
2025-05-15 13:18:11,721:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 13:18:11,721:INFO:Checking exceptions
2025-05-15 13:18:11,725:INFO:Preloading libraries
2025-05-15 13:18:11,727:INFO:Copying training dataset
2025-05-15 13:18:11,727:INFO:Plot type: auc
2025-05-15 13:18:11,955:INFO:Fitting Model
2025-05-15 13:18:11,957:INFO:Scoring test/hold-out set
2025-05-15 13:18:12,076:INFO:Visual Rendered Successfully
2025-05-15 13:18:12,133:INFO:plot_model() successfully completed......................................
2025-05-15 13:18:12,134:INFO:Initializing plot_model()
2025-05-15 13:18:12,134:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x10673a9d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 13:18:12,134:INFO:Checking exceptions
2025-05-15 13:18:12,138:INFO:Preloading libraries
2025-05-15 13:18:12,140:INFO:Copying training dataset
2025-05-15 13:18:12,140:INFO:Plot type: feature
2025-05-15 13:18:12,141:WARNING:No coef_ found. Trying feature_importances_
2025-05-15 13:18:12,211:INFO:Visual Rendered Successfully
2025-05-15 13:18:12,269:INFO:plot_model() successfully completed......................................
2025-05-15 21:18:26,243:INFO:PyCaret ClassificationExperiment
2025-05-15 21:18:26,243:INFO:Logging name: clf-default-name
2025-05-15 21:18:26,244:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 21:18:26,244:INFO:version 3.3.2
2025-05-15 21:18:26,244:INFO:Initializing setup()
2025-05-15 21:18:26,244:INFO:self.USI: 1110
2025-05-15 21:18:26,244:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-15 21:18:26,244:INFO:Checking environment
2025-05-15 21:18:26,244:INFO:python_version: 3.11.0
2025-05-15 21:18:26,244:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 21:18:26,244:INFO:machine: arm64
2025-05-15 21:18:26,244:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 21:18:26,244:INFO:Memory: svmem(total=17179869184, available=3001827328, percent=82.5, used=5942312960, free=68501504, active=2956361728, inactive=2913665024, wired=2985951232)
2025-05-15 21:18:26,244:INFO:Physical Core: 12
2025-05-15 21:18:26,244:INFO:Logical Core: 12
2025-05-15 21:18:26,244:INFO:Checking libraries
2025-05-15 21:18:26,245:INFO:System:
2025-05-15 21:18:26,245:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 21:18:26,245:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 21:18:26,245:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 21:18:26,245:INFO:PyCaret required dependencies:
2025-05-15 21:18:26,245:INFO:                 pip: 22.3
2025-05-15 21:18:26,245:INFO:          setuptools: 65.5.0
2025-05-15 21:18:26,245:INFO:             pycaret: 3.3.2
2025-05-15 21:18:26,245:INFO:             IPython: 9.2.0
2025-05-15 21:18:26,245:INFO:          ipywidgets: 8.1.7
2025-05-15 21:18:26,245:INFO:                tqdm: 4.67.1
2025-05-15 21:18:26,245:INFO:               numpy: 1.26.4
2025-05-15 21:18:26,245:INFO:              pandas: 2.1.4
2025-05-15 21:18:26,245:INFO:              jinja2: 3.1.6
2025-05-15 21:18:26,245:INFO:               scipy: 1.11.4
2025-05-15 21:18:26,245:INFO:              joblib: 1.3.2
2025-05-15 21:18:26,245:INFO:             sklearn: 1.4.2
2025-05-15 21:18:26,245:INFO:                pyod: 2.0.5
2025-05-15 21:18:26,245:INFO:            imblearn: 0.13.0
2025-05-15 21:18:26,245:INFO:   category_encoders: 2.7.0
2025-05-15 21:18:26,245:INFO:            lightgbm: 4.6.0
2025-05-15 21:18:26,245:INFO:               numba: 0.61.2
2025-05-15 21:18:26,245:INFO:            requests: 2.32.3
2025-05-15 21:18:26,245:INFO:          matplotlib: 3.7.5
2025-05-15 21:18:26,245:INFO:          scikitplot: 0.3.7
2025-05-15 21:18:26,245:INFO:         yellowbrick: 1.5
2025-05-15 21:18:26,245:INFO:              plotly: 5.24.1
2025-05-15 21:18:26,245:INFO:    plotly-resampler: Not installed
2025-05-15 21:18:26,245:INFO:             kaleido: 0.2.1
2025-05-15 21:18:26,246:INFO:           schemdraw: 0.15
2025-05-15 21:18:26,246:INFO:         statsmodels: 0.14.4
2025-05-15 21:18:26,246:INFO:              sktime: 0.26.0
2025-05-15 21:18:26,246:INFO:               tbats: 1.1.3
2025-05-15 21:18:26,246:INFO:            pmdarima: 2.0.4
2025-05-15 21:18:26,246:INFO:              psutil: 7.0.0
2025-05-15 21:18:26,246:INFO:          markupsafe: 3.0.2
2025-05-15 21:18:26,246:INFO:             pickle5: Not installed
2025-05-15 21:18:26,246:INFO:         cloudpickle: 3.1.1
2025-05-15 21:18:26,246:INFO:         deprecation: 2.1.0
2025-05-15 21:18:26,246:INFO:              xxhash: 3.5.0
2025-05-15 21:18:26,246:INFO:           wurlitzer: 3.1.1
2025-05-15 21:18:26,246:INFO:PyCaret optional dependencies:
2025-05-15 21:18:26,246:INFO:                shap: 0.47.2
2025-05-15 21:18:26,246:INFO:           interpret: Not installed
2025-05-15 21:18:26,246:INFO:                umap: Not installed
2025-05-15 21:18:26,246:INFO:     ydata_profiling: Not installed
2025-05-15 21:18:26,246:INFO:  explainerdashboard: Not installed
2025-05-15 21:18:26,246:INFO:             autoviz: Not installed
2025-05-15 21:18:26,246:INFO:           fairlearn: Not installed
2025-05-15 21:18:26,246:INFO:          deepchecks: Not installed
2025-05-15 21:18:26,246:INFO:             xgboost: Not installed
2025-05-15 21:18:26,246:INFO:            catboost: 1.2.8
2025-05-15 21:18:26,246:INFO:              kmodes: Not installed
2025-05-15 21:18:26,246:INFO:             mlxtend: Not installed
2025-05-15 21:18:26,246:INFO:       statsforecast: Not installed
2025-05-15 21:18:26,246:INFO:        tune_sklearn: Not installed
2025-05-15 21:18:26,246:INFO:                 ray: Not installed
2025-05-15 21:18:26,246:INFO:            hyperopt: Not installed
2025-05-15 21:18:26,246:INFO:              optuna: 4.3.0
2025-05-15 21:18:26,246:INFO:               skopt: Not installed
2025-05-15 21:18:26,246:INFO:              mlflow: Not installed
2025-05-15 21:18:26,246:INFO:              gradio: Not installed
2025-05-15 21:18:26,246:INFO:             fastapi: Not installed
2025-05-15 21:18:26,246:INFO:             uvicorn: Not installed
2025-05-15 21:18:26,246:INFO:              m2cgen: Not installed
2025-05-15 21:18:26,246:INFO:           evidently: Not installed
2025-05-15 21:18:26,246:INFO:               fugue: Not installed
2025-05-15 21:18:26,246:INFO:           streamlit: Not installed
2025-05-15 21:18:26,246:INFO:             prophet: Not installed
2025-05-15 21:18:26,246:INFO:None
2025-05-15 21:18:26,246:INFO:Set up data.
2025-05-15 21:18:26,288:INFO:Set up folding strategy.
2025-05-15 21:18:26,288:INFO:Set up train/test split.
2025-05-15 21:18:26,303:INFO:Set up index.
2025-05-15 21:18:26,303:INFO:Assigning column types.
2025-05-15 21:18:26,307:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 21:18:26,326:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 21:18:26,327:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:18:26,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:18:26,340:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:18:26,360:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 21:18:26,361:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:18:26,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:18:26,372:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:18:26,372:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 21:18:26,390:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:18:26,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:18:26,402:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:18:26,420:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:18:26,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:18:26,431:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:18:26,431:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 21:18:26,459:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:18:26,459:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:18:26,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:18:26,487:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:18:26,489:INFO:Preparing preprocessing pipeline...
2025-05-15 21:18:26,491:INFO:Set up simple imputation.
2025-05-15 21:18:26,499:INFO:Set up encoding of ordinal features.
2025-05-15 21:18:26,509:INFO:Set up encoding of categorical features.
2025-05-15 21:18:26,509:INFO:Set up column transformation.
2025-05-15 21:18:27,135:INFO:Finished creating preprocessing pipeline.
2025-05-15 21:18:27,153:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                 TransformerWrapper(exclude=None, include=['Country', 'Race'],
                                    transformer=OneHotEncoder(cols=['Country',
                                                                    'Race'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 21:18:27,153:INFO:Creating final display dataframe.
2025-05-15 21:18:27,491:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape       (69727, 29)
5   Transformed train set shape       (48808, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Transformation              True
16        Transformation method       yeo-johnson
17               Fold Generator   StratifiedKFold
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              1110
2025-05-15 21:18:27,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:18:27,527:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:18:27,557:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:18:27,557:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:18:27,559:INFO:setup() successfully completed in 1.32s...............
2025-05-15 21:18:27,559:INFO:Initializing create_model()
2025-05-15 21:18:27,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced'})
2025-05-15 21:18:27,559:INFO:Checking exceptions
2025-05-15 21:18:27,566:INFO:Importing libraries
2025-05-15 21:18:27,566:INFO:Copying training dataset
2025-05-15 21:18:27,579:INFO:Defining folds
2025-05-15 21:18:27,579:INFO:Declaring metric variables
2025-05-15 21:18:27,581:INFO:Importing untrained model
2025-05-15 21:18:27,582:INFO:Logistic Regression Imported successfully
2025-05-15 21:18:27,585:INFO:Starting cross validation
2025-05-15 21:18:27,587:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:18:32,083:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:18:32,087:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:18:32,100:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:18:32,109:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:18:32,110:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:18:32,181:INFO:Calculating mean and std
2025-05-15 21:18:32,189:INFO:Creating metrics dataframe
2025-05-15 21:18:32,199:INFO:Finalizing model
2025-05-15 21:18:36,545:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:18:36,553:INFO:Uploading results into container
2025-05-15 21:18:36,554:INFO:Uploading model into container now
2025-05-15 21:18:36,562:INFO:_master_model_container: 1
2025-05-15 21:18:36,562:INFO:_display_container: 2
2025-05-15 21:18:36,562:INFO:LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 21:18:36,563:INFO:create_model() successfully completed......................................
2025-05-15 21:18:36,964:INFO:Initializing create_model()
2025-05-15 21:18:36,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced'})
2025-05-15 21:18:36,965:INFO:Checking exceptions
2025-05-15 21:18:36,971:INFO:Importing libraries
2025-05-15 21:18:36,971:INFO:Copying training dataset
2025-05-15 21:18:36,983:INFO:Defining folds
2025-05-15 21:18:36,983:INFO:Declaring metric variables
2025-05-15 21:18:36,985:INFO:Importing untrained model
2025-05-15 21:18:36,986:INFO:Random Forest Classifier Imported successfully
2025-05-15 21:18:36,989:INFO:Starting cross validation
2025-05-15 21:18:36,990:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:18:41,646:INFO:Calculating mean and std
2025-05-15 21:18:41,649:INFO:Creating metrics dataframe
2025-05-15 21:18:41,660:INFO:Finalizing model
2025-05-15 21:18:42,904:INFO:Uploading results into container
2025-05-15 21:18:42,904:INFO:Uploading model into container now
2025-05-15 21:18:42,914:INFO:_master_model_container: 2
2025-05-15 21:18:42,914:INFO:_display_container: 3
2025-05-15 21:18:42,914:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 21:18:42,914:INFO:create_model() successfully completed......................................
2025-05-15 21:18:43,045:INFO:Initializing create_model()
2025-05-15 21:18:43,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced'})
2025-05-15 21:18:43,045:INFO:Checking exceptions
2025-05-15 21:18:43,051:INFO:Importing libraries
2025-05-15 21:18:43,051:INFO:Copying training dataset
2025-05-15 21:18:43,063:INFO:Defining folds
2025-05-15 21:18:43,063:INFO:Declaring metric variables
2025-05-15 21:18:43,065:INFO:Importing untrained model
2025-05-15 21:18:43,066:INFO:Extra Trees Classifier Imported successfully
2025-05-15 21:18:43,069:INFO:Starting cross validation
2025-05-15 21:18:43,070:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:18:46,636:INFO:Calculating mean and std
2025-05-15 21:18:46,640:INFO:Creating metrics dataframe
2025-05-15 21:18:46,649:INFO:Finalizing model
2025-05-15 21:18:47,685:INFO:Uploading results into container
2025-05-15 21:18:47,685:INFO:Uploading model into container now
2025-05-15 21:18:47,690:INFO:_master_model_container: 3
2025-05-15 21:18:47,690:INFO:_display_container: 4
2025-05-15 21:18:47,691:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 21:18:47,691:INFO:create_model() successfully completed......................................
2025-05-15 21:18:47,805:INFO:Initializing create_model()
2025-05-15 21:18:47,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 7.333397074290085})
2025-05-15 21:18:47,805:INFO:Checking exceptions
2025-05-15 21:18:47,805:INFO:Initializing create_model()
2025-05-15 21:18:47,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'is_unbalance': True})
2025-05-15 21:18:47,806:INFO:Checking exceptions
2025-05-15 21:18:47,811:INFO:Importing libraries
2025-05-15 21:18:47,811:INFO:Copying training dataset
2025-05-15 21:18:47,829:INFO:Defining folds
2025-05-15 21:18:47,829:INFO:Declaring metric variables
2025-05-15 21:18:47,830:INFO:Importing untrained model
2025-05-15 21:18:47,832:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 21:18:47,834:INFO:Starting cross validation
2025-05-15 21:18:47,836:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:18:51,222:INFO:Calculating mean and std
2025-05-15 21:18:51,223:INFO:Creating metrics dataframe
2025-05-15 21:18:51,227:INFO:Finalizing model
2025-05-15 21:18:51,876:INFO:[LightGBM] [Info] Number of positive: 5857, number of negative: 42951
2025-05-15 21:18:51,880:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001476 seconds.
2025-05-15 21:18:51,880:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 21:18:51,880:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 21:18:51,880:INFO:[LightGBM] [Info] Total Bins 1140
2025-05-15 21:18:51,881:INFO:[LightGBM] [Info] Number of data points in the train set: 48808, number of used features: 28
2025-05-15 21:18:51,881:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120001 -> initscore=-1.992422
2025-05-15 21:18:51,881:INFO:[LightGBM] [Info] Start training from score -1.992422
2025-05-15 21:18:52,708:INFO:Uploading results into container
2025-05-15 21:18:52,709:INFO:Uploading model into container now
2025-05-15 21:18:52,716:INFO:_master_model_container: 4
2025-05-15 21:18:52,716:INFO:_display_container: 5
2025-05-15 21:18:52,718:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', is_unbalance=True, learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-05-15 21:18:52,718:INFO:create_model() successfully completed......................................
2025-05-15 21:18:52,844:INFO:Initializing create_model()
2025-05-15 21:18:52,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'auto_class_weights': 'Balanced'})
2025-05-15 21:18:52,844:INFO:Checking exceptions
2025-05-15 21:18:52,850:INFO:Importing libraries
2025-05-15 21:18:52,850:INFO:Copying training dataset
2025-05-15 21:18:52,867:INFO:Defining folds
2025-05-15 21:18:52,867:INFO:Declaring metric variables
2025-05-15 21:18:52,869:INFO:Importing untrained model
2025-05-15 21:18:52,871:INFO:CatBoost Classifier Imported successfully
2025-05-15 21:18:52,875:INFO:Starting cross validation
2025-05-15 21:18:52,877:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:02,427:INFO:Calculating mean and std
2025-05-15 21:19:02,430:INFO:Creating metrics dataframe
2025-05-15 21:19:02,440:INFO:Finalizing model
2025-05-15 21:19:07,036:INFO:Uploading results into container
2025-05-15 21:19:07,037:INFO:Uploading model into container now
2025-05-15 21:19:07,042:INFO:_master_model_container: 5
2025-05-15 21:19:07,042:INFO:_display_container: 6
2025-05-15 21:19:07,042:INFO:<catboost.core.CatBoostClassifier object at 0x32e536610>
2025-05-15 21:19:07,042:INFO:create_model() successfully completed......................................
2025-05-15 21:19:07,154:INFO:Initializing create_model()
2025-05-15 21:19:07,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced'})
2025-05-15 21:19:07,154:INFO:Checking exceptions
2025-05-15 21:19:07,159:INFO:Importing libraries
2025-05-15 21:19:07,159:INFO:Copying training dataset
2025-05-15 21:19:07,172:INFO:Defining folds
2025-05-15 21:19:07,172:INFO:Declaring metric variables
2025-05-15 21:19:07,173:INFO:Importing untrained model
2025-05-15 21:19:07,175:INFO:Initializing compare_models()
2025-05-15 21:19:07,175:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-15 21:19:07,175:INFO:Checking exceptions
2025-05-15 21:19:07,180:INFO:Preparing display monitor
2025-05-15 21:19:07,187:INFO:Initializing Logistic Regression
2025-05-15 21:19:07,187:INFO:Total runtime is 1.5179316202799478e-06 minutes
2025-05-15 21:19:07,188:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:07,188:INFO:Initializing create_model()
2025-05-15 21:19:07,188:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:07,188:INFO:Checking exceptions
2025-05-15 21:19:07,188:INFO:Importing libraries
2025-05-15 21:19:07,188:INFO:Copying training dataset
2025-05-15 21:19:07,200:INFO:Defining folds
2025-05-15 21:19:07,200:INFO:Declaring metric variables
2025-05-15 21:19:07,201:INFO:Importing untrained model
2025-05-15 21:19:07,203:INFO:Logistic Regression Imported successfully
2025-05-15 21:19:07,205:INFO:Starting cross validation
2025-05-15 21:19:07,206:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:09,059:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:19:09,166:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:19:09,204:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:19:09,213:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:19:10,666:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:19:10,716:INFO:Calculating mean and std
2025-05-15 21:19:10,716:INFO:Creating metrics dataframe
2025-05-15 21:19:10,717:INFO:Uploading results into container
2025-05-15 21:19:10,717:INFO:Uploading model into container now
2025-05-15 21:19:10,718:INFO:_master_model_container: 6
2025-05-15 21:19:10,718:INFO:_display_container: 7
2025-05-15 21:19:10,718:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 21:19:10,718:INFO:create_model() successfully completed......................................
2025-05-15 21:19:10,783:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:10,784:INFO:Creating metrics dataframe
2025-05-15 21:19:10,787:INFO:Initializing K Neighbors Classifier
2025-05-15 21:19:10,787:INFO:Total runtime is 0.060004719098409015 minutes
2025-05-15 21:19:10,788:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:10,789:INFO:Initializing create_model()
2025-05-15 21:19:10,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:10,789:INFO:Checking exceptions
2025-05-15 21:19:10,789:INFO:Importing libraries
2025-05-15 21:19:10,789:INFO:Copying training dataset
2025-05-15 21:19:10,799:INFO:Defining folds
2025-05-15 21:19:10,799:INFO:Declaring metric variables
2025-05-15 21:19:10,800:INFO:Importing untrained model
2025-05-15 21:19:10,801:INFO:K Neighbors Classifier Imported successfully
2025-05-15 21:19:10,803:INFO:Starting cross validation
2025-05-15 21:19:10,804:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:13,628:INFO:Calculating mean and std
2025-05-15 21:19:13,630:INFO:Creating metrics dataframe
2025-05-15 21:19:13,632:INFO:Uploading results into container
2025-05-15 21:19:13,632:INFO:Uploading model into container now
2025-05-15 21:19:13,632:INFO:_master_model_container: 7
2025-05-15 21:19:13,632:INFO:_display_container: 7
2025-05-15 21:19:13,632:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-15 21:19:13,632:INFO:create_model() successfully completed......................................
2025-05-15 21:19:13,696:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:13,696:INFO:Creating metrics dataframe
2025-05-15 21:19:13,699:INFO:Initializing Naive Bayes
2025-05-15 21:19:13,699:INFO:Total runtime is 0.10854158401489258 minutes
2025-05-15 21:19:13,701:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:13,701:INFO:Initializing create_model()
2025-05-15 21:19:13,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:13,701:INFO:Checking exceptions
2025-05-15 21:19:13,701:INFO:Importing libraries
2025-05-15 21:19:13,701:INFO:Copying training dataset
2025-05-15 21:19:13,710:INFO:Defining folds
2025-05-15 21:19:13,710:INFO:Declaring metric variables
2025-05-15 21:19:13,711:INFO:Importing untrained model
2025-05-15 21:19:13,712:INFO:Naive Bayes Imported successfully
2025-05-15 21:19:13,714:INFO:Starting cross validation
2025-05-15 21:19:13,715:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:14,375:INFO:Calculating mean and std
2025-05-15 21:19:14,375:INFO:Creating metrics dataframe
2025-05-15 21:19:14,376:INFO:Uploading results into container
2025-05-15 21:19:14,377:INFO:Uploading model into container now
2025-05-15 21:19:14,377:INFO:_master_model_container: 8
2025-05-15 21:19:14,377:INFO:_display_container: 7
2025-05-15 21:19:14,377:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-15 21:19:14,377:INFO:create_model() successfully completed......................................
2025-05-15 21:19:14,438:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:14,438:INFO:Creating metrics dataframe
2025-05-15 21:19:14,441:INFO:Initializing Decision Tree Classifier
2025-05-15 21:19:14,441:INFO:Total runtime is 0.12090443372726441 minutes
2025-05-15 21:19:14,442:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:14,442:INFO:Initializing create_model()
2025-05-15 21:19:14,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:14,443:INFO:Checking exceptions
2025-05-15 21:19:14,443:INFO:Importing libraries
2025-05-15 21:19:14,443:INFO:Copying training dataset
2025-05-15 21:19:14,452:INFO:Defining folds
2025-05-15 21:19:14,452:INFO:Declaring metric variables
2025-05-15 21:19:14,453:INFO:Importing untrained model
2025-05-15 21:19:14,454:INFO:Decision Tree Classifier Imported successfully
2025-05-15 21:19:14,456:INFO:Starting cross validation
2025-05-15 21:19:14,457:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:15,477:INFO:Calculating mean and std
2025-05-15 21:19:15,478:INFO:Creating metrics dataframe
2025-05-15 21:19:15,478:INFO:Uploading results into container
2025-05-15 21:19:15,479:INFO:Uploading model into container now
2025-05-15 21:19:15,479:INFO:_master_model_container: 9
2025-05-15 21:19:15,479:INFO:_display_container: 7
2025-05-15 21:19:15,479:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-15 21:19:15,479:INFO:create_model() successfully completed......................................
2025-05-15 21:19:15,540:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:15,540:INFO:Creating metrics dataframe
2025-05-15 21:19:15,543:INFO:Initializing SVM - Linear Kernel
2025-05-15 21:19:15,543:INFO:Total runtime is 0.13927086194356283 minutes
2025-05-15 21:19:15,544:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:15,545:INFO:Initializing create_model()
2025-05-15 21:19:15,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:15,545:INFO:Checking exceptions
2025-05-15 21:19:15,545:INFO:Importing libraries
2025-05-15 21:19:15,545:INFO:Copying training dataset
2025-05-15 21:19:15,555:INFO:Defining folds
2025-05-15 21:19:15,555:INFO:Declaring metric variables
2025-05-15 21:19:15,557:INFO:Importing untrained model
2025-05-15 21:19:15,558:INFO:SVM - Linear Kernel Imported successfully
2025-05-15 21:19:15,560:INFO:Starting cross validation
2025-05-15 21:19:15,561:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:16,980:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:19:17,132:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:19:17,180:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:19:17,212:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:19:17,236:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:19:17,243:INFO:Calculating mean and std
2025-05-15 21:19:17,244:INFO:Creating metrics dataframe
2025-05-15 21:19:17,245:INFO:Uploading results into container
2025-05-15 21:19:17,245:INFO:Uploading model into container now
2025-05-15 21:19:17,245:INFO:_master_model_container: 10
2025-05-15 21:19:17,245:INFO:_display_container: 7
2025-05-15 21:19:17,245:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-15 21:19:17,245:INFO:create_model() successfully completed......................................
2025-05-15 21:19:17,307:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:17,307:INFO:Creating metrics dataframe
2025-05-15 21:19:17,310:INFO:Initializing Ridge Classifier
2025-05-15 21:19:17,310:INFO:Total runtime is 0.1687235156695048 minutes
2025-05-15 21:19:17,311:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:17,312:INFO:Initializing create_model()
2025-05-15 21:19:17,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:17,312:INFO:Checking exceptions
2025-05-15 21:19:17,312:INFO:Importing libraries
2025-05-15 21:19:17,312:INFO:Copying training dataset
2025-05-15 21:19:17,321:INFO:Defining folds
2025-05-15 21:19:17,321:INFO:Declaring metric variables
2025-05-15 21:19:17,322:INFO:Importing untrained model
2025-05-15 21:19:17,323:INFO:Ridge Classifier Imported successfully
2025-05-15 21:19:17,325:INFO:Starting cross validation
2025-05-15 21:19:17,326:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:17,987:INFO:Calculating mean and std
2025-05-15 21:19:17,987:INFO:Creating metrics dataframe
2025-05-15 21:19:17,988:INFO:Uploading results into container
2025-05-15 21:19:17,988:INFO:Uploading model into container now
2025-05-15 21:19:17,988:INFO:_master_model_container: 11
2025-05-15 21:19:17,988:INFO:_display_container: 7
2025-05-15 21:19:17,989:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-15 21:19:17,989:INFO:create_model() successfully completed......................................
2025-05-15 21:19:18,053:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:18,053:INFO:Creating metrics dataframe
2025-05-15 21:19:18,057:INFO:Initializing Random Forest Classifier
2025-05-15 21:19:18,057:INFO:Total runtime is 0.1811631162961324 minutes
2025-05-15 21:19:18,058:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:18,058:INFO:Initializing create_model()
2025-05-15 21:19:18,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:18,058:INFO:Checking exceptions
2025-05-15 21:19:18,058:INFO:Importing libraries
2025-05-15 21:19:18,058:INFO:Copying training dataset
2025-05-15 21:19:18,068:INFO:Defining folds
2025-05-15 21:19:18,068:INFO:Declaring metric variables
2025-05-15 21:19:18,069:INFO:Importing untrained model
2025-05-15 21:19:18,070:INFO:Random Forest Classifier Imported successfully
2025-05-15 21:19:18,073:INFO:Starting cross validation
2025-05-15 21:19:18,074:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:21,123:INFO:Calculating mean and std
2025-05-15 21:19:21,126:INFO:Creating metrics dataframe
2025-05-15 21:19:21,130:INFO:Uploading results into container
2025-05-15 21:19:21,131:INFO:Uploading model into container now
2025-05-15 21:19:21,131:INFO:_master_model_container: 12
2025-05-15 21:19:21,131:INFO:_display_container: 7
2025-05-15 21:19:21,132:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 21:19:21,132:INFO:create_model() successfully completed......................................
2025-05-15 21:19:21,241:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:21,241:INFO:Creating metrics dataframe
2025-05-15 21:19:21,244:INFO:Initializing Quadratic Discriminant Analysis
2025-05-15 21:19:21,245:INFO:Total runtime is 0.2342946489651998 minutes
2025-05-15 21:19:21,246:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:21,246:INFO:Initializing create_model()
2025-05-15 21:19:21,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:21,246:INFO:Checking exceptions
2025-05-15 21:19:21,246:INFO:Importing libraries
2025-05-15 21:19:21,246:INFO:Copying training dataset
2025-05-15 21:19:21,256:INFO:Defining folds
2025-05-15 21:19:21,256:INFO:Declaring metric variables
2025-05-15 21:19:21,257:INFO:Importing untrained model
2025-05-15 21:19:21,259:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 21:19:21,261:INFO:Starting cross validation
2025-05-15 21:19:21,262:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:21,868:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:19:21,871:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:19:21,886:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:19:21,895:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:19:21,904:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:19:21,972:INFO:Calculating mean and std
2025-05-15 21:19:21,973:INFO:Creating metrics dataframe
2025-05-15 21:19:21,974:INFO:Uploading results into container
2025-05-15 21:19:21,974:INFO:Uploading model into container now
2025-05-15 21:19:21,974:INFO:_master_model_container: 13
2025-05-15 21:19:21,974:INFO:_display_container: 7
2025-05-15 21:19:21,975:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 21:19:21,975:INFO:create_model() successfully completed......................................
2025-05-15 21:19:22,039:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:22,040:INFO:Creating metrics dataframe
2025-05-15 21:19:22,043:INFO:Initializing Ada Boost Classifier
2025-05-15 21:19:22,043:INFO:Total runtime is 0.24760468403498334 minutes
2025-05-15 21:19:22,045:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:22,045:INFO:Initializing create_model()
2025-05-15 21:19:22,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:22,045:INFO:Checking exceptions
2025-05-15 21:19:22,045:INFO:Importing libraries
2025-05-15 21:19:22,045:INFO:Copying training dataset
2025-05-15 21:19:22,056:INFO:Defining folds
2025-05-15 21:19:22,056:INFO:Declaring metric variables
2025-05-15 21:19:22,057:INFO:Importing untrained model
2025-05-15 21:19:22,058:INFO:Ada Boost Classifier Imported successfully
2025-05-15 21:19:22,061:INFO:Starting cross validation
2025-05-15 21:19:22,062:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:22,646:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:19:22,660:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:19:22,660:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:19:22,661:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:19:22,696:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:19:23,971:INFO:Calculating mean and std
2025-05-15 21:19:23,971:INFO:Creating metrics dataframe
2025-05-15 21:19:23,972:INFO:Uploading results into container
2025-05-15 21:19:23,972:INFO:Uploading model into container now
2025-05-15 21:19:23,973:INFO:_master_model_container: 14
2025-05-15 21:19:23,973:INFO:_display_container: 7
2025-05-15 21:19:23,973:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-15 21:19:23,973:INFO:create_model() successfully completed......................................
2025-05-15 21:19:24,037:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:24,038:INFO:Creating metrics dataframe
2025-05-15 21:19:24,042:INFO:Initializing Gradient Boosting Classifier
2025-05-15 21:19:24,042:INFO:Total runtime is 0.2809119462966919 minutes
2025-05-15 21:19:24,043:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:24,043:INFO:Initializing create_model()
2025-05-15 21:19:24,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:24,043:INFO:Checking exceptions
2025-05-15 21:19:24,043:INFO:Importing libraries
2025-05-15 21:19:24,043:INFO:Copying training dataset
2025-05-15 21:19:24,053:INFO:Defining folds
2025-05-15 21:19:24,053:INFO:Declaring metric variables
2025-05-15 21:19:24,054:INFO:Importing untrained model
2025-05-15 21:19:24,055:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 21:19:24,057:INFO:Starting cross validation
2025-05-15 21:19:24,058:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:30,123:INFO:Calculating mean and std
2025-05-15 21:19:30,123:INFO:Creating metrics dataframe
2025-05-15 21:19:30,124:INFO:Uploading results into container
2025-05-15 21:19:30,124:INFO:Uploading model into container now
2025-05-15 21:19:30,125:INFO:_master_model_container: 15
2025-05-15 21:19:30,125:INFO:_display_container: 7
2025-05-15 21:19:30,125:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 21:19:30,125:INFO:create_model() successfully completed......................................
2025-05-15 21:19:30,181:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:30,181:INFO:Creating metrics dataframe
2025-05-15 21:19:30,185:INFO:Initializing Linear Discriminant Analysis
2025-05-15 21:19:30,185:INFO:Total runtime is 0.3833000818888347 minutes
2025-05-15 21:19:30,186:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:30,186:INFO:Initializing create_model()
2025-05-15 21:19:30,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:30,186:INFO:Checking exceptions
2025-05-15 21:19:30,186:INFO:Importing libraries
2025-05-15 21:19:30,186:INFO:Copying training dataset
2025-05-15 21:19:30,196:INFO:Defining folds
2025-05-15 21:19:30,196:INFO:Declaring metric variables
2025-05-15 21:19:30,197:INFO:Importing untrained model
2025-05-15 21:19:30,198:INFO:Linear Discriminant Analysis Imported successfully
2025-05-15 21:19:30,200:INFO:Starting cross validation
2025-05-15 21:19:30,201:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:30,922:INFO:Calculating mean and std
2025-05-15 21:19:30,923:INFO:Creating metrics dataframe
2025-05-15 21:19:30,924:INFO:Uploading results into container
2025-05-15 21:19:30,924:INFO:Uploading model into container now
2025-05-15 21:19:30,924:INFO:_master_model_container: 16
2025-05-15 21:19:30,924:INFO:_display_container: 7
2025-05-15 21:19:30,924:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-15 21:19:30,924:INFO:create_model() successfully completed......................................
2025-05-15 21:19:30,982:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:30,982:INFO:Creating metrics dataframe
2025-05-15 21:19:30,986:INFO:Initializing Extra Trees Classifier
2025-05-15 21:19:30,986:INFO:Total runtime is 0.396657685438792 minutes
2025-05-15 21:19:30,987:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:30,988:INFO:Initializing create_model()
2025-05-15 21:19:30,988:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:30,988:INFO:Checking exceptions
2025-05-15 21:19:30,988:INFO:Importing libraries
2025-05-15 21:19:30,988:INFO:Copying training dataset
2025-05-15 21:19:30,998:INFO:Defining folds
2025-05-15 21:19:30,998:INFO:Declaring metric variables
2025-05-15 21:19:31,000:INFO:Importing untrained model
2025-05-15 21:19:31,001:INFO:Extra Trees Classifier Imported successfully
2025-05-15 21:19:31,003:INFO:Starting cross validation
2025-05-15 21:19:31,004:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:33,203:INFO:Calculating mean and std
2025-05-15 21:19:33,205:INFO:Creating metrics dataframe
2025-05-15 21:19:33,209:INFO:Uploading results into container
2025-05-15 21:19:33,209:INFO:Uploading model into container now
2025-05-15 21:19:33,210:INFO:_master_model_container: 17
2025-05-15 21:19:33,210:INFO:_display_container: 7
2025-05-15 21:19:33,211:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 21:19:33,211:INFO:create_model() successfully completed......................................
2025-05-15 21:19:33,341:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:33,341:INFO:Creating metrics dataframe
2025-05-15 21:19:33,346:INFO:Initializing Light Gradient Boosting Machine
2025-05-15 21:19:33,346:INFO:Total runtime is 0.4359816471735637 minutes
2025-05-15 21:19:33,347:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:33,348:INFO:Initializing create_model()
2025-05-15 21:19:33,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:33,348:INFO:Checking exceptions
2025-05-15 21:19:33,348:INFO:Importing libraries
2025-05-15 21:19:33,348:INFO:Copying training dataset
2025-05-15 21:19:33,368:INFO:Defining folds
2025-05-15 21:19:33,368:INFO:Declaring metric variables
2025-05-15 21:19:33,370:INFO:Importing untrained model
2025-05-15 21:19:33,371:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 21:19:33,374:INFO:Starting cross validation
2025-05-15 21:19:33,375:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:36,643:INFO:Calculating mean and std
2025-05-15 21:19:36,644:INFO:Creating metrics dataframe
2025-05-15 21:19:36,645:INFO:Uploading results into container
2025-05-15 21:19:36,645:INFO:Uploading model into container now
2025-05-15 21:19:36,645:INFO:_master_model_container: 18
2025-05-15 21:19:36,645:INFO:_display_container: 7
2025-05-15 21:19:36,646:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 21:19:36,646:INFO:create_model() successfully completed......................................
2025-05-15 21:19:36,705:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:36,706:INFO:Creating metrics dataframe
2025-05-15 21:19:36,710:INFO:Initializing CatBoost Classifier
2025-05-15 21:19:36,710:INFO:Total runtime is 0.49204658269882207 minutes
2025-05-15 21:19:36,711:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:36,711:INFO:Initializing create_model()
2025-05-15 21:19:36,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:36,711:INFO:Checking exceptions
2025-05-15 21:19:36,711:INFO:Importing libraries
2025-05-15 21:19:36,711:INFO:Copying training dataset
2025-05-15 21:19:36,721:INFO:Defining folds
2025-05-15 21:19:36,721:INFO:Declaring metric variables
2025-05-15 21:19:36,722:INFO:Importing untrained model
2025-05-15 21:19:36,723:INFO:CatBoost Classifier Imported successfully
2025-05-15 21:19:36,725:INFO:Starting cross validation
2025-05-15 21:19:36,726:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:45,912:INFO:Calculating mean and std
2025-05-15 21:19:45,915:INFO:Creating metrics dataframe
2025-05-15 21:19:45,922:INFO:Uploading results into container
2025-05-15 21:19:45,923:INFO:Uploading model into container now
2025-05-15 21:19:45,923:INFO:_master_model_container: 19
2025-05-15 21:19:45,924:INFO:_display_container: 7
2025-05-15 21:19:45,924:INFO:<catboost.core.CatBoostClassifier object at 0x330236390>
2025-05-15 21:19:45,924:INFO:create_model() successfully completed......................................
2025-05-15 21:19:46,064:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:46,065:INFO:Creating metrics dataframe
2025-05-15 21:19:46,071:INFO:Initializing Dummy Classifier
2025-05-15 21:19:46,071:INFO:Total runtime is 0.6480649987856547 minutes
2025-05-15 21:19:46,072:INFO:SubProcess create_model() called ==================================
2025-05-15 21:19:46,073:INFO:Initializing create_model()
2025-05-15 21:19:46,073:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3631a78d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:46,073:INFO:Checking exceptions
2025-05-15 21:19:46,073:INFO:Importing libraries
2025-05-15 21:19:46,073:INFO:Copying training dataset
2025-05-15 21:19:46,095:INFO:Defining folds
2025-05-15 21:19:46,096:INFO:Declaring metric variables
2025-05-15 21:19:46,098:INFO:Importing untrained model
2025-05-15 21:19:46,099:INFO:Dummy Classifier Imported successfully
2025-05-15 21:19:46,102:INFO:Starting cross validation
2025-05-15 21:19:46,103:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:19:46,772:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:19:46,804:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:19:46,818:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:19:46,826:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:19:46,834:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:19:46,849:INFO:Calculating mean and std
2025-05-15 21:19:46,850:INFO:Creating metrics dataframe
2025-05-15 21:19:46,851:INFO:Uploading results into container
2025-05-15 21:19:46,851:INFO:Uploading model into container now
2025-05-15 21:19:46,851:INFO:_master_model_container: 20
2025-05-15 21:19:46,851:INFO:_display_container: 7
2025-05-15 21:19:46,851:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-15 21:19:46,851:INFO:create_model() successfully completed......................................
2025-05-15 21:19:46,918:INFO:SubProcess create_model() end ==================================
2025-05-15 21:19:46,918:INFO:Creating metrics dataframe
2025-05-15 21:19:46,924:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-15 21:19:46,928:INFO:Initializing create_model()
2025-05-15 21:19:46,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:46,928:INFO:Checking exceptions
2025-05-15 21:19:46,929:INFO:Importing libraries
2025-05-15 21:19:46,929:INFO:Copying training dataset
2025-05-15 21:19:46,938:INFO:Defining folds
2025-05-15 21:19:46,938:INFO:Declaring metric variables
2025-05-15 21:19:46,938:INFO:Importing untrained model
2025-05-15 21:19:46,938:INFO:Declaring custom model
2025-05-15 21:19:46,939:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 21:19:46,939:INFO:Cross validation set to False
2025-05-15 21:19:46,939:INFO:Fitting Model
2025-05-15 21:19:47,639:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:19:47,653:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 21:19:47,653:INFO:create_model() successfully completed......................................
2025-05-15 21:19:47,743:INFO:Initializing create_model()
2025-05-15 21:19:47,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=<catboost.core.CatBoostClassifier object at 0x330236390>, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:47,743:INFO:Checking exceptions
2025-05-15 21:19:47,744:INFO:Importing libraries
2025-05-15 21:19:47,744:INFO:Copying training dataset
2025-05-15 21:19:47,758:INFO:Defining folds
2025-05-15 21:19:47,758:INFO:Declaring metric variables
2025-05-15 21:19:47,758:INFO:Importing untrained model
2025-05-15 21:19:47,758:INFO:Declaring custom model
2025-05-15 21:19:47,758:INFO:CatBoost Classifier Imported successfully
2025-05-15 21:19:47,759:INFO:Cross validation set to False
2025-05-15 21:19:47,759:INFO:Fitting Model
2025-05-15 21:19:52,213:INFO:<catboost.core.CatBoostClassifier object at 0x32e58b8d0>
2025-05-15 21:19:52,213:INFO:create_model() successfully completed......................................
2025-05-15 21:19:52,272:INFO:Initializing create_model()
2025-05-15 21:19:52,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:19:52,272:INFO:Checking exceptions
2025-05-15 21:19:52,273:INFO:Importing libraries
2025-05-15 21:19:52,273:INFO:Copying training dataset
2025-05-15 21:19:52,282:INFO:Defining folds
2025-05-15 21:19:52,282:INFO:Declaring metric variables
2025-05-15 21:19:52,282:INFO:Importing untrained model
2025-05-15 21:19:52,282:INFO:Declaring custom model
2025-05-15 21:19:52,283:INFO:Extra Trees Classifier Imported successfully
2025-05-15 21:19:52,283:INFO:Cross validation set to False
2025-05-15 21:19:52,283:INFO:Fitting Model
2025-05-15 21:19:53,230:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 21:19:53,230:INFO:create_model() successfully completed......................................
2025-05-15 21:19:53,301:INFO:_master_model_container: 20
2025-05-15 21:19:53,301:INFO:_display_container: 7
2025-05-15 21:19:53,301:INFO:[QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), <catboost.core.CatBoostClassifier object at 0x32e58b8d0>, ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)]
2025-05-15 21:19:53,301:INFO:compare_models() successfully completed......................................
2025-05-15 21:19:53,304:INFO:Initializing evaluate_model()
2025-05-15 21:19:53,304:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 21:19:53,312:INFO:Initializing plot_model()
2025-05-15 21:19:53,312:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 21:19:53,312:INFO:Checking exceptions
2025-05-15 21:19:53,315:INFO:Preloading libraries
2025-05-15 21:19:53,315:INFO:Copying training dataset
2025-05-15 21:19:53,315:INFO:Plot type: pipeline
2025-05-15 21:19:53,378:INFO:Visual Rendered Successfully
2025-05-15 21:19:53,441:INFO:plot_model() successfully completed......................................
2025-05-15 21:19:53,442:INFO:Initializing get_config()
2025-05-15 21:19:53,442:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33050a950>, variable=prep_pipe)
2025-05-15 21:38:49,629:INFO:PyCaret ClassificationExperiment
2025-05-15 21:38:49,629:INFO:Logging name: clf-default-name
2025-05-15 21:38:49,629:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 21:38:49,629:INFO:version 3.3.2
2025-05-15 21:38:49,629:INFO:Initializing setup()
2025-05-15 21:38:49,629:INFO:self.USI: a3bb
2025-05-15 21:38:49,629:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-15 21:38:49,629:INFO:Checking environment
2025-05-15 21:38:49,629:INFO:python_version: 3.11.0
2025-05-15 21:38:49,629:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 21:38:49,629:INFO:machine: arm64
2025-05-15 21:38:49,629:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 21:38:49,629:INFO:Memory: svmem(total=17179869184, available=4959649792, percent=71.1, used=7134085120, free=85049344, active=4290854912, inactive=4842127360, wired=2843230208)
2025-05-15 21:38:49,629:INFO:Physical Core: 12
2025-05-15 21:38:49,629:INFO:Logical Core: 12
2025-05-15 21:38:49,629:INFO:Checking libraries
2025-05-15 21:38:49,629:INFO:System:
2025-05-15 21:38:49,629:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 21:38:49,629:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 21:38:49,629:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 21:38:49,629:INFO:PyCaret required dependencies:
2025-05-15 21:38:49,629:INFO:                 pip: 22.3
2025-05-15 21:38:49,629:INFO:          setuptools: 65.5.0
2025-05-15 21:38:49,629:INFO:             pycaret: 3.3.2
2025-05-15 21:38:49,629:INFO:             IPython: 9.2.0
2025-05-15 21:38:49,629:INFO:          ipywidgets: 8.1.7
2025-05-15 21:38:49,629:INFO:                tqdm: 4.67.1
2025-05-15 21:38:49,629:INFO:               numpy: 1.26.4
2025-05-15 21:38:49,629:INFO:              pandas: 2.1.4
2025-05-15 21:38:49,629:INFO:              jinja2: 3.1.6
2025-05-15 21:38:49,629:INFO:               scipy: 1.11.4
2025-05-15 21:38:49,630:INFO:              joblib: 1.3.2
2025-05-15 21:38:49,630:INFO:             sklearn: 1.4.2
2025-05-15 21:38:49,630:INFO:                pyod: 2.0.5
2025-05-15 21:38:49,630:INFO:            imblearn: 0.13.0
2025-05-15 21:38:49,630:INFO:   category_encoders: 2.7.0
2025-05-15 21:38:49,630:INFO:            lightgbm: 4.6.0
2025-05-15 21:38:49,630:INFO:               numba: 0.61.2
2025-05-15 21:38:49,630:INFO:            requests: 2.32.3
2025-05-15 21:38:49,630:INFO:          matplotlib: 3.7.5
2025-05-15 21:38:49,630:INFO:          scikitplot: 0.3.7
2025-05-15 21:38:49,630:INFO:         yellowbrick: 1.5
2025-05-15 21:38:49,630:INFO:              plotly: 5.24.1
2025-05-15 21:38:49,630:INFO:    plotly-resampler: Not installed
2025-05-15 21:38:49,630:INFO:             kaleido: 0.2.1
2025-05-15 21:38:49,630:INFO:           schemdraw: 0.15
2025-05-15 21:38:49,630:INFO:         statsmodels: 0.14.4
2025-05-15 21:38:49,630:INFO:              sktime: 0.26.0
2025-05-15 21:38:49,630:INFO:               tbats: 1.1.3
2025-05-15 21:38:49,630:INFO:            pmdarima: 2.0.4
2025-05-15 21:38:49,630:INFO:              psutil: 7.0.0
2025-05-15 21:38:49,630:INFO:          markupsafe: 3.0.2
2025-05-15 21:38:49,630:INFO:             pickle5: Not installed
2025-05-15 21:38:49,630:INFO:         cloudpickle: 3.1.1
2025-05-15 21:38:49,630:INFO:         deprecation: 2.1.0
2025-05-15 21:38:49,630:INFO:              xxhash: 3.5.0
2025-05-15 21:38:49,630:INFO:           wurlitzer: 3.1.1
2025-05-15 21:38:49,630:INFO:PyCaret optional dependencies:
2025-05-15 21:38:49,630:INFO:                shap: 0.47.2
2025-05-15 21:38:49,630:INFO:           interpret: Not installed
2025-05-15 21:38:49,630:INFO:                umap: Not installed
2025-05-15 21:38:49,630:INFO:     ydata_profiling: Not installed
2025-05-15 21:38:49,630:INFO:  explainerdashboard: Not installed
2025-05-15 21:38:49,630:INFO:             autoviz: Not installed
2025-05-15 21:38:49,630:INFO:           fairlearn: Not installed
2025-05-15 21:38:49,630:INFO:          deepchecks: Not installed
2025-05-15 21:38:49,630:INFO:             xgboost: Not installed
2025-05-15 21:38:49,630:INFO:            catboost: 1.2.8
2025-05-15 21:38:49,630:INFO:              kmodes: Not installed
2025-05-15 21:38:49,630:INFO:             mlxtend: Not installed
2025-05-15 21:38:49,630:INFO:       statsforecast: Not installed
2025-05-15 21:38:49,630:INFO:        tune_sklearn: Not installed
2025-05-15 21:38:49,630:INFO:                 ray: Not installed
2025-05-15 21:38:49,630:INFO:            hyperopt: Not installed
2025-05-15 21:38:49,630:INFO:              optuna: 4.3.0
2025-05-15 21:38:49,630:INFO:               skopt: Not installed
2025-05-15 21:38:49,630:INFO:              mlflow: Not installed
2025-05-15 21:38:49,630:INFO:              gradio: Not installed
2025-05-15 21:38:49,630:INFO:             fastapi: Not installed
2025-05-15 21:38:49,630:INFO:             uvicorn: Not installed
2025-05-15 21:38:49,630:INFO:              m2cgen: Not installed
2025-05-15 21:38:49,630:INFO:           evidently: Not installed
2025-05-15 21:38:49,630:INFO:               fugue: Not installed
2025-05-15 21:38:49,630:INFO:           streamlit: Not installed
2025-05-15 21:38:49,630:INFO:             prophet: Not installed
2025-05-15 21:38:49,630:INFO:None
2025-05-15 21:38:49,630:INFO:Set up data.
2025-05-15 21:38:49,661:INFO:Set up folding strategy.
2025-05-15 21:38:49,661:INFO:Set up train/test split.
2025-05-15 21:38:49,675:INFO:Set up index.
2025-05-15 21:38:49,676:INFO:Assigning column types.
2025-05-15 21:38:49,680:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 21:38:49,698:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 21:38:49,699:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:38:49,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:38:49,711:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:38:49,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 21:38:49,730:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:38:49,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:38:49,741:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:38:49,741:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 21:38:49,759:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:38:49,771:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:38:49,771:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:38:49,789:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:38:49,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:38:49,800:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:38:49,800:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 21:38:49,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:38:49,829:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:38:49,859:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:38:49,859:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:38:49,859:INFO:Preparing preprocessing pipeline...
2025-05-15 21:38:49,861:INFO:Set up simple imputation.
2025-05-15 21:38:49,867:INFO:Set up encoding of ordinal features.
2025-05-15 21:38:49,876:INFO:Set up encoding of categorical features.
2025-05-15 21:38:49,876:INFO:Set up column transformation.
2025-05-15 21:38:50,143:INFO:Finished creating preprocessing pipeline.
2025-05-15 21:38:50,162:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                 TransformerWrapper(exclude=None, include=['Country', 'Race'],
                                    transformer=OneHotEncoder(cols=['Country',
                                                                    'Race'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 21:38:50,162:INFO:Creating final display dataframe.
2025-05-15 21:38:50,381:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape       (69727, 29)
5   Transformed train set shape       (48808, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Transformation              True
16        Transformation method       yeo-johnson
17               Fold Generator   StratifiedKFold
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              a3bb
2025-05-15 21:38:50,415:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:38:50,415:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:38:50,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:38:50,446:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:38:50,447:INFO:setup() successfully completed in 0.82s...............
2025-05-15 21:38:50,447:INFO:Initializing create_model()
2025-05-15 21:38:50,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced'})
2025-05-15 21:38:50,447:INFO:Checking exceptions
2025-05-15 21:38:50,453:INFO:Importing libraries
2025-05-15 21:38:50,453:INFO:Copying training dataset
2025-05-15 21:38:50,466:INFO:Defining folds
2025-05-15 21:38:50,466:INFO:Declaring metric variables
2025-05-15 21:38:50,467:INFO:Importing untrained model
2025-05-15 21:38:50,469:INFO:Logistic Regression Imported successfully
2025-05-15 21:38:50,471:INFO:Starting cross validation
2025-05-15 21:38:50,473:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:38:54,468:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:38:54,595:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:38:54,630:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:38:54,635:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:38:54,660:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:38:54,716:INFO:Calculating mean and std
2025-05-15 21:38:54,717:INFO:Creating metrics dataframe
2025-05-15 21:38:54,720:INFO:Finalizing model
2025-05-15 21:38:58,417:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:38:58,425:INFO:Uploading results into container
2025-05-15 21:38:58,425:INFO:Uploading model into container now
2025-05-15 21:38:58,437:INFO:_master_model_container: 1
2025-05-15 21:38:58,437:INFO:_display_container: 2
2025-05-15 21:38:58,437:INFO:LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 21:38:58,437:INFO:create_model() successfully completed......................................
2025-05-15 21:38:58,539:INFO:Initializing create_model()
2025-05-15 21:38:58,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced'})
2025-05-15 21:38:58,540:INFO:Checking exceptions
2025-05-15 21:38:58,553:INFO:Importing libraries
2025-05-15 21:38:58,553:INFO:Copying training dataset
2025-05-15 21:38:58,570:INFO:Defining folds
2025-05-15 21:38:58,570:INFO:Declaring metric variables
2025-05-15 21:38:58,572:INFO:Importing untrained model
2025-05-15 21:38:58,576:INFO:Random Forest Classifier Imported successfully
2025-05-15 21:38:58,581:INFO:Starting cross validation
2025-05-15 21:38:58,583:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:02,466:INFO:Calculating mean and std
2025-05-15 21:39:02,471:INFO:Creating metrics dataframe
2025-05-15 21:39:02,478:INFO:Finalizing model
2025-05-15 21:39:03,668:INFO:Uploading results into container
2025-05-15 21:39:03,669:INFO:Uploading model into container now
2025-05-15 21:39:03,672:INFO:_master_model_container: 2
2025-05-15 21:39:03,672:INFO:_display_container: 3
2025-05-15 21:39:03,673:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 21:39:03,673:INFO:create_model() successfully completed......................................
2025-05-15 21:39:03,768:INFO:Initializing create_model()
2025-05-15 21:39:03,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced'})
2025-05-15 21:39:03,768:INFO:Checking exceptions
2025-05-15 21:39:03,773:INFO:Importing libraries
2025-05-15 21:39:03,774:INFO:Copying training dataset
2025-05-15 21:39:03,784:INFO:Defining folds
2025-05-15 21:39:03,784:INFO:Declaring metric variables
2025-05-15 21:39:03,785:INFO:Importing untrained model
2025-05-15 21:39:03,786:INFO:Extra Trees Classifier Imported successfully
2025-05-15 21:39:03,788:INFO:Starting cross validation
2025-05-15 21:39:03,789:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:06,143:INFO:Calculating mean and std
2025-05-15 21:39:06,144:INFO:Creating metrics dataframe
2025-05-15 21:39:06,146:INFO:Finalizing model
2025-05-15 21:39:07,089:INFO:Uploading results into container
2025-05-15 21:39:07,090:INFO:Uploading model into container now
2025-05-15 21:39:07,093:INFO:_master_model_container: 3
2025-05-15 21:39:07,093:INFO:_display_container: 4
2025-05-15 21:39:07,093:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 21:39:07,093:INFO:create_model() successfully completed......................................
2025-05-15 21:39:07,162:INFO:Initializing create_model()
2025-05-15 21:39:07,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 7.333397074290085})
2025-05-15 21:39:07,162:INFO:Checking exceptions
2025-05-15 21:39:07,162:INFO:Initializing create_model()
2025-05-15 21:39:07,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'is_unbalance': True})
2025-05-15 21:39:07,162:INFO:Checking exceptions
2025-05-15 21:39:07,167:INFO:Importing libraries
2025-05-15 21:39:07,167:INFO:Copying training dataset
2025-05-15 21:39:07,177:INFO:Defining folds
2025-05-15 21:39:07,177:INFO:Declaring metric variables
2025-05-15 21:39:07,179:INFO:Importing untrained model
2025-05-15 21:39:07,180:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 21:39:07,182:INFO:Starting cross validation
2025-05-15 21:39:07,183:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:10,524:INFO:Calculating mean and std
2025-05-15 21:39:10,525:INFO:Creating metrics dataframe
2025-05-15 21:39:10,527:INFO:Finalizing model
2025-05-15 21:39:11,128:INFO:[LightGBM] [Info] Number of positive: 5857, number of negative: 42951
2025-05-15 21:39:11,131:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.
2025-05-15 21:39:11,131:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 21:39:11,131:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 21:39:11,131:INFO:[LightGBM] [Info] Total Bins 1140
2025-05-15 21:39:11,131:INFO:[LightGBM] [Info] Number of data points in the train set: 48808, number of used features: 28
2025-05-15 21:39:11,131:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120001 -> initscore=-1.992422
2025-05-15 21:39:11,131:INFO:[LightGBM] [Info] Start training from score -1.992422
2025-05-15 21:39:11,827:INFO:Uploading results into container
2025-05-15 21:39:11,828:INFO:Uploading model into container now
2025-05-15 21:39:11,831:INFO:_master_model_container: 4
2025-05-15 21:39:11,831:INFO:_display_container: 5
2025-05-15 21:39:11,831:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', is_unbalance=True, learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-05-15 21:39:11,831:INFO:create_model() successfully completed......................................
2025-05-15 21:39:11,897:INFO:Initializing create_model()
2025-05-15 21:39:11,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'auto_class_weights': 'Balanced'})
2025-05-15 21:39:11,897:INFO:Checking exceptions
2025-05-15 21:39:11,902:INFO:Importing libraries
2025-05-15 21:39:11,903:INFO:Copying training dataset
2025-05-15 21:39:11,912:INFO:Defining folds
2025-05-15 21:39:11,912:INFO:Declaring metric variables
2025-05-15 21:39:11,913:INFO:Importing untrained model
2025-05-15 21:39:11,915:INFO:CatBoost Classifier Imported successfully
2025-05-15 21:39:11,917:INFO:Starting cross validation
2025-05-15 21:39:11,918:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:20,412:INFO:Calculating mean and std
2025-05-15 21:39:20,414:INFO:Creating metrics dataframe
2025-05-15 21:39:20,421:INFO:Finalizing model
2025-05-15 21:39:24,986:INFO:Uploading results into container
2025-05-15 21:39:24,986:INFO:Uploading model into container now
2025-05-15 21:39:24,990:INFO:_master_model_container: 5
2025-05-15 21:39:24,990:INFO:_display_container: 6
2025-05-15 21:39:24,990:INFO:<catboost.core.CatBoostClassifier object at 0x332160410>
2025-05-15 21:39:24,991:INFO:create_model() successfully completed......................................
2025-05-15 21:39:25,074:INFO:Initializing create_model()
2025-05-15 21:39:25,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced'})
2025-05-15 21:39:25,074:INFO:Checking exceptions
2025-05-15 21:39:25,079:INFO:Importing libraries
2025-05-15 21:39:25,080:INFO:Copying training dataset
2025-05-15 21:39:25,090:INFO:Defining folds
2025-05-15 21:39:25,090:INFO:Declaring metric variables
2025-05-15 21:39:25,091:INFO:Importing untrained model
2025-05-15 21:39:25,092:INFO:Initializing compare_models()
2025-05-15 21:39:25,092:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-15 21:39:25,092:INFO:Checking exceptions
2025-05-15 21:39:25,099:INFO:Preparing display monitor
2025-05-15 21:39:25,107:INFO:Initializing Logistic Regression
2025-05-15 21:39:25,107:INFO:Total runtime is 1.0649363199869792e-06 minutes
2025-05-15 21:39:25,108:INFO:SubProcess create_model() called ==================================
2025-05-15 21:39:25,108:INFO:Initializing create_model()
2025-05-15 21:39:25,108:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:39:25,108:INFO:Checking exceptions
2025-05-15 21:39:25,108:INFO:Importing libraries
2025-05-15 21:39:25,108:INFO:Copying training dataset
2025-05-15 21:39:25,120:INFO:Defining folds
2025-05-15 21:39:25,120:INFO:Declaring metric variables
2025-05-15 21:39:25,122:INFO:Importing untrained model
2025-05-15 21:39:25,123:INFO:Logistic Regression Imported successfully
2025-05-15 21:39:25,125:INFO:Starting cross validation
2025-05-15 21:39:25,126:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:27,095:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:39:27,105:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:39:27,137:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:39:27,159:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:39:27,218:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:39:27,266:INFO:Calculating mean and std
2025-05-15 21:39:27,267:INFO:Creating metrics dataframe
2025-05-15 21:39:27,267:INFO:Uploading results into container
2025-05-15 21:39:27,268:INFO:Uploading model into container now
2025-05-15 21:39:27,268:INFO:_master_model_container: 6
2025-05-15 21:39:27,268:INFO:_display_container: 7
2025-05-15 21:39:27,268:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 21:39:27,268:INFO:create_model() successfully completed......................................
2025-05-15 21:39:27,332:INFO:SubProcess create_model() end ==================================
2025-05-15 21:39:27,332:INFO:Creating metrics dataframe
2025-05-15 21:39:27,335:INFO:Initializing K Neighbors Classifier
2025-05-15 21:39:27,335:INFO:Total runtime is 0.037133347988128666 minutes
2025-05-15 21:39:27,336:INFO:SubProcess create_model() called ==================================
2025-05-15 21:39:27,336:INFO:Initializing create_model()
2025-05-15 21:39:27,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:39:27,336:INFO:Checking exceptions
2025-05-15 21:39:27,336:INFO:Importing libraries
2025-05-15 21:39:27,336:INFO:Copying training dataset
2025-05-15 21:39:27,345:INFO:Defining folds
2025-05-15 21:39:27,346:INFO:Declaring metric variables
2025-05-15 21:39:27,347:INFO:Importing untrained model
2025-05-15 21:39:27,348:INFO:K Neighbors Classifier Imported successfully
2025-05-15 21:39:27,350:INFO:Starting cross validation
2025-05-15 21:39:27,351:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:30,129:INFO:Calculating mean and std
2025-05-15 21:39:30,129:INFO:Creating metrics dataframe
2025-05-15 21:39:30,130:INFO:Uploading results into container
2025-05-15 21:39:30,130:INFO:Uploading model into container now
2025-05-15 21:39:30,131:INFO:_master_model_container: 7
2025-05-15 21:39:30,131:INFO:_display_container: 7
2025-05-15 21:39:30,131:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-15 21:39:30,131:INFO:create_model() successfully completed......................................
2025-05-15 21:39:30,202:INFO:SubProcess create_model() end ==================================
2025-05-15 21:39:30,202:INFO:Creating metrics dataframe
2025-05-15 21:39:30,205:INFO:Initializing Naive Bayes
2025-05-15 21:39:30,205:INFO:Total runtime is 0.08496351242065431 minutes
2025-05-15 21:39:30,206:INFO:SubProcess create_model() called ==================================
2025-05-15 21:39:30,206:INFO:Initializing create_model()
2025-05-15 21:39:30,206:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:39:30,206:INFO:Checking exceptions
2025-05-15 21:39:30,206:INFO:Importing libraries
2025-05-15 21:39:30,206:INFO:Copying training dataset
2025-05-15 21:39:30,216:INFO:Defining folds
2025-05-15 21:39:30,216:INFO:Declaring metric variables
2025-05-15 21:39:30,217:INFO:Importing untrained model
2025-05-15 21:39:30,218:INFO:Naive Bayes Imported successfully
2025-05-15 21:39:30,220:INFO:Starting cross validation
2025-05-15 21:39:30,221:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:30,866:INFO:Calculating mean and std
2025-05-15 21:39:30,866:INFO:Creating metrics dataframe
2025-05-15 21:39:30,867:INFO:Uploading results into container
2025-05-15 21:39:30,867:INFO:Uploading model into container now
2025-05-15 21:39:30,868:INFO:_master_model_container: 8
2025-05-15 21:39:30,868:INFO:_display_container: 7
2025-05-15 21:39:30,868:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-15 21:39:30,868:INFO:create_model() successfully completed......................................
2025-05-15 21:39:30,929:INFO:SubProcess create_model() end ==================================
2025-05-15 21:39:30,929:INFO:Creating metrics dataframe
2025-05-15 21:39:30,932:INFO:Initializing Decision Tree Classifier
2025-05-15 21:39:30,932:INFO:Total runtime is 0.09709025224049887 minutes
2025-05-15 21:39:30,933:INFO:SubProcess create_model() called ==================================
2025-05-15 21:39:30,934:INFO:Initializing create_model()
2025-05-15 21:39:30,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:39:30,934:INFO:Checking exceptions
2025-05-15 21:39:30,934:INFO:Importing libraries
2025-05-15 21:39:30,934:INFO:Copying training dataset
2025-05-15 21:39:30,943:INFO:Defining folds
2025-05-15 21:39:30,943:INFO:Declaring metric variables
2025-05-15 21:39:30,944:INFO:Importing untrained model
2025-05-15 21:39:30,945:INFO:Decision Tree Classifier Imported successfully
2025-05-15 21:39:30,947:INFO:Starting cross validation
2025-05-15 21:39:30,949:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:33,271:INFO:Calculating mean and std
2025-05-15 21:39:33,272:INFO:Creating metrics dataframe
2025-05-15 21:39:33,273:INFO:Uploading results into container
2025-05-15 21:39:33,273:INFO:Uploading model into container now
2025-05-15 21:39:33,273:INFO:_master_model_container: 9
2025-05-15 21:39:33,273:INFO:_display_container: 7
2025-05-15 21:39:33,273:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-15 21:39:33,273:INFO:create_model() successfully completed......................................
2025-05-15 21:39:33,339:INFO:SubProcess create_model() end ==================================
2025-05-15 21:39:33,339:INFO:Creating metrics dataframe
2025-05-15 21:39:33,342:INFO:Initializing SVM - Linear Kernel
2025-05-15 21:39:33,342:INFO:Total runtime is 0.13725430170694988 minutes
2025-05-15 21:39:33,343:INFO:SubProcess create_model() called ==================================
2025-05-15 21:39:33,343:INFO:Initializing create_model()
2025-05-15 21:39:33,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:39:33,343:INFO:Checking exceptions
2025-05-15 21:39:33,343:INFO:Importing libraries
2025-05-15 21:39:33,344:INFO:Copying training dataset
2025-05-15 21:39:33,353:INFO:Defining folds
2025-05-15 21:39:33,353:INFO:Declaring metric variables
2025-05-15 21:39:33,354:INFO:Importing untrained model
2025-05-15 21:39:33,355:INFO:SVM - Linear Kernel Imported successfully
2025-05-15 21:39:33,357:INFO:Starting cross validation
2025-05-15 21:39:33,358:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:34,838:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:39:34,923:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:39:35,020:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:39:35,032:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:39:35,042:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:39:35,059:INFO:Calculating mean and std
2025-05-15 21:39:35,059:INFO:Creating metrics dataframe
2025-05-15 21:39:35,060:INFO:Uploading results into container
2025-05-15 21:39:35,060:INFO:Uploading model into container now
2025-05-15 21:39:35,060:INFO:_master_model_container: 10
2025-05-15 21:39:35,061:INFO:_display_container: 7
2025-05-15 21:39:35,061:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-15 21:39:35,061:INFO:create_model() successfully completed......................................
2025-05-15 21:39:35,121:INFO:SubProcess create_model() end ==================================
2025-05-15 21:39:35,121:INFO:Creating metrics dataframe
2025-05-15 21:39:35,125:INFO:Initializing Ridge Classifier
2025-05-15 21:39:35,125:INFO:Total runtime is 0.16696755091349286 minutes
2025-05-15 21:39:35,126:INFO:SubProcess create_model() called ==================================
2025-05-15 21:39:35,126:INFO:Initializing create_model()
2025-05-15 21:39:35,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:39:35,126:INFO:Checking exceptions
2025-05-15 21:39:35,126:INFO:Importing libraries
2025-05-15 21:39:35,127:INFO:Copying training dataset
2025-05-15 21:39:35,136:INFO:Defining folds
2025-05-15 21:39:35,136:INFO:Declaring metric variables
2025-05-15 21:39:35,137:INFO:Importing untrained model
2025-05-15 21:39:35,138:INFO:Ridge Classifier Imported successfully
2025-05-15 21:39:35,141:INFO:Starting cross validation
2025-05-15 21:39:35,141:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:35,770:INFO:Calculating mean and std
2025-05-15 21:39:35,771:INFO:Creating metrics dataframe
2025-05-15 21:39:35,772:INFO:Uploading results into container
2025-05-15 21:39:35,772:INFO:Uploading model into container now
2025-05-15 21:39:35,772:INFO:_master_model_container: 11
2025-05-15 21:39:35,772:INFO:_display_container: 7
2025-05-15 21:39:35,772:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-15 21:39:35,773:INFO:create_model() successfully completed......................................
2025-05-15 21:39:35,834:INFO:SubProcess create_model() end ==================================
2025-05-15 21:39:35,834:INFO:Creating metrics dataframe
2025-05-15 21:39:35,837:INFO:Initializing Random Forest Classifier
2025-05-15 21:39:35,837:INFO:Total runtime is 0.17883661588033042 minutes
2025-05-15 21:39:35,838:INFO:SubProcess create_model() called ==================================
2025-05-15 21:39:35,838:INFO:Initializing create_model()
2025-05-15 21:39:35,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:39:35,838:INFO:Checking exceptions
2025-05-15 21:39:35,839:INFO:Importing libraries
2025-05-15 21:39:35,839:INFO:Copying training dataset
2025-05-15 21:39:35,848:INFO:Defining folds
2025-05-15 21:39:35,848:INFO:Declaring metric variables
2025-05-15 21:39:35,849:INFO:Importing untrained model
2025-05-15 21:39:35,850:INFO:Random Forest Classifier Imported successfully
2025-05-15 21:39:35,852:INFO:Starting cross validation
2025-05-15 21:39:35,853:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:38,671:INFO:Calculating mean and std
2025-05-15 21:39:38,671:INFO:Creating metrics dataframe
2025-05-15 21:39:38,673:INFO:Uploading results into container
2025-05-15 21:39:38,673:INFO:Uploading model into container now
2025-05-15 21:39:38,673:INFO:_master_model_container: 12
2025-05-15 21:39:38,673:INFO:_display_container: 7
2025-05-15 21:39:38,674:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 21:39:38,674:INFO:create_model() successfully completed......................................
2025-05-15 21:39:38,735:INFO:SubProcess create_model() end ==================================
2025-05-15 21:39:38,735:INFO:Creating metrics dataframe
2025-05-15 21:39:38,738:INFO:Initializing Quadratic Discriminant Analysis
2025-05-15 21:39:38,738:INFO:Total runtime is 0.22718698183695477 minutes
2025-05-15 21:39:38,739:INFO:SubProcess create_model() called ==================================
2025-05-15 21:39:38,739:INFO:Initializing create_model()
2025-05-15 21:39:38,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:39:38,740:INFO:Checking exceptions
2025-05-15 21:39:38,740:INFO:Importing libraries
2025-05-15 21:39:38,740:INFO:Copying training dataset
2025-05-15 21:39:38,748:INFO:Defining folds
2025-05-15 21:39:38,748:INFO:Declaring metric variables
2025-05-15 21:39:38,749:INFO:Importing untrained model
2025-05-15 21:39:38,750:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 21:39:38,752:INFO:Starting cross validation
2025-05-15 21:39:38,753:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:39,370:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:39:39,370:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:39:39,384:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:39:39,403:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:39:39,404:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:39:39,461:INFO:Calculating mean and std
2025-05-15 21:39:39,462:INFO:Creating metrics dataframe
2025-05-15 21:39:39,463:INFO:Uploading results into container
2025-05-15 21:39:39,463:INFO:Uploading model into container now
2025-05-15 21:39:39,463:INFO:_master_model_container: 13
2025-05-15 21:39:39,463:INFO:_display_container: 7
2025-05-15 21:39:39,463:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 21:39:39,463:INFO:create_model() successfully completed......................................
2025-05-15 21:39:39,524:INFO:SubProcess create_model() end ==================================
2025-05-15 21:39:39,524:INFO:Creating metrics dataframe
2025-05-15 21:39:39,528:INFO:Initializing Ada Boost Classifier
2025-05-15 21:39:39,528:INFO:Total runtime is 0.2403489629427592 minutes
2025-05-15 21:39:39,529:INFO:SubProcess create_model() called ==================================
2025-05-15 21:39:39,529:INFO:Initializing create_model()
2025-05-15 21:39:39,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:39:39,529:INFO:Checking exceptions
2025-05-15 21:39:39,529:INFO:Importing libraries
2025-05-15 21:39:39,529:INFO:Copying training dataset
2025-05-15 21:39:39,538:INFO:Defining folds
2025-05-15 21:39:39,538:INFO:Declaring metric variables
2025-05-15 21:39:39,539:INFO:Importing untrained model
2025-05-15 21:39:39,540:INFO:Ada Boost Classifier Imported successfully
2025-05-15 21:39:39,542:INFO:Starting cross validation
2025-05-15 21:39:39,543:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:40,101:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:39:40,116:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:39:40,132:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:39:40,135:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:39:40,139:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:39:41,385:INFO:Calculating mean and std
2025-05-15 21:39:41,386:INFO:Creating metrics dataframe
2025-05-15 21:39:41,387:INFO:Uploading results into container
2025-05-15 21:39:41,387:INFO:Uploading model into container now
2025-05-15 21:39:41,387:INFO:_master_model_container: 14
2025-05-15 21:39:41,387:INFO:_display_container: 7
2025-05-15 21:39:41,388:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-15 21:39:41,388:INFO:create_model() successfully completed......................................
2025-05-15 21:39:41,453:INFO:SubProcess create_model() end ==================================
2025-05-15 21:39:41,453:INFO:Creating metrics dataframe
2025-05-15 21:39:41,456:INFO:Initializing Gradient Boosting Classifier
2025-05-15 21:39:41,457:INFO:Total runtime is 0.27249481678009035 minutes
2025-05-15 21:39:41,458:INFO:SubProcess create_model() called ==================================
2025-05-15 21:39:41,458:INFO:Initializing create_model()
2025-05-15 21:39:41,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:39:41,458:INFO:Checking exceptions
2025-05-15 21:39:41,458:INFO:Importing libraries
2025-05-15 21:39:41,458:INFO:Copying training dataset
2025-05-15 21:39:41,468:INFO:Defining folds
2025-05-15 21:39:41,468:INFO:Declaring metric variables
2025-05-15 21:39:41,469:INFO:Importing untrained model
2025-05-15 21:39:41,470:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 21:39:41,472:INFO:Starting cross validation
2025-05-15 21:39:41,473:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:47,481:INFO:Calculating mean and std
2025-05-15 21:39:47,482:INFO:Creating metrics dataframe
2025-05-15 21:39:47,483:INFO:Uploading results into container
2025-05-15 21:39:47,483:INFO:Uploading model into container now
2025-05-15 21:39:47,483:INFO:_master_model_container: 15
2025-05-15 21:39:47,483:INFO:_display_container: 7
2025-05-15 21:39:47,483:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 21:39:47,483:INFO:create_model() successfully completed......................................
2025-05-15 21:39:47,549:INFO:SubProcess create_model() end ==================================
2025-05-15 21:39:47,549:INFO:Creating metrics dataframe
2025-05-15 21:39:47,553:INFO:Initializing Linear Discriminant Analysis
2025-05-15 21:39:47,553:INFO:Total runtime is 0.37409991423288985 minutes
2025-05-15 21:39:47,554:INFO:SubProcess create_model() called ==================================
2025-05-15 21:39:47,554:INFO:Initializing create_model()
2025-05-15 21:39:47,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:39:47,554:INFO:Checking exceptions
2025-05-15 21:39:47,554:INFO:Importing libraries
2025-05-15 21:39:47,554:INFO:Copying training dataset
2025-05-15 21:39:47,564:INFO:Defining folds
2025-05-15 21:39:47,564:INFO:Declaring metric variables
2025-05-15 21:39:47,565:INFO:Importing untrained model
2025-05-15 21:39:47,566:INFO:Linear Discriminant Analysis Imported successfully
2025-05-15 21:39:47,568:INFO:Starting cross validation
2025-05-15 21:39:47,569:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:48,292:INFO:Calculating mean and std
2025-05-15 21:39:48,292:INFO:Creating metrics dataframe
2025-05-15 21:39:48,293:INFO:Uploading results into container
2025-05-15 21:39:48,293:INFO:Uploading model into container now
2025-05-15 21:39:48,293:INFO:_master_model_container: 16
2025-05-15 21:39:48,293:INFO:_display_container: 7
2025-05-15 21:39:48,294:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-15 21:39:48,294:INFO:create_model() successfully completed......................................
2025-05-15 21:39:48,373:INFO:SubProcess create_model() end ==================================
2025-05-15 21:39:48,373:INFO:Creating metrics dataframe
2025-05-15 21:39:48,377:INFO:Initializing Extra Trees Classifier
2025-05-15 21:39:48,377:INFO:Total runtime is 0.38783866564432784 minutes
2025-05-15 21:39:48,378:INFO:SubProcess create_model() called ==================================
2025-05-15 21:39:48,378:INFO:Initializing create_model()
2025-05-15 21:39:48,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:39:48,379:INFO:Checking exceptions
2025-05-15 21:39:48,379:INFO:Importing libraries
2025-05-15 21:39:48,379:INFO:Copying training dataset
2025-05-15 21:39:48,389:INFO:Defining folds
2025-05-15 21:39:48,389:INFO:Declaring metric variables
2025-05-15 21:39:48,390:INFO:Importing untrained model
2025-05-15 21:39:48,391:INFO:Extra Trees Classifier Imported successfully
2025-05-15 21:39:48,393:INFO:Starting cross validation
2025-05-15 21:39:48,394:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:50,629:INFO:Calculating mean and std
2025-05-15 21:39:50,634:INFO:Creating metrics dataframe
2025-05-15 21:39:50,640:INFO:Uploading results into container
2025-05-15 21:39:50,640:INFO:Uploading model into container now
2025-05-15 21:39:50,641:INFO:_master_model_container: 17
2025-05-15 21:39:50,641:INFO:_display_container: 7
2025-05-15 21:39:50,641:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 21:39:50,641:INFO:create_model() successfully completed......................................
2025-05-15 21:39:50,731:INFO:SubProcess create_model() end ==================================
2025-05-15 21:39:50,731:INFO:Creating metrics dataframe
2025-05-15 21:39:50,735:INFO:Initializing Light Gradient Boosting Machine
2025-05-15 21:39:50,735:INFO:Total runtime is 0.42714288234710696 minutes
2025-05-15 21:39:50,737:INFO:SubProcess create_model() called ==================================
2025-05-15 21:39:50,737:INFO:Initializing create_model()
2025-05-15 21:39:50,737:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:39:50,737:INFO:Checking exceptions
2025-05-15 21:39:50,737:INFO:Importing libraries
2025-05-15 21:39:50,737:INFO:Copying training dataset
2025-05-15 21:39:50,747:INFO:Defining folds
2025-05-15 21:39:50,747:INFO:Declaring metric variables
2025-05-15 21:39:50,748:INFO:Importing untrained model
2025-05-15 21:39:50,749:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 21:39:50,751:INFO:Starting cross validation
2025-05-15 21:39:50,752:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:39:54,085:INFO:Calculating mean and std
2025-05-15 21:39:54,086:INFO:Creating metrics dataframe
2025-05-15 21:39:54,087:INFO:Uploading results into container
2025-05-15 21:39:54,087:INFO:Uploading model into container now
2025-05-15 21:39:54,087:INFO:_master_model_container: 18
2025-05-15 21:39:54,088:INFO:_display_container: 7
2025-05-15 21:39:54,088:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 21:39:54,088:INFO:create_model() successfully completed......................................
2025-05-15 21:39:54,189:INFO:SubProcess create_model() end ==================================
2025-05-15 21:39:54,189:INFO:Creating metrics dataframe
2025-05-15 21:39:54,193:INFO:Initializing CatBoost Classifier
2025-05-15 21:39:54,193:INFO:Total runtime is 0.48477336565653484 minutes
2025-05-15 21:39:54,194:INFO:SubProcess create_model() called ==================================
2025-05-15 21:39:54,194:INFO:Initializing create_model()
2025-05-15 21:39:54,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:39:54,195:INFO:Checking exceptions
2025-05-15 21:39:54,195:INFO:Importing libraries
2025-05-15 21:39:54,195:INFO:Copying training dataset
2025-05-15 21:39:54,211:INFO:Defining folds
2025-05-15 21:39:54,211:INFO:Declaring metric variables
2025-05-15 21:39:54,212:INFO:Importing untrained model
2025-05-15 21:39:54,213:INFO:CatBoost Classifier Imported successfully
2025-05-15 21:39:54,215:INFO:Starting cross validation
2025-05-15 21:39:54,216:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:40:01,764:INFO:Calculating mean and std
2025-05-15 21:40:01,765:INFO:Creating metrics dataframe
2025-05-15 21:40:01,767:INFO:Uploading results into container
2025-05-15 21:40:01,767:INFO:Uploading model into container now
2025-05-15 21:40:01,767:INFO:_master_model_container: 19
2025-05-15 21:40:01,767:INFO:_display_container: 7
2025-05-15 21:40:01,767:INFO:<catboost.core.CatBoostClassifier object at 0x331fed3d0>
2025-05-15 21:40:01,767:INFO:create_model() successfully completed......................................
2025-05-15 21:40:01,834:INFO:SubProcess create_model() end ==================================
2025-05-15 21:40:01,834:INFO:Creating metrics dataframe
2025-05-15 21:40:01,838:INFO:Initializing Dummy Classifier
2025-05-15 21:40:01,839:INFO:Total runtime is 0.612195098400116 minutes
2025-05-15 21:40:01,840:INFO:SubProcess create_model() called ==================================
2025-05-15 21:40:01,840:INFO:Initializing create_model()
2025-05-15 21:40:01,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332056810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:40:01,840:INFO:Checking exceptions
2025-05-15 21:40:01,840:INFO:Importing libraries
2025-05-15 21:40:01,840:INFO:Copying training dataset
2025-05-15 21:40:01,849:INFO:Defining folds
2025-05-15 21:40:01,849:INFO:Declaring metric variables
2025-05-15 21:40:01,850:INFO:Importing untrained model
2025-05-15 21:40:01,851:INFO:Dummy Classifier Imported successfully
2025-05-15 21:40:01,854:INFO:Starting cross validation
2025-05-15 21:40:01,855:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:40:02,440:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:40:02,471:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:40:02,473:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:40:02,485:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:40:02,497:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:40:02,512:INFO:Calculating mean and std
2025-05-15 21:40:02,513:INFO:Creating metrics dataframe
2025-05-15 21:40:02,514:INFO:Uploading results into container
2025-05-15 21:40:02,514:INFO:Uploading model into container now
2025-05-15 21:40:02,514:INFO:_master_model_container: 20
2025-05-15 21:40:02,514:INFO:_display_container: 7
2025-05-15 21:40:02,515:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-15 21:40:02,515:INFO:create_model() successfully completed......................................
2025-05-15 21:40:02,582:INFO:SubProcess create_model() end ==================================
2025-05-15 21:40:02,582:INFO:Creating metrics dataframe
2025-05-15 21:40:02,586:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-15 21:40:02,589:INFO:Initializing create_model()
2025-05-15 21:40:02,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:40:02,589:INFO:Checking exceptions
2025-05-15 21:40:02,590:INFO:Importing libraries
2025-05-15 21:40:02,590:INFO:Copying training dataset
2025-05-15 21:40:02,598:INFO:Defining folds
2025-05-15 21:40:02,598:INFO:Declaring metric variables
2025-05-15 21:40:02,598:INFO:Importing untrained model
2025-05-15 21:40:02,598:INFO:Declaring custom model
2025-05-15 21:40:02,599:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 21:40:02,599:INFO:Cross validation set to False
2025-05-15 21:40:02,599:INFO:Fitting Model
2025-05-15 21:40:03,248:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:40:03,256:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 21:40:03,256:INFO:create_model() successfully completed......................................
2025-05-15 21:40:03,401:INFO:_master_model_container: 20
2025-05-15 21:40:03,402:INFO:_display_container: 7
2025-05-15 21:40:03,402:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 21:40:03,402:INFO:compare_models() successfully completed......................................
2025-05-15 21:40:03,403:INFO:Initializing evaluate_model()
2025-05-15 21:40:03,403:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 21:40:03,421:INFO:Initializing plot_model()
2025-05-15 21:40:03,421:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 21:40:03,421:INFO:Checking exceptions
2025-05-15 21:40:03,431:INFO:Preloading libraries
2025-05-15 21:40:03,431:INFO:Copying training dataset
2025-05-15 21:40:03,431:INFO:Plot type: pipeline
2025-05-15 21:40:03,493:INFO:Visual Rendered Successfully
2025-05-15 21:40:03,567:INFO:plot_model() successfully completed......................................
2025-05-15 21:40:03,569:INFO:Initializing get_config()
2025-05-15 21:40:03,569:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36441a410>, variable=prep_pipe)
2025-05-15 21:51:11,890:INFO:PyCaret ClassificationExperiment
2025-05-15 21:51:11,890:INFO:Logging name: clf-default-name
2025-05-15 21:51:11,890:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 21:51:11,890:INFO:version 3.3.2
2025-05-15 21:51:11,890:INFO:Initializing setup()
2025-05-15 21:51:11,890:INFO:self.USI: 234a
2025-05-15 21:51:11,890:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-15 21:51:11,890:INFO:Checking environment
2025-05-15 21:51:11,890:INFO:python_version: 3.11.0
2025-05-15 21:51:11,890:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 21:51:11,891:INFO:machine: arm64
2025-05-15 21:51:11,891:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 21:51:11,891:INFO:Memory: svmem(total=17179869184, available=3680534528, percent=78.6, used=6523158528, free=65552384, active=3634135040, inactive=3608969216, wired=2889023488)
2025-05-15 21:51:11,891:INFO:Physical Core: 12
2025-05-15 21:51:11,891:INFO:Logical Core: 12
2025-05-15 21:51:11,891:INFO:Checking libraries
2025-05-15 21:51:11,891:INFO:System:
2025-05-15 21:51:11,891:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 21:51:11,891:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 21:51:11,891:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 21:51:11,891:INFO:PyCaret required dependencies:
2025-05-15 21:51:11,891:INFO:                 pip: 22.3
2025-05-15 21:51:11,891:INFO:          setuptools: 65.5.0
2025-05-15 21:51:11,891:INFO:             pycaret: 3.3.2
2025-05-15 21:51:11,891:INFO:             IPython: 9.2.0
2025-05-15 21:51:11,891:INFO:          ipywidgets: 8.1.7
2025-05-15 21:51:11,891:INFO:                tqdm: 4.67.1
2025-05-15 21:51:11,891:INFO:               numpy: 1.26.4
2025-05-15 21:51:11,891:INFO:              pandas: 2.1.4
2025-05-15 21:51:11,891:INFO:              jinja2: 3.1.6
2025-05-15 21:51:11,891:INFO:               scipy: 1.11.4
2025-05-15 21:51:11,891:INFO:              joblib: 1.3.2
2025-05-15 21:51:11,891:INFO:             sklearn: 1.4.2
2025-05-15 21:51:11,891:INFO:                pyod: 2.0.5
2025-05-15 21:51:11,891:INFO:            imblearn: 0.13.0
2025-05-15 21:51:11,891:INFO:   category_encoders: 2.7.0
2025-05-15 21:51:11,891:INFO:            lightgbm: 4.6.0
2025-05-15 21:51:11,891:INFO:               numba: 0.61.2
2025-05-15 21:51:11,891:INFO:            requests: 2.32.3
2025-05-15 21:51:11,891:INFO:          matplotlib: 3.7.5
2025-05-15 21:51:11,891:INFO:          scikitplot: 0.3.7
2025-05-15 21:51:11,891:INFO:         yellowbrick: 1.5
2025-05-15 21:51:11,891:INFO:              plotly: 5.24.1
2025-05-15 21:51:11,891:INFO:    plotly-resampler: Not installed
2025-05-15 21:51:11,891:INFO:             kaleido: 0.2.1
2025-05-15 21:51:11,891:INFO:           schemdraw: 0.15
2025-05-15 21:51:11,891:INFO:         statsmodels: 0.14.4
2025-05-15 21:51:11,891:INFO:              sktime: 0.26.0
2025-05-15 21:51:11,891:INFO:               tbats: 1.1.3
2025-05-15 21:51:11,891:INFO:            pmdarima: 2.0.4
2025-05-15 21:51:11,891:INFO:              psutil: 7.0.0
2025-05-15 21:51:11,891:INFO:          markupsafe: 3.0.2
2025-05-15 21:51:11,891:INFO:             pickle5: Not installed
2025-05-15 21:51:11,891:INFO:         cloudpickle: 3.1.1
2025-05-15 21:51:11,891:INFO:         deprecation: 2.1.0
2025-05-15 21:51:11,891:INFO:              xxhash: 3.5.0
2025-05-15 21:51:11,891:INFO:           wurlitzer: 3.1.1
2025-05-15 21:51:11,891:INFO:PyCaret optional dependencies:
2025-05-15 21:51:11,891:INFO:                shap: 0.47.2
2025-05-15 21:51:11,891:INFO:           interpret: Not installed
2025-05-15 21:51:11,891:INFO:                umap: Not installed
2025-05-15 21:51:11,891:INFO:     ydata_profiling: Not installed
2025-05-15 21:51:11,891:INFO:  explainerdashboard: Not installed
2025-05-15 21:51:11,891:INFO:             autoviz: Not installed
2025-05-15 21:51:11,891:INFO:           fairlearn: Not installed
2025-05-15 21:51:11,891:INFO:          deepchecks: Not installed
2025-05-15 21:51:11,891:INFO:             xgboost: Not installed
2025-05-15 21:51:11,891:INFO:            catboost: 1.2.8
2025-05-15 21:51:11,891:INFO:              kmodes: Not installed
2025-05-15 21:51:11,892:INFO:             mlxtend: Not installed
2025-05-15 21:51:11,892:INFO:       statsforecast: Not installed
2025-05-15 21:51:11,892:INFO:        tune_sklearn: Not installed
2025-05-15 21:51:11,892:INFO:                 ray: Not installed
2025-05-15 21:51:11,892:INFO:            hyperopt: Not installed
2025-05-15 21:51:11,892:INFO:              optuna: 4.3.0
2025-05-15 21:51:11,892:INFO:               skopt: Not installed
2025-05-15 21:51:11,892:INFO:              mlflow: Not installed
2025-05-15 21:51:11,892:INFO:              gradio: Not installed
2025-05-15 21:51:11,892:INFO:             fastapi: Not installed
2025-05-15 21:51:11,892:INFO:             uvicorn: Not installed
2025-05-15 21:51:11,892:INFO:              m2cgen: Not installed
2025-05-15 21:51:11,892:INFO:           evidently: Not installed
2025-05-15 21:51:11,892:INFO:               fugue: Not installed
2025-05-15 21:51:11,892:INFO:           streamlit: Not installed
2025-05-15 21:51:11,892:INFO:             prophet: Not installed
2025-05-15 21:51:11,892:INFO:None
2025-05-15 21:51:11,892:INFO:Set up data.
2025-05-15 21:51:11,937:INFO:Set up folding strategy.
2025-05-15 21:51:11,937:INFO:Set up train/test split.
2025-05-15 21:51:11,956:INFO:Set up index.
2025-05-15 21:51:11,957:INFO:Assigning column types.
2025-05-15 21:51:11,962:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 21:51:11,981:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 21:51:11,982:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:51:11,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:51:11,994:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:51:12,013:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 21:51:12,013:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:51:12,025:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:51:12,025:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:51:12,026:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 21:51:12,044:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:51:12,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:51:12,056:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:51:12,075:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:51:12,086:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:51:12,086:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:51:12,087:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 21:51:12,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:51:12,116:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:51:12,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:51:12,146:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:51:12,147:INFO:Preparing preprocessing pipeline...
2025-05-15 21:51:12,148:INFO:Set up simple imputation.
2025-05-15 21:51:12,156:INFO:Set up encoding of ordinal features.
2025-05-15 21:51:12,167:INFO:Set up encoding of categorical features.
2025-05-15 21:51:12,168:INFO:Set up column transformation.
2025-05-15 21:51:12,441:INFO:Finished creating preprocessing pipeline.
2025-05-15 21:51:12,461:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                 TransformerWrapper(exclude=None, include=['Country', 'Race'],
                                    transformer=OneHotEncoder(cols=['Country',
                                                                    'Race'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 21:51:12,461:INFO:Creating final display dataframe.
2025-05-15 21:51:12,666:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape       (69727, 29)
5   Transformed train set shape       (48808, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Transformation              True
16        Transformation method       yeo-johnson
17               Fold Generator   StratifiedKFold
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              234a
2025-05-15 21:51:12,698:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:51:12,698:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:51:12,728:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:51:12,729:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:51:12,730:INFO:setup() successfully completed in 0.85s...............
2025-05-15 21:53:12,008:INFO:PyCaret ClassificationExperiment
2025-05-15 21:53:12,008:INFO:Logging name: clf-default-name
2025-05-15 21:53:12,008:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 21:53:12,008:INFO:version 3.3.2
2025-05-15 21:53:12,008:INFO:Initializing setup()
2025-05-15 21:53:12,008:INFO:self.USI: fbd3
2025-05-15 21:53:12,008:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-15 21:53:12,008:INFO:Checking environment
2025-05-15 21:53:12,008:INFO:python_version: 3.11.0
2025-05-15 21:53:12,008:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 21:53:12,008:INFO:machine: arm64
2025-05-15 21:53:12,008:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 21:53:12,008:INFO:Memory: svmem(total=17179869184, available=3483942912, percent=79.7, used=6299025408, free=69173248, active=3439214592, inactive=3410231296, wired=2859810816)
2025-05-15 21:53:12,008:INFO:Physical Core: 12
2025-05-15 21:53:12,008:INFO:Logical Core: 12
2025-05-15 21:53:12,008:INFO:Checking libraries
2025-05-15 21:53:12,008:INFO:System:
2025-05-15 21:53:12,008:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 21:53:12,008:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 21:53:12,008:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 21:53:12,008:INFO:PyCaret required dependencies:
2025-05-15 21:53:12,009:INFO:                 pip: 22.3
2025-05-15 21:53:12,009:INFO:          setuptools: 65.5.0
2025-05-15 21:53:12,009:INFO:             pycaret: 3.3.2
2025-05-15 21:53:12,009:INFO:             IPython: 9.2.0
2025-05-15 21:53:12,009:INFO:          ipywidgets: 8.1.7
2025-05-15 21:53:12,009:INFO:                tqdm: 4.67.1
2025-05-15 21:53:12,009:INFO:               numpy: 1.26.4
2025-05-15 21:53:12,009:INFO:              pandas: 2.1.4
2025-05-15 21:53:12,009:INFO:              jinja2: 3.1.6
2025-05-15 21:53:12,009:INFO:               scipy: 1.11.4
2025-05-15 21:53:12,009:INFO:              joblib: 1.3.2
2025-05-15 21:53:12,009:INFO:             sklearn: 1.4.2
2025-05-15 21:53:12,009:INFO:                pyod: 2.0.5
2025-05-15 21:53:12,009:INFO:            imblearn: 0.13.0
2025-05-15 21:53:12,009:INFO:   category_encoders: 2.7.0
2025-05-15 21:53:12,009:INFO:            lightgbm: 4.6.0
2025-05-15 21:53:12,009:INFO:               numba: 0.61.2
2025-05-15 21:53:12,009:INFO:            requests: 2.32.3
2025-05-15 21:53:12,009:INFO:          matplotlib: 3.7.5
2025-05-15 21:53:12,009:INFO:          scikitplot: 0.3.7
2025-05-15 21:53:12,009:INFO:         yellowbrick: 1.5
2025-05-15 21:53:12,009:INFO:              plotly: 5.24.1
2025-05-15 21:53:12,009:INFO:    plotly-resampler: Not installed
2025-05-15 21:53:12,009:INFO:             kaleido: 0.2.1
2025-05-15 21:53:12,009:INFO:           schemdraw: 0.15
2025-05-15 21:53:12,009:INFO:         statsmodels: 0.14.4
2025-05-15 21:53:12,009:INFO:              sktime: 0.26.0
2025-05-15 21:53:12,009:INFO:               tbats: 1.1.3
2025-05-15 21:53:12,009:INFO:            pmdarima: 2.0.4
2025-05-15 21:53:12,009:INFO:              psutil: 7.0.0
2025-05-15 21:53:12,009:INFO:          markupsafe: 3.0.2
2025-05-15 21:53:12,009:INFO:             pickle5: Not installed
2025-05-15 21:53:12,009:INFO:         cloudpickle: 3.1.1
2025-05-15 21:53:12,009:INFO:         deprecation: 2.1.0
2025-05-15 21:53:12,009:INFO:              xxhash: 3.5.0
2025-05-15 21:53:12,009:INFO:           wurlitzer: 3.1.1
2025-05-15 21:53:12,009:INFO:PyCaret optional dependencies:
2025-05-15 21:53:12,009:INFO:                shap: 0.47.2
2025-05-15 21:53:12,009:INFO:           interpret: Not installed
2025-05-15 21:53:12,009:INFO:                umap: Not installed
2025-05-15 21:53:12,009:INFO:     ydata_profiling: Not installed
2025-05-15 21:53:12,009:INFO:  explainerdashboard: Not installed
2025-05-15 21:53:12,009:INFO:             autoviz: Not installed
2025-05-15 21:53:12,009:INFO:           fairlearn: Not installed
2025-05-15 21:53:12,009:INFO:          deepchecks: Not installed
2025-05-15 21:53:12,009:INFO:             xgboost: Not installed
2025-05-15 21:53:12,009:INFO:            catboost: 1.2.8
2025-05-15 21:53:12,009:INFO:              kmodes: Not installed
2025-05-15 21:53:12,009:INFO:             mlxtend: Not installed
2025-05-15 21:53:12,009:INFO:       statsforecast: Not installed
2025-05-15 21:53:12,009:INFO:        tune_sklearn: Not installed
2025-05-15 21:53:12,009:INFO:                 ray: Not installed
2025-05-15 21:53:12,009:INFO:            hyperopt: Not installed
2025-05-15 21:53:12,009:INFO:              optuna: 4.3.0
2025-05-15 21:53:12,009:INFO:               skopt: Not installed
2025-05-15 21:53:12,009:INFO:              mlflow: Not installed
2025-05-15 21:53:12,009:INFO:              gradio: Not installed
2025-05-15 21:53:12,009:INFO:             fastapi: Not installed
2025-05-15 21:53:12,009:INFO:             uvicorn: Not installed
2025-05-15 21:53:12,009:INFO:              m2cgen: Not installed
2025-05-15 21:53:12,009:INFO:           evidently: Not installed
2025-05-15 21:53:12,009:INFO:               fugue: Not installed
2025-05-15 21:53:12,009:INFO:           streamlit: Not installed
2025-05-15 21:53:12,009:INFO:             prophet: Not installed
2025-05-15 21:53:12,009:INFO:None
2025-05-15 21:53:12,010:INFO:Set up data.
2025-05-15 21:53:12,047:INFO:Set up folding strategy.
2025-05-15 21:53:12,047:INFO:Set up train/test split.
2025-05-15 21:53:12,061:INFO:Set up index.
2025-05-15 21:53:12,062:INFO:Assigning column types.
2025-05-15 21:53:12,067:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 21:53:12,085:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 21:53:12,085:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:53:12,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:53:12,097:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:53:12,116:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 21:53:12,117:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:53:12,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:53:12,128:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:53:12,128:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 21:53:12,147:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:53:12,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:53:12,158:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:53:12,176:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 21:53:12,188:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:53:12,188:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:53:12,188:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 21:53:12,218:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:53:12,218:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:53:12,247:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:53:12,247:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:53:12,248:INFO:Preparing preprocessing pipeline...
2025-05-15 21:53:12,249:INFO:Set up simple imputation.
2025-05-15 21:53:12,256:INFO:Set up encoding of ordinal features.
2025-05-15 21:53:12,266:INFO:Set up encoding of categorical features.
2025-05-15 21:53:12,266:INFO:Set up column transformation.
2025-05-15 21:53:12,536:INFO:Finished creating preprocessing pipeline.
2025-05-15 21:53:12,555:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                 TransformerWrapper(exclude=None, include=['Country', 'Race'],
                                    transformer=OneHotEncoder(cols=['Country',
                                                                    'Race'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 21:53:12,556:INFO:Creating final display dataframe.
2025-05-15 21:53:12,763:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape       (69727, 29)
5   Transformed train set shape       (48808, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Transformation              True
16        Transformation method       yeo-johnson
17               Fold Generator   StratifiedKFold
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              fbd3
2025-05-15 21:53:12,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:53:12,795:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:53:12,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 21:53:12,825:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 21:53:12,826:INFO:setup() successfully completed in 0.83s...............
2025-05-15 21:53:12,830:INFO:Initializing compare_models()
2025-05-15 21:53:12,830:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-15 21:53:12,830:INFO:Checking exceptions
2025-05-15 21:53:12,835:INFO:Preparing display monitor
2025-05-15 21:53:12,844:INFO:Initializing Logistic Regression
2025-05-15 21:53:12,844:INFO:Total runtime is 1.617272694905599e-06 minutes
2025-05-15 21:53:12,845:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:12,845:INFO:Initializing create_model()
2025-05-15 21:53:12,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:12,845:INFO:Checking exceptions
2025-05-15 21:53:12,845:INFO:Importing libraries
2025-05-15 21:53:12,845:INFO:Copying training dataset
2025-05-15 21:53:12,855:INFO:Defining folds
2025-05-15 21:53:12,856:INFO:Declaring metric variables
2025-05-15 21:53:12,857:INFO:Importing untrained model
2025-05-15 21:53:12,858:INFO:Logistic Regression Imported successfully
2025-05-15 21:53:12,861:INFO:Starting cross validation
2025-05-15 21:53:12,862:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:16,918:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:53:16,953:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:53:17,046:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:53:17,091:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:53:17,217:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 21:53:17,289:INFO:Calculating mean and std
2025-05-15 21:53:17,295:INFO:Creating metrics dataframe
2025-05-15 21:53:17,300:INFO:Uploading results into container
2025-05-15 21:53:17,301:INFO:Uploading model into container now
2025-05-15 21:53:17,302:INFO:_master_model_container: 1
2025-05-15 21:53:17,303:INFO:_display_container: 2
2025-05-15 21:53:17,304:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 21:53:17,304:INFO:create_model() successfully completed......................................
2025-05-15 21:53:17,472:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:17,473:INFO:Creating metrics dataframe
2025-05-15 21:53:17,476:INFO:Initializing K Neighbors Classifier
2025-05-15 21:53:17,476:INFO:Total runtime is 0.07719861666361491 minutes
2025-05-15 21:53:17,477:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:17,477:INFO:Initializing create_model()
2025-05-15 21:53:17,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:17,477:INFO:Checking exceptions
2025-05-15 21:53:17,477:INFO:Importing libraries
2025-05-15 21:53:17,478:INFO:Copying training dataset
2025-05-15 21:53:17,497:INFO:Defining folds
2025-05-15 21:53:17,498:INFO:Declaring metric variables
2025-05-15 21:53:17,499:INFO:Importing untrained model
2025-05-15 21:53:17,501:INFO:K Neighbors Classifier Imported successfully
2025-05-15 21:53:17,505:INFO:Starting cross validation
2025-05-15 21:53:17,507:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:21,737:INFO:Calculating mean and std
2025-05-15 21:53:21,739:INFO:Creating metrics dataframe
2025-05-15 21:53:21,741:INFO:Uploading results into container
2025-05-15 21:53:21,741:INFO:Uploading model into container now
2025-05-15 21:53:21,741:INFO:_master_model_container: 2
2025-05-15 21:53:21,741:INFO:_display_container: 2
2025-05-15 21:53:21,742:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-15 21:53:21,742:INFO:create_model() successfully completed......................................
2025-05-15 21:53:21,840:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:21,840:INFO:Creating metrics dataframe
2025-05-15 21:53:21,843:INFO:Initializing Naive Bayes
2025-05-15 21:53:21,843:INFO:Total runtime is 0.14999200503031412 minutes
2025-05-15 21:53:21,844:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:21,845:INFO:Initializing create_model()
2025-05-15 21:53:21,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:21,845:INFO:Checking exceptions
2025-05-15 21:53:21,845:INFO:Importing libraries
2025-05-15 21:53:21,845:INFO:Copying training dataset
2025-05-15 21:53:21,855:INFO:Defining folds
2025-05-15 21:53:21,855:INFO:Declaring metric variables
2025-05-15 21:53:21,857:INFO:Importing untrained model
2025-05-15 21:53:21,858:INFO:Naive Bayes Imported successfully
2025-05-15 21:53:21,861:INFO:Starting cross validation
2025-05-15 21:53:21,862:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:22,651:INFO:Calculating mean and std
2025-05-15 21:53:22,652:INFO:Creating metrics dataframe
2025-05-15 21:53:22,653:INFO:Uploading results into container
2025-05-15 21:53:22,653:INFO:Uploading model into container now
2025-05-15 21:53:22,654:INFO:_master_model_container: 3
2025-05-15 21:53:22,654:INFO:_display_container: 2
2025-05-15 21:53:22,654:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-15 21:53:22,654:INFO:create_model() successfully completed......................................
2025-05-15 21:53:22,748:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:22,748:INFO:Creating metrics dataframe
2025-05-15 21:53:22,751:INFO:Initializing Decision Tree Classifier
2025-05-15 21:53:22,751:INFO:Total runtime is 0.16511923869450887 minutes
2025-05-15 21:53:22,752:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:22,753:INFO:Initializing create_model()
2025-05-15 21:53:22,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:22,753:INFO:Checking exceptions
2025-05-15 21:53:22,753:INFO:Importing libraries
2025-05-15 21:53:22,753:INFO:Copying training dataset
2025-05-15 21:53:22,763:INFO:Defining folds
2025-05-15 21:53:22,763:INFO:Declaring metric variables
2025-05-15 21:53:22,764:INFO:Importing untrained model
2025-05-15 21:53:22,765:INFO:Decision Tree Classifier Imported successfully
2025-05-15 21:53:22,768:INFO:Starting cross validation
2025-05-15 21:53:22,769:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:25,241:INFO:Calculating mean and std
2025-05-15 21:53:25,244:INFO:Creating metrics dataframe
2025-05-15 21:53:25,250:INFO:Uploading results into container
2025-05-15 21:53:25,250:INFO:Uploading model into container now
2025-05-15 21:53:25,251:INFO:_master_model_container: 4
2025-05-15 21:53:25,251:INFO:_display_container: 2
2025-05-15 21:53:25,252:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-15 21:53:25,252:INFO:create_model() successfully completed......................................
2025-05-15 21:53:25,387:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:25,387:INFO:Creating metrics dataframe
2025-05-15 21:53:25,391:INFO:Initializing SVM - Linear Kernel
2025-05-15 21:53:25,391:INFO:Total runtime is 0.2091246525446574 minutes
2025-05-15 21:53:25,392:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:25,393:INFO:Initializing create_model()
2025-05-15 21:53:25,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:25,393:INFO:Checking exceptions
2025-05-15 21:53:25,393:INFO:Importing libraries
2025-05-15 21:53:25,393:INFO:Copying training dataset
2025-05-15 21:53:25,410:INFO:Defining folds
2025-05-15 21:53:25,411:INFO:Declaring metric variables
2025-05-15 21:53:25,412:INFO:Importing untrained model
2025-05-15 21:53:25,414:INFO:SVM - Linear Kernel Imported successfully
2025-05-15 21:53:25,416:INFO:Starting cross validation
2025-05-15 21:53:25,417:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:27,271:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:53:27,330:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:53:27,393:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:53:27,402:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:53:27,429:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:53:27,434:INFO:Calculating mean and std
2025-05-15 21:53:27,434:INFO:Creating metrics dataframe
2025-05-15 21:53:27,435:INFO:Uploading results into container
2025-05-15 21:53:27,436:INFO:Uploading model into container now
2025-05-15 21:53:27,436:INFO:_master_model_container: 5
2025-05-15 21:53:27,436:INFO:_display_container: 2
2025-05-15 21:53:27,436:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-15 21:53:27,436:INFO:create_model() successfully completed......................................
2025-05-15 21:53:27,508:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:27,508:INFO:Creating metrics dataframe
2025-05-15 21:53:27,512:INFO:Initializing Ridge Classifier
2025-05-15 21:53:27,512:INFO:Total runtime is 0.24446983734766642 minutes
2025-05-15 21:53:27,514:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:27,514:INFO:Initializing create_model()
2025-05-15 21:53:27,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:27,515:INFO:Checking exceptions
2025-05-15 21:53:27,515:INFO:Importing libraries
2025-05-15 21:53:27,515:INFO:Copying training dataset
2025-05-15 21:53:27,525:INFO:Defining folds
2025-05-15 21:53:27,525:INFO:Declaring metric variables
2025-05-15 21:53:27,527:INFO:Importing untrained model
2025-05-15 21:53:27,528:INFO:Ridge Classifier Imported successfully
2025-05-15 21:53:27,531:INFO:Starting cross validation
2025-05-15 21:53:27,532:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:29,437:INFO:Calculating mean and std
2025-05-15 21:53:29,439:INFO:Creating metrics dataframe
2025-05-15 21:53:29,441:INFO:Uploading results into container
2025-05-15 21:53:29,441:INFO:Uploading model into container now
2025-05-15 21:53:29,441:INFO:_master_model_container: 6
2025-05-15 21:53:29,441:INFO:_display_container: 2
2025-05-15 21:53:29,442:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-15 21:53:29,442:INFO:create_model() successfully completed......................................
2025-05-15 21:53:29,522:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:29,522:INFO:Creating metrics dataframe
2025-05-15 21:53:29,525:INFO:Initializing Random Forest Classifier
2025-05-15 21:53:29,525:INFO:Total runtime is 0.27802350123723346 minutes
2025-05-15 21:53:29,526:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:29,526:INFO:Initializing create_model()
2025-05-15 21:53:29,527:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:29,527:INFO:Checking exceptions
2025-05-15 21:53:29,527:INFO:Importing libraries
2025-05-15 21:53:29,527:INFO:Copying training dataset
2025-05-15 21:53:29,536:INFO:Defining folds
2025-05-15 21:53:29,536:INFO:Declaring metric variables
2025-05-15 21:53:29,537:INFO:Importing untrained model
2025-05-15 21:53:29,538:INFO:Random Forest Classifier Imported successfully
2025-05-15 21:53:29,540:INFO:Starting cross validation
2025-05-15 21:53:29,541:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:32,817:INFO:Calculating mean and std
2025-05-15 21:53:32,818:INFO:Creating metrics dataframe
2025-05-15 21:53:32,819:INFO:Uploading results into container
2025-05-15 21:53:32,819:INFO:Uploading model into container now
2025-05-15 21:53:32,819:INFO:_master_model_container: 7
2025-05-15 21:53:32,819:INFO:_display_container: 2
2025-05-15 21:53:32,820:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 21:53:32,820:INFO:create_model() successfully completed......................................
2025-05-15 21:53:32,920:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:32,920:INFO:Creating metrics dataframe
2025-05-15 21:53:32,924:INFO:Initializing Quadratic Discriminant Analysis
2025-05-15 21:53:32,924:INFO:Total runtime is 0.3346660534540812 minutes
2025-05-15 21:53:32,925:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:32,925:INFO:Initializing create_model()
2025-05-15 21:53:32,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:32,926:INFO:Checking exceptions
2025-05-15 21:53:32,926:INFO:Importing libraries
2025-05-15 21:53:32,926:INFO:Copying training dataset
2025-05-15 21:53:32,946:INFO:Defining folds
2025-05-15 21:53:32,946:INFO:Declaring metric variables
2025-05-15 21:53:32,948:INFO:Importing untrained model
2025-05-15 21:53:32,949:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 21:53:32,952:INFO:Starting cross validation
2025-05-15 21:53:32,953:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:33,736:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:53:33,737:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:53:33,744:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:53:33,759:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:53:33,795:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:53:33,876:INFO:Calculating mean and std
2025-05-15 21:53:33,878:INFO:Creating metrics dataframe
2025-05-15 21:53:33,881:INFO:Uploading results into container
2025-05-15 21:53:33,882:INFO:Uploading model into container now
2025-05-15 21:53:33,882:INFO:_master_model_container: 8
2025-05-15 21:53:33,882:INFO:_display_container: 2
2025-05-15 21:53:33,883:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 21:53:33,883:INFO:create_model() successfully completed......................................
2025-05-15 21:53:34,028:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:34,028:INFO:Creating metrics dataframe
2025-05-15 21:53:34,032:INFO:Initializing Ada Boost Classifier
2025-05-15 21:53:34,033:INFO:Total runtime is 0.35314775307973223 minutes
2025-05-15 21:53:34,034:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:34,034:INFO:Initializing create_model()
2025-05-15 21:53:34,034:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:34,035:INFO:Checking exceptions
2025-05-15 21:53:34,035:INFO:Importing libraries
2025-05-15 21:53:34,035:INFO:Copying training dataset
2025-05-15 21:53:34,048:INFO:Defining folds
2025-05-15 21:53:34,048:INFO:Declaring metric variables
2025-05-15 21:53:34,050:INFO:Importing untrained model
2025-05-15 21:53:34,052:INFO:Ada Boost Classifier Imported successfully
2025-05-15 21:53:34,054:INFO:Starting cross validation
2025-05-15 21:53:34,055:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:34,674:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:53:34,675:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:53:34,677:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:53:34,683:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:53:34,694:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 21:53:36,050:INFO:Calculating mean and std
2025-05-15 21:53:36,051:INFO:Creating metrics dataframe
2025-05-15 21:53:36,052:INFO:Uploading results into container
2025-05-15 21:53:36,052:INFO:Uploading model into container now
2025-05-15 21:53:36,052:INFO:_master_model_container: 9
2025-05-15 21:53:36,052:INFO:_display_container: 2
2025-05-15 21:53:36,052:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-15 21:53:36,052:INFO:create_model() successfully completed......................................
2025-05-15 21:53:36,120:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:36,120:INFO:Creating metrics dataframe
2025-05-15 21:53:36,123:INFO:Initializing Gradient Boosting Classifier
2025-05-15 21:53:36,123:INFO:Total runtime is 0.3879929343859354 minutes
2025-05-15 21:53:36,124:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:36,125:INFO:Initializing create_model()
2025-05-15 21:53:36,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:36,125:INFO:Checking exceptions
2025-05-15 21:53:36,125:INFO:Importing libraries
2025-05-15 21:53:36,125:INFO:Copying training dataset
2025-05-15 21:53:36,134:INFO:Defining folds
2025-05-15 21:53:36,134:INFO:Declaring metric variables
2025-05-15 21:53:36,135:INFO:Importing untrained model
2025-05-15 21:53:36,137:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 21:53:36,139:INFO:Starting cross validation
2025-05-15 21:53:36,140:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:42,210:INFO:Calculating mean and std
2025-05-15 21:53:42,211:INFO:Creating metrics dataframe
2025-05-15 21:53:42,212:INFO:Uploading results into container
2025-05-15 21:53:42,212:INFO:Uploading model into container now
2025-05-15 21:53:42,212:INFO:_master_model_container: 10
2025-05-15 21:53:42,213:INFO:_display_container: 2
2025-05-15 21:53:42,213:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 21:53:42,213:INFO:create_model() successfully completed......................................
2025-05-15 21:53:42,281:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:42,281:INFO:Creating metrics dataframe
2025-05-15 21:53:42,284:INFO:Initializing Linear Discriminant Analysis
2025-05-15 21:53:42,284:INFO:Total runtime is 0.49067913293838494 minutes
2025-05-15 21:53:42,286:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:42,286:INFO:Initializing create_model()
2025-05-15 21:53:42,286:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:42,286:INFO:Checking exceptions
2025-05-15 21:53:42,286:INFO:Importing libraries
2025-05-15 21:53:42,286:INFO:Copying training dataset
2025-05-15 21:53:42,296:INFO:Defining folds
2025-05-15 21:53:42,296:INFO:Declaring metric variables
2025-05-15 21:53:42,297:INFO:Importing untrained model
2025-05-15 21:53:42,298:INFO:Linear Discriminant Analysis Imported successfully
2025-05-15 21:53:42,300:INFO:Starting cross validation
2025-05-15 21:53:42,301:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:43,060:INFO:Calculating mean and std
2025-05-15 21:53:43,061:INFO:Creating metrics dataframe
2025-05-15 21:53:43,061:INFO:Uploading results into container
2025-05-15 21:53:43,062:INFO:Uploading model into container now
2025-05-15 21:53:43,062:INFO:_master_model_container: 11
2025-05-15 21:53:43,062:INFO:_display_container: 2
2025-05-15 21:53:43,062:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-15 21:53:43,062:INFO:create_model() successfully completed......................................
2025-05-15 21:53:43,129:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:43,129:INFO:Creating metrics dataframe
2025-05-15 21:53:43,133:INFO:Initializing Extra Trees Classifier
2025-05-15 21:53:43,133:INFO:Total runtime is 0.5048173189163208 minutes
2025-05-15 21:53:43,134:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:43,134:INFO:Initializing create_model()
2025-05-15 21:53:43,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:43,134:INFO:Checking exceptions
2025-05-15 21:53:43,134:INFO:Importing libraries
2025-05-15 21:53:43,134:INFO:Copying training dataset
2025-05-15 21:53:43,143:INFO:Defining folds
2025-05-15 21:53:43,143:INFO:Declaring metric variables
2025-05-15 21:53:43,144:INFO:Importing untrained model
2025-05-15 21:53:43,146:INFO:Extra Trees Classifier Imported successfully
2025-05-15 21:53:43,148:INFO:Starting cross validation
2025-05-15 21:53:43,149:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:45,243:INFO:Calculating mean and std
2025-05-15 21:53:45,245:INFO:Creating metrics dataframe
2025-05-15 21:53:45,252:INFO:Uploading results into container
2025-05-15 21:53:45,254:INFO:Uploading model into container now
2025-05-15 21:53:45,255:INFO:_master_model_container: 12
2025-05-15 21:53:45,255:INFO:_display_container: 2
2025-05-15 21:53:45,256:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 21:53:45,256:INFO:create_model() successfully completed......................................
2025-05-15 21:53:45,386:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:45,386:INFO:Creating metrics dataframe
2025-05-15 21:53:45,392:INFO:Initializing Light Gradient Boosting Machine
2025-05-15 21:53:45,392:INFO:Total runtime is 0.542471170425415 minutes
2025-05-15 21:53:45,394:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:45,394:INFO:Initializing create_model()
2025-05-15 21:53:45,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:45,394:INFO:Checking exceptions
2025-05-15 21:53:45,394:INFO:Importing libraries
2025-05-15 21:53:45,394:INFO:Copying training dataset
2025-05-15 21:53:45,406:INFO:Defining folds
2025-05-15 21:53:45,406:INFO:Declaring metric variables
2025-05-15 21:53:45,408:INFO:Importing untrained model
2025-05-15 21:53:45,410:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 21:53:45,412:INFO:Starting cross validation
2025-05-15 21:53:45,414:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:48,638:INFO:Calculating mean and std
2025-05-15 21:53:48,639:INFO:Creating metrics dataframe
2025-05-15 21:53:48,640:INFO:Uploading results into container
2025-05-15 21:53:48,640:INFO:Uploading model into container now
2025-05-15 21:53:48,640:INFO:_master_model_container: 13
2025-05-15 21:53:48,641:INFO:_display_container: 2
2025-05-15 21:53:48,641:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 21:53:48,641:INFO:create_model() successfully completed......................................
2025-05-15 21:53:48,710:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:48,711:INFO:Creating metrics dataframe
2025-05-15 21:53:48,715:INFO:Initializing CatBoost Classifier
2025-05-15 21:53:48,715:INFO:Total runtime is 0.5978524843851726 minutes
2025-05-15 21:53:48,716:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:48,716:INFO:Initializing create_model()
2025-05-15 21:53:48,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:48,716:INFO:Checking exceptions
2025-05-15 21:53:48,716:INFO:Importing libraries
2025-05-15 21:53:48,717:INFO:Copying training dataset
2025-05-15 21:53:48,725:INFO:Defining folds
2025-05-15 21:53:48,726:INFO:Declaring metric variables
2025-05-15 21:53:48,727:INFO:Importing untrained model
2025-05-15 21:53:48,728:INFO:CatBoost Classifier Imported successfully
2025-05-15 21:53:48,730:INFO:Starting cross validation
2025-05-15 21:53:48,731:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:57,243:INFO:Calculating mean and std
2025-05-15 21:53:57,244:INFO:Creating metrics dataframe
2025-05-15 21:53:57,245:INFO:Uploading results into container
2025-05-15 21:53:57,245:INFO:Uploading model into container now
2025-05-15 21:53:57,245:INFO:_master_model_container: 14
2025-05-15 21:53:57,245:INFO:_display_container: 2
2025-05-15 21:53:57,246:INFO:<catboost.core.CatBoostClassifier object at 0x330234a90>
2025-05-15 21:53:57,246:INFO:create_model() successfully completed......................................
2025-05-15 21:53:57,313:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:57,314:INFO:Creating metrics dataframe
2025-05-15 21:53:57,318:INFO:Initializing Dummy Classifier
2025-05-15 21:53:57,318:INFO:Total runtime is 0.741239885489146 minutes
2025-05-15 21:53:57,319:INFO:SubProcess create_model() called ==================================
2025-05-15 21:53:57,319:INFO:Initializing create_model()
2025-05-15 21:53:57,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363037610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:57,320:INFO:Checking exceptions
2025-05-15 21:53:57,320:INFO:Importing libraries
2025-05-15 21:53:57,320:INFO:Copying training dataset
2025-05-15 21:53:57,329:INFO:Defining folds
2025-05-15 21:53:57,329:INFO:Declaring metric variables
2025-05-15 21:53:57,330:INFO:Importing untrained model
2025-05-15 21:53:57,331:INFO:Dummy Classifier Imported successfully
2025-05-15 21:53:57,333:INFO:Starting cross validation
2025-05-15 21:53:57,334:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 21:53:57,939:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:53:57,970:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:53:57,973:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:53:57,980:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:53:57,999:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 21:53:58,007:INFO:Calculating mean and std
2025-05-15 21:53:58,008:INFO:Creating metrics dataframe
2025-05-15 21:53:58,010:INFO:Uploading results into container
2025-05-15 21:53:58,010:INFO:Uploading model into container now
2025-05-15 21:53:58,010:INFO:_master_model_container: 15
2025-05-15 21:53:58,010:INFO:_display_container: 2
2025-05-15 21:53:58,010:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-15 21:53:58,011:INFO:create_model() successfully completed......................................
2025-05-15 21:53:58,089:INFO:SubProcess create_model() end ==================================
2025-05-15 21:53:58,089:INFO:Creating metrics dataframe
2025-05-15 21:53:58,093:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-15 21:53:58,096:INFO:Initializing create_model()
2025-05-15 21:53:58,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:58,096:INFO:Checking exceptions
2025-05-15 21:53:58,097:INFO:Importing libraries
2025-05-15 21:53:58,097:INFO:Copying training dataset
2025-05-15 21:53:58,106:INFO:Defining folds
2025-05-15 21:53:58,106:INFO:Declaring metric variables
2025-05-15 21:53:58,106:INFO:Importing untrained model
2025-05-15 21:53:58,106:INFO:Declaring custom model
2025-05-15 21:53:58,106:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 21:53:58,107:INFO:Cross validation set to False
2025-05-15 21:53:58,107:INFO:Fitting Model
2025-05-15 21:53:58,739:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 21:53:58,746:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 21:53:58,746:INFO:create_model() successfully completed......................................
2025-05-15 21:53:58,831:INFO:Initializing create_model()
2025-05-15 21:53:58,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=<catboost.core.CatBoostClassifier object at 0x330234a90>, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:53:58,831:INFO:Checking exceptions
2025-05-15 21:53:58,833:INFO:Importing libraries
2025-05-15 21:53:58,833:INFO:Copying training dataset
2025-05-15 21:53:58,844:INFO:Defining folds
2025-05-15 21:53:58,844:INFO:Declaring metric variables
2025-05-15 21:53:58,844:INFO:Importing untrained model
2025-05-15 21:53:58,844:INFO:Declaring custom model
2025-05-15 21:53:58,845:INFO:CatBoost Classifier Imported successfully
2025-05-15 21:53:58,845:INFO:Cross validation set to False
2025-05-15 21:53:58,845:INFO:Fitting Model
2025-05-15 21:54:03,760:INFO:<catboost.core.CatBoostClassifier object at 0x32ebbfbd0>
2025-05-15 21:54:03,760:INFO:create_model() successfully completed......................................
2025-05-15 21:54:03,830:INFO:Initializing create_model()
2025-05-15 21:54:03,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36458dad0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 21:54:03,830:INFO:Checking exceptions
2025-05-15 21:54:03,831:INFO:Importing libraries
2025-05-15 21:54:03,831:INFO:Copying training dataset
2025-05-15 21:54:03,841:INFO:Defining folds
2025-05-15 21:54:03,842:INFO:Declaring metric variables
2025-05-15 21:54:03,842:INFO:Importing untrained model
2025-05-15 21:54:03,842:INFO:Declaring custom model
2025-05-15 21:54:03,842:INFO:Extra Trees Classifier Imported successfully
2025-05-15 21:54:03,843:INFO:Cross validation set to False
2025-05-15 21:54:03,843:INFO:Fitting Model
2025-05-15 21:54:04,776:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 21:54:04,776:INFO:create_model() successfully completed......................................
2025-05-15 21:54:04,849:INFO:_master_model_container: 15
2025-05-15 21:54:04,849:INFO:_display_container: 2
2025-05-15 21:54:04,849:INFO:[QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), <catboost.core.CatBoostClassifier object at 0x32ebbfbd0>, ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)]
2025-05-15 21:54:04,849:INFO:compare_models() successfully completed......................................
2025-05-15 22:09:24,496:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/4055261274.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:10:29,308:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/3243682463.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:11:16,314:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1600598247.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:11:37,208:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2766503984.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:11:57,448:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/3800045837.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:12:11,514:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/3193312254.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:12:51,238:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/4003839272.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:13:23,711:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/4158977036.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:13:38,488:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2300964796.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:13:54,824:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1266690967.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:14:16,975:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2401976321.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:14:35,297:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2948988729.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:14:48,650:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/235800113.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:15:02,802:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/259412182.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:15:53,975:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/3386105262.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:16:37,892:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1066434949.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:17:03,067:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1351201770.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:17:19,650:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1860869313.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:17:34,270:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/751662038.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:17:47,159:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/3819838284.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:17:57,973:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/3876472627.py:394: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')

2025-05-15 22:20:27,420:INFO:PyCaret ClassificationExperiment
2025-05-15 22:20:27,420:INFO:Logging name: clf-default-name
2025-05-15 22:20:27,421:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 22:20:27,421:INFO:version 3.3.2
2025-05-15 22:20:27,421:INFO:Initializing setup()
2025-05-15 22:20:27,421:INFO:self.USI: 1821
2025-05-15 22:20:27,421:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-15 22:20:27,421:INFO:Checking environment
2025-05-15 22:20:27,421:INFO:python_version: 3.11.0
2025-05-15 22:20:27,421:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 22:20:27,421:INFO:machine: arm64
2025-05-15 22:20:27,421:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 22:20:27,421:INFO:Memory: svmem(total=17179869184, available=4056203264, percent=76.4, used=6842073088, free=58556416, active=4009246720, inactive=3993141248, wired=2832826368)
2025-05-15 22:20:27,421:INFO:Physical Core: 12
2025-05-15 22:20:27,421:INFO:Logical Core: 12
2025-05-15 22:20:27,422:INFO:Checking libraries
2025-05-15 22:20:27,422:INFO:System:
2025-05-15 22:20:27,422:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 22:20:27,422:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 22:20:27,422:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 22:20:27,422:INFO:PyCaret required dependencies:
2025-05-15 22:20:27,422:INFO:                 pip: 22.3
2025-05-15 22:20:27,422:INFO:          setuptools: 65.5.0
2025-05-15 22:20:27,422:INFO:             pycaret: 3.3.2
2025-05-15 22:20:27,422:INFO:             IPython: 9.2.0
2025-05-15 22:20:27,422:INFO:          ipywidgets: 8.1.7
2025-05-15 22:20:27,422:INFO:                tqdm: 4.67.1
2025-05-15 22:20:27,422:INFO:               numpy: 1.26.4
2025-05-15 22:20:27,422:INFO:              pandas: 2.1.4
2025-05-15 22:20:27,422:INFO:              jinja2: 3.1.6
2025-05-15 22:20:27,422:INFO:               scipy: 1.11.4
2025-05-15 22:20:27,422:INFO:              joblib: 1.3.2
2025-05-15 22:20:27,422:INFO:             sklearn: 1.4.2
2025-05-15 22:20:27,422:INFO:                pyod: 2.0.5
2025-05-15 22:20:27,422:INFO:            imblearn: 0.13.0
2025-05-15 22:20:27,422:INFO:   category_encoders: 2.7.0
2025-05-15 22:20:27,422:INFO:            lightgbm: 4.6.0
2025-05-15 22:20:27,422:INFO:               numba: 0.61.2
2025-05-15 22:20:27,422:INFO:            requests: 2.32.3
2025-05-15 22:20:27,422:INFO:          matplotlib: 3.7.5
2025-05-15 22:20:27,422:INFO:          scikitplot: 0.3.7
2025-05-15 22:20:27,422:INFO:         yellowbrick: 1.5
2025-05-15 22:20:27,422:INFO:              plotly: 5.24.1
2025-05-15 22:20:27,422:INFO:    plotly-resampler: Not installed
2025-05-15 22:20:27,422:INFO:             kaleido: 0.2.1
2025-05-15 22:20:27,422:INFO:           schemdraw: 0.15
2025-05-15 22:20:27,422:INFO:         statsmodels: 0.14.4
2025-05-15 22:20:27,422:INFO:              sktime: 0.26.0
2025-05-15 22:20:27,422:INFO:               tbats: 1.1.3
2025-05-15 22:20:27,422:INFO:            pmdarima: 2.0.4
2025-05-15 22:20:27,422:INFO:              psutil: 7.0.0
2025-05-15 22:20:27,422:INFO:          markupsafe: 3.0.2
2025-05-15 22:20:27,422:INFO:             pickle5: Not installed
2025-05-15 22:20:27,422:INFO:         cloudpickle: 3.1.1
2025-05-15 22:20:27,422:INFO:         deprecation: 2.1.0
2025-05-15 22:20:27,422:INFO:              xxhash: 3.5.0
2025-05-15 22:20:27,422:INFO:           wurlitzer: 3.1.1
2025-05-15 22:20:27,422:INFO:PyCaret optional dependencies:
2025-05-15 22:20:27,422:INFO:                shap: 0.47.2
2025-05-15 22:20:27,422:INFO:           interpret: Not installed
2025-05-15 22:20:27,422:INFO:                umap: Not installed
2025-05-15 22:20:27,422:INFO:     ydata_profiling: Not installed
2025-05-15 22:20:27,422:INFO:  explainerdashboard: Not installed
2025-05-15 22:20:27,422:INFO:             autoviz: Not installed
2025-05-15 22:20:27,422:INFO:           fairlearn: Not installed
2025-05-15 22:20:27,422:INFO:          deepchecks: Not installed
2025-05-15 22:20:27,422:INFO:             xgboost: Not installed
2025-05-15 22:20:27,422:INFO:            catboost: 1.2.8
2025-05-15 22:20:27,422:INFO:              kmodes: Not installed
2025-05-15 22:20:27,422:INFO:             mlxtend: Not installed
2025-05-15 22:20:27,422:INFO:       statsforecast: Not installed
2025-05-15 22:20:27,422:INFO:        tune_sklearn: Not installed
2025-05-15 22:20:27,422:INFO:                 ray: Not installed
2025-05-15 22:20:27,422:INFO:            hyperopt: Not installed
2025-05-15 22:20:27,422:INFO:              optuna: 4.3.0
2025-05-15 22:20:27,422:INFO:               skopt: Not installed
2025-05-15 22:20:27,422:INFO:              mlflow: Not installed
2025-05-15 22:20:27,422:INFO:              gradio: Not installed
2025-05-15 22:20:27,422:INFO:             fastapi: Not installed
2025-05-15 22:20:27,422:INFO:             uvicorn: Not installed
2025-05-15 22:20:27,422:INFO:              m2cgen: Not installed
2025-05-15 22:20:27,422:INFO:           evidently: Not installed
2025-05-15 22:20:27,422:INFO:               fugue: Not installed
2025-05-15 22:20:27,422:INFO:           streamlit: Not installed
2025-05-15 22:20:27,422:INFO:             prophet: Not installed
2025-05-15 22:20:27,422:INFO:None
2025-05-15 22:20:27,422:INFO:Set up data.
2025-05-15 22:20:27,456:INFO:Set up folding strategy.
2025-05-15 22:20:27,456:INFO:Set up train/test split.
2025-05-15 22:20:27,473:INFO:Set up index.
2025-05-15 22:20:27,474:INFO:Assigning column types.
2025-05-15 22:20:27,478:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 22:20:27,499:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 22:20:27,500:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:20:27,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:20:27,514:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:20:27,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 22:20:27,537:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:20:27,548:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:20:27,548:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:20:27,548:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 22:20:27,567:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:20:27,578:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:20:27,578:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:20:27,596:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:20:27,608:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:20:27,608:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:20:27,609:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 22:20:27,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:20:27,638:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:20:27,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:20:27,669:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:20:27,670:INFO:Preparing preprocessing pipeline...
2025-05-15 22:20:27,672:INFO:Set up simple imputation.
2025-05-15 22:20:27,679:INFO:Set up encoding of ordinal features.
2025-05-15 22:20:27,688:INFO:Set up encoding of categorical features.
2025-05-15 22:20:27,689:INFO:Set up imbalanced handling.
2025-05-15 22:20:27,689:INFO:Set up column transformation.
2025-05-15 22:20:28,673:INFO:Finished creating preprocessing pipeline.
2025-05-15 22:20:28,693:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 22:20:28,693:INFO:Creating final display dataframe.
2025-05-15 22:20:29,142:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 15)
4        Transformed data shape      (106821, 28)
5   Transformed train set shape       (85902, 28)
6    Transformed test set shape       (20919, 28)
7              Numeric features                 5
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              1821
2025-05-15 22:20:29,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:20:29,173:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:20:29,206:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:20:29,206:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:20:29,208:INFO:setup() successfully completed in 1.79s...............
2025-05-15 22:20:29,212:INFO:Initializing compare_models()
2025-05-15 22:20:29,212:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-15 22:20:29,213:INFO:Checking exceptions
2025-05-15 22:20:29,217:INFO:Preparing display monitor
2025-05-15 22:20:29,227:INFO:Initializing Logistic Regression
2025-05-15 22:20:29,227:INFO:Total runtime is 1.7484029134114583e-06 minutes
2025-05-15 22:20:29,228:INFO:SubProcess create_model() called ==================================
2025-05-15 22:20:29,228:INFO:Initializing create_model()
2025-05-15 22:20:29,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:20:29,228:INFO:Checking exceptions
2025-05-15 22:20:29,228:INFO:Importing libraries
2025-05-15 22:20:29,228:INFO:Copying training dataset
2025-05-15 22:20:29,238:INFO:Defining folds
2025-05-15 22:20:29,238:INFO:Declaring metric variables
2025-05-15 22:20:29,239:INFO:Importing untrained model
2025-05-15 22:20:29,241:INFO:Logistic Regression Imported successfully
2025-05-15 22:20:29,243:INFO:Starting cross validation
2025-05-15 22:20:29,244:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:20:35,372:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:20:35,407:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:20:35,449:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:20:35,469:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:20:35,498:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:20:35,561:INFO:Calculating mean and std
2025-05-15 22:20:35,565:INFO:Creating metrics dataframe
2025-05-15 22:20:35,570:INFO:Uploading results into container
2025-05-15 22:20:35,570:INFO:Uploading model into container now
2025-05-15 22:20:35,571:INFO:_master_model_container: 1
2025-05-15 22:20:35,571:INFO:_display_container: 2
2025-05-15 22:20:35,572:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 22:20:35,572:INFO:create_model() successfully completed......................................
2025-05-15 22:20:35,802:INFO:SubProcess create_model() end ==================================
2025-05-15 22:20:35,802:INFO:Creating metrics dataframe
2025-05-15 22:20:35,805:INFO:Initializing K Neighbors Classifier
2025-05-15 22:20:35,805:INFO:Total runtime is 0.10964299837748209 minutes
2025-05-15 22:20:35,806:INFO:SubProcess create_model() called ==================================
2025-05-15 22:20:35,807:INFO:Initializing create_model()
2025-05-15 22:20:35,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:20:35,807:INFO:Checking exceptions
2025-05-15 22:20:35,807:INFO:Importing libraries
2025-05-15 22:20:35,807:INFO:Copying training dataset
2025-05-15 22:20:35,817:INFO:Defining folds
2025-05-15 22:20:35,817:INFO:Declaring metric variables
2025-05-15 22:20:35,819:INFO:Importing untrained model
2025-05-15 22:20:35,820:INFO:K Neighbors Classifier Imported successfully
2025-05-15 22:20:35,822:INFO:Starting cross validation
2025-05-15 22:20:35,824:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:20:41,976:INFO:Calculating mean and std
2025-05-15 22:20:41,982:INFO:Creating metrics dataframe
2025-05-15 22:20:41,985:INFO:Uploading results into container
2025-05-15 22:20:41,986:INFO:Uploading model into container now
2025-05-15 22:20:41,987:INFO:_master_model_container: 2
2025-05-15 22:20:41,987:INFO:_display_container: 2
2025-05-15 22:20:41,989:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-15 22:20:41,989:INFO:create_model() successfully completed......................................
2025-05-15 22:20:42,182:INFO:SubProcess create_model() end ==================================
2025-05-15 22:20:42,182:INFO:Creating metrics dataframe
2025-05-15 22:20:42,185:INFO:Initializing Naive Bayes
2025-05-15 22:20:42,185:INFO:Total runtime is 0.21598096688588458 minutes
2025-05-15 22:20:42,187:INFO:SubProcess create_model() called ==================================
2025-05-15 22:20:42,187:INFO:Initializing create_model()
2025-05-15 22:20:42,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:20:42,187:INFO:Checking exceptions
2025-05-15 22:20:42,187:INFO:Importing libraries
2025-05-15 22:20:42,187:INFO:Copying training dataset
2025-05-15 22:20:42,196:INFO:Defining folds
2025-05-15 22:20:42,197:INFO:Declaring metric variables
2025-05-15 22:20:42,198:INFO:Importing untrained model
2025-05-15 22:20:42,199:INFO:Naive Bayes Imported successfully
2025-05-15 22:20:42,201:INFO:Starting cross validation
2025-05-15 22:20:42,203:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:20:44,909:INFO:Calculating mean and std
2025-05-15 22:20:44,911:INFO:Creating metrics dataframe
2025-05-15 22:20:44,919:INFO:Uploading results into container
2025-05-15 22:20:44,921:INFO:Uploading model into container now
2025-05-15 22:20:44,923:INFO:_master_model_container: 3
2025-05-15 22:20:44,923:INFO:_display_container: 2
2025-05-15 22:20:44,923:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-15 22:20:44,923:INFO:create_model() successfully completed......................................
2025-05-15 22:20:45,091:INFO:SubProcess create_model() end ==================================
2025-05-15 22:20:45,091:INFO:Creating metrics dataframe
2025-05-15 22:20:45,095:INFO:Initializing Decision Tree Classifier
2025-05-15 22:20:45,095:INFO:Total runtime is 0.26446668306986487 minutes
2025-05-15 22:20:45,096:INFO:SubProcess create_model() called ==================================
2025-05-15 22:20:45,096:INFO:Initializing create_model()
2025-05-15 22:20:45,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:20:45,096:INFO:Checking exceptions
2025-05-15 22:20:45,096:INFO:Importing libraries
2025-05-15 22:20:45,097:INFO:Copying training dataset
2025-05-15 22:20:45,107:INFO:Defining folds
2025-05-15 22:20:45,107:INFO:Declaring metric variables
2025-05-15 22:20:45,108:INFO:Importing untrained model
2025-05-15 22:20:45,110:INFO:Decision Tree Classifier Imported successfully
2025-05-15 22:20:45,112:INFO:Starting cross validation
2025-05-15 22:20:45,113:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:20:47,989:INFO:Calculating mean and std
2025-05-15 22:20:47,991:INFO:Creating metrics dataframe
2025-05-15 22:20:47,992:INFO:Uploading results into container
2025-05-15 22:20:47,992:INFO:Uploading model into container now
2025-05-15 22:20:47,992:INFO:_master_model_container: 4
2025-05-15 22:20:47,992:INFO:_display_container: 2
2025-05-15 22:20:47,993:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-15 22:20:47,993:INFO:create_model() successfully completed......................................
2025-05-15 22:20:48,127:INFO:SubProcess create_model() end ==================================
2025-05-15 22:20:48,127:INFO:Creating metrics dataframe
2025-05-15 22:20:48,130:INFO:Initializing SVM - Linear Kernel
2025-05-15 22:20:48,130:INFO:Total runtime is 0.3150556166966756 minutes
2025-05-15 22:20:48,131:INFO:SubProcess create_model() called ==================================
2025-05-15 22:20:48,131:INFO:Initializing create_model()
2025-05-15 22:20:48,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:20:48,131:INFO:Checking exceptions
2025-05-15 22:20:48,131:INFO:Importing libraries
2025-05-15 22:20:48,132:INFO:Copying training dataset
2025-05-15 22:20:48,144:INFO:Defining folds
2025-05-15 22:20:48,144:INFO:Declaring metric variables
2025-05-15 22:20:48,146:INFO:Importing untrained model
2025-05-15 22:20:48,147:INFO:SVM - Linear Kernel Imported successfully
2025-05-15 22:20:48,149:INFO:Starting cross validation
2025-05-15 22:20:48,151:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:20:52,467:INFO:Calculating mean and std
2025-05-15 22:20:52,471:INFO:Creating metrics dataframe
2025-05-15 22:20:52,477:INFO:Uploading results into container
2025-05-15 22:20:52,477:INFO:Uploading model into container now
2025-05-15 22:20:52,478:INFO:_master_model_container: 5
2025-05-15 22:20:52,478:INFO:_display_container: 2
2025-05-15 22:20:52,479:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-15 22:20:52,479:INFO:create_model() successfully completed......................................
2025-05-15 22:20:52,700:INFO:SubProcess create_model() end ==================================
2025-05-15 22:20:52,700:INFO:Creating metrics dataframe
2025-05-15 22:20:52,704:INFO:Initializing Ridge Classifier
2025-05-15 22:20:52,704:INFO:Total runtime is 0.3912953972816467 minutes
2025-05-15 22:20:52,706:INFO:SubProcess create_model() called ==================================
2025-05-15 22:20:52,706:INFO:Initializing create_model()
2025-05-15 22:20:52,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:20:52,706:INFO:Checking exceptions
2025-05-15 22:20:52,706:INFO:Importing libraries
2025-05-15 22:20:52,707:INFO:Copying training dataset
2025-05-15 22:20:52,722:INFO:Defining folds
2025-05-15 22:20:52,722:INFO:Declaring metric variables
2025-05-15 22:20:52,724:INFO:Importing untrained model
2025-05-15 22:20:52,725:INFO:Ridge Classifier Imported successfully
2025-05-15 22:20:52,727:INFO:Starting cross validation
2025-05-15 22:20:52,729:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:20:53,989:INFO:Calculating mean and std
2025-05-15 22:20:53,990:INFO:Creating metrics dataframe
2025-05-15 22:20:53,991:INFO:Uploading results into container
2025-05-15 22:20:53,991:INFO:Uploading model into container now
2025-05-15 22:20:53,992:INFO:_master_model_container: 6
2025-05-15 22:20:53,992:INFO:_display_container: 2
2025-05-15 22:20:53,992:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-15 22:20:53,992:INFO:create_model() successfully completed......................................
2025-05-15 22:20:54,132:INFO:SubProcess create_model() end ==================================
2025-05-15 22:20:54,132:INFO:Creating metrics dataframe
2025-05-15 22:20:54,136:INFO:Initializing Random Forest Classifier
2025-05-15 22:20:54,136:INFO:Total runtime is 0.4151521841684977 minutes
2025-05-15 22:20:54,137:INFO:SubProcess create_model() called ==================================
2025-05-15 22:20:54,137:INFO:Initializing create_model()
2025-05-15 22:20:54,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:20:54,138:INFO:Checking exceptions
2025-05-15 22:20:54,138:INFO:Importing libraries
2025-05-15 22:20:54,138:INFO:Copying training dataset
2025-05-15 22:20:54,151:INFO:Defining folds
2025-05-15 22:20:54,151:INFO:Declaring metric variables
2025-05-15 22:20:54,153:INFO:Importing untrained model
2025-05-15 22:20:54,154:INFO:Random Forest Classifier Imported successfully
2025-05-15 22:20:54,157:INFO:Starting cross validation
2025-05-15 22:20:54,159:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:21:00,560:INFO:Calculating mean and std
2025-05-15 22:21:00,564:INFO:Creating metrics dataframe
2025-05-15 22:21:00,569:INFO:Uploading results into container
2025-05-15 22:21:00,570:INFO:Uploading model into container now
2025-05-15 22:21:00,571:INFO:_master_model_container: 7
2025-05-15 22:21:00,571:INFO:_display_container: 2
2025-05-15 22:21:00,572:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 22:21:00,572:INFO:create_model() successfully completed......................................
2025-05-15 22:21:00,795:INFO:SubProcess create_model() end ==================================
2025-05-15 22:21:00,795:INFO:Creating metrics dataframe
2025-05-15 22:21:00,799:INFO:Initializing Quadratic Discriminant Analysis
2025-05-15 22:21:00,799:INFO:Total runtime is 0.5262093345324198 minutes
2025-05-15 22:21:00,800:INFO:SubProcess create_model() called ==================================
2025-05-15 22:21:00,801:INFO:Initializing create_model()
2025-05-15 22:21:00,801:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:21:00,801:INFO:Checking exceptions
2025-05-15 22:21:00,801:INFO:Importing libraries
2025-05-15 22:21:00,801:INFO:Copying training dataset
2025-05-15 22:21:00,815:INFO:Defining folds
2025-05-15 22:21:00,815:INFO:Declaring metric variables
2025-05-15 22:21:00,816:INFO:Importing untrained model
2025-05-15 22:21:00,818:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 22:21:00,821:INFO:Starting cross validation
2025-05-15 22:21:00,824:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:21:01,883:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:21:01,887:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:21:01,918:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:21:01,921:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:21:01,935:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:21:01,968:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:21:01,973:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:21:01,999:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:21:02,013:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:21:02,014:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:21:02,028:INFO:Calculating mean and std
2025-05-15 22:21:02,028:INFO:Creating metrics dataframe
2025-05-15 22:21:02,029:INFO:Uploading results into container
2025-05-15 22:21:02,030:INFO:Uploading model into container now
2025-05-15 22:21:02,030:INFO:_master_model_container: 8
2025-05-15 22:21:02,030:INFO:_display_container: 2
2025-05-15 22:21:02,030:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 22:21:02,030:INFO:create_model() successfully completed......................................
2025-05-15 22:21:02,158:INFO:SubProcess create_model() end ==================================
2025-05-15 22:21:02,158:INFO:Creating metrics dataframe
2025-05-15 22:21:02,162:INFO:Initializing Ada Boost Classifier
2025-05-15 22:21:02,162:INFO:Total runtime is 0.5489225506782531 minutes
2025-05-15 22:21:02,163:INFO:SubProcess create_model() called ==================================
2025-05-15 22:21:02,163:INFO:Initializing create_model()
2025-05-15 22:21:02,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:21:02,163:INFO:Checking exceptions
2025-05-15 22:21:02,163:INFO:Importing libraries
2025-05-15 22:21:02,164:INFO:Copying training dataset
2025-05-15 22:21:02,172:INFO:Defining folds
2025-05-15 22:21:02,172:INFO:Declaring metric variables
2025-05-15 22:21:02,173:INFO:Importing untrained model
2025-05-15 22:21:02,175:INFO:Ada Boost Classifier Imported successfully
2025-05-15 22:21:02,177:INFO:Starting cross validation
2025-05-15 22:21:02,178:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:21:03,159:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:21:03,166:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:21:03,179:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:21:03,189:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:21:03,213:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:21:05,978:INFO:Calculating mean and std
2025-05-15 22:21:05,980:INFO:Creating metrics dataframe
2025-05-15 22:21:05,982:INFO:Uploading results into container
2025-05-15 22:21:05,982:INFO:Uploading model into container now
2025-05-15 22:21:05,983:INFO:_master_model_container: 9
2025-05-15 22:21:05,983:INFO:_display_container: 2
2025-05-15 22:21:05,983:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-15 22:21:05,983:INFO:create_model() successfully completed......................................
2025-05-15 22:21:06,114:INFO:SubProcess create_model() end ==================================
2025-05-15 22:21:06,114:INFO:Creating metrics dataframe
2025-05-15 22:21:06,118:INFO:Initializing Gradient Boosting Classifier
2025-05-15 22:21:06,118:INFO:Total runtime is 0.614854085445404 minutes
2025-05-15 22:21:06,119:INFO:SubProcess create_model() called ==================================
2025-05-15 22:21:06,119:INFO:Initializing create_model()
2025-05-15 22:21:06,119:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:21:06,119:INFO:Checking exceptions
2025-05-15 22:21:06,120:INFO:Importing libraries
2025-05-15 22:21:06,120:INFO:Copying training dataset
2025-05-15 22:21:06,129:INFO:Defining folds
2025-05-15 22:21:06,129:INFO:Declaring metric variables
2025-05-15 22:21:06,130:INFO:Importing untrained model
2025-05-15 22:21:06,131:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 22:21:06,134:INFO:Starting cross validation
2025-05-15 22:21:06,135:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:21:19,847:INFO:Calculating mean and std
2025-05-15 22:21:19,848:INFO:Creating metrics dataframe
2025-05-15 22:21:19,849:INFO:Uploading results into container
2025-05-15 22:21:19,850:INFO:Uploading model into container now
2025-05-15 22:21:19,850:INFO:_master_model_container: 10
2025-05-15 22:21:19,850:INFO:_display_container: 2
2025-05-15 22:21:19,850:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 22:21:19,850:INFO:create_model() successfully completed......................................
2025-05-15 22:21:20,056:INFO:SubProcess create_model() end ==================================
2025-05-15 22:21:20,056:INFO:Creating metrics dataframe
2025-05-15 22:21:20,062:INFO:Initializing Linear Discriminant Analysis
2025-05-15 22:21:20,062:INFO:Total runtime is 0.8472500642140706 minutes
2025-05-15 22:21:20,063:INFO:SubProcess create_model() called ==================================
2025-05-15 22:21:20,063:INFO:Initializing create_model()
2025-05-15 22:21:20,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:21:20,063:INFO:Checking exceptions
2025-05-15 22:21:20,063:INFO:Importing libraries
2025-05-15 22:21:20,063:INFO:Copying training dataset
2025-05-15 22:21:20,074:INFO:Defining folds
2025-05-15 22:21:20,074:INFO:Declaring metric variables
2025-05-15 22:21:20,075:INFO:Importing untrained model
2025-05-15 22:21:20,076:INFO:Linear Discriminant Analysis Imported successfully
2025-05-15 22:21:20,079:INFO:Starting cross validation
2025-05-15 22:21:20,081:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:21:21,305:INFO:Calculating mean and std
2025-05-15 22:21:21,307:INFO:Creating metrics dataframe
2025-05-15 22:21:21,313:INFO:Uploading results into container
2025-05-15 22:21:21,313:INFO:Uploading model into container now
2025-05-15 22:21:21,314:INFO:_master_model_container: 11
2025-05-15 22:21:21,314:INFO:_display_container: 2
2025-05-15 22:21:21,314:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-15 22:21:21,315:INFO:create_model() successfully completed......................................
2025-05-15 22:21:21,470:INFO:SubProcess create_model() end ==================================
2025-05-15 22:21:21,470:INFO:Creating metrics dataframe
2025-05-15 22:21:21,475:INFO:Initializing Extra Trees Classifier
2025-05-15 22:21:21,475:INFO:Total runtime is 0.8708068172136941 minutes
2025-05-15 22:21:21,476:INFO:SubProcess create_model() called ==================================
2025-05-15 22:21:21,476:INFO:Initializing create_model()
2025-05-15 22:21:21,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:21:21,476:INFO:Checking exceptions
2025-05-15 22:21:21,476:INFO:Importing libraries
2025-05-15 22:21:21,477:INFO:Copying training dataset
2025-05-15 22:21:21,488:INFO:Defining folds
2025-05-15 22:21:21,489:INFO:Declaring metric variables
2025-05-15 22:21:21,490:INFO:Importing untrained model
2025-05-15 22:21:21,492:INFO:Extra Trees Classifier Imported successfully
2025-05-15 22:21:21,494:INFO:Starting cross validation
2025-05-15 22:21:21,495:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:21:26,051:INFO:Calculating mean and std
2025-05-15 22:21:26,057:INFO:Creating metrics dataframe
2025-05-15 22:21:26,070:INFO:Uploading results into container
2025-05-15 22:21:26,071:INFO:Uploading model into container now
2025-05-15 22:21:26,072:INFO:_master_model_container: 12
2025-05-15 22:21:26,072:INFO:_display_container: 2
2025-05-15 22:21:26,073:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 22:21:26,073:INFO:create_model() successfully completed......................................
2025-05-15 22:21:26,306:INFO:SubProcess create_model() end ==================================
2025-05-15 22:21:26,306:INFO:Creating metrics dataframe
2025-05-15 22:21:26,315:INFO:Initializing Light Gradient Boosting Machine
2025-05-15 22:21:26,315:INFO:Total runtime is 0.9514747977256773 minutes
2025-05-15 22:21:26,317:INFO:SubProcess create_model() called ==================================
2025-05-15 22:21:26,317:INFO:Initializing create_model()
2025-05-15 22:21:26,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:21:26,318:INFO:Checking exceptions
2025-05-15 22:21:26,318:INFO:Importing libraries
2025-05-15 22:21:26,318:INFO:Copying training dataset
2025-05-15 22:21:26,332:INFO:Defining folds
2025-05-15 22:21:26,333:INFO:Declaring metric variables
2025-05-15 22:21:26,334:INFO:Importing untrained model
2025-05-15 22:21:26,336:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 22:21:26,339:INFO:Starting cross validation
2025-05-15 22:21:26,341:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:21:30,355:INFO:Calculating mean and std
2025-05-15 22:21:30,356:INFO:Creating metrics dataframe
2025-05-15 22:21:30,358:INFO:Uploading results into container
2025-05-15 22:21:30,358:INFO:Uploading model into container now
2025-05-15 22:21:30,358:INFO:_master_model_container: 13
2025-05-15 22:21:30,358:INFO:_display_container: 2
2025-05-15 22:21:30,359:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:21:30,359:INFO:create_model() successfully completed......................................
2025-05-15 22:21:30,490:INFO:SubProcess create_model() end ==================================
2025-05-15 22:21:30,490:INFO:Creating metrics dataframe
2025-05-15 22:21:30,494:INFO:Initializing CatBoost Classifier
2025-05-15 22:21:30,494:INFO:Total runtime is 1.0211235324541725 minutes
2025-05-15 22:21:30,495:INFO:SubProcess create_model() called ==================================
2025-05-15 22:21:30,495:INFO:Initializing create_model()
2025-05-15 22:21:30,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:21:30,496:INFO:Checking exceptions
2025-05-15 22:21:30,496:INFO:Importing libraries
2025-05-15 22:21:30,496:INFO:Copying training dataset
2025-05-15 22:21:30,505:INFO:Defining folds
2025-05-15 22:21:30,505:INFO:Declaring metric variables
2025-05-15 22:21:30,506:INFO:Importing untrained model
2025-05-15 22:21:30,507:INFO:CatBoost Classifier Imported successfully
2025-05-15 22:21:30,509:INFO:Starting cross validation
2025-05-15 22:21:30,510:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:21:47,494:INFO:Calculating mean and std
2025-05-15 22:21:47,496:INFO:Creating metrics dataframe
2025-05-15 22:21:47,499:INFO:Uploading results into container
2025-05-15 22:21:47,500:INFO:Uploading model into container now
2025-05-15 22:21:47,500:INFO:_master_model_container: 14
2025-05-15 22:21:47,500:INFO:_display_container: 2
2025-05-15 22:21:47,500:INFO:<catboost.core.CatBoostClassifier object at 0x363f60310>
2025-05-15 22:21:47,500:INFO:create_model() successfully completed......................................
2025-05-15 22:21:47,655:INFO:SubProcess create_model() end ==================================
2025-05-15 22:21:47,655:INFO:Creating metrics dataframe
2025-05-15 22:21:47,660:INFO:Initializing Dummy Classifier
2025-05-15 22:21:47,660:INFO:Total runtime is 1.307216918468475 minutes
2025-05-15 22:21:47,661:INFO:SubProcess create_model() called ==================================
2025-05-15 22:21:47,661:INFO:Initializing create_model()
2025-05-15 22:21:47,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32eb80ed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:21:47,661:INFO:Checking exceptions
2025-05-15 22:21:47,661:INFO:Importing libraries
2025-05-15 22:21:47,661:INFO:Copying training dataset
2025-05-15 22:21:47,672:INFO:Defining folds
2025-05-15 22:21:47,672:INFO:Declaring metric variables
2025-05-15 22:21:47,674:INFO:Importing untrained model
2025-05-15 22:21:47,675:INFO:Dummy Classifier Imported successfully
2025-05-15 22:21:47,677:INFO:Starting cross validation
2025-05-15 22:21:47,679:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:21:48,675:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:21:48,690:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:21:48,722:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:21:48,758:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:21:48,818:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:21:48,827:INFO:Calculating mean and std
2025-05-15 22:21:48,827:INFO:Creating metrics dataframe
2025-05-15 22:21:48,828:INFO:Uploading results into container
2025-05-15 22:21:48,828:INFO:Uploading model into container now
2025-05-15 22:21:48,828:INFO:_master_model_container: 15
2025-05-15 22:21:48,829:INFO:_display_container: 2
2025-05-15 22:21:48,829:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-15 22:21:48,829:INFO:create_model() successfully completed......................................
2025-05-15 22:21:48,969:INFO:SubProcess create_model() end ==================================
2025-05-15 22:21:48,969:INFO:Creating metrics dataframe
2025-05-15 22:21:48,974:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-15 22:21:48,977:INFO:Initializing create_model()
2025-05-15 22:21:48,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:21:48,977:INFO:Checking exceptions
2025-05-15 22:21:48,978:INFO:Importing libraries
2025-05-15 22:21:48,978:INFO:Copying training dataset
2025-05-15 22:21:48,988:INFO:Defining folds
2025-05-15 22:21:48,988:INFO:Declaring metric variables
2025-05-15 22:21:48,988:INFO:Importing untrained model
2025-05-15 22:21:48,988:INFO:Declaring custom model
2025-05-15 22:21:48,989:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 22:21:48,990:INFO:Cross validation set to False
2025-05-15 22:21:48,990:INFO:Fitting Model
2025-05-15 22:21:50,286:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 22:21:50,294:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004464 seconds.
2025-05-15 22:21:50,294:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 22:21:50,294:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 22:21:50,294:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-15 22:21:50,295:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 27
2025-05-15 22:21:50,295:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 22:21:51,063:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:21:51,063:INFO:create_model() successfully completed......................................
2025-05-15 22:21:51,176:INFO:Initializing create_model()
2025-05-15 22:21:51,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:21:51,176:INFO:Checking exceptions
2025-05-15 22:21:51,177:INFO:Importing libraries
2025-05-15 22:21:51,177:INFO:Copying training dataset
2025-05-15 22:21:51,185:INFO:Defining folds
2025-05-15 22:21:51,185:INFO:Declaring metric variables
2025-05-15 22:21:51,185:INFO:Importing untrained model
2025-05-15 22:21:51,185:INFO:Declaring custom model
2025-05-15 22:21:51,186:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 22:21:51,187:INFO:Cross validation set to False
2025-05-15 22:21:51,187:INFO:Fitting Model
2025-05-15 22:22:07,345:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 22:22:07,346:INFO:create_model() successfully completed......................................
2025-05-15 22:22:07,472:INFO:Initializing create_model()
2025-05-15 22:22:07,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=<catboost.core.CatBoostClassifier object at 0x363f60310>, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:22:07,472:INFO:Checking exceptions
2025-05-15 22:22:07,473:INFO:Importing libraries
2025-05-15 22:22:07,473:INFO:Copying training dataset
2025-05-15 22:22:07,482:INFO:Defining folds
2025-05-15 22:22:07,482:INFO:Declaring metric variables
2025-05-15 22:22:07,482:INFO:Importing untrained model
2025-05-15 22:22:07,482:INFO:Declaring custom model
2025-05-15 22:22:07,482:INFO:CatBoost Classifier Imported successfully
2025-05-15 22:22:07,483:INFO:Cross validation set to False
2025-05-15 22:22:07,483:INFO:Fitting Model
2025-05-15 22:22:15,743:INFO:<catboost.core.CatBoostClassifier object at 0x35616e5d0>
2025-05-15 22:22:15,743:INFO:create_model() successfully completed......................................
2025-05-15 22:22:15,965:INFO:_master_model_container: 15
2025-05-15 22:22:15,965:INFO:_display_container: 2
2025-05-15 22:22:15,965:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), <catboost.core.CatBoostClassifier object at 0x35616e5d0>]
2025-05-15 22:22:15,966:INFO:compare_models() successfully completed......................................
2025-05-15 22:22:15,978:INFO:Initializing evaluate_model()
2025-05-15 22:22:15,978:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 22:22:15,989:INFO:Initializing plot_model()
2025-05-15 22:22:15,989:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 22:22:15,989:INFO:Checking exceptions
2025-05-15 22:22:15,993:INFO:Preloading libraries
2025-05-15 22:22:15,996:INFO:Copying training dataset
2025-05-15 22:22:15,996:INFO:Plot type: pipeline
2025-05-15 22:22:16,058:INFO:Visual Rendered Successfully
2025-05-15 22:22:16,185:INFO:plot_model() successfully completed......................................
2025-05-15 22:22:16,186:INFO:Initializing tune_model()
2025-05-15 22:22:16,186:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-15 22:22:16,187:INFO:Checking exceptions
2025-05-15 22:22:16,196:INFO:Copying training dataset
2025-05-15 22:22:16,209:INFO:Checking base model
2025-05-15 22:22:16,209:INFO:Base model : Light Gradient Boosting Machine
2025-05-15 22:22:16,210:INFO:Declaring metric variables
2025-05-15 22:22:16,212:INFO:Defining Hyperparameters
2025-05-15 22:22:16,339:INFO:Tuning with n_jobs=-1
2025-05-15 22:22:16,339:INFO:Initializing RandomizedSearchCV
2025-05-15 22:22:54,137:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-15 22:22:54,139:INFO:Hyperparameter search completed
2025-05-15 22:22:54,139:INFO:SubProcess create_model() called ==================================
2025-05-15 22:22:54,140:INFO:Initializing create_model()
2025-05-15 22:22:54,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363089fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-15 22:22:54,140:INFO:Checking exceptions
2025-05-15 22:22:54,141:INFO:Importing libraries
2025-05-15 22:22:54,141:INFO:Copying training dataset
2025-05-15 22:22:54,155:INFO:Defining folds
2025-05-15 22:22:54,155:INFO:Declaring metric variables
2025-05-15 22:22:54,159:INFO:Importing untrained model
2025-05-15 22:22:54,159:INFO:Declaring custom model
2025-05-15 22:22:54,162:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 22:22:54,165:INFO:Starting cross validation
2025-05-15 22:22:54,169:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:23:00,474:INFO:Calculating mean and std
2025-05-15 22:23:00,475:INFO:Creating metrics dataframe
2025-05-15 22:23:00,478:INFO:Finalizing model
2025-05-15 22:23:01,470:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 22:23:01,470:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 22:23:01,470:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 22:23:01,499:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 22:23:01,499:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 22:23:01,499:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 22:23:01,499:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 22:23:01,508:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004655 seconds.
2025-05-15 22:23:01,508:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 22:23:01,508:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 22:23:01,508:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-15 22:23:01,509:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 27
2025-05-15 22:23:01,509:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 22:23:02,963:INFO:Uploading results into container
2025-05-15 22:23:02,964:INFO:Uploading model into container now
2025-05-15 22:23:02,964:INFO:_master_model_container: 16
2025-05-15 22:23:02,964:INFO:_display_container: 3
2025-05-15 22:23:02,965:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:23:02,965:INFO:create_model() successfully completed......................................
2025-05-15 22:23:03,176:INFO:SubProcess create_model() end ==================================
2025-05-15 22:23:03,176:INFO:choose_better activated
2025-05-15 22:23:03,178:INFO:SubProcess create_model() called ==================================
2025-05-15 22:23:03,178:INFO:Initializing create_model()
2025-05-15 22:23:03,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:23:03,178:INFO:Checking exceptions
2025-05-15 22:23:03,179:INFO:Importing libraries
2025-05-15 22:23:03,179:INFO:Copying training dataset
2025-05-15 22:23:03,187:INFO:Defining folds
2025-05-15 22:23:03,187:INFO:Declaring metric variables
2025-05-15 22:23:03,187:INFO:Importing untrained model
2025-05-15 22:23:03,187:INFO:Declaring custom model
2025-05-15 22:23:03,188:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 22:23:03,188:INFO:Starting cross validation
2025-05-15 22:23:03,189:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:23:07,197:INFO:Calculating mean and std
2025-05-15 22:23:07,200:INFO:Creating metrics dataframe
2025-05-15 22:23:07,208:INFO:Finalizing model
2025-05-15 22:23:08,233:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 22:23:08,243:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004658 seconds.
2025-05-15 22:23:08,243:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 22:23:08,243:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 22:23:08,243:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-15 22:23:08,243:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 27
2025-05-15 22:23:08,243:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 22:23:09,018:INFO:Uploading results into container
2025-05-15 22:23:09,019:INFO:Uploading model into container now
2025-05-15 22:23:09,019:INFO:_master_model_container: 17
2025-05-15 22:23:09,019:INFO:_display_container: 4
2025-05-15 22:23:09,019:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:23:09,019:INFO:create_model() successfully completed......................................
2025-05-15 22:23:09,141:INFO:SubProcess create_model() end ==================================
2025-05-15 22:23:09,142:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4648
2025-05-15 22:23:09,142:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4903
2025-05-15 22:23:09,142:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-15 22:23:09,142:INFO:choose_better completed
2025-05-15 22:23:09,146:INFO:_master_model_container: 17
2025-05-15 22:23:09,146:INFO:_display_container: 3
2025-05-15 22:23:09,147:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:23:09,147:INFO:tune_model() successfully completed......................................
2025-05-15 22:23:09,271:INFO:Initializing evaluate_model()
2025-05-15 22:23:09,271:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 22:23:09,279:INFO:Initializing plot_model()
2025-05-15 22:23:09,279:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 22:23:09,279:INFO:Checking exceptions
2025-05-15 22:23:09,283:INFO:Preloading libraries
2025-05-15 22:23:09,287:INFO:Copying training dataset
2025-05-15 22:23:09,288:INFO:Plot type: pipeline
2025-05-15 22:23:09,345:INFO:Visual Rendered Successfully
2025-05-15 22:23:09,458:INFO:plot_model() successfully completed......................................
2025-05-15 22:23:09,460:INFO:Initializing interpret_model()
2025-05-15 22:23:09,460:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-15 22:23:09,460:INFO:Checking exceptions
2025-05-15 22:23:09,460:INFO:Soft dependency imported: shap: 0.47.2
2025-05-15 22:23:09,548:INFO:plot type: summary
2025-05-15 22:23:09,548:INFO:Creating TreeExplainer
2025-05-15 22:23:09,625:INFO:Compiling shap values
2025-05-15 22:23:10,614:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray
  warnings.warn(

2025-05-15 22:23:10,614:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-05-15 22:23:11,890:INFO:Visual Rendered Successfully
2025-05-15 22:23:11,891:INFO:interpret_model() successfully completed......................................
2025-05-15 22:23:12,025:INFO:Initializing finalize_model()
2025-05-15 22:23:12,025:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-15 22:23:12,025:INFO:Finalizing LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:23:12,029:INFO:Initializing create_model()
2025-05-15 22:23:12,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:23:12,029:INFO:Checking exceptions
2025-05-15 22:23:12,029:INFO:Importing libraries
2025-05-15 22:23:12,029:INFO:Copying training dataset
2025-05-15 22:23:12,030:INFO:Defining folds
2025-05-15 22:23:12,030:INFO:Declaring metric variables
2025-05-15 22:23:12,030:INFO:Importing untrained model
2025-05-15 22:23:12,030:INFO:Declaring custom model
2025-05-15 22:23:12,030:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 22:23:12,031:INFO:Cross validation set to False
2025-05-15 22:23:12,031:INFO:Fitting Model
2025-05-15 22:23:13,365:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 22:23:13,365:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 22:23:13,365:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 22:23:13,406:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 22:23:13,406:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 22:23:13,406:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 22:23:13,406:INFO:[LightGBM] [Info] Number of positive: 61360, number of negative: 61360
2025-05-15 22:23:13,418:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005331 seconds.
2025-05-15 22:23:13,418:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 22:23:13,418:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 22:23:13,418:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-15 22:23:13,418:INFO:[LightGBM] [Info] Number of data points in the train set: 122720, number of used features: 27
2025-05-15 22:23:13,418:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 22:23:14,975:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 22:23:14,975:INFO:create_model() successfully completed......................................
2025-05-15 22:23:15,090:INFO:_master_model_container: 17
2025-05-15 22:23:15,091:INFO:_display_container: 3
2025-05-15 22:23:15,111:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 22:23:15,111:INFO:finalize_model() successfully completed......................................
2025-05-15 22:23:15,268:INFO:Initializing save_model()
2025-05-15 22:23:15,268:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-15 22:23:15,268:INFO:Adding model into prep_pipe
2025-05-15 22:23:15,268:WARNING:Only Model saved as it was a pipeline.
2025-05-15 22:23:15,275:INFO:final_cancer_model.pkl saved in current working directory
2025-05-15 22:23:15,295:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 22:23:15,295:INFO:save_model() successfully completed......................................
2025-05-15 22:23:15,433:INFO:Initializing predict_model()
2025-05-15 22:23:15,433:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x106e93d80>)
2025-05-15 22:23:15,433:INFO:Checking exceptions
2025-05-15 22:23:15,433:INFO:Preloading libraries
2025-05-15 22:23:15,434:INFO:Set up data.
2025-05-15 22:23:15,458:INFO:Set up index.
2025-05-15 22:23:15,834:INFO:Initializing plot_model()
2025-05-15 22:23:15,834:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 22:23:15,834:INFO:Checking exceptions
2025-05-15 22:23:15,838:INFO:Preloading libraries
2025-05-15 22:23:15,840:INFO:Copying training dataset
2025-05-15 22:23:15,840:INFO:Plot type: confusion_matrix
2025-05-15 22:23:16,055:INFO:Fitting Model
2025-05-15 22:23:16,055:INFO:Scoring test/hold-out set
2025-05-15 22:23:16,130:INFO:Visual Rendered Successfully
2025-05-15 22:23:16,244:INFO:plot_model() successfully completed......................................
2025-05-15 22:23:16,245:INFO:Initializing plot_model()
2025-05-15 22:23:16,245:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 22:23:16,245:INFO:Checking exceptions
2025-05-15 22:23:16,249:INFO:Preloading libraries
2025-05-15 22:23:16,250:INFO:Copying training dataset
2025-05-15 22:23:16,250:INFO:Plot type: auc
2025-05-15 22:23:16,448:INFO:Fitting Model
2025-05-15 22:23:16,450:INFO:Scoring test/hold-out set
2025-05-15 22:23:16,570:INFO:Visual Rendered Successfully
2025-05-15 22:23:16,684:INFO:plot_model() successfully completed......................................
2025-05-15 22:23:16,684:INFO:Initializing plot_model()
2025-05-15 22:23:16,684:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32ed8b650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 22:23:16,685:INFO:Checking exceptions
2025-05-15 22:23:16,689:INFO:Preloading libraries
2025-05-15 22:23:16,690:INFO:Copying training dataset
2025-05-15 22:23:16,690:INFO:Plot type: feature
2025-05-15 22:23:16,691:WARNING:No coef_ found. Trying feature_importances_
2025-05-15 22:23:16,761:INFO:Visual Rendered Successfully
2025-05-15 22:23:16,875:INFO:plot_model() successfully completed......................................
2025-05-15 22:23:47,229:INFO:PyCaret ClassificationExperiment
2025-05-15 22:23:47,229:INFO:Logging name: clf-default-name
2025-05-15 22:23:47,230:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 22:23:47,230:INFO:version 3.3.2
2025-05-15 22:23:47,230:INFO:Initializing setup()
2025-05-15 22:23:47,230:INFO:self.USI: d958
2025-05-15 22:23:47,230:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-15 22:23:47,230:INFO:Checking environment
2025-05-15 22:23:47,230:INFO:python_version: 3.11.0
2025-05-15 22:23:47,230:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 22:23:47,230:INFO:machine: arm64
2025-05-15 22:23:47,230:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 22:23:47,230:INFO:Memory: svmem(total=17179869184, available=3179986944, percent=81.5, used=5928730624, free=65372160, active=3139485696, inactive=3097722880, wired=2789244928)
2025-05-15 22:23:47,230:INFO:Physical Core: 12
2025-05-15 22:23:47,230:INFO:Logical Core: 12
2025-05-15 22:23:47,230:INFO:Checking libraries
2025-05-15 22:23:47,230:INFO:System:
2025-05-15 22:23:47,230:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 22:23:47,230:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 22:23:47,230:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 22:23:47,230:INFO:PyCaret required dependencies:
2025-05-15 22:23:47,230:INFO:                 pip: 22.3
2025-05-15 22:23:47,230:INFO:          setuptools: 65.5.0
2025-05-15 22:23:47,230:INFO:             pycaret: 3.3.2
2025-05-15 22:23:47,230:INFO:             IPython: 9.2.0
2025-05-15 22:23:47,230:INFO:          ipywidgets: 8.1.7
2025-05-15 22:23:47,230:INFO:                tqdm: 4.67.1
2025-05-15 22:23:47,230:INFO:               numpy: 1.26.4
2025-05-15 22:23:47,230:INFO:              pandas: 2.1.4
2025-05-15 22:23:47,230:INFO:              jinja2: 3.1.6
2025-05-15 22:23:47,230:INFO:               scipy: 1.11.4
2025-05-15 22:23:47,230:INFO:              joblib: 1.3.2
2025-05-15 22:23:47,230:INFO:             sklearn: 1.4.2
2025-05-15 22:23:47,230:INFO:                pyod: 2.0.5
2025-05-15 22:23:47,230:INFO:            imblearn: 0.13.0
2025-05-15 22:23:47,230:INFO:   category_encoders: 2.7.0
2025-05-15 22:23:47,230:INFO:            lightgbm: 4.6.0
2025-05-15 22:23:47,230:INFO:               numba: 0.61.2
2025-05-15 22:23:47,230:INFO:            requests: 2.32.3
2025-05-15 22:23:47,230:INFO:          matplotlib: 3.7.5
2025-05-15 22:23:47,230:INFO:          scikitplot: 0.3.7
2025-05-15 22:23:47,230:INFO:         yellowbrick: 1.5
2025-05-15 22:23:47,230:INFO:              plotly: 5.24.1
2025-05-15 22:23:47,230:INFO:    plotly-resampler: Not installed
2025-05-15 22:23:47,230:INFO:             kaleido: 0.2.1
2025-05-15 22:23:47,230:INFO:           schemdraw: 0.15
2025-05-15 22:23:47,231:INFO:         statsmodels: 0.14.4
2025-05-15 22:23:47,231:INFO:              sktime: 0.26.0
2025-05-15 22:23:47,231:INFO:               tbats: 1.1.3
2025-05-15 22:23:47,231:INFO:            pmdarima: 2.0.4
2025-05-15 22:23:47,231:INFO:              psutil: 7.0.0
2025-05-15 22:23:47,231:INFO:          markupsafe: 3.0.2
2025-05-15 22:23:47,231:INFO:             pickle5: Not installed
2025-05-15 22:23:47,231:INFO:         cloudpickle: 3.1.1
2025-05-15 22:23:47,231:INFO:         deprecation: 2.1.0
2025-05-15 22:23:47,231:INFO:              xxhash: 3.5.0
2025-05-15 22:23:47,231:INFO:           wurlitzer: 3.1.1
2025-05-15 22:23:47,231:INFO:PyCaret optional dependencies:
2025-05-15 22:23:47,231:INFO:                shap: 0.47.2
2025-05-15 22:23:47,231:INFO:           interpret: Not installed
2025-05-15 22:23:47,231:INFO:                umap: Not installed
2025-05-15 22:23:47,231:INFO:     ydata_profiling: Not installed
2025-05-15 22:23:47,231:INFO:  explainerdashboard: Not installed
2025-05-15 22:23:47,231:INFO:             autoviz: Not installed
2025-05-15 22:23:47,231:INFO:           fairlearn: Not installed
2025-05-15 22:23:47,231:INFO:          deepchecks: Not installed
2025-05-15 22:23:47,231:INFO:             xgboost: Not installed
2025-05-15 22:23:47,231:INFO:            catboost: 1.2.8
2025-05-15 22:23:47,231:INFO:              kmodes: Not installed
2025-05-15 22:23:47,231:INFO:             mlxtend: Not installed
2025-05-15 22:23:47,231:INFO:       statsforecast: Not installed
2025-05-15 22:23:47,231:INFO:        tune_sklearn: Not installed
2025-05-15 22:23:47,231:INFO:                 ray: Not installed
2025-05-15 22:23:47,231:INFO:            hyperopt: Not installed
2025-05-15 22:23:47,231:INFO:              optuna: 4.3.0
2025-05-15 22:23:47,231:INFO:               skopt: Not installed
2025-05-15 22:23:47,231:INFO:              mlflow: Not installed
2025-05-15 22:23:47,231:INFO:              gradio: Not installed
2025-05-15 22:23:47,231:INFO:             fastapi: Not installed
2025-05-15 22:23:47,231:INFO:             uvicorn: Not installed
2025-05-15 22:23:47,231:INFO:              m2cgen: Not installed
2025-05-15 22:23:47,231:INFO:           evidently: Not installed
2025-05-15 22:23:47,231:INFO:               fugue: Not installed
2025-05-15 22:23:47,231:INFO:           streamlit: Not installed
2025-05-15 22:23:47,231:INFO:             prophet: Not installed
2025-05-15 22:23:47,231:INFO:None
2025-05-15 22:23:47,231:INFO:Set up data.
2025-05-15 22:23:47,262:INFO:Set up folding strategy.
2025-05-15 22:23:47,263:INFO:Set up train/test split.
2025-05-15 22:23:47,276:INFO:Set up index.
2025-05-15 22:23:47,276:INFO:Assigning column types.
2025-05-15 22:23:47,279:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 22:23:47,297:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 22:23:47,298:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:23:47,309:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:23:47,310:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:23:47,328:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 22:23:47,329:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:23:47,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:23:47,340:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:23:47,340:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 22:23:47,358:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:23:47,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:23:47,370:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:23:47,388:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:23:47,399:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:23:47,400:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:23:47,400:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 22:23:47,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:23:47,429:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:23:47,458:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:23:47,458:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:23:47,459:INFO:Preparing preprocessing pipeline...
2025-05-15 22:23:47,460:INFO:Set up simple imputation.
2025-05-15 22:23:47,466:INFO:Set up encoding of ordinal features.
2025-05-15 22:23:47,475:INFO:Set up encoding of categorical features.
2025-05-15 22:23:47,475:INFO:Set up imbalanced handling.
2025-05-15 22:23:47,475:INFO:Set up column transformation.
2025-05-15 22:23:47,748:INFO:Finished creating preprocessing pipeline.
2025-05-15 22:23:47,768:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 22:23:47,768:INFO:Creating final display dataframe.
2025-05-15 22:23:48,168:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 15)
4        Transformed data shape      (106821, 28)
5   Transformed train set shape       (85902, 28)
6    Transformed test set shape       (20919, 28)
7              Numeric features                 5
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              d958
2025-05-15 22:23:48,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:23:48,201:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:23:48,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:23:48,231:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:23:48,232:INFO:setup() successfully completed in 1.01s...............
2025-05-15 22:23:48,232:INFO:Initializing compare_models()
2025-05-15 22:23:48,232:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-15 22:23:48,232:INFO:Checking exceptions
2025-05-15 22:23:48,237:INFO:Preparing display monitor
2025-05-15 22:23:48,253:INFO:Initializing Logistic Regression
2025-05-15 22:23:48,253:INFO:Total runtime is 1.8318494160970053e-06 minutes
2025-05-15 22:23:48,255:INFO:SubProcess create_model() called ==================================
2025-05-15 22:23:48,255:INFO:Initializing create_model()
2025-05-15 22:23:48,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:23:48,255:INFO:Checking exceptions
2025-05-15 22:23:48,255:INFO:Importing libraries
2025-05-15 22:23:48,255:INFO:Copying training dataset
2025-05-15 22:23:48,265:INFO:Defining folds
2025-05-15 22:23:48,265:INFO:Declaring metric variables
2025-05-15 22:23:48,266:INFO:Importing untrained model
2025-05-15 22:23:48,268:INFO:Logistic Regression Imported successfully
2025-05-15 22:23:48,270:INFO:Starting cross validation
2025-05-15 22:23:48,271:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:23:52,145:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:23:52,205:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:23:52,239:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:23:52,303:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:23:52,333:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:23:52,399:INFO:Calculating mean and std
2025-05-15 22:23:52,400:INFO:Creating metrics dataframe
2025-05-15 22:23:52,401:INFO:Uploading results into container
2025-05-15 22:23:52,401:INFO:Uploading model into container now
2025-05-15 22:23:52,401:INFO:_master_model_container: 1
2025-05-15 22:23:52,401:INFO:_display_container: 2
2025-05-15 22:23:52,401:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 22:23:52,401:INFO:create_model() successfully completed......................................
2025-05-15 22:23:52,576:INFO:SubProcess create_model() end ==================================
2025-05-15 22:23:52,576:INFO:Creating metrics dataframe
2025-05-15 22:23:52,578:INFO:Initializing K Neighbors Classifier
2025-05-15 22:23:52,578:INFO:Total runtime is 0.07208968003590902 minutes
2025-05-15 22:23:52,580:INFO:SubProcess create_model() called ==================================
2025-05-15 22:23:52,580:INFO:Initializing create_model()
2025-05-15 22:23:52,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:23:52,580:INFO:Checking exceptions
2025-05-15 22:23:52,580:INFO:Importing libraries
2025-05-15 22:23:52,580:INFO:Copying training dataset
2025-05-15 22:23:52,589:INFO:Defining folds
2025-05-15 22:23:52,589:INFO:Declaring metric variables
2025-05-15 22:23:52,590:INFO:Importing untrained model
2025-05-15 22:23:52,591:INFO:K Neighbors Classifier Imported successfully
2025-05-15 22:23:52,593:INFO:Starting cross validation
2025-05-15 22:23:52,594:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:23:57,236:INFO:Calculating mean and std
2025-05-15 22:23:57,237:INFO:Creating metrics dataframe
2025-05-15 22:23:57,240:INFO:Uploading results into container
2025-05-15 22:23:57,240:INFO:Uploading model into container now
2025-05-15 22:23:57,240:INFO:_master_model_container: 2
2025-05-15 22:23:57,241:INFO:_display_container: 2
2025-05-15 22:23:57,241:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-15 22:23:57,241:INFO:create_model() successfully completed......................................
2025-05-15 22:23:57,390:INFO:SubProcess create_model() end ==================================
2025-05-15 22:23:57,390:INFO:Creating metrics dataframe
2025-05-15 22:23:57,394:INFO:Initializing Naive Bayes
2025-05-15 22:23:57,394:INFO:Total runtime is 0.1523421009381612 minutes
2025-05-15 22:23:57,395:INFO:SubProcess create_model() called ==================================
2025-05-15 22:23:57,395:INFO:Initializing create_model()
2025-05-15 22:23:57,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:23:57,395:INFO:Checking exceptions
2025-05-15 22:23:57,395:INFO:Importing libraries
2025-05-15 22:23:57,395:INFO:Copying training dataset
2025-05-15 22:23:57,413:INFO:Defining folds
2025-05-15 22:23:57,413:INFO:Declaring metric variables
2025-05-15 22:23:57,415:INFO:Importing untrained model
2025-05-15 22:23:57,416:INFO:Naive Bayes Imported successfully
2025-05-15 22:23:57,418:INFO:Starting cross validation
2025-05-15 22:23:57,419:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:23:58,534:INFO:Calculating mean and std
2025-05-15 22:23:58,535:INFO:Creating metrics dataframe
2025-05-15 22:23:58,535:INFO:Uploading results into container
2025-05-15 22:23:58,536:INFO:Uploading model into container now
2025-05-15 22:23:58,536:INFO:_master_model_container: 3
2025-05-15 22:23:58,536:INFO:_display_container: 2
2025-05-15 22:23:58,536:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-15 22:23:58,536:INFO:create_model() successfully completed......................................
2025-05-15 22:23:58,649:INFO:SubProcess create_model() end ==================================
2025-05-15 22:23:58,649:INFO:Creating metrics dataframe
2025-05-15 22:23:58,652:INFO:Initializing Decision Tree Classifier
2025-05-15 22:23:58,652:INFO:Total runtime is 0.17332111597061156 minutes
2025-05-15 22:23:58,654:INFO:SubProcess create_model() called ==================================
2025-05-15 22:23:58,654:INFO:Initializing create_model()
2025-05-15 22:23:58,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:23:58,654:INFO:Checking exceptions
2025-05-15 22:23:58,654:INFO:Importing libraries
2025-05-15 22:23:58,654:INFO:Copying training dataset
2025-05-15 22:23:58,667:INFO:Defining folds
2025-05-15 22:23:58,667:INFO:Declaring metric variables
2025-05-15 22:23:58,668:INFO:Importing untrained model
2025-05-15 22:23:58,669:INFO:Decision Tree Classifier Imported successfully
2025-05-15 22:23:58,671:INFO:Starting cross validation
2025-05-15 22:23:58,672:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:24:00,317:INFO:Calculating mean and std
2025-05-15 22:24:00,318:INFO:Creating metrics dataframe
2025-05-15 22:24:00,319:INFO:Uploading results into container
2025-05-15 22:24:00,319:INFO:Uploading model into container now
2025-05-15 22:24:00,319:INFO:_master_model_container: 4
2025-05-15 22:24:00,319:INFO:_display_container: 2
2025-05-15 22:24:00,319:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-15 22:24:00,319:INFO:create_model() successfully completed......................................
2025-05-15 22:24:00,442:INFO:SubProcess create_model() end ==================================
2025-05-15 22:24:00,442:INFO:Creating metrics dataframe
2025-05-15 22:24:00,446:INFO:Initializing SVM - Linear Kernel
2025-05-15 22:24:00,446:INFO:Total runtime is 0.20321143468221028 minutes
2025-05-15 22:24:00,447:INFO:SubProcess create_model() called ==================================
2025-05-15 22:24:00,447:INFO:Initializing create_model()
2025-05-15 22:24:00,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:24:00,447:INFO:Checking exceptions
2025-05-15 22:24:00,447:INFO:Importing libraries
2025-05-15 22:24:00,447:INFO:Copying training dataset
2025-05-15 22:24:00,457:INFO:Defining folds
2025-05-15 22:24:00,457:INFO:Declaring metric variables
2025-05-15 22:24:00,459:INFO:Importing untrained model
2025-05-15 22:24:00,460:INFO:SVM - Linear Kernel Imported successfully
2025-05-15 22:24:00,462:INFO:Starting cross validation
2025-05-15 22:24:00,464:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:24:03,598:INFO:Calculating mean and std
2025-05-15 22:24:03,601:INFO:Creating metrics dataframe
2025-05-15 22:24:03,604:INFO:Uploading results into container
2025-05-15 22:24:03,604:INFO:Uploading model into container now
2025-05-15 22:24:03,604:INFO:_master_model_container: 5
2025-05-15 22:24:03,604:INFO:_display_container: 2
2025-05-15 22:24:03,605:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-15 22:24:03,605:INFO:create_model() successfully completed......................................
2025-05-15 22:24:03,800:INFO:SubProcess create_model() end ==================================
2025-05-15 22:24:03,801:INFO:Creating metrics dataframe
2025-05-15 22:24:03,804:INFO:Initializing Ridge Classifier
2025-05-15 22:24:03,804:INFO:Total runtime is 0.25918576717376707 minutes
2025-05-15 22:24:03,805:INFO:SubProcess create_model() called ==================================
2025-05-15 22:24:03,806:INFO:Initializing create_model()
2025-05-15 22:24:03,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:24:03,806:INFO:Checking exceptions
2025-05-15 22:24:03,806:INFO:Importing libraries
2025-05-15 22:24:03,806:INFO:Copying training dataset
2025-05-15 22:24:03,817:INFO:Defining folds
2025-05-15 22:24:03,817:INFO:Declaring metric variables
2025-05-15 22:24:03,819:INFO:Importing untrained model
2025-05-15 22:24:03,820:INFO:Ridge Classifier Imported successfully
2025-05-15 22:24:03,823:INFO:Starting cross validation
2025-05-15 22:24:03,825:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:24:04,972:INFO:Calculating mean and std
2025-05-15 22:24:04,973:INFO:Creating metrics dataframe
2025-05-15 22:24:04,973:INFO:Uploading results into container
2025-05-15 22:24:04,974:INFO:Uploading model into container now
2025-05-15 22:24:04,974:INFO:_master_model_container: 6
2025-05-15 22:24:04,974:INFO:_display_container: 2
2025-05-15 22:24:04,974:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-15 22:24:04,974:INFO:create_model() successfully completed......................................
2025-05-15 22:24:05,096:INFO:SubProcess create_model() end ==================================
2025-05-15 22:24:05,096:INFO:Creating metrics dataframe
2025-05-15 22:24:05,099:INFO:Initializing Random Forest Classifier
2025-05-15 22:24:05,100:INFO:Total runtime is 0.2807738979657491 minutes
2025-05-15 22:24:05,101:INFO:SubProcess create_model() called ==================================
2025-05-15 22:24:05,101:INFO:Initializing create_model()
2025-05-15 22:24:05,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:24:05,101:INFO:Checking exceptions
2025-05-15 22:24:05,101:INFO:Importing libraries
2025-05-15 22:24:05,101:INFO:Copying training dataset
2025-05-15 22:24:05,111:INFO:Defining folds
2025-05-15 22:24:05,111:INFO:Declaring metric variables
2025-05-15 22:24:05,112:INFO:Importing untrained model
2025-05-15 22:24:05,113:INFO:Random Forest Classifier Imported successfully
2025-05-15 22:24:05,116:INFO:Starting cross validation
2025-05-15 22:24:05,117:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:24:10,782:INFO:Calculating mean and std
2025-05-15 22:24:10,784:INFO:Creating metrics dataframe
2025-05-15 22:24:10,787:INFO:Uploading results into container
2025-05-15 22:24:10,788:INFO:Uploading model into container now
2025-05-15 22:24:10,789:INFO:_master_model_container: 7
2025-05-15 22:24:10,789:INFO:_display_container: 2
2025-05-15 22:24:10,791:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 22:24:10,791:INFO:create_model() successfully completed......................................
2025-05-15 22:24:10,981:INFO:SubProcess create_model() end ==================================
2025-05-15 22:24:10,981:INFO:Creating metrics dataframe
2025-05-15 22:24:10,985:INFO:Initializing Quadratic Discriminant Analysis
2025-05-15 22:24:10,985:INFO:Total runtime is 0.3788695971171061 minutes
2025-05-15 22:24:10,986:INFO:SubProcess create_model() called ==================================
2025-05-15 22:24:10,987:INFO:Initializing create_model()
2025-05-15 22:24:10,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:24:10,987:INFO:Checking exceptions
2025-05-15 22:24:10,987:INFO:Importing libraries
2025-05-15 22:24:10,987:INFO:Copying training dataset
2025-05-15 22:24:10,999:INFO:Defining folds
2025-05-15 22:24:10,999:INFO:Declaring metric variables
2025-05-15 22:24:11,001:INFO:Importing untrained model
2025-05-15 22:24:11,002:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 22:24:11,005:INFO:Starting cross validation
2025-05-15 22:24:11,006:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:24:12,032:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:24:12,055:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:24:12,067:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:24:12,082:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:24:12,111:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:24:12,132:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:24:12,141:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:24:12,152:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:24:12,167:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:24:12,186:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:24:12,191:INFO:Calculating mean and std
2025-05-15 22:24:12,191:INFO:Creating metrics dataframe
2025-05-15 22:24:12,192:INFO:Uploading results into container
2025-05-15 22:24:12,192:INFO:Uploading model into container now
2025-05-15 22:24:12,193:INFO:_master_model_container: 8
2025-05-15 22:24:12,193:INFO:_display_container: 2
2025-05-15 22:24:12,193:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 22:24:12,193:INFO:create_model() successfully completed......................................
2025-05-15 22:24:12,318:INFO:SubProcess create_model() end ==================================
2025-05-15 22:24:12,318:INFO:Creating metrics dataframe
2025-05-15 22:24:12,321:INFO:Initializing Ada Boost Classifier
2025-05-15 22:24:12,321:INFO:Total runtime is 0.4011382977167765 minutes
2025-05-15 22:24:12,323:INFO:SubProcess create_model() called ==================================
2025-05-15 22:24:12,323:INFO:Initializing create_model()
2025-05-15 22:24:12,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:24:12,323:INFO:Checking exceptions
2025-05-15 22:24:12,323:INFO:Importing libraries
2025-05-15 22:24:12,323:INFO:Copying training dataset
2025-05-15 22:24:12,338:INFO:Defining folds
2025-05-15 22:24:12,338:INFO:Declaring metric variables
2025-05-15 22:24:12,340:INFO:Importing untrained model
2025-05-15 22:24:12,341:INFO:Ada Boost Classifier Imported successfully
2025-05-15 22:24:12,344:INFO:Starting cross validation
2025-05-15 22:24:12,345:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:24:13,315:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:24:13,344:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:24:13,370:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:24:13,418:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:24:13,444:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:24:16,113:INFO:Calculating mean and std
2025-05-15 22:24:16,113:INFO:Creating metrics dataframe
2025-05-15 22:24:16,114:INFO:Uploading results into container
2025-05-15 22:24:16,114:INFO:Uploading model into container now
2025-05-15 22:24:16,115:INFO:_master_model_container: 9
2025-05-15 22:24:16,115:INFO:_display_container: 2
2025-05-15 22:24:16,115:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-15 22:24:16,115:INFO:create_model() successfully completed......................................
2025-05-15 22:24:16,241:INFO:SubProcess create_model() end ==================================
2025-05-15 22:24:16,241:INFO:Creating metrics dataframe
2025-05-15 22:24:16,245:INFO:Initializing Gradient Boosting Classifier
2025-05-15 22:24:16,245:INFO:Total runtime is 0.4665345470110575 minutes
2025-05-15 22:24:16,246:INFO:SubProcess create_model() called ==================================
2025-05-15 22:24:16,247:INFO:Initializing create_model()
2025-05-15 22:24:16,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:24:16,247:INFO:Checking exceptions
2025-05-15 22:24:16,247:INFO:Importing libraries
2025-05-15 22:24:16,247:INFO:Copying training dataset
2025-05-15 22:24:16,255:INFO:Defining folds
2025-05-15 22:24:16,255:INFO:Declaring metric variables
2025-05-15 22:24:16,256:INFO:Importing untrained model
2025-05-15 22:24:16,258:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 22:24:16,260:INFO:Starting cross validation
2025-05-15 22:24:16,261:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:24:29,714:INFO:Calculating mean and std
2025-05-15 22:24:29,717:INFO:Creating metrics dataframe
2025-05-15 22:24:29,719:INFO:Uploading results into container
2025-05-15 22:24:29,719:INFO:Uploading model into container now
2025-05-15 22:24:29,719:INFO:_master_model_container: 10
2025-05-15 22:24:29,719:INFO:_display_container: 2
2025-05-15 22:24:29,720:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 22:24:29,720:INFO:create_model() successfully completed......................................
2025-05-15 22:24:29,931:INFO:SubProcess create_model() end ==================================
2025-05-15 22:24:29,931:INFO:Creating metrics dataframe
2025-05-15 22:24:29,936:INFO:Initializing Linear Discriminant Analysis
2025-05-15 22:24:29,936:INFO:Total runtime is 0.6947175979614257 minutes
2025-05-15 22:24:29,938:INFO:SubProcess create_model() called ==================================
2025-05-15 22:24:29,938:INFO:Initializing create_model()
2025-05-15 22:24:29,938:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:24:29,939:INFO:Checking exceptions
2025-05-15 22:24:29,939:INFO:Importing libraries
2025-05-15 22:24:29,939:INFO:Copying training dataset
2025-05-15 22:24:29,961:INFO:Defining folds
2025-05-15 22:24:29,961:INFO:Declaring metric variables
2025-05-15 22:24:29,962:INFO:Importing untrained model
2025-05-15 22:24:29,964:INFO:Linear Discriminant Analysis Imported successfully
2025-05-15 22:24:29,966:INFO:Starting cross validation
2025-05-15 22:24:29,968:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:24:31,210:INFO:Calculating mean and std
2025-05-15 22:24:31,210:INFO:Creating metrics dataframe
2025-05-15 22:24:31,211:INFO:Uploading results into container
2025-05-15 22:24:31,212:INFO:Uploading model into container now
2025-05-15 22:24:31,212:INFO:_master_model_container: 11
2025-05-15 22:24:31,212:INFO:_display_container: 2
2025-05-15 22:24:31,212:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-15 22:24:31,212:INFO:create_model() successfully completed......................................
2025-05-15 22:24:31,328:INFO:SubProcess create_model() end ==================================
2025-05-15 22:24:31,328:INFO:Creating metrics dataframe
2025-05-15 22:24:31,332:INFO:Initializing Extra Trees Classifier
2025-05-15 22:24:31,332:INFO:Total runtime is 0.7179779489835103 minutes
2025-05-15 22:24:31,333:INFO:SubProcess create_model() called ==================================
2025-05-15 22:24:31,333:INFO:Initializing create_model()
2025-05-15 22:24:31,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:24:31,333:INFO:Checking exceptions
2025-05-15 22:24:31,333:INFO:Importing libraries
2025-05-15 22:24:31,333:INFO:Copying training dataset
2025-05-15 22:24:31,343:INFO:Defining folds
2025-05-15 22:24:31,343:INFO:Declaring metric variables
2025-05-15 22:24:31,344:INFO:Importing untrained model
2025-05-15 22:24:31,346:INFO:Extra Trees Classifier Imported successfully
2025-05-15 22:24:31,348:INFO:Starting cross validation
2025-05-15 22:24:31,349:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:24:35,677:INFO:Calculating mean and std
2025-05-15 22:24:35,688:INFO:Creating metrics dataframe
2025-05-15 22:24:35,694:INFO:Uploading results into container
2025-05-15 22:24:35,694:INFO:Uploading model into container now
2025-05-15 22:24:35,695:INFO:_master_model_container: 12
2025-05-15 22:24:35,695:INFO:_display_container: 2
2025-05-15 22:24:35,696:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 22:24:35,698:INFO:create_model() successfully completed......................................
2025-05-15 22:24:35,942:INFO:SubProcess create_model() end ==================================
2025-05-15 22:24:35,942:INFO:Creating metrics dataframe
2025-05-15 22:24:35,947:INFO:Initializing Light Gradient Boosting Machine
2025-05-15 22:24:35,947:INFO:Total runtime is 0.7948928157488505 minutes
2025-05-15 22:24:35,948:INFO:SubProcess create_model() called ==================================
2025-05-15 22:24:35,948:INFO:Initializing create_model()
2025-05-15 22:24:35,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:24:35,948:INFO:Checking exceptions
2025-05-15 22:24:35,948:INFO:Importing libraries
2025-05-15 22:24:35,948:INFO:Copying training dataset
2025-05-15 22:24:35,975:INFO:Defining folds
2025-05-15 22:24:35,976:INFO:Declaring metric variables
2025-05-15 22:24:35,978:INFO:Importing untrained model
2025-05-15 22:24:35,979:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 22:24:35,982:INFO:Starting cross validation
2025-05-15 22:24:35,983:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:24:39,888:INFO:Calculating mean and std
2025-05-15 22:24:39,889:INFO:Creating metrics dataframe
2025-05-15 22:24:39,891:INFO:Uploading results into container
2025-05-15 22:24:39,892:INFO:Uploading model into container now
2025-05-15 22:24:39,892:INFO:_master_model_container: 13
2025-05-15 22:24:39,892:INFO:_display_container: 2
2025-05-15 22:24:39,893:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:24:39,893:INFO:create_model() successfully completed......................................
2025-05-15 22:24:40,037:INFO:SubProcess create_model() end ==================================
2025-05-15 22:24:40,037:INFO:Creating metrics dataframe
2025-05-15 22:24:40,042:INFO:Initializing CatBoost Classifier
2025-05-15 22:24:40,042:INFO:Total runtime is 0.8631528814633688 minutes
2025-05-15 22:24:40,044:INFO:SubProcess create_model() called ==================================
2025-05-15 22:24:40,044:INFO:Initializing create_model()
2025-05-15 22:24:40,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:24:40,044:INFO:Checking exceptions
2025-05-15 22:24:40,044:INFO:Importing libraries
2025-05-15 22:24:40,044:INFO:Copying training dataset
2025-05-15 22:24:40,053:INFO:Defining folds
2025-05-15 22:24:40,053:INFO:Declaring metric variables
2025-05-15 22:24:40,055:INFO:Importing untrained model
2025-05-15 22:24:40,057:INFO:CatBoost Classifier Imported successfully
2025-05-15 22:24:40,059:INFO:Starting cross validation
2025-05-15 22:24:40,060:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:24:56,847:INFO:Calculating mean and std
2025-05-15 22:24:56,850:INFO:Creating metrics dataframe
2025-05-15 22:24:56,851:INFO:Uploading results into container
2025-05-15 22:24:56,852:INFO:Uploading model into container now
2025-05-15 22:24:56,852:INFO:_master_model_container: 14
2025-05-15 22:24:56,852:INFO:_display_container: 2
2025-05-15 22:24:56,852:INFO:<catboost.core.CatBoostClassifier object at 0x373c1ca50>
2025-05-15 22:24:56,852:INFO:create_model() successfully completed......................................
2025-05-15 22:24:56,999:INFO:SubProcess create_model() end ==================================
2025-05-15 22:24:56,999:INFO:Creating metrics dataframe
2025-05-15 22:24:57,004:INFO:Initializing Dummy Classifier
2025-05-15 22:24:57,004:INFO:Total runtime is 1.145849879582723 minutes
2025-05-15 22:24:57,005:INFO:SubProcess create_model() called ==================================
2025-05-15 22:24:57,006:INFO:Initializing create_model()
2025-05-15 22:24:57,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x381436890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:24:57,006:INFO:Checking exceptions
2025-05-15 22:24:57,006:INFO:Importing libraries
2025-05-15 22:24:57,006:INFO:Copying training dataset
2025-05-15 22:24:57,016:INFO:Defining folds
2025-05-15 22:24:57,016:INFO:Declaring metric variables
2025-05-15 22:24:57,018:INFO:Importing untrained model
2025-05-15 22:24:57,019:INFO:Dummy Classifier Imported successfully
2025-05-15 22:24:57,022:INFO:Starting cross validation
2025-05-15 22:24:57,023:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:24:57,988:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:24:58,074:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:24:58,079:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:24:58,099:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:24:59,356:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:24:59,366:INFO:Calculating mean and std
2025-05-15 22:24:59,366:INFO:Creating metrics dataframe
2025-05-15 22:24:59,368:INFO:Uploading results into container
2025-05-15 22:24:59,369:INFO:Uploading model into container now
2025-05-15 22:24:59,369:INFO:_master_model_container: 15
2025-05-15 22:24:59,370:INFO:_display_container: 2
2025-05-15 22:24:59,370:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-15 22:24:59,371:INFO:create_model() successfully completed......................................
2025-05-15 22:24:59,559:INFO:SubProcess create_model() end ==================================
2025-05-15 22:24:59,559:INFO:Creating metrics dataframe
2025-05-15 22:24:59,564:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-15 22:24:59,567:INFO:Initializing create_model()
2025-05-15 22:24:59,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:24:59,567:INFO:Checking exceptions
2025-05-15 22:24:59,568:INFO:Importing libraries
2025-05-15 22:24:59,568:INFO:Copying training dataset
2025-05-15 22:24:59,578:INFO:Defining folds
2025-05-15 22:24:59,578:INFO:Declaring metric variables
2025-05-15 22:24:59,578:INFO:Importing untrained model
2025-05-15 22:24:59,578:INFO:Declaring custom model
2025-05-15 22:24:59,579:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 22:24:59,579:INFO:Cross validation set to False
2025-05-15 22:24:59,579:INFO:Fitting Model
2025-05-15 22:25:00,869:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 22:25:00,878:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004210 seconds.
2025-05-15 22:25:00,878:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 22:25:00,878:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 22:25:00,878:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-15 22:25:00,878:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 27
2025-05-15 22:25:00,878:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 22:25:01,645:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:25:01,645:INFO:create_model() successfully completed......................................
2025-05-15 22:25:01,762:INFO:Initializing create_model()
2025-05-15 22:25:01,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:25:01,762:INFO:Checking exceptions
2025-05-15 22:25:01,763:INFO:Importing libraries
2025-05-15 22:25:01,763:INFO:Copying training dataset
2025-05-15 22:25:01,771:INFO:Defining folds
2025-05-15 22:25:01,771:INFO:Declaring metric variables
2025-05-15 22:25:01,771:INFO:Importing untrained model
2025-05-15 22:25:01,771:INFO:Declaring custom model
2025-05-15 22:25:01,772:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 22:25:01,772:INFO:Cross validation set to False
2025-05-15 22:25:01,772:INFO:Fitting Model
2025-05-15 22:25:17,362:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 22:25:17,363:INFO:create_model() successfully completed......................................
2025-05-15 22:25:17,476:INFO:Initializing create_model()
2025-05-15 22:25:17,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=<catboost.core.CatBoostClassifier object at 0x373c1ca50>, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:25:17,476:INFO:Checking exceptions
2025-05-15 22:25:17,477:INFO:Importing libraries
2025-05-15 22:25:17,477:INFO:Copying training dataset
2025-05-15 22:25:17,485:INFO:Defining folds
2025-05-15 22:25:17,485:INFO:Declaring metric variables
2025-05-15 22:25:17,485:INFO:Importing untrained model
2025-05-15 22:25:17,485:INFO:Declaring custom model
2025-05-15 22:25:17,485:INFO:CatBoost Classifier Imported successfully
2025-05-15 22:25:17,486:INFO:Cross validation set to False
2025-05-15 22:25:17,486:INFO:Fitting Model
2025-05-15 22:25:24,394:INFO:<catboost.core.CatBoostClassifier object at 0x32eded210>
2025-05-15 22:25:24,394:INFO:create_model() successfully completed......................................
2025-05-15 22:25:24,513:INFO:_master_model_container: 15
2025-05-15 22:25:24,513:INFO:_display_container: 2
2025-05-15 22:25:24,514:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), <catboost.core.CatBoostClassifier object at 0x32eded210>]
2025-05-15 22:25:24,514:INFO:compare_models() successfully completed......................................
2025-05-15 22:25:24,515:INFO:Initializing evaluate_model()
2025-05-15 22:25:24,515:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 22:25:24,521:INFO:Initializing plot_model()
2025-05-15 22:25:24,521:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 22:25:24,521:INFO:Checking exceptions
2025-05-15 22:25:24,525:INFO:Preloading libraries
2025-05-15 22:25:24,527:INFO:Copying training dataset
2025-05-15 22:25:24,527:INFO:Plot type: pipeline
2025-05-15 22:25:24,587:INFO:Visual Rendered Successfully
2025-05-15 22:25:24,704:INFO:plot_model() successfully completed......................................
2025-05-15 22:25:24,706:INFO:Initializing tune_model()
2025-05-15 22:25:24,706:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-15 22:25:24,706:INFO:Checking exceptions
2025-05-15 22:25:24,715:INFO:Copying training dataset
2025-05-15 22:25:24,723:INFO:Checking base model
2025-05-15 22:25:24,723:INFO:Base model : Light Gradient Boosting Machine
2025-05-15 22:25:24,724:INFO:Declaring metric variables
2025-05-15 22:25:24,727:INFO:Defining Hyperparameters
2025-05-15 22:25:24,848:INFO:Tuning with n_jobs=-1
2025-05-15 22:25:24,848:INFO:Initializing RandomizedSearchCV
2025-05-15 22:25:58,985:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-15 22:25:58,988:INFO:Hyperparameter search completed
2025-05-15 22:25:58,988:INFO:SubProcess create_model() called ==================================
2025-05-15 22:25:58,989:INFO:Initializing create_model()
2025-05-15 22:25:58,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36ed02850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-15 22:25:58,989:INFO:Checking exceptions
2025-05-15 22:25:58,989:INFO:Importing libraries
2025-05-15 22:25:58,989:INFO:Copying training dataset
2025-05-15 22:25:59,004:INFO:Defining folds
2025-05-15 22:25:59,004:INFO:Declaring metric variables
2025-05-15 22:25:59,015:INFO:Importing untrained model
2025-05-15 22:25:59,015:INFO:Declaring custom model
2025-05-15 22:25:59,018:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 22:25:59,020:INFO:Starting cross validation
2025-05-15 22:25:59,022:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:26:05,237:INFO:Calculating mean and std
2025-05-15 22:26:05,238:INFO:Creating metrics dataframe
2025-05-15 22:26:05,241:INFO:Finalizing model
2025-05-15 22:26:06,231:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 22:26:06,232:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 22:26:06,232:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 22:26:06,261:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 22:26:06,261:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 22:26:06,261:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 22:26:06,261:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 22:26:06,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004594 seconds.
2025-05-15 22:26:06,270:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 22:26:06,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 22:26:06,270:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-15 22:26:06,270:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 27
2025-05-15 22:26:06,271:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 22:26:07,729:INFO:Uploading results into container
2025-05-15 22:26:07,730:INFO:Uploading model into container now
2025-05-15 22:26:07,731:INFO:_master_model_container: 16
2025-05-15 22:26:07,731:INFO:_display_container: 3
2025-05-15 22:26:07,731:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:26:07,731:INFO:create_model() successfully completed......................................
2025-05-15 22:26:07,923:INFO:SubProcess create_model() end ==================================
2025-05-15 22:26:07,923:INFO:choose_better activated
2025-05-15 22:26:07,925:INFO:SubProcess create_model() called ==================================
2025-05-15 22:26:07,925:INFO:Initializing create_model()
2025-05-15 22:26:07,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:26:07,925:INFO:Checking exceptions
2025-05-15 22:26:07,926:INFO:Importing libraries
2025-05-15 22:26:07,926:INFO:Copying training dataset
2025-05-15 22:26:07,935:INFO:Defining folds
2025-05-15 22:26:07,935:INFO:Declaring metric variables
2025-05-15 22:26:07,935:INFO:Importing untrained model
2025-05-15 22:26:07,935:INFO:Declaring custom model
2025-05-15 22:26:07,935:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 22:26:07,935:INFO:Starting cross validation
2025-05-15 22:26:07,936:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:26:11,903:INFO:Calculating mean and std
2025-05-15 22:26:11,903:INFO:Creating metrics dataframe
2025-05-15 22:26:11,904:INFO:Finalizing model
2025-05-15 22:26:12,890:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 22:26:12,899:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004422 seconds.
2025-05-15 22:26:12,899:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 22:26:12,899:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 22:26:12,899:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-15 22:26:12,899:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 27
2025-05-15 22:26:12,900:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 22:26:13,668:INFO:Uploading results into container
2025-05-15 22:26:13,669:INFO:Uploading model into container now
2025-05-15 22:26:13,669:INFO:_master_model_container: 17
2025-05-15 22:26:13,669:INFO:_display_container: 4
2025-05-15 22:26:13,669:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:26:13,669:INFO:create_model() successfully completed......................................
2025-05-15 22:26:13,781:INFO:SubProcess create_model() end ==================================
2025-05-15 22:26:13,781:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4636
2025-05-15 22:26:13,781:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4903
2025-05-15 22:26:13,782:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-15 22:26:13,782:INFO:choose_better completed
2025-05-15 22:26:13,785:INFO:_master_model_container: 17
2025-05-15 22:26:13,785:INFO:_display_container: 3
2025-05-15 22:26:13,786:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:26:13,786:INFO:tune_model() successfully completed......................................
2025-05-15 22:26:13,905:INFO:Initializing evaluate_model()
2025-05-15 22:26:13,905:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 22:26:13,912:INFO:Initializing plot_model()
2025-05-15 22:26:13,912:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 22:26:13,912:INFO:Checking exceptions
2025-05-15 22:26:13,916:INFO:Preloading libraries
2025-05-15 22:26:13,920:INFO:Copying training dataset
2025-05-15 22:26:13,920:INFO:Plot type: pipeline
2025-05-15 22:26:13,979:INFO:Visual Rendered Successfully
2025-05-15 22:26:14,097:INFO:plot_model() successfully completed......................................
2025-05-15 22:26:14,098:INFO:Initializing interpret_model()
2025-05-15 22:26:14,098:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-15 22:26:14,099:INFO:Checking exceptions
2025-05-15 22:26:14,099:INFO:Soft dependency imported: shap: 0.47.2
2025-05-15 22:26:14,187:INFO:plot type: summary
2025-05-15 22:26:14,187:INFO:Creating TreeExplainer
2025-05-15 22:26:14,261:INFO:Compiling shap values
2025-05-15 22:26:15,215:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray
  warnings.warn(

2025-05-15 22:26:15,215:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-05-15 22:26:16,473:INFO:Visual Rendered Successfully
2025-05-15 22:26:16,473:INFO:interpret_model() successfully completed......................................
2025-05-15 22:26:16,590:INFO:Initializing finalize_model()
2025-05-15 22:26:16,590:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-15 22:26:16,591:INFO:Finalizing LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:26:16,594:INFO:Initializing create_model()
2025-05-15 22:26:16,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:26:16,594:INFO:Checking exceptions
2025-05-15 22:26:16,595:INFO:Importing libraries
2025-05-15 22:26:16,595:INFO:Copying training dataset
2025-05-15 22:26:16,595:INFO:Defining folds
2025-05-15 22:26:16,595:INFO:Declaring metric variables
2025-05-15 22:26:16,595:INFO:Importing untrained model
2025-05-15 22:26:16,595:INFO:Declaring custom model
2025-05-15 22:26:16,595:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 22:26:16,596:INFO:Cross validation set to False
2025-05-15 22:26:16,596:INFO:Fitting Model
2025-05-15 22:26:17,877:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 22:26:17,877:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 22:26:17,877:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 22:26:17,920:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-15 22:26:17,920:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-15 22:26:17,920:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-15 22:26:17,920:INFO:[LightGBM] [Info] Number of positive: 61360, number of negative: 61360
2025-05-15 22:26:17,932:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005726 seconds.
2025-05-15 22:26:17,932:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 22:26:17,932:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 22:26:17,932:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-15 22:26:17,933:INFO:[LightGBM] [Info] Number of data points in the train set: 122720, number of used features: 27
2025-05-15 22:26:17,933:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 22:26:19,484:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 22:26:19,484:INFO:create_model() successfully completed......................................
2025-05-15 22:26:19,598:INFO:_master_model_container: 17
2025-05-15 22:26:19,598:INFO:_display_container: 3
2025-05-15 22:26:19,618:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 22:26:19,618:INFO:finalize_model() successfully completed......................................
2025-05-15 22:26:19,770:INFO:Initializing save_model()
2025-05-15 22:26:19,770:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-15 22:26:19,770:INFO:Adding model into prep_pipe
2025-05-15 22:26:19,770:WARNING:Only Model saved as it was a pipeline.
2025-05-15 22:26:19,777:INFO:final_cancer_model.pkl saved in current working directory
2025-05-15 22:26:19,797:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-15 22:26:19,797:INFO:save_model() successfully completed......................................
2025-05-15 22:26:19,932:INFO:Initializing predict_model()
2025-05-15 22:26:19,932:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x32f0022a0>)
2025-05-15 22:26:19,932:INFO:Checking exceptions
2025-05-15 22:26:19,932:INFO:Preloading libraries
2025-05-15 22:26:19,933:INFO:Set up data.
2025-05-15 22:26:19,951:INFO:Set up index.
2025-05-15 22:26:20,329:INFO:Initializing plot_model()
2025-05-15 22:26:20,329:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 22:26:20,329:INFO:Checking exceptions
2025-05-15 22:26:20,335:INFO:Preloading libraries
2025-05-15 22:26:20,337:INFO:Copying training dataset
2025-05-15 22:26:20,337:INFO:Plot type: confusion_matrix
2025-05-15 22:26:20,537:INFO:Fitting Model
2025-05-15 22:26:20,537:INFO:Scoring test/hold-out set
2025-05-15 22:26:20,613:INFO:Visual Rendered Successfully
2025-05-15 22:26:20,727:INFO:plot_model() successfully completed......................................
2025-05-15 22:26:20,728:INFO:Initializing plot_model()
2025-05-15 22:26:20,728:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 22:26:20,728:INFO:Checking exceptions
2025-05-15 22:26:20,732:INFO:Preloading libraries
2025-05-15 22:26:20,734:INFO:Copying training dataset
2025-05-15 22:26:20,734:INFO:Plot type: auc
2025-05-15 22:26:20,931:INFO:Fitting Model
2025-05-15 22:26:20,933:INFO:Scoring test/hold-out set
2025-05-15 22:26:21,061:INFO:Visual Rendered Successfully
2025-05-15 22:26:21,176:INFO:plot_model() successfully completed......................................
2025-05-15 22:26:21,177:INFO:Initializing plot_model()
2025-05-15 22:26:21,177:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x373824050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 22:26:21,177:INFO:Checking exceptions
2025-05-15 22:26:21,181:INFO:Preloading libraries
2025-05-15 22:26:21,182:INFO:Copying training dataset
2025-05-15 22:26:21,182:INFO:Plot type: feature
2025-05-15 22:26:21,183:WARNING:No coef_ found. Trying feature_importances_
2025-05-15 22:26:21,252:INFO:Visual Rendered Successfully
2025-05-15 22:26:21,367:INFO:plot_model() successfully completed......................................
2025-05-15 22:26:55,492:INFO:PyCaret ClassificationExperiment
2025-05-15 22:26:55,492:INFO:Logging name: clf-default-name
2025-05-15 22:26:55,492:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 22:26:55,492:INFO:version 3.3.2
2025-05-15 22:26:55,492:INFO:Initializing setup()
2025-05-15 22:26:55,492:INFO:self.USI: a0e5
2025-05-15 22:26:55,492:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-15 22:26:55,492:INFO:Checking environment
2025-05-15 22:26:55,492:INFO:python_version: 3.11.0
2025-05-15 22:26:55,492:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 22:26:55,492:INFO:machine: arm64
2025-05-15 22:26:55,492:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 22:26:55,492:INFO:Memory: svmem(total=17179869184, available=3313958912, percent=80.7, used=5981470720, free=72843264, active=3260252160, inactive=3234840576, wired=2721218560)
2025-05-15 22:26:55,492:INFO:Physical Core: 12
2025-05-15 22:26:55,492:INFO:Logical Core: 12
2025-05-15 22:26:55,492:INFO:Checking libraries
2025-05-15 22:26:55,492:INFO:System:
2025-05-15 22:26:55,492:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 22:26:55,492:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 22:26:55,492:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 22:26:55,492:INFO:PyCaret required dependencies:
2025-05-15 22:26:55,492:INFO:                 pip: 22.3
2025-05-15 22:26:55,492:INFO:          setuptools: 65.5.0
2025-05-15 22:26:55,492:INFO:             pycaret: 3.3.2
2025-05-15 22:26:55,492:INFO:             IPython: 9.2.0
2025-05-15 22:26:55,492:INFO:          ipywidgets: 8.1.7
2025-05-15 22:26:55,492:INFO:                tqdm: 4.67.1
2025-05-15 22:26:55,492:INFO:               numpy: 1.26.4
2025-05-15 22:26:55,492:INFO:              pandas: 2.1.4
2025-05-15 22:26:55,492:INFO:              jinja2: 3.1.6
2025-05-15 22:26:55,492:INFO:               scipy: 1.11.4
2025-05-15 22:26:55,492:INFO:              joblib: 1.3.2
2025-05-15 22:26:55,492:INFO:             sklearn: 1.4.2
2025-05-15 22:26:55,492:INFO:                pyod: 2.0.5
2025-05-15 22:26:55,492:INFO:            imblearn: 0.13.0
2025-05-15 22:26:55,492:INFO:   category_encoders: 2.7.0
2025-05-15 22:26:55,492:INFO:            lightgbm: 4.6.0
2025-05-15 22:26:55,492:INFO:               numba: 0.61.2
2025-05-15 22:26:55,492:INFO:            requests: 2.32.3
2025-05-15 22:26:55,492:INFO:          matplotlib: 3.7.5
2025-05-15 22:26:55,493:INFO:          scikitplot: 0.3.7
2025-05-15 22:26:55,493:INFO:         yellowbrick: 1.5
2025-05-15 22:26:55,493:INFO:              plotly: 5.24.1
2025-05-15 22:26:55,493:INFO:    plotly-resampler: Not installed
2025-05-15 22:26:55,493:INFO:             kaleido: 0.2.1
2025-05-15 22:26:55,493:INFO:           schemdraw: 0.15
2025-05-15 22:26:55,493:INFO:         statsmodels: 0.14.4
2025-05-15 22:26:55,493:INFO:              sktime: 0.26.0
2025-05-15 22:26:55,493:INFO:               tbats: 1.1.3
2025-05-15 22:26:55,493:INFO:            pmdarima: 2.0.4
2025-05-15 22:26:55,493:INFO:              psutil: 7.0.0
2025-05-15 22:26:55,493:INFO:          markupsafe: 3.0.2
2025-05-15 22:26:55,493:INFO:             pickle5: Not installed
2025-05-15 22:26:55,493:INFO:         cloudpickle: 3.1.1
2025-05-15 22:26:55,493:INFO:         deprecation: 2.1.0
2025-05-15 22:26:55,493:INFO:              xxhash: 3.5.0
2025-05-15 22:26:55,493:INFO:           wurlitzer: 3.1.1
2025-05-15 22:26:55,493:INFO:PyCaret optional dependencies:
2025-05-15 22:26:55,493:INFO:                shap: 0.47.2
2025-05-15 22:26:55,493:INFO:           interpret: Not installed
2025-05-15 22:26:55,493:INFO:                umap: Not installed
2025-05-15 22:26:55,493:INFO:     ydata_profiling: Not installed
2025-05-15 22:26:55,493:INFO:  explainerdashboard: Not installed
2025-05-15 22:26:55,493:INFO:             autoviz: Not installed
2025-05-15 22:26:55,493:INFO:           fairlearn: Not installed
2025-05-15 22:26:55,493:INFO:          deepchecks: Not installed
2025-05-15 22:26:55,493:INFO:             xgboost: Not installed
2025-05-15 22:26:55,493:INFO:            catboost: 1.2.8
2025-05-15 22:26:55,493:INFO:              kmodes: Not installed
2025-05-15 22:26:55,493:INFO:             mlxtend: Not installed
2025-05-15 22:26:55,493:INFO:       statsforecast: Not installed
2025-05-15 22:26:55,493:INFO:        tune_sklearn: Not installed
2025-05-15 22:26:55,493:INFO:                 ray: Not installed
2025-05-15 22:26:55,493:INFO:            hyperopt: Not installed
2025-05-15 22:26:55,493:INFO:              optuna: 4.3.0
2025-05-15 22:26:55,493:INFO:               skopt: Not installed
2025-05-15 22:26:55,493:INFO:              mlflow: Not installed
2025-05-15 22:26:55,493:INFO:              gradio: Not installed
2025-05-15 22:26:55,493:INFO:             fastapi: Not installed
2025-05-15 22:26:55,493:INFO:             uvicorn: Not installed
2025-05-15 22:26:55,493:INFO:              m2cgen: Not installed
2025-05-15 22:26:55,493:INFO:           evidently: Not installed
2025-05-15 22:26:55,493:INFO:               fugue: Not installed
2025-05-15 22:26:55,493:INFO:           streamlit: Not installed
2025-05-15 22:26:55,493:INFO:             prophet: Not installed
2025-05-15 22:26:55,493:INFO:None
2025-05-15 22:26:55,493:INFO:Set up data.
2025-05-15 22:26:55,527:INFO:Set up folding strategy.
2025-05-15 22:26:55,527:INFO:Set up train/test split.
2025-05-15 22:26:55,544:INFO:Set up index.
2025-05-15 22:26:55,545:INFO:Assigning column types.
2025-05-15 22:26:55,551:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 22:26:55,569:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 22:26:55,569:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:26:55,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:26:55,581:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:26:55,599:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 22:26:55,600:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:26:55,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:26:55,611:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:26:55,611:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 22:26:55,630:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:26:55,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:26:55,641:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:26:55,659:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:26:55,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:26:55,672:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:26:55,672:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 22:26:55,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:26:55,701:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:26:55,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:26:55,732:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:26:55,732:INFO:Preparing preprocessing pipeline...
2025-05-15 22:26:55,734:INFO:Set up simple imputation.
2025-05-15 22:26:55,742:INFO:Set up encoding of ordinal features.
2025-05-15 22:26:55,761:INFO:Set up encoding of categorical features.
2025-05-15 22:26:55,761:INFO:Set up imbalanced handling.
2025-05-15 22:26:55,761:INFO:Set up column transformation.
2025-05-15 22:26:57,005:INFO:Finished creating preprocessing pipeline.
2025-05-15 22:26:57,024:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Iodine_Deficiency_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabetes_Bina...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 22:26:57,024:INFO:Creating final display dataframe.
2025-05-15 22:26:57,535:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 22)
4        Transformed data shape      (106821, 35)
5   Transformed train set shape       (85902, 35)
6    Transformed test set shape       (20919, 35)
7              Numeric features                12
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              a0e5
2025-05-15 22:26:57,568:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:26:57,568:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:26:57,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:26:57,601:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:26:57,602:INFO:setup() successfully completed in 2.12s...............
2025-05-15 22:26:57,602:INFO:Initializing compare_models()
2025-05-15 22:26:57,603:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-15 22:26:57,603:INFO:Checking exceptions
2025-05-15 22:26:57,611:INFO:Preparing display monitor
2025-05-15 22:26:57,619:INFO:Initializing Logistic Regression
2025-05-15 22:26:57,619:INFO:Total runtime is 1.998742421468099e-06 minutes
2025-05-15 22:26:57,620:INFO:SubProcess create_model() called ==================================
2025-05-15 22:26:57,621:INFO:Initializing create_model()
2025-05-15 22:26:57,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:26:57,621:INFO:Checking exceptions
2025-05-15 22:26:57,621:INFO:Importing libraries
2025-05-15 22:26:57,621:INFO:Copying training dataset
2025-05-15 22:26:57,636:INFO:Defining folds
2025-05-15 22:26:57,637:INFO:Declaring metric variables
2025-05-15 22:26:57,638:INFO:Importing untrained model
2025-05-15 22:26:57,639:INFO:Logistic Regression Imported successfully
2025-05-15 22:26:57,641:INFO:Starting cross validation
2025-05-15 22:26:57,642:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:27:01,861:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:27:01,913:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:27:01,969:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:27:02,397:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:27:07,655:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:27:07,704:INFO:Calculating mean and std
2025-05-15 22:27:07,705:INFO:Creating metrics dataframe
2025-05-15 22:27:07,706:INFO:Uploading results into container
2025-05-15 22:27:07,706:INFO:Uploading model into container now
2025-05-15 22:27:07,706:INFO:_master_model_container: 1
2025-05-15 22:27:07,707:INFO:_display_container: 2
2025-05-15 22:27:07,707:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 22:27:07,707:INFO:create_model() successfully completed......................................
2025-05-15 22:27:07,859:INFO:SubProcess create_model() end ==================================
2025-05-15 22:27:07,859:INFO:Creating metrics dataframe
2025-05-15 22:27:07,861:INFO:Initializing K Neighbors Classifier
2025-05-15 22:27:07,861:INFO:Total runtime is 0.1707028786341349 minutes
2025-05-15 22:27:07,863:INFO:SubProcess create_model() called ==================================
2025-05-15 22:27:07,863:INFO:Initializing create_model()
2025-05-15 22:27:07,863:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:27:07,863:INFO:Checking exceptions
2025-05-15 22:27:07,863:INFO:Importing libraries
2025-05-15 22:27:07,863:INFO:Copying training dataset
2025-05-15 22:27:07,878:INFO:Defining folds
2025-05-15 22:27:07,878:INFO:Declaring metric variables
2025-05-15 22:27:07,879:INFO:Importing untrained model
2025-05-15 22:27:07,881:INFO:K Neighbors Classifier Imported successfully
2025-05-15 22:27:07,883:INFO:Starting cross validation
2025-05-15 22:27:07,884:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:27:13,190:INFO:Calculating mean and std
2025-05-15 22:27:13,191:INFO:Creating metrics dataframe
2025-05-15 22:27:13,192:INFO:Uploading results into container
2025-05-15 22:27:13,192:INFO:Uploading model into container now
2025-05-15 22:27:13,192:INFO:_master_model_container: 2
2025-05-15 22:27:13,192:INFO:_display_container: 2
2025-05-15 22:27:13,193:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-15 22:27:13,193:INFO:create_model() successfully completed......................................
2025-05-15 22:27:13,307:INFO:SubProcess create_model() end ==================================
2025-05-15 22:27:13,307:INFO:Creating metrics dataframe
2025-05-15 22:27:13,310:INFO:Initializing Naive Bayes
2025-05-15 22:27:13,310:INFO:Total runtime is 0.26150901714960734 minutes
2025-05-15 22:27:13,311:INFO:SubProcess create_model() called ==================================
2025-05-15 22:27:13,311:INFO:Initializing create_model()
2025-05-15 22:27:13,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:27:13,311:INFO:Checking exceptions
2025-05-15 22:27:13,311:INFO:Importing libraries
2025-05-15 22:27:13,311:INFO:Copying training dataset
2025-05-15 22:27:13,327:INFO:Defining folds
2025-05-15 22:27:13,328:INFO:Declaring metric variables
2025-05-15 22:27:13,329:INFO:Importing untrained model
2025-05-15 22:27:13,330:INFO:Naive Bayes Imported successfully
2025-05-15 22:27:13,333:INFO:Starting cross validation
2025-05-15 22:27:13,334:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:27:14,792:INFO:Calculating mean and std
2025-05-15 22:27:14,793:INFO:Creating metrics dataframe
2025-05-15 22:27:14,794:INFO:Uploading results into container
2025-05-15 22:27:14,794:INFO:Uploading model into container now
2025-05-15 22:27:14,795:INFO:_master_model_container: 3
2025-05-15 22:27:14,795:INFO:_display_container: 2
2025-05-15 22:27:14,795:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-15 22:27:14,795:INFO:create_model() successfully completed......................................
2025-05-15 22:27:14,919:INFO:SubProcess create_model() end ==================================
2025-05-15 22:27:14,919:INFO:Creating metrics dataframe
2025-05-15 22:27:14,922:INFO:Initializing Decision Tree Classifier
2025-05-15 22:27:14,922:INFO:Total runtime is 0.28837518294652303 minutes
2025-05-15 22:27:14,923:INFO:SubProcess create_model() called ==================================
2025-05-15 22:27:14,923:INFO:Initializing create_model()
2025-05-15 22:27:14,923:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:27:14,923:INFO:Checking exceptions
2025-05-15 22:27:14,923:INFO:Importing libraries
2025-05-15 22:27:14,923:INFO:Copying training dataset
2025-05-15 22:27:14,939:INFO:Defining folds
2025-05-15 22:27:14,939:INFO:Declaring metric variables
2025-05-15 22:27:14,940:INFO:Importing untrained model
2025-05-15 22:27:14,942:INFO:Decision Tree Classifier Imported successfully
2025-05-15 22:27:14,944:INFO:Starting cross validation
2025-05-15 22:27:14,946:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:27:16,822:INFO:Calculating mean and std
2025-05-15 22:27:16,823:INFO:Creating metrics dataframe
2025-05-15 22:27:16,824:INFO:Uploading results into container
2025-05-15 22:27:16,825:INFO:Uploading model into container now
2025-05-15 22:27:16,825:INFO:_master_model_container: 4
2025-05-15 22:27:16,825:INFO:_display_container: 2
2025-05-15 22:27:16,825:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-15 22:27:16,825:INFO:create_model() successfully completed......................................
2025-05-15 22:27:16,958:INFO:SubProcess create_model() end ==================================
2025-05-15 22:27:16,958:INFO:Creating metrics dataframe
2025-05-15 22:27:16,961:INFO:Initializing SVM - Linear Kernel
2025-05-15 22:27:16,961:INFO:Total runtime is 0.3223700801531474 minutes
2025-05-15 22:27:16,963:INFO:SubProcess create_model() called ==================================
2025-05-15 22:27:16,963:INFO:Initializing create_model()
2025-05-15 22:27:16,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:27:16,963:INFO:Checking exceptions
2025-05-15 22:27:16,963:INFO:Importing libraries
2025-05-15 22:27:16,963:INFO:Copying training dataset
2025-05-15 22:27:16,980:INFO:Defining folds
2025-05-15 22:27:16,980:INFO:Declaring metric variables
2025-05-15 22:27:16,982:INFO:Importing untrained model
2025-05-15 22:27:16,983:INFO:SVM - Linear Kernel Imported successfully
2025-05-15 22:27:16,986:INFO:Starting cross validation
2025-05-15 22:27:16,987:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:27:20,542:INFO:Calculating mean and std
2025-05-15 22:27:20,543:INFO:Creating metrics dataframe
2025-05-15 22:27:20,544:INFO:Uploading results into container
2025-05-15 22:27:20,544:INFO:Uploading model into container now
2025-05-15 22:27:20,544:INFO:_master_model_container: 5
2025-05-15 22:27:20,544:INFO:_display_container: 2
2025-05-15 22:27:20,545:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-15 22:27:20,545:INFO:create_model() successfully completed......................................
2025-05-15 22:27:20,659:INFO:SubProcess create_model() end ==================================
2025-05-15 22:27:20,659:INFO:Creating metrics dataframe
2025-05-15 22:27:20,662:INFO:Initializing Ridge Classifier
2025-05-15 22:27:20,662:INFO:Total runtime is 0.3840493321418762 minutes
2025-05-15 22:27:20,663:INFO:SubProcess create_model() called ==================================
2025-05-15 22:27:20,663:INFO:Initializing create_model()
2025-05-15 22:27:20,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:27:20,664:INFO:Checking exceptions
2025-05-15 22:27:20,664:INFO:Importing libraries
2025-05-15 22:27:20,664:INFO:Copying training dataset
2025-05-15 22:27:20,680:INFO:Defining folds
2025-05-15 22:27:20,680:INFO:Declaring metric variables
2025-05-15 22:27:20,681:INFO:Importing untrained model
2025-05-15 22:27:20,683:INFO:Ridge Classifier Imported successfully
2025-05-15 22:27:20,685:INFO:Starting cross validation
2025-05-15 22:27:20,686:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:27:22,099:INFO:Calculating mean and std
2025-05-15 22:27:22,100:INFO:Creating metrics dataframe
2025-05-15 22:27:22,101:INFO:Uploading results into container
2025-05-15 22:27:22,101:INFO:Uploading model into container now
2025-05-15 22:27:22,101:INFO:_master_model_container: 6
2025-05-15 22:27:22,101:INFO:_display_container: 2
2025-05-15 22:27:22,102:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-15 22:27:22,102:INFO:create_model() successfully completed......................................
2025-05-15 22:27:22,271:INFO:SubProcess create_model() end ==================================
2025-05-15 22:27:22,272:INFO:Creating metrics dataframe
2025-05-15 22:27:22,275:INFO:Initializing Random Forest Classifier
2025-05-15 22:27:22,275:INFO:Total runtime is 0.41092856725056964 minutes
2025-05-15 22:27:22,276:INFO:SubProcess create_model() called ==================================
2025-05-15 22:27:22,276:INFO:Initializing create_model()
2025-05-15 22:27:22,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:27:22,276:INFO:Checking exceptions
2025-05-15 22:27:22,276:INFO:Importing libraries
2025-05-15 22:27:22,276:INFO:Copying training dataset
2025-05-15 22:27:22,291:INFO:Defining folds
2025-05-15 22:27:22,291:INFO:Declaring metric variables
2025-05-15 22:27:22,292:INFO:Importing untrained model
2025-05-15 22:27:22,294:INFO:Random Forest Classifier Imported successfully
2025-05-15 22:27:22,296:INFO:Starting cross validation
2025-05-15 22:27:22,298:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:27:27,648:INFO:Calculating mean and std
2025-05-15 22:27:27,650:INFO:Creating metrics dataframe
2025-05-15 22:27:27,652:INFO:Uploading results into container
2025-05-15 22:27:27,653:INFO:Uploading model into container now
2025-05-15 22:27:27,653:INFO:_master_model_container: 7
2025-05-15 22:27:27,653:INFO:_display_container: 2
2025-05-15 22:27:27,653:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 22:27:27,654:INFO:create_model() successfully completed......................................
2025-05-15 22:27:27,786:INFO:SubProcess create_model() end ==================================
2025-05-15 22:27:27,786:INFO:Creating metrics dataframe
2025-05-15 22:27:27,790:INFO:Initializing Quadratic Discriminant Analysis
2025-05-15 22:27:27,790:INFO:Total runtime is 0.5028439482053121 minutes
2025-05-15 22:27:27,791:INFO:SubProcess create_model() called ==================================
2025-05-15 22:27:27,791:INFO:Initializing create_model()
2025-05-15 22:27:27,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:27:27,791:INFO:Checking exceptions
2025-05-15 22:27:27,791:INFO:Importing libraries
2025-05-15 22:27:27,791:INFO:Copying training dataset
2025-05-15 22:27:27,817:INFO:Defining folds
2025-05-15 22:27:27,817:INFO:Declaring metric variables
2025-05-15 22:27:27,818:INFO:Importing untrained model
2025-05-15 22:27:27,820:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 22:27:27,822:INFO:Starting cross validation
2025-05-15 22:27:27,824:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:27:29,149:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:27:29,179:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:27:29,194:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:27:29,196:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:27:29,274:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:27:29,288:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:27:29,293:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:27:29,324:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:27:29,405:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:27:29,415:INFO:Calculating mean and std
2025-05-15 22:27:29,417:INFO:Creating metrics dataframe
2025-05-15 22:27:29,420:INFO:Uploading results into container
2025-05-15 22:27:29,420:INFO:Uploading model into container now
2025-05-15 22:27:29,421:INFO:_master_model_container: 8
2025-05-15 22:27:29,421:INFO:_display_container: 2
2025-05-15 22:27:29,421:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 22:27:29,421:INFO:create_model() successfully completed......................................
2025-05-15 22:27:29,603:INFO:SubProcess create_model() end ==================================
2025-05-15 22:27:29,604:INFO:Creating metrics dataframe
2025-05-15 22:27:29,607:INFO:Initializing Ada Boost Classifier
2025-05-15 22:27:29,607:INFO:Total runtime is 0.533135998249054 minutes
2025-05-15 22:27:29,609:INFO:SubProcess create_model() called ==================================
2025-05-15 22:27:29,609:INFO:Initializing create_model()
2025-05-15 22:27:29,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:27:29,609:INFO:Checking exceptions
2025-05-15 22:27:29,609:INFO:Importing libraries
2025-05-15 22:27:29,609:INFO:Copying training dataset
2025-05-15 22:27:29,629:INFO:Defining folds
2025-05-15 22:27:29,630:INFO:Declaring metric variables
2025-05-15 22:27:29,631:INFO:Importing untrained model
2025-05-15 22:27:29,633:INFO:Ada Boost Classifier Imported successfully
2025-05-15 22:27:29,635:INFO:Starting cross validation
2025-05-15 22:27:29,637:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:27:30,879:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:27:30,927:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:27:30,936:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:27:30,942:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:27:31,038:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:27:33,880:INFO:Calculating mean and std
2025-05-15 22:27:33,881:INFO:Creating metrics dataframe
2025-05-15 22:27:33,882:INFO:Uploading results into container
2025-05-15 22:27:33,882:INFO:Uploading model into container now
2025-05-15 22:27:33,882:INFO:_master_model_container: 9
2025-05-15 22:27:33,882:INFO:_display_container: 2
2025-05-15 22:27:33,882:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-15 22:27:33,882:INFO:create_model() successfully completed......................................
2025-05-15 22:27:34,012:INFO:SubProcess create_model() end ==================================
2025-05-15 22:27:34,012:INFO:Creating metrics dataframe
2025-05-15 22:27:34,016:INFO:Initializing Gradient Boosting Classifier
2025-05-15 22:27:34,017:INFO:Total runtime is 0.6066234985987345 minutes
2025-05-15 22:27:34,018:INFO:SubProcess create_model() called ==================================
2025-05-15 22:27:34,018:INFO:Initializing create_model()
2025-05-15 22:27:34,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:27:34,018:INFO:Checking exceptions
2025-05-15 22:27:34,018:INFO:Importing libraries
2025-05-15 22:27:34,018:INFO:Copying training dataset
2025-05-15 22:27:34,034:INFO:Defining folds
2025-05-15 22:27:34,035:INFO:Declaring metric variables
2025-05-15 22:27:34,036:INFO:Importing untrained model
2025-05-15 22:27:34,038:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 22:27:34,040:INFO:Starting cross validation
2025-05-15 22:27:34,041:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:27:49,387:INFO:Calculating mean and std
2025-05-15 22:27:49,390:INFO:Creating metrics dataframe
2025-05-15 22:27:49,393:INFO:Uploading results into container
2025-05-15 22:27:49,393:INFO:Uploading model into container now
2025-05-15 22:27:49,394:INFO:_master_model_container: 10
2025-05-15 22:27:49,394:INFO:_display_container: 2
2025-05-15 22:27:49,395:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 22:27:49,395:INFO:create_model() successfully completed......................................
2025-05-15 22:27:49,590:INFO:SubProcess create_model() end ==================================
2025-05-15 22:27:49,590:INFO:Creating metrics dataframe
2025-05-15 22:27:49,594:INFO:Initializing Linear Discriminant Analysis
2025-05-15 22:27:49,594:INFO:Total runtime is 0.8662485996882121 minutes
2025-05-15 22:27:49,595:INFO:SubProcess create_model() called ==================================
2025-05-15 22:27:49,596:INFO:Initializing create_model()
2025-05-15 22:27:49,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:27:49,596:INFO:Checking exceptions
2025-05-15 22:27:49,596:INFO:Importing libraries
2025-05-15 22:27:49,596:INFO:Copying training dataset
2025-05-15 22:27:49,703:INFO:Defining folds
2025-05-15 22:27:49,704:INFO:Declaring metric variables
2025-05-15 22:27:49,716:INFO:Importing untrained model
2025-05-15 22:27:49,721:INFO:Linear Discriminant Analysis Imported successfully
2025-05-15 22:27:49,724:INFO:Starting cross validation
2025-05-15 22:27:49,728:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:27:51,285:INFO:Calculating mean and std
2025-05-15 22:27:51,286:INFO:Creating metrics dataframe
2025-05-15 22:27:51,287:INFO:Uploading results into container
2025-05-15 22:27:51,287:INFO:Uploading model into container now
2025-05-15 22:27:51,287:INFO:_master_model_container: 11
2025-05-15 22:27:51,287:INFO:_display_container: 2
2025-05-15 22:27:51,287:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-15 22:27:51,287:INFO:create_model() successfully completed......................................
2025-05-15 22:27:51,407:INFO:SubProcess create_model() end ==================================
2025-05-15 22:27:51,407:INFO:Creating metrics dataframe
2025-05-15 22:27:51,411:INFO:Initializing Extra Trees Classifier
2025-05-15 22:27:51,411:INFO:Total runtime is 0.8965357661247254 minutes
2025-05-15 22:27:51,413:INFO:SubProcess create_model() called ==================================
2025-05-15 22:27:51,413:INFO:Initializing create_model()
2025-05-15 22:27:51,413:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:27:51,413:INFO:Checking exceptions
2025-05-15 22:27:51,413:INFO:Importing libraries
2025-05-15 22:27:51,413:INFO:Copying training dataset
2025-05-15 22:27:51,427:INFO:Defining folds
2025-05-15 22:27:51,427:INFO:Declaring metric variables
2025-05-15 22:27:51,429:INFO:Importing untrained model
2025-05-15 22:27:51,430:INFO:Extra Trees Classifier Imported successfully
2025-05-15 22:27:51,432:INFO:Starting cross validation
2025-05-15 22:27:51,433:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:27:55,944:INFO:Calculating mean and std
2025-05-15 22:27:55,947:INFO:Creating metrics dataframe
2025-05-15 22:27:55,950:INFO:Uploading results into container
2025-05-15 22:27:55,951:INFO:Uploading model into container now
2025-05-15 22:27:55,951:INFO:_master_model_container: 12
2025-05-15 22:27:55,951:INFO:_display_container: 2
2025-05-15 22:27:55,952:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 22:27:55,952:INFO:create_model() successfully completed......................................
2025-05-15 22:27:56,130:INFO:SubProcess create_model() end ==================================
2025-05-15 22:27:56,130:INFO:Creating metrics dataframe
2025-05-15 22:27:56,135:INFO:Initializing Light Gradient Boosting Machine
2025-05-15 22:27:56,135:INFO:Total runtime is 0.9752625823020936 minutes
2025-05-15 22:27:56,136:INFO:SubProcess create_model() called ==================================
2025-05-15 22:27:56,136:INFO:Initializing create_model()
2025-05-15 22:27:56,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:27:56,137:INFO:Checking exceptions
2025-05-15 22:27:56,137:INFO:Importing libraries
2025-05-15 22:27:56,137:INFO:Copying training dataset
2025-05-15 22:27:56,155:INFO:Defining folds
2025-05-15 22:27:56,155:INFO:Declaring metric variables
2025-05-15 22:27:56,156:INFO:Importing untrained model
2025-05-15 22:27:56,157:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 22:27:56,159:INFO:Starting cross validation
2025-05-15 22:27:56,161:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:28:00,351:INFO:Calculating mean and std
2025-05-15 22:28:00,352:INFO:Creating metrics dataframe
2025-05-15 22:28:00,354:INFO:Uploading results into container
2025-05-15 22:28:00,355:INFO:Uploading model into container now
2025-05-15 22:28:00,355:INFO:_master_model_container: 13
2025-05-15 22:28:00,355:INFO:_display_container: 2
2025-05-15 22:28:00,355:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:28:00,356:INFO:create_model() successfully completed......................................
2025-05-15 22:28:00,481:INFO:SubProcess create_model() end ==================================
2025-05-15 22:28:00,481:INFO:Creating metrics dataframe
2025-05-15 22:28:00,486:INFO:Initializing CatBoost Classifier
2025-05-15 22:28:00,486:INFO:Total runtime is 1.0477752486864726 minutes
2025-05-15 22:28:00,487:INFO:SubProcess create_model() called ==================================
2025-05-15 22:28:00,487:INFO:Initializing create_model()
2025-05-15 22:28:00,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:28:00,487:INFO:Checking exceptions
2025-05-15 22:28:00,487:INFO:Importing libraries
2025-05-15 22:28:00,487:INFO:Copying training dataset
2025-05-15 22:28:00,503:INFO:Defining folds
2025-05-15 22:28:00,503:INFO:Declaring metric variables
2025-05-15 22:28:00,505:INFO:Importing untrained model
2025-05-15 22:28:00,506:INFO:CatBoost Classifier Imported successfully
2025-05-15 22:28:00,508:INFO:Starting cross validation
2025-05-15 22:28:00,509:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:28:17,725:INFO:Calculating mean and std
2025-05-15 22:28:17,727:INFO:Creating metrics dataframe
2025-05-15 22:28:17,728:INFO:Uploading results into container
2025-05-15 22:28:17,728:INFO:Uploading model into container now
2025-05-15 22:28:17,729:INFO:_master_model_container: 14
2025-05-15 22:28:17,729:INFO:_display_container: 2
2025-05-15 22:28:17,729:INFO:<catboost.core.CatBoostClassifier object at 0x363e4b890>
2025-05-15 22:28:17,729:INFO:create_model() successfully completed......................................
2025-05-15 22:28:17,849:INFO:SubProcess create_model() end ==================================
2025-05-15 22:28:17,849:INFO:Creating metrics dataframe
2025-05-15 22:28:17,853:INFO:Initializing Dummy Classifier
2025-05-15 22:28:17,853:INFO:Total runtime is 1.3372311313947043 minutes
2025-05-15 22:28:17,854:INFO:SubProcess create_model() called ==================================
2025-05-15 22:28:17,854:INFO:Initializing create_model()
2025-05-15 22:28:17,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f77e890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:28:17,855:INFO:Checking exceptions
2025-05-15 22:28:17,855:INFO:Importing libraries
2025-05-15 22:28:17,855:INFO:Copying training dataset
2025-05-15 22:28:17,872:INFO:Defining folds
2025-05-15 22:28:17,872:INFO:Declaring metric variables
2025-05-15 22:28:17,873:INFO:Importing untrained model
2025-05-15 22:28:17,874:INFO:Dummy Classifier Imported successfully
2025-05-15 22:28:17,876:INFO:Starting cross validation
2025-05-15 22:28:17,877:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:28:19,187:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:28:19,213:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:28:19,225:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:28:19,292:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:28:20,622:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:28:20,632:INFO:Calculating mean and std
2025-05-15 22:28:20,632:INFO:Creating metrics dataframe
2025-05-15 22:28:20,633:INFO:Uploading results into container
2025-05-15 22:28:20,634:INFO:Uploading model into container now
2025-05-15 22:28:20,634:INFO:_master_model_container: 15
2025-05-15 22:28:20,634:INFO:_display_container: 2
2025-05-15 22:28:20,634:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-15 22:28:20,634:INFO:create_model() successfully completed......................................
2025-05-15 22:28:20,814:INFO:SubProcess create_model() end ==================================
2025-05-15 22:28:20,814:INFO:Creating metrics dataframe
2025-05-15 22:28:20,819:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-15 22:28:20,822:INFO:Initializing create_model()
2025-05-15 22:28:20,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:28:20,822:INFO:Checking exceptions
2025-05-15 22:28:20,823:INFO:Importing libraries
2025-05-15 22:28:20,823:INFO:Copying training dataset
2025-05-15 22:28:20,839:INFO:Defining folds
2025-05-15 22:28:20,839:INFO:Declaring metric variables
2025-05-15 22:28:20,839:INFO:Importing untrained model
2025-05-15 22:28:20,839:INFO:Declaring custom model
2025-05-15 22:28:20,839:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 22:28:20,840:INFO:Cross validation set to False
2025-05-15 22:28:20,840:INFO:Fitting Model
2025-05-15 22:28:38,170:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 22:28:38,171:INFO:create_model() successfully completed......................................
2025-05-15 22:28:38,286:INFO:Initializing create_model()
2025-05-15 22:28:38,286:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:28:38,286:INFO:Checking exceptions
2025-05-15 22:28:38,287:INFO:Importing libraries
2025-05-15 22:28:38,287:INFO:Copying training dataset
2025-05-15 22:28:38,301:INFO:Defining folds
2025-05-15 22:28:38,301:INFO:Declaring metric variables
2025-05-15 22:28:38,301:INFO:Importing untrained model
2025-05-15 22:28:38,301:INFO:Declaring custom model
2025-05-15 22:28:38,302:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 22:28:38,302:INFO:Cross validation set to False
2025-05-15 22:28:38,303:INFO:Fitting Model
2025-05-15 22:28:39,640:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 22:28:39,652:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006040 seconds.
2025-05-15 22:28:39,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 22:28:39,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 22:28:39,653:INFO:[LightGBM] [Info] Total Bins 5940
2025-05-15 22:28:39,653:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 34
2025-05-15 22:28:39,653:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 22:28:40,437:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:28:40,437:INFO:create_model() successfully completed......................................
2025-05-15 22:28:40,555:INFO:Initializing create_model()
2025-05-15 22:28:40,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=<catboost.core.CatBoostClassifier object at 0x363e4b890>, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:28:40,555:INFO:Checking exceptions
2025-05-15 22:28:40,556:INFO:Importing libraries
2025-05-15 22:28:40,556:INFO:Copying training dataset
2025-05-15 22:28:40,570:INFO:Defining folds
2025-05-15 22:28:40,570:INFO:Declaring metric variables
2025-05-15 22:28:40,570:INFO:Importing untrained model
2025-05-15 22:28:40,570:INFO:Declaring custom model
2025-05-15 22:28:40,570:INFO:CatBoost Classifier Imported successfully
2025-05-15 22:28:40,571:INFO:Cross validation set to False
2025-05-15 22:28:40,571:INFO:Fitting Model
2025-05-15 22:28:48,040:INFO:<catboost.core.CatBoostClassifier object at 0x36f0775d0>
2025-05-15 22:28:48,041:INFO:create_model() successfully completed......................................
2025-05-15 22:28:48,166:INFO:_master_model_container: 15
2025-05-15 22:28:48,166:INFO:_display_container: 2
2025-05-15 22:28:48,167:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x36f0775d0>]
2025-05-15 22:28:48,167:INFO:compare_models() successfully completed......................................
2025-05-15 22:28:48,168:INFO:Initializing evaluate_model()
2025-05-15 22:28:48,168:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 22:28:48,177:INFO:Initializing plot_model()
2025-05-15 22:28:48,177:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 22:28:48,177:INFO:Checking exceptions
2025-05-15 22:28:48,184:INFO:Preloading libraries
2025-05-15 22:28:48,187:INFO:Copying training dataset
2025-05-15 22:28:48,187:INFO:Plot type: pipeline
2025-05-15 22:28:48,244:INFO:Visual Rendered Successfully
2025-05-15 22:28:48,384:INFO:plot_model() successfully completed......................................
2025-05-15 22:28:48,386:INFO:Initializing tune_model()
2025-05-15 22:28:48,386:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-15 22:28:48,386:INFO:Checking exceptions
2025-05-15 22:28:48,396:INFO:Copying training dataset
2025-05-15 22:28:48,407:INFO:Checking base model
2025-05-15 22:28:48,407:INFO:Base model : Gradient Boosting Classifier
2025-05-15 22:28:48,408:INFO:Declaring metric variables
2025-05-15 22:28:48,409:INFO:Defining Hyperparameters
2025-05-15 22:28:48,531:INFO:Tuning with n_jobs=-1
2025-05-15 22:28:48,531:INFO:Initializing RandomizedSearchCV
2025-05-15 22:29:27,885:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-15 22:29:27,888:INFO:Hyperparameter search completed
2025-05-15 22:29:27,888:INFO:SubProcess create_model() called ==================================
2025-05-15 22:29:27,890:INFO:Initializing create_model()
2025-05-15 22:29:27,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373c91b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-15 22:29:27,890:INFO:Checking exceptions
2025-05-15 22:29:27,890:INFO:Importing libraries
2025-05-15 22:29:27,890:INFO:Copying training dataset
2025-05-15 22:29:27,915:INFO:Defining folds
2025-05-15 22:29:27,915:INFO:Declaring metric variables
2025-05-15 22:29:27,918:INFO:Importing untrained model
2025-05-15 22:29:27,918:INFO:Declaring custom model
2025-05-15 22:29:27,921:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 22:29:27,924:INFO:Starting cross validation
2025-05-15 22:29:27,931:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:29:37,368:INFO:Calculating mean and std
2025-05-15 22:29:37,370:INFO:Creating metrics dataframe
2025-05-15 22:29:37,372:INFO:Finalizing model
2025-05-15 22:29:47,540:INFO:Uploading results into container
2025-05-15 22:29:47,541:INFO:Uploading model into container now
2025-05-15 22:29:47,541:INFO:_master_model_container: 16
2025-05-15 22:29:47,541:INFO:_display_container: 3
2025-05-15 22:29:47,541:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 22:29:47,541:INFO:create_model() successfully completed......................................
2025-05-15 22:29:47,721:INFO:SubProcess create_model() end ==================================
2025-05-15 22:29:47,721:INFO:choose_better activated
2025-05-15 22:29:47,723:INFO:SubProcess create_model() called ==================================
2025-05-15 22:29:47,723:INFO:Initializing create_model()
2025-05-15 22:29:47,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:29:47,723:INFO:Checking exceptions
2025-05-15 22:29:47,724:INFO:Importing libraries
2025-05-15 22:29:47,724:INFO:Copying training dataset
2025-05-15 22:29:47,738:INFO:Defining folds
2025-05-15 22:29:47,738:INFO:Declaring metric variables
2025-05-15 22:29:47,738:INFO:Importing untrained model
2025-05-15 22:29:47,738:INFO:Declaring custom model
2025-05-15 22:29:47,739:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 22:29:47,739:INFO:Starting cross validation
2025-05-15 22:29:47,740:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:30:02,801:INFO:Calculating mean and std
2025-05-15 22:30:02,802:INFO:Creating metrics dataframe
2025-05-15 22:30:02,804:INFO:Finalizing model
2025-05-15 22:30:20,216:INFO:Uploading results into container
2025-05-15 22:30:20,217:INFO:Uploading model into container now
2025-05-15 22:30:20,217:INFO:_master_model_container: 17
2025-05-15 22:30:20,217:INFO:_display_container: 4
2025-05-15 22:30:20,218:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 22:30:20,218:INFO:create_model() successfully completed......................................
2025-05-15 22:30:20,339:INFO:SubProcess create_model() end ==================================
2025-05-15 22:30:20,340:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4603
2025-05-15 22:30:20,340:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4895
2025-05-15 22:30:20,340:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-15 22:30:20,340:INFO:choose_better completed
2025-05-15 22:30:20,344:INFO:_master_model_container: 17
2025-05-15 22:30:20,344:INFO:_display_container: 3
2025-05-15 22:30:20,344:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 22:30:20,344:INFO:tune_model() successfully completed......................................
2025-05-15 22:30:20,464:INFO:Initializing evaluate_model()
2025-05-15 22:30:20,464:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 22:30:20,475:INFO:Initializing plot_model()
2025-05-15 22:30:20,475:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 22:30:20,475:INFO:Checking exceptions
2025-05-15 22:30:20,483:INFO:Preloading libraries
2025-05-15 22:30:20,492:INFO:Copying training dataset
2025-05-15 22:30:20,492:INFO:Plot type: pipeline
2025-05-15 22:30:20,555:INFO:Visual Rendered Successfully
2025-05-15 22:30:20,679:INFO:plot_model() successfully completed......................................
2025-05-15 22:30:20,680:INFO:Initializing interpret_model()
2025-05-15 22:30:20,681:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-15 22:30:20,681:INFO:Checking exceptions
2025-05-15 22:30:20,681:INFO:Soft dependency imported: shap: 0.47.2
2025-05-15 22:30:20,681:INFO:Initializing finalize_model()
2025-05-15 22:30:20,681:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-15 22:30:20,681:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 22:30:20,688:INFO:Initializing create_model()
2025-05-15 22:30:20,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:30:20,688:INFO:Checking exceptions
2025-05-15 22:30:20,688:INFO:Importing libraries
2025-05-15 22:30:20,688:INFO:Copying training dataset
2025-05-15 22:30:20,689:INFO:Defining folds
2025-05-15 22:30:20,689:INFO:Declaring metric variables
2025-05-15 22:30:20,689:INFO:Importing untrained model
2025-05-15 22:30:20,689:INFO:Declaring custom model
2025-05-15 22:30:20,690:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 22:30:20,691:INFO:Cross validation set to False
2025-05-15 22:30:20,691:INFO:Fitting Model
2025-05-15 22:30:35,807:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Iodine_Deficiency_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabetes_Binary',
                                             'Risk_Factor_Sum'],
                                    transformer=SimpleImputer(add_in...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-15 22:30:35,807:INFO:create_model() successfully completed......................................
2025-05-15 22:30:35,943:INFO:_master_model_container: 17
2025-05-15 22:30:35,943:INFO:_display_container: 3
2025-05-15 22:30:35,965:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Iodine_Deficiency_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabetes_Binary',
                                             'Risk_Factor_Sum'],
                                    transformer=SimpleImputer(add_in...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-15 22:30:35,965:INFO:finalize_model() successfully completed......................................
2025-05-15 22:30:36,127:INFO:Initializing save_model()
2025-05-15 22:30:36,127:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Iodine_Deficiency_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabetes_Binary',
                                             'Risk_Factor_Sum'],
                                    transformer=SimpleImputer(add_in...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Iodine_Deficiency_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabetes_Bina...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-15 22:30:36,127:INFO:Adding model into prep_pipe
2025-05-15 22:30:36,127:WARNING:Only Model saved as it was a pipeline.
2025-05-15 22:30:36,153:INFO:final_cancer_model.pkl saved in current working directory
2025-05-15 22:30:36,172:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Iodine_Deficiency_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabetes_Binary',
                                             'Risk_Factor_Sum'],
                                    transformer=SimpleImputer(add_in...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-15 22:30:36,172:INFO:save_model() successfully completed......................................
2025-05-15 22:30:36,306:INFO:Initializing predict_model()
2025-05-15 22:30:36,306:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Family_Background_Binary',
                                             'Radiation_History_Binary',
                                             'Iodine_Deficiency_Binary',
                                             'Smoke_Binary',
                                             'Weight_Risk_Binary',
                                             'Diabetes_Binary',
                                             'Risk_Factor_Sum'],
                                    transformer=SimpleImputer(add_in...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x32e58e840>)
2025-05-15 22:30:36,306:INFO:Checking exceptions
2025-05-15 22:30:36,306:INFO:Preloading libraries
2025-05-15 22:30:36,307:INFO:Set up data.
2025-05-15 22:30:36,328:INFO:Set up index.
2025-05-15 22:30:37,270:INFO:Initializing plot_model()
2025-05-15 22:30:37,270:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 22:30:37,270:INFO:Checking exceptions
2025-05-15 22:30:37,276:INFO:Preloading libraries
2025-05-15 22:30:37,280:INFO:Copying training dataset
2025-05-15 22:30:37,280:INFO:Plot type: confusion_matrix
2025-05-15 22:30:37,525:INFO:Fitting Model
2025-05-15 22:30:37,527:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-15 22:30:37,528:INFO:Scoring test/hold-out set
2025-05-15 22:30:37,604:INFO:Visual Rendered Successfully
2025-05-15 22:30:37,739:INFO:plot_model() successfully completed......................................
2025-05-15 22:30:37,740:INFO:Initializing plot_model()
2025-05-15 22:30:37,740:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 22:30:37,740:INFO:Checking exceptions
2025-05-15 22:30:37,746:INFO:Preloading libraries
2025-05-15 22:30:37,749:INFO:Copying training dataset
2025-05-15 22:30:37,750:INFO:Plot type: auc
2025-05-15 22:30:37,979:INFO:Fitting Model
2025-05-15 22:30:37,980:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-15 22:30:37,980:INFO:Scoring test/hold-out set
2025-05-15 22:30:38,099:INFO:Visual Rendered Successfully
2025-05-15 22:30:38,217:INFO:plot_model() successfully completed......................................
2025-05-15 22:30:38,218:INFO:Initializing plot_model()
2025-05-15 22:30:38,218:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3738620d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-15 22:30:38,218:INFO:Checking exceptions
2025-05-15 22:30:38,224:INFO:Preloading libraries
2025-05-15 22:30:38,227:INFO:Copying training dataset
2025-05-15 22:30:38,228:INFO:Plot type: feature
2025-05-15 22:30:38,228:WARNING:No coef_ found. Trying feature_importances_
2025-05-15 22:30:38,305:INFO:Visual Rendered Successfully
2025-05-15 22:30:38,422:INFO:plot_model() successfully completed......................................
2025-05-15 22:35:44,944:INFO:PyCaret ClassificationExperiment
2025-05-15 22:35:44,944:INFO:Logging name: clf-default-name
2025-05-15 22:35:44,944:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 22:35:44,944:INFO:version 3.3.2
2025-05-15 22:35:44,944:INFO:Initializing setup()
2025-05-15 22:35:44,944:INFO:self.USI: 996e
2025-05-15 22:35:44,944:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-15 22:35:44,944:INFO:Checking environment
2025-05-15 22:35:44,944:INFO:python_version: 3.11.0
2025-05-15 22:35:44,944:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 22:35:44,944:INFO:machine: arm64
2025-05-15 22:35:44,944:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 22:35:44,944:INFO:Memory: svmem(total=17179869184, available=4578426880, percent=73.4, used=7258718208, free=58540032, active=4545069056, inactive=4513955840, wired=2713649152)
2025-05-15 22:35:44,945:INFO:Physical Core: 12
2025-05-15 22:35:44,945:INFO:Logical Core: 12
2025-05-15 22:35:44,945:INFO:Checking libraries
2025-05-15 22:35:44,945:INFO:System:
2025-05-15 22:35:44,945:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 22:35:44,945:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 22:35:44,945:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 22:35:44,945:INFO:PyCaret required dependencies:
2025-05-15 22:35:44,945:INFO:                 pip: 22.3
2025-05-15 22:35:44,945:INFO:          setuptools: 65.5.0
2025-05-15 22:35:44,945:INFO:             pycaret: 3.3.2
2025-05-15 22:35:44,945:INFO:             IPython: 9.2.0
2025-05-15 22:35:44,945:INFO:          ipywidgets: 8.1.7
2025-05-15 22:35:44,945:INFO:                tqdm: 4.67.1
2025-05-15 22:35:44,945:INFO:               numpy: 1.26.4
2025-05-15 22:35:44,945:INFO:              pandas: 2.1.4
2025-05-15 22:35:44,945:INFO:              jinja2: 3.1.6
2025-05-15 22:35:44,945:INFO:               scipy: 1.11.4
2025-05-15 22:35:44,945:INFO:              joblib: 1.3.2
2025-05-15 22:35:44,945:INFO:             sklearn: 1.4.2
2025-05-15 22:35:44,945:INFO:                pyod: 2.0.5
2025-05-15 22:35:44,945:INFO:            imblearn: 0.13.0
2025-05-15 22:35:44,945:INFO:   category_encoders: 2.7.0
2025-05-15 22:35:44,945:INFO:            lightgbm: 4.6.0
2025-05-15 22:35:44,945:INFO:               numba: 0.61.2
2025-05-15 22:35:44,945:INFO:            requests: 2.32.3
2025-05-15 22:35:44,945:INFO:          matplotlib: 3.7.5
2025-05-15 22:35:44,945:INFO:          scikitplot: 0.3.7
2025-05-15 22:35:44,945:INFO:         yellowbrick: 1.5
2025-05-15 22:35:44,945:INFO:              plotly: 5.24.1
2025-05-15 22:35:44,945:INFO:    plotly-resampler: Not installed
2025-05-15 22:35:44,945:INFO:             kaleido: 0.2.1
2025-05-15 22:35:44,945:INFO:           schemdraw: 0.15
2025-05-15 22:35:44,945:INFO:         statsmodels: 0.14.4
2025-05-15 22:35:44,945:INFO:              sktime: 0.26.0
2025-05-15 22:35:44,945:INFO:               tbats: 1.1.3
2025-05-15 22:35:44,945:INFO:            pmdarima: 2.0.4
2025-05-15 22:35:44,945:INFO:              psutil: 7.0.0
2025-05-15 22:35:44,945:INFO:          markupsafe: 3.0.2
2025-05-15 22:35:44,945:INFO:             pickle5: Not installed
2025-05-15 22:35:44,945:INFO:         cloudpickle: 3.1.1
2025-05-15 22:35:44,945:INFO:         deprecation: 2.1.0
2025-05-15 22:35:44,945:INFO:              xxhash: 3.5.0
2025-05-15 22:35:44,945:INFO:           wurlitzer: 3.1.1
2025-05-15 22:35:44,945:INFO:PyCaret optional dependencies:
2025-05-15 22:35:44,945:INFO:                shap: 0.47.2
2025-05-15 22:35:44,945:INFO:           interpret: Not installed
2025-05-15 22:35:44,945:INFO:                umap: Not installed
2025-05-15 22:35:44,945:INFO:     ydata_profiling: Not installed
2025-05-15 22:35:44,945:INFO:  explainerdashboard: Not installed
2025-05-15 22:35:44,945:INFO:             autoviz: Not installed
2025-05-15 22:35:44,945:INFO:           fairlearn: Not installed
2025-05-15 22:35:44,945:INFO:          deepchecks: Not installed
2025-05-15 22:35:44,945:INFO:             xgboost: Not installed
2025-05-15 22:35:44,945:INFO:            catboost: 1.2.8
2025-05-15 22:35:44,945:INFO:              kmodes: Not installed
2025-05-15 22:35:44,945:INFO:             mlxtend: Not installed
2025-05-15 22:35:44,945:INFO:       statsforecast: Not installed
2025-05-15 22:35:44,945:INFO:        tune_sklearn: Not installed
2025-05-15 22:35:44,945:INFO:                 ray: Not installed
2025-05-15 22:35:44,945:INFO:            hyperopt: Not installed
2025-05-15 22:35:44,945:INFO:              optuna: 4.3.0
2025-05-15 22:35:44,945:INFO:               skopt: Not installed
2025-05-15 22:35:44,945:INFO:              mlflow: Not installed
2025-05-15 22:35:44,945:INFO:              gradio: Not installed
2025-05-15 22:35:44,945:INFO:             fastapi: Not installed
2025-05-15 22:35:44,945:INFO:             uvicorn: Not installed
2025-05-15 22:35:44,945:INFO:              m2cgen: Not installed
2025-05-15 22:35:44,945:INFO:           evidently: Not installed
2025-05-15 22:35:44,945:INFO:               fugue: Not installed
2025-05-15 22:35:44,945:INFO:           streamlit: Not installed
2025-05-15 22:35:44,945:INFO:             prophet: Not installed
2025-05-15 22:35:44,945:INFO:None
2025-05-15 22:35:44,946:INFO:Set up data.
2025-05-15 22:35:44,978:INFO:Set up folding strategy.
2025-05-15 22:35:44,978:INFO:Set up train/test split.
2025-05-15 22:35:44,993:INFO:Set up index.
2025-05-15 22:35:44,993:INFO:Assigning column types.
2025-05-15 22:35:44,997:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 22:35:45,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 22:35:45,015:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:35:45,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:35:45,026:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:35:45,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 22:35:45,045:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:35:45,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:35:45,055:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:35:45,056:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 22:35:45,073:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:35:45,083:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:35:45,084:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:35:45,101:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:35:45,112:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:35:45,112:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:35:45,113:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 22:35:45,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:35:45,142:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:35:45,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:35:45,171:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:35:45,172:INFO:Preparing preprocessing pipeline...
2025-05-15 22:35:45,173:INFO:Set up simple imputation.
2025-05-15 22:35:45,179:INFO:Set up encoding of ordinal features.
2025-05-15 22:35:45,188:INFO:Set up encoding of categorical features.
2025-05-15 22:35:45,188:INFO:Set up imbalanced handling.
2025-05-15 22:35:45,188:INFO:Set up column transformation.
2025-05-15 22:35:45,443:INFO:Finished creating preprocessing pipeline.
2025-05-15 22:35:45,465:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 22:35:45,465:INFO:Creating final display dataframe.
2025-05-15 22:35:45,659:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 15)
4        Transformed data shape      (106821, 28)
5   Transformed train set shape       (85902, 28)
6    Transformed test set shape       (20919, 28)
7              Numeric features                 5
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              996e
2025-05-15 22:35:45,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:35:45,691:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:35:45,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:35:45,722:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:35:45,723:INFO:setup() successfully completed in 0.79s...............
2025-05-15 22:35:45,723:INFO:Initializing compare_models()
2025-05-15 22:35:45,724:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-15 22:35:45,724:INFO:Checking exceptions
2025-05-15 22:35:45,729:INFO:Preparing display monitor
2025-05-15 22:35:45,737:INFO:Initializing Logistic Regression
2025-05-15 22:35:45,737:INFO:Total runtime is 1.7523765563964843e-06 minutes
2025-05-15 22:35:45,739:INFO:SubProcess create_model() called ==================================
2025-05-15 22:35:45,739:INFO:Initializing create_model()
2025-05-15 22:35:45,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:35:45,739:INFO:Checking exceptions
2025-05-15 22:35:45,739:INFO:Importing libraries
2025-05-15 22:35:45,739:INFO:Copying training dataset
2025-05-15 22:35:45,748:INFO:Defining folds
2025-05-15 22:35:45,748:INFO:Declaring metric variables
2025-05-15 22:35:45,750:INFO:Importing untrained model
2025-05-15 22:35:45,752:INFO:Logistic Regression Imported successfully
2025-05-15 22:35:45,754:INFO:Starting cross validation
2025-05-15 22:35:45,755:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:35:51,704:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:35:51,723:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:35:51,764:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:35:51,767:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:35:51,839:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:35:51,886:INFO:Calculating mean and std
2025-05-15 22:35:51,888:INFO:Creating metrics dataframe
2025-05-15 22:35:51,892:INFO:Uploading results into container
2025-05-15 22:35:51,892:INFO:Uploading model into container now
2025-05-15 22:35:51,893:INFO:_master_model_container: 1
2025-05-15 22:35:51,893:INFO:_display_container: 2
2025-05-15 22:35:51,893:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 22:35:51,893:INFO:create_model() successfully completed......................................
2025-05-15 22:35:52,073:INFO:SubProcess create_model() end ==================================
2025-05-15 22:35:52,073:INFO:Creating metrics dataframe
2025-05-15 22:35:52,076:INFO:Initializing K Neighbors Classifier
2025-05-15 22:35:52,076:INFO:Total runtime is 0.1056466499964396 minutes
2025-05-15 22:35:52,077:INFO:SubProcess create_model() called ==================================
2025-05-15 22:35:52,077:INFO:Initializing create_model()
2025-05-15 22:35:52,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:35:52,077:INFO:Checking exceptions
2025-05-15 22:35:52,077:INFO:Importing libraries
2025-05-15 22:35:52,078:INFO:Copying training dataset
2025-05-15 22:35:52,086:INFO:Defining folds
2025-05-15 22:35:52,086:INFO:Declaring metric variables
2025-05-15 22:35:52,088:INFO:Importing untrained model
2025-05-15 22:35:52,089:INFO:K Neighbors Classifier Imported successfully
2025-05-15 22:35:52,091:INFO:Starting cross validation
2025-05-15 22:35:52,093:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:35:57,934:INFO:Calculating mean and std
2025-05-15 22:35:57,936:INFO:Creating metrics dataframe
2025-05-15 22:35:57,941:INFO:Uploading results into container
2025-05-15 22:35:57,942:INFO:Uploading model into container now
2025-05-15 22:35:57,942:INFO:_master_model_container: 2
2025-05-15 22:35:57,942:INFO:_display_container: 2
2025-05-15 22:35:57,943:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-15 22:35:57,943:INFO:create_model() successfully completed......................................
2025-05-15 22:35:58,085:INFO:SubProcess create_model() end ==================================
2025-05-15 22:35:58,085:INFO:Creating metrics dataframe
2025-05-15 22:35:58,088:INFO:Initializing Naive Bayes
2025-05-15 22:35:58,088:INFO:Total runtime is 0.20585001707077027 minutes
2025-05-15 22:35:58,089:INFO:SubProcess create_model() called ==================================
2025-05-15 22:35:58,090:INFO:Initializing create_model()
2025-05-15 22:35:58,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:35:58,090:INFO:Checking exceptions
2025-05-15 22:35:58,090:INFO:Importing libraries
2025-05-15 22:35:58,090:INFO:Copying training dataset
2025-05-15 22:35:58,100:INFO:Defining folds
2025-05-15 22:35:58,100:INFO:Declaring metric variables
2025-05-15 22:35:58,102:INFO:Importing untrained model
2025-05-15 22:35:58,103:INFO:Naive Bayes Imported successfully
2025-05-15 22:35:58,105:INFO:Starting cross validation
2025-05-15 22:35:58,106:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:36:00,558:INFO:Calculating mean and std
2025-05-15 22:36:00,558:INFO:Creating metrics dataframe
2025-05-15 22:36:00,559:INFO:Uploading results into container
2025-05-15 22:36:00,560:INFO:Uploading model into container now
2025-05-15 22:36:00,560:INFO:_master_model_container: 3
2025-05-15 22:36:00,560:INFO:_display_container: 2
2025-05-15 22:36:00,561:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-15 22:36:00,561:INFO:create_model() successfully completed......................................
2025-05-15 22:36:00,702:INFO:SubProcess create_model() end ==================================
2025-05-15 22:36:00,702:INFO:Creating metrics dataframe
2025-05-15 22:36:00,706:INFO:Initializing Decision Tree Classifier
2025-05-15 22:36:00,706:INFO:Total runtime is 0.24947660366694133 minutes
2025-05-15 22:36:00,707:INFO:SubProcess create_model() called ==================================
2025-05-15 22:36:00,707:INFO:Initializing create_model()
2025-05-15 22:36:00,707:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:36:00,707:INFO:Checking exceptions
2025-05-15 22:36:00,707:INFO:Importing libraries
2025-05-15 22:36:00,708:INFO:Copying training dataset
2025-05-15 22:36:00,717:INFO:Defining folds
2025-05-15 22:36:00,717:INFO:Declaring metric variables
2025-05-15 22:36:00,718:INFO:Importing untrained model
2025-05-15 22:36:00,720:INFO:Decision Tree Classifier Imported successfully
2025-05-15 22:36:00,722:INFO:Starting cross validation
2025-05-15 22:36:00,723:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:36:03,726:INFO:Calculating mean and std
2025-05-15 22:36:03,731:INFO:Creating metrics dataframe
2025-05-15 22:36:03,735:INFO:Uploading results into container
2025-05-15 22:36:03,735:INFO:Uploading model into container now
2025-05-15 22:36:03,736:INFO:_master_model_container: 4
2025-05-15 22:36:03,736:INFO:_display_container: 2
2025-05-15 22:36:03,736:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-15 22:36:03,736:INFO:create_model() successfully completed......................................
2025-05-15 22:36:03,890:INFO:SubProcess create_model() end ==================================
2025-05-15 22:36:03,890:INFO:Creating metrics dataframe
2025-05-15 22:36:03,893:INFO:Initializing SVM - Linear Kernel
2025-05-15 22:36:03,894:INFO:Total runtime is 0.3026063005129496 minutes
2025-05-15 22:36:03,895:INFO:SubProcess create_model() called ==================================
2025-05-15 22:36:03,895:INFO:Initializing create_model()
2025-05-15 22:36:03,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:36:03,895:INFO:Checking exceptions
2025-05-15 22:36:03,895:INFO:Importing libraries
2025-05-15 22:36:03,895:INFO:Copying training dataset
2025-05-15 22:36:03,905:INFO:Defining folds
2025-05-15 22:36:03,905:INFO:Declaring metric variables
2025-05-15 22:36:03,906:INFO:Importing untrained model
2025-05-15 22:36:03,908:INFO:SVM - Linear Kernel Imported successfully
2025-05-15 22:36:03,910:INFO:Starting cross validation
2025-05-15 22:36:03,911:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:36:07,410:INFO:Calculating mean and std
2025-05-15 22:36:07,411:INFO:Creating metrics dataframe
2025-05-15 22:36:07,412:INFO:Uploading results into container
2025-05-15 22:36:07,412:INFO:Uploading model into container now
2025-05-15 22:36:07,412:INFO:_master_model_container: 5
2025-05-15 22:36:07,413:INFO:_display_container: 2
2025-05-15 22:36:07,413:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-15 22:36:07,413:INFO:create_model() successfully completed......................................
2025-05-15 22:36:07,583:INFO:SubProcess create_model() end ==================================
2025-05-15 22:36:07,583:INFO:Creating metrics dataframe
2025-05-15 22:36:07,587:INFO:Initializing Ridge Classifier
2025-05-15 22:36:07,587:INFO:Total runtime is 0.36415813366572064 minutes
2025-05-15 22:36:07,588:INFO:SubProcess create_model() called ==================================
2025-05-15 22:36:07,588:INFO:Initializing create_model()
2025-05-15 22:36:07,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:36:07,588:INFO:Checking exceptions
2025-05-15 22:36:07,588:INFO:Importing libraries
2025-05-15 22:36:07,588:INFO:Copying training dataset
2025-05-15 22:36:07,599:INFO:Defining folds
2025-05-15 22:36:07,599:INFO:Declaring metric variables
2025-05-15 22:36:07,600:INFO:Importing untrained model
2025-05-15 22:36:07,602:INFO:Ridge Classifier Imported successfully
2025-05-15 22:36:07,603:INFO:Starting cross validation
2025-05-15 22:36:07,604:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:36:08,687:INFO:Calculating mean and std
2025-05-15 22:36:08,688:INFO:Creating metrics dataframe
2025-05-15 22:36:08,689:INFO:Uploading results into container
2025-05-15 22:36:08,689:INFO:Uploading model into container now
2025-05-15 22:36:08,689:INFO:_master_model_container: 6
2025-05-15 22:36:08,689:INFO:_display_container: 2
2025-05-15 22:36:08,690:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-15 22:36:08,690:INFO:create_model() successfully completed......................................
2025-05-15 22:36:08,811:INFO:SubProcess create_model() end ==================================
2025-05-15 22:36:08,811:INFO:Creating metrics dataframe
2025-05-15 22:36:08,814:INFO:Initializing Random Forest Classifier
2025-05-15 22:36:08,814:INFO:Total runtime is 0.38461778163909915 minutes
2025-05-15 22:36:08,815:INFO:SubProcess create_model() called ==================================
2025-05-15 22:36:08,816:INFO:Initializing create_model()
2025-05-15 22:36:08,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:36:08,816:INFO:Checking exceptions
2025-05-15 22:36:08,816:INFO:Importing libraries
2025-05-15 22:36:08,816:INFO:Copying training dataset
2025-05-15 22:36:08,825:INFO:Defining folds
2025-05-15 22:36:08,825:INFO:Declaring metric variables
2025-05-15 22:36:08,826:INFO:Importing untrained model
2025-05-15 22:36:08,827:INFO:Random Forest Classifier Imported successfully
2025-05-15 22:36:08,829:INFO:Starting cross validation
2025-05-15 22:36:08,831:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:36:14,508:INFO:Calculating mean and std
2025-05-15 22:36:14,513:INFO:Creating metrics dataframe
2025-05-15 22:36:14,517:INFO:Uploading results into container
2025-05-15 22:36:14,517:INFO:Uploading model into container now
2025-05-15 22:36:14,518:INFO:_master_model_container: 7
2025-05-15 22:36:14,518:INFO:_display_container: 2
2025-05-15 22:36:14,518:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-15 22:36:14,518:INFO:create_model() successfully completed......................................
2025-05-15 22:36:14,671:INFO:SubProcess create_model() end ==================================
2025-05-15 22:36:14,671:INFO:Creating metrics dataframe
2025-05-15 22:36:14,675:INFO:Initializing Quadratic Discriminant Analysis
2025-05-15 22:36:14,675:INFO:Total runtime is 0.48230186700820926 minutes
2025-05-15 22:36:14,677:INFO:SubProcess create_model() called ==================================
2025-05-15 22:36:14,677:INFO:Initializing create_model()
2025-05-15 22:36:14,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:36:14,677:INFO:Checking exceptions
2025-05-15 22:36:14,677:INFO:Importing libraries
2025-05-15 22:36:14,677:INFO:Copying training dataset
2025-05-15 22:36:14,687:INFO:Defining folds
2025-05-15 22:36:14,687:INFO:Declaring metric variables
2025-05-15 22:36:14,688:INFO:Importing untrained model
2025-05-15 22:36:14,689:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-15 22:36:14,691:INFO:Starting cross validation
2025-05-15 22:36:14,692:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:36:15,658:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:36:15,679:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:36:15,697:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:36:15,724:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:36:15,742:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:36:15,747:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-15 22:36:15,753:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:36:15,776:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:36:15,793:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:36:15,818:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:36:15,828:INFO:Calculating mean and std
2025-05-15 22:36:15,829:INFO:Creating metrics dataframe
2025-05-15 22:36:15,830:INFO:Uploading results into container
2025-05-15 22:36:15,830:INFO:Uploading model into container now
2025-05-15 22:36:15,830:INFO:_master_model_container: 8
2025-05-15 22:36:15,830:INFO:_display_container: 2
2025-05-15 22:36:15,830:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-15 22:36:15,830:INFO:create_model() successfully completed......................................
2025-05-15 22:36:15,987:INFO:SubProcess create_model() end ==================================
2025-05-15 22:36:15,987:INFO:Creating metrics dataframe
2025-05-15 22:36:15,991:INFO:Initializing Ada Boost Classifier
2025-05-15 22:36:15,991:INFO:Total runtime is 0.5042339205741883 minutes
2025-05-15 22:36:15,993:INFO:SubProcess create_model() called ==================================
2025-05-15 22:36:15,993:INFO:Initializing create_model()
2025-05-15 22:36:15,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:36:15,993:INFO:Checking exceptions
2025-05-15 22:36:15,993:INFO:Importing libraries
2025-05-15 22:36:15,993:INFO:Copying training dataset
2025-05-15 22:36:16,005:INFO:Defining folds
2025-05-15 22:36:16,005:INFO:Declaring metric variables
2025-05-15 22:36:16,007:INFO:Importing untrained model
2025-05-15 22:36:16,008:INFO:Ada Boost Classifier Imported successfully
2025-05-15 22:36:16,011:INFO:Starting cross validation
2025-05-15 22:36:16,012:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:36:16,990:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:36:16,990:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:36:16,992:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:36:17,010:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:36:17,049:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-15 22:36:19,702:INFO:Calculating mean and std
2025-05-15 22:36:19,703:INFO:Creating metrics dataframe
2025-05-15 22:36:19,704:INFO:Uploading results into container
2025-05-15 22:36:19,704:INFO:Uploading model into container now
2025-05-15 22:36:19,704:INFO:_master_model_container: 9
2025-05-15 22:36:19,704:INFO:_display_container: 2
2025-05-15 22:36:19,705:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-15 22:36:19,705:INFO:create_model() successfully completed......................................
2025-05-15 22:36:19,829:INFO:SubProcess create_model() end ==================================
2025-05-15 22:36:19,829:INFO:Creating metrics dataframe
2025-05-15 22:36:19,832:INFO:Initializing Gradient Boosting Classifier
2025-05-15 22:36:19,832:INFO:Total runtime is 0.5682538549105327 minutes
2025-05-15 22:36:19,834:INFO:SubProcess create_model() called ==================================
2025-05-15 22:36:19,834:INFO:Initializing create_model()
2025-05-15 22:36:19,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:36:19,834:INFO:Checking exceptions
2025-05-15 22:36:19,834:INFO:Importing libraries
2025-05-15 22:36:19,834:INFO:Copying training dataset
2025-05-15 22:36:19,843:INFO:Defining folds
2025-05-15 22:36:19,843:INFO:Declaring metric variables
2025-05-15 22:36:19,845:INFO:Importing untrained model
2025-05-15 22:36:19,846:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 22:36:19,848:INFO:Starting cross validation
2025-05-15 22:36:19,849:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:36:33,648:INFO:Calculating mean and std
2025-05-15 22:36:33,651:INFO:Creating metrics dataframe
2025-05-15 22:36:33,655:INFO:Uploading results into container
2025-05-15 22:36:33,655:INFO:Uploading model into container now
2025-05-15 22:36:33,656:INFO:_master_model_container: 10
2025-05-15 22:36:33,656:INFO:_display_container: 2
2025-05-15 22:36:33,656:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 22:36:33,656:INFO:create_model() successfully completed......................................
2025-05-15 22:36:33,888:INFO:SubProcess create_model() end ==================================
2025-05-15 22:36:33,888:INFO:Creating metrics dataframe
2025-05-15 22:36:33,892:INFO:Initializing Linear Discriminant Analysis
2025-05-15 22:36:33,892:INFO:Total runtime is 0.802586305141449 minutes
2025-05-15 22:36:33,894:INFO:SubProcess create_model() called ==================================
2025-05-15 22:36:33,894:INFO:Initializing create_model()
2025-05-15 22:36:33,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:36:33,894:INFO:Checking exceptions
2025-05-15 22:36:33,894:INFO:Importing libraries
2025-05-15 22:36:33,894:INFO:Copying training dataset
2025-05-15 22:36:33,911:INFO:Defining folds
2025-05-15 22:36:33,911:INFO:Declaring metric variables
2025-05-15 22:36:33,912:INFO:Importing untrained model
2025-05-15 22:36:33,913:INFO:Linear Discriminant Analysis Imported successfully
2025-05-15 22:36:33,915:INFO:Starting cross validation
2025-05-15 22:36:33,917:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:36:35,105:INFO:Calculating mean and std
2025-05-15 22:36:35,106:INFO:Creating metrics dataframe
2025-05-15 22:36:35,107:INFO:Uploading results into container
2025-05-15 22:36:35,107:INFO:Uploading model into container now
2025-05-15 22:36:35,107:INFO:_master_model_container: 11
2025-05-15 22:36:35,108:INFO:_display_container: 2
2025-05-15 22:36:35,108:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-15 22:36:35,108:INFO:create_model() successfully completed......................................
2025-05-15 22:36:35,236:INFO:SubProcess create_model() end ==================================
2025-05-15 22:36:35,236:INFO:Creating metrics dataframe
2025-05-15 22:36:35,240:INFO:Initializing Extra Trees Classifier
2025-05-15 22:36:35,240:INFO:Total runtime is 0.8250424861907959 minutes
2025-05-15 22:36:35,241:INFO:SubProcess create_model() called ==================================
2025-05-15 22:36:35,241:INFO:Initializing create_model()
2025-05-15 22:36:35,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:36:35,241:INFO:Checking exceptions
2025-05-15 22:36:35,241:INFO:Importing libraries
2025-05-15 22:36:35,241:INFO:Copying training dataset
2025-05-15 22:36:35,250:INFO:Defining folds
2025-05-15 22:36:35,250:INFO:Declaring metric variables
2025-05-15 22:36:35,251:INFO:Importing untrained model
2025-05-15 22:36:35,253:INFO:Extra Trees Classifier Imported successfully
2025-05-15 22:36:35,255:INFO:Starting cross validation
2025-05-15 22:36:35,256:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:36:39,979:INFO:Calculating mean and std
2025-05-15 22:36:39,983:INFO:Creating metrics dataframe
2025-05-15 22:36:39,989:INFO:Uploading results into container
2025-05-15 22:36:39,989:INFO:Uploading model into container now
2025-05-15 22:36:39,990:INFO:_master_model_container: 12
2025-05-15 22:36:39,990:INFO:_display_container: 2
2025-05-15 22:36:39,992:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-15 22:36:39,993:INFO:create_model() successfully completed......................................
2025-05-15 22:36:40,254:INFO:SubProcess create_model() end ==================================
2025-05-15 22:36:40,254:INFO:Creating metrics dataframe
2025-05-15 22:36:40,259:INFO:Initializing Light Gradient Boosting Machine
2025-05-15 22:36:40,259:INFO:Total runtime is 0.9087047656377156 minutes
2025-05-15 22:36:40,261:INFO:SubProcess create_model() called ==================================
2025-05-15 22:36:40,261:INFO:Initializing create_model()
2025-05-15 22:36:40,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:36:40,261:INFO:Checking exceptions
2025-05-15 22:36:40,261:INFO:Importing libraries
2025-05-15 22:36:40,261:INFO:Copying training dataset
2025-05-15 22:36:40,280:INFO:Defining folds
2025-05-15 22:36:40,280:INFO:Declaring metric variables
2025-05-15 22:36:40,282:INFO:Importing untrained model
2025-05-15 22:36:40,284:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 22:36:40,286:INFO:Starting cross validation
2025-05-15 22:36:40,287:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:36:44,354:INFO:Calculating mean and std
2025-05-15 22:36:44,354:INFO:Creating metrics dataframe
2025-05-15 22:36:44,355:INFO:Uploading results into container
2025-05-15 22:36:44,356:INFO:Uploading model into container now
2025-05-15 22:36:44,356:INFO:_master_model_container: 13
2025-05-15 22:36:44,356:INFO:_display_container: 2
2025-05-15 22:36:44,357:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:36:44,357:INFO:create_model() successfully completed......................................
2025-05-15 22:36:44,492:INFO:SubProcess create_model() end ==================================
2025-05-15 22:36:44,492:INFO:Creating metrics dataframe
2025-05-15 22:36:44,496:INFO:Initializing CatBoost Classifier
2025-05-15 22:36:44,496:INFO:Total runtime is 0.9793210665384928 minutes
2025-05-15 22:36:44,498:INFO:SubProcess create_model() called ==================================
2025-05-15 22:36:44,498:INFO:Initializing create_model()
2025-05-15 22:36:44,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:36:44,498:INFO:Checking exceptions
2025-05-15 22:36:44,498:INFO:Importing libraries
2025-05-15 22:36:44,499:INFO:Copying training dataset
2025-05-15 22:36:44,509:INFO:Defining folds
2025-05-15 22:36:44,510:INFO:Declaring metric variables
2025-05-15 22:36:44,511:INFO:Importing untrained model
2025-05-15 22:36:44,512:INFO:CatBoost Classifier Imported successfully
2025-05-15 22:36:44,515:INFO:Starting cross validation
2025-05-15 22:36:44,516:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:37:01,067:INFO:Calculating mean and std
2025-05-15 22:37:01,069:INFO:Creating metrics dataframe
2025-05-15 22:37:01,071:INFO:Uploading results into container
2025-05-15 22:37:01,072:INFO:Uploading model into container now
2025-05-15 22:37:01,073:INFO:_master_model_container: 14
2025-05-15 22:37:01,073:INFO:_display_container: 2
2025-05-15 22:37:01,073:INFO:<catboost.core.CatBoostClassifier object at 0x3304132d0>
2025-05-15 22:37:01,073:INFO:create_model() successfully completed......................................
2025-05-15 22:37:01,246:INFO:SubProcess create_model() end ==================================
2025-05-15 22:37:01,246:INFO:Creating metrics dataframe
2025-05-15 22:37:01,250:INFO:Initializing Dummy Classifier
2025-05-15 22:37:01,250:INFO:Total runtime is 1.2585521697998048 minutes
2025-05-15 22:37:01,252:INFO:SubProcess create_model() called ==================================
2025-05-15 22:37:01,252:INFO:Initializing create_model()
2025-05-15 22:37:01,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3568cf790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:37:01,252:INFO:Checking exceptions
2025-05-15 22:37:01,252:INFO:Importing libraries
2025-05-15 22:37:01,252:INFO:Copying training dataset
2025-05-15 22:37:01,268:INFO:Defining folds
2025-05-15 22:37:01,268:INFO:Declaring metric variables
2025-05-15 22:37:01,269:INFO:Importing untrained model
2025-05-15 22:37:01,270:INFO:Dummy Classifier Imported successfully
2025-05-15 22:37:01,272:INFO:Starting cross validation
2025-05-15 22:37:01,274:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:37:02,302:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:37:02,305:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:37:02,311:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:37:02,322:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:37:02,362:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-15 22:37:02,368:INFO:Calculating mean and std
2025-05-15 22:37:02,369:INFO:Creating metrics dataframe
2025-05-15 22:37:02,370:INFO:Uploading results into container
2025-05-15 22:37:02,370:INFO:Uploading model into container now
2025-05-15 22:37:02,370:INFO:_master_model_container: 15
2025-05-15 22:37:02,370:INFO:_display_container: 2
2025-05-15 22:37:02,370:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-15 22:37:02,370:INFO:create_model() successfully completed......................................
2025-05-15 22:37:02,485:INFO:SubProcess create_model() end ==================================
2025-05-15 22:37:02,485:INFO:Creating metrics dataframe
2025-05-15 22:37:02,490:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-15 22:37:02,493:INFO:Initializing create_model()
2025-05-15 22:37:02,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:37:02,493:INFO:Checking exceptions
2025-05-15 22:37:02,494:INFO:Importing libraries
2025-05-15 22:37:02,494:INFO:Copying training dataset
2025-05-15 22:37:02,502:INFO:Defining folds
2025-05-15 22:37:02,502:INFO:Declaring metric variables
2025-05-15 22:37:02,502:INFO:Importing untrained model
2025-05-15 22:37:02,502:INFO:Declaring custom model
2025-05-15 22:37:02,503:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-15 22:37:02,503:INFO:Cross validation set to False
2025-05-15 22:37:02,503:INFO:Fitting Model
2025-05-15 22:37:03,825:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-15 22:37:03,835:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004531 seconds.
2025-05-15 22:37:03,835:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-15 22:37:03,835:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-15 22:37:03,835:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-15 22:37:03,836:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 27
2025-05-15 22:37:03,836:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-15 22:37:04,602:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-15 22:37:04,603:INFO:create_model() successfully completed......................................
2025-05-15 22:37:04,721:INFO:Initializing create_model()
2025-05-15 22:37:04,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:37:04,721:INFO:Checking exceptions
2025-05-15 22:37:04,721:INFO:Importing libraries
2025-05-15 22:37:04,721:INFO:Copying training dataset
2025-05-15 22:37:04,730:INFO:Defining folds
2025-05-15 22:37:04,730:INFO:Declaring metric variables
2025-05-15 22:37:04,730:INFO:Importing untrained model
2025-05-15 22:37:04,730:INFO:Declaring custom model
2025-05-15 22:37:04,731:INFO:Gradient Boosting Classifier Imported successfully
2025-05-15 22:37:04,731:INFO:Cross validation set to False
2025-05-15 22:37:04,731:INFO:Fitting Model
2025-05-15 22:37:20,598:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-15 22:37:20,599:INFO:create_model() successfully completed......................................
2025-05-15 22:37:20,777:INFO:Initializing create_model()
2025-05-15 22:37:20,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=<catboost.core.CatBoostClassifier object at 0x3304132d0>, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:37:20,777:INFO:Checking exceptions
2025-05-15 22:37:20,778:INFO:Importing libraries
2025-05-15 22:37:20,778:INFO:Copying training dataset
2025-05-15 22:37:20,788:INFO:Defining folds
2025-05-15 22:37:20,788:INFO:Declaring metric variables
2025-05-15 22:37:20,788:INFO:Importing untrained model
2025-05-15 22:37:20,788:INFO:Declaring custom model
2025-05-15 22:37:20,789:INFO:CatBoost Classifier Imported successfully
2025-05-15 22:37:20,790:INFO:Cross validation set to False
2025-05-15 22:37:20,790:INFO:Fitting Model
2025-05-15 22:37:29,531:INFO:<catboost.core.CatBoostClassifier object at 0x36eda75d0>
2025-05-15 22:37:29,532:INFO:create_model() successfully completed......................................
2025-05-15 22:37:29,824:INFO:_master_model_container: 15
2025-05-15 22:37:29,824:INFO:_display_container: 2
2025-05-15 22:37:29,825:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), <catboost.core.CatBoostClassifier object at 0x36eda75d0>]
2025-05-15 22:37:29,825:INFO:compare_models() successfully completed......................................
2025-05-15 22:37:29,827:INFO:Initializing evaluate_model()
2025-05-15 22:37:29,827:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-15 22:37:29,841:INFO:Initializing plot_model()
2025-05-15 22:37:29,841:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-15 22:37:29,841:INFO:Checking exceptions
2025-05-15 22:37:29,847:INFO:Preloading libraries
2025-05-15 22:37:29,850:INFO:Copying training dataset
2025-05-15 22:37:29,850:INFO:Plot type: pipeline
2025-05-15 22:37:29,912:INFO:Visual Rendered Successfully
2025-05-15 22:37:30,045:INFO:plot_model() successfully completed......................................
2025-05-15 22:37:30,047:INFO:Initializing tune_model()
2025-05-15 22:37:30,047:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36f06fa90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-15 22:37:30,047:INFO:Checking exceptions
2025-05-15 22:37:30,056:INFO:Copying training dataset
2025-05-15 22:37:30,063:INFO:Checking base model
2025-05-15 22:37:30,063:INFO:Base model : Light Gradient Boosting Machine
2025-05-15 22:37:30,064:INFO:Declaring metric variables
2025-05-15 22:37:30,065:INFO:Defining Hyperparameters
2025-05-15 22:37:30,190:INFO:Tuning with n_jobs=-1
2025-05-15 22:37:30,190:INFO:Initializing RandomizedSearchCV
2025-05-15 22:38:15,203:INFO:PyCaret ClassificationExperiment
2025-05-15 22:38:15,203:INFO:Logging name: clf-default-name
2025-05-15 22:38:15,203:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-15 22:38:15,203:INFO:version 3.3.2
2025-05-15 22:38:15,203:INFO:Initializing setup()
2025-05-15 22:38:15,203:INFO:self.USI: a69f
2025-05-15 22:38:15,203:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-15 22:38:15,203:INFO:Checking environment
2025-05-15 22:38:15,203:INFO:python_version: 3.11.0
2025-05-15 22:38:15,203:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-15 22:38:15,203:INFO:machine: arm64
2025-05-15 22:38:15,203:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-15 22:38:15,204:INFO:Memory: svmem(total=17179869184, available=4127916032, percent=76.0, used=6053789696, free=865271808, active=3275915264, inactive=3241132032, wired=2777874432)
2025-05-15 22:38:15,204:INFO:Physical Core: 12
2025-05-15 22:38:15,204:INFO:Logical Core: 12
2025-05-15 22:38:15,204:INFO:Checking libraries
2025-05-15 22:38:15,204:INFO:System:
2025-05-15 22:38:15,204:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-15 22:38:15,204:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-15 22:38:15,204:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-15 22:38:15,204:INFO:PyCaret required dependencies:
2025-05-15 22:38:15,204:INFO:                 pip: 22.3
2025-05-15 22:38:15,204:INFO:          setuptools: 65.5.0
2025-05-15 22:38:15,204:INFO:             pycaret: 3.3.2
2025-05-15 22:38:15,204:INFO:             IPython: 9.2.0
2025-05-15 22:38:15,204:INFO:          ipywidgets: 8.1.7
2025-05-15 22:38:15,204:INFO:                tqdm: 4.67.1
2025-05-15 22:38:15,204:INFO:               numpy: 1.26.4
2025-05-15 22:38:15,204:INFO:              pandas: 2.1.4
2025-05-15 22:38:15,204:INFO:              jinja2: 3.1.6
2025-05-15 22:38:15,204:INFO:               scipy: 1.11.4
2025-05-15 22:38:15,204:INFO:              joblib: 1.3.2
2025-05-15 22:38:15,204:INFO:             sklearn: 1.4.2
2025-05-15 22:38:15,204:INFO:                pyod: 2.0.5
2025-05-15 22:38:15,204:INFO:            imblearn: 0.13.0
2025-05-15 22:38:15,204:INFO:   category_encoders: 2.7.0
2025-05-15 22:38:15,204:INFO:            lightgbm: 4.6.0
2025-05-15 22:38:15,204:INFO:               numba: 0.61.2
2025-05-15 22:38:15,204:INFO:            requests: 2.32.3
2025-05-15 22:38:15,204:INFO:          matplotlib: 3.7.5
2025-05-15 22:38:15,204:INFO:          scikitplot: 0.3.7
2025-05-15 22:38:15,204:INFO:         yellowbrick: 1.5
2025-05-15 22:38:15,204:INFO:              plotly: 5.24.1
2025-05-15 22:38:15,204:INFO:    plotly-resampler: Not installed
2025-05-15 22:38:15,204:INFO:             kaleido: 0.2.1
2025-05-15 22:38:15,204:INFO:           schemdraw: 0.15
2025-05-15 22:38:15,204:INFO:         statsmodels: 0.14.4
2025-05-15 22:38:15,204:INFO:              sktime: 0.26.0
2025-05-15 22:38:15,204:INFO:               tbats: 1.1.3
2025-05-15 22:38:15,204:INFO:            pmdarima: 2.0.4
2025-05-15 22:38:15,204:INFO:              psutil: 7.0.0
2025-05-15 22:38:15,204:INFO:          markupsafe: 3.0.2
2025-05-15 22:38:15,204:INFO:             pickle5: Not installed
2025-05-15 22:38:15,204:INFO:         cloudpickle: 3.1.1
2025-05-15 22:38:15,204:INFO:         deprecation: 2.1.0
2025-05-15 22:38:15,204:INFO:              xxhash: 3.5.0
2025-05-15 22:38:15,204:INFO:           wurlitzer: 3.1.1
2025-05-15 22:38:15,204:INFO:PyCaret optional dependencies:
2025-05-15 22:38:15,204:INFO:                shap: 0.47.2
2025-05-15 22:38:15,204:INFO:           interpret: Not installed
2025-05-15 22:38:15,204:INFO:                umap: Not installed
2025-05-15 22:38:15,204:INFO:     ydata_profiling: Not installed
2025-05-15 22:38:15,204:INFO:  explainerdashboard: Not installed
2025-05-15 22:38:15,204:INFO:             autoviz: Not installed
2025-05-15 22:38:15,204:INFO:           fairlearn: Not installed
2025-05-15 22:38:15,204:INFO:          deepchecks: Not installed
2025-05-15 22:38:15,204:INFO:             xgboost: Not installed
2025-05-15 22:38:15,204:INFO:            catboost: 1.2.8
2025-05-15 22:38:15,204:INFO:              kmodes: Not installed
2025-05-15 22:38:15,204:INFO:             mlxtend: Not installed
2025-05-15 22:38:15,204:INFO:       statsforecast: Not installed
2025-05-15 22:38:15,204:INFO:        tune_sklearn: Not installed
2025-05-15 22:38:15,204:INFO:                 ray: Not installed
2025-05-15 22:38:15,204:INFO:            hyperopt: Not installed
2025-05-15 22:38:15,204:INFO:              optuna: 4.3.0
2025-05-15 22:38:15,204:INFO:               skopt: Not installed
2025-05-15 22:38:15,204:INFO:              mlflow: Not installed
2025-05-15 22:38:15,204:INFO:              gradio: Not installed
2025-05-15 22:38:15,204:INFO:             fastapi: Not installed
2025-05-15 22:38:15,204:INFO:             uvicorn: Not installed
2025-05-15 22:38:15,204:INFO:              m2cgen: Not installed
2025-05-15 22:38:15,204:INFO:           evidently: Not installed
2025-05-15 22:38:15,204:INFO:               fugue: Not installed
2025-05-15 22:38:15,204:INFO:           streamlit: Not installed
2025-05-15 22:38:15,204:INFO:             prophet: Not installed
2025-05-15 22:38:15,204:INFO:None
2025-05-15 22:38:15,204:INFO:Set up data.
2025-05-15 22:38:15,235:INFO:Set up folding strategy.
2025-05-15 22:38:15,235:INFO:Set up train/test split.
2025-05-15 22:38:15,251:INFO:Set up index.
2025-05-15 22:38:15,251:INFO:Assigning column types.
2025-05-15 22:38:15,256:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 22:38:15,274:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 22:38:15,275:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:38:15,286:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:38:15,286:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:38:15,304:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 22:38:15,304:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:38:15,315:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:38:15,315:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:38:15,316:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 22:38:15,334:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:38:15,345:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:38:15,345:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:38:15,363:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 22:38:15,374:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:38:15,374:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:38:15,375:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-15 22:38:15,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:38:15,406:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:38:15,435:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:38:15,435:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:38:15,435:INFO:Preparing preprocessing pipeline...
2025-05-15 22:38:15,437:INFO:Set up simple imputation.
2025-05-15 22:38:15,443:INFO:Set up encoding of ordinal features.
2025-05-15 22:38:15,452:INFO:Set up encoding of categorical features.
2025-05-15 22:38:15,452:INFO:Set up imbalanced handling.
2025-05-15 22:38:15,452:INFO:Set up column transformation.
2025-05-15 22:38:16,495:INFO:Finished creating preprocessing pipeline.
2025-05-15 22:38:16,515:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-15 22:38:16,515:INFO:Creating final display dataframe.
2025-05-15 22:38:16,974:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 5
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              a69f
2025-05-15 22:38:17,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:38:17,008:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:38:17,039:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 22:38:17,040:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-15 22:38:17,040:INFO:setup() successfully completed in 1.84s...............
2025-05-15 22:38:17,041:INFO:Initializing compare_models()
2025-05-15 22:38:17,041:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36336fa90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x36336fa90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-15 22:38:17,041:INFO:Checking exceptions
2025-05-15 22:38:17,046:INFO:Preparing display monitor
2025-05-15 22:38:17,054:INFO:Initializing Logistic Regression
2025-05-15 22:38:17,054:INFO:Total runtime is 2.133846282958984e-06 minutes
2025-05-15 22:38:17,055:INFO:SubProcess create_model() called ==================================
2025-05-15 22:38:17,056:INFO:Initializing create_model()
2025-05-15 22:38:17,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36336fa90>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356061410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:38:17,056:INFO:Checking exceptions
2025-05-15 22:38:17,056:INFO:Importing libraries
2025-05-15 22:38:17,056:INFO:Copying training dataset
2025-05-15 22:38:17,066:INFO:Defining folds
2025-05-15 22:38:17,066:INFO:Declaring metric variables
2025-05-15 22:38:17,068:INFO:Importing untrained model
2025-05-15 22:38:17,069:INFO:Logistic Regression Imported successfully
2025-05-15 22:38:17,071:INFO:Starting cross validation
2025-05-15 22:38:17,072:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:38:23,262:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:38:23,264:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:38:23,282:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:38:23,325:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:38:23,332:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-15 22:38:23,401:INFO:Calculating mean and std
2025-05-15 22:38:23,407:INFO:Creating metrics dataframe
2025-05-15 22:38:23,417:INFO:Uploading results into container
2025-05-15 22:38:23,417:INFO:Uploading model into container now
2025-05-15 22:38:23,418:INFO:_master_model_container: 1
2025-05-15 22:38:23,418:INFO:_display_container: 2
2025-05-15 22:38:23,419:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-15 22:38:23,419:INFO:create_model() successfully completed......................................
2025-05-15 22:38:23,716:INFO:SubProcess create_model() end ==================================
2025-05-15 22:38:23,716:INFO:Creating metrics dataframe
2025-05-15 22:38:23,719:INFO:Initializing K Neighbors Classifier
2025-05-15 22:38:23,719:INFO:Total runtime is 0.11108923355738322 minutes
2025-05-15 22:38:23,721:INFO:SubProcess create_model() called ==================================
2025-05-15 22:38:23,721:INFO:Initializing create_model()
2025-05-15 22:38:23,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36336fa90>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356061410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:38:23,721:INFO:Checking exceptions
2025-05-15 22:38:23,721:INFO:Importing libraries
2025-05-15 22:38:23,721:INFO:Copying training dataset
2025-05-15 22:38:23,733:INFO:Defining folds
2025-05-15 22:38:23,733:INFO:Declaring metric variables
2025-05-15 22:38:23,735:INFO:Importing untrained model
2025-05-15 22:38:23,736:INFO:K Neighbors Classifier Imported successfully
2025-05-15 22:38:23,739:INFO:Starting cross validation
2025-05-15 22:38:23,741:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:38:29,726:INFO:Calculating mean and std
2025-05-15 22:38:29,726:INFO:Creating metrics dataframe
2025-05-15 22:38:29,727:INFO:Uploading results into container
2025-05-15 22:38:29,728:INFO:Uploading model into container now
2025-05-15 22:38:29,728:INFO:_master_model_container: 2
2025-05-15 22:38:29,728:INFO:_display_container: 2
2025-05-15 22:38:29,728:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-15 22:38:29,728:INFO:create_model() successfully completed......................................
2025-05-15 22:38:29,870:INFO:SubProcess create_model() end ==================================
2025-05-15 22:38:29,870:INFO:Creating metrics dataframe
2025-05-15 22:38:29,873:INFO:Initializing Naive Bayes
2025-05-15 22:38:29,873:INFO:Total runtime is 0.21364972988764447 minutes
2025-05-15 22:38:29,874:INFO:SubProcess create_model() called ==================================
2025-05-15 22:38:29,874:INFO:Initializing create_model()
2025-05-15 22:38:29,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36336fa90>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356061410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:38:29,875:INFO:Checking exceptions
2025-05-15 22:38:29,875:INFO:Importing libraries
2025-05-15 22:38:29,875:INFO:Copying training dataset
2025-05-15 22:38:29,886:INFO:Defining folds
2025-05-15 22:38:29,886:INFO:Declaring metric variables
2025-05-15 22:38:29,888:INFO:Importing untrained model
2025-05-15 22:38:29,889:INFO:Naive Bayes Imported successfully
2025-05-15 22:38:29,892:INFO:Starting cross validation
2025-05-15 22:38:29,893:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:38:32,249:INFO:Calculating mean and std
2025-05-15 22:38:32,250:INFO:Creating metrics dataframe
2025-05-15 22:38:32,253:INFO:Uploading results into container
2025-05-15 22:38:32,253:INFO:Uploading model into container now
2025-05-15 22:38:32,253:INFO:_master_model_container: 3
2025-05-15 22:38:32,254:INFO:_display_container: 2
2025-05-15 22:38:32,254:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-15 22:38:32,254:INFO:create_model() successfully completed......................................
2025-05-15 22:38:32,457:INFO:SubProcess create_model() end ==================================
2025-05-15 22:38:32,457:INFO:Creating metrics dataframe
2025-05-15 22:38:32,460:INFO:Initializing Decision Tree Classifier
2025-05-15 22:38:32,460:INFO:Total runtime is 0.2567661325136821 minutes
2025-05-15 22:38:32,461:INFO:SubProcess create_model() called ==================================
2025-05-15 22:38:32,461:INFO:Initializing create_model()
2025-05-15 22:38:32,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36336fa90>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356061410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:38:32,462:INFO:Checking exceptions
2025-05-15 22:38:32,462:INFO:Importing libraries
2025-05-15 22:38:32,462:INFO:Copying training dataset
2025-05-15 22:38:32,476:INFO:Defining folds
2025-05-15 22:38:32,476:INFO:Declaring metric variables
2025-05-15 22:38:32,477:INFO:Importing untrained model
2025-05-15 22:38:32,479:INFO:Decision Tree Classifier Imported successfully
2025-05-15 22:38:32,482:INFO:Starting cross validation
2025-05-15 22:38:32,485:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-15 22:38:35,389:INFO:Calculating mean and std
2025-05-15 22:38:35,390:INFO:Creating metrics dataframe
2025-05-15 22:38:35,391:INFO:Uploading results into container
2025-05-15 22:38:35,391:INFO:Uploading model into container now
2025-05-15 22:38:35,391:INFO:_master_model_container: 4
2025-05-15 22:38:35,392:INFO:_display_container: 2
2025-05-15 22:38:35,392:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-15 22:38:35,392:INFO:create_model() successfully completed......................................
2025-05-15 22:38:35,584:INFO:SubProcess create_model() end ==================================
2025-05-15 22:38:35,585:INFO:Creating metrics dataframe
2025-05-15 22:38:35,589:INFO:Initializing SVM - Linear Kernel
2025-05-15 22:38:35,589:INFO:Total runtime is 0.3089113672574362 minutes
2025-05-15 22:38:35,590:INFO:SubProcess create_model() called ==================================
2025-05-15 22:38:35,590:INFO:Initializing create_model()
2025-05-15 22:38:35,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x36336fa90>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356061410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-15 22:38:35,591:INFO:Checking exceptions
2025-05-15 22:38:35,591:INFO:Importing libraries
2025-05-15 22:38:35,591:INFO:Copying training dataset
2025-05-15 22:38:35,602:INFO:Defining folds
2025-05-15 22:38:35,603:INFO:Declaring metric variables
2025-05-15 22:38:35,604:INFO:Importing untrained model
2025-05-15 22:38:35,606:INFO:SVM - Linear Kernel Imported successfully
2025-05-15 22:38:35,609:INFO:Starting cross validation
2025-05-15 22:38:35,610:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:12:36,341:INFO:PyCaret ClassificationExperiment
2025-05-18 19:12:36,341:INFO:Logging name: clf-default-name
2025-05-18 19:12:36,341:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-18 19:12:36,341:INFO:version 3.3.2
2025-05-18 19:12:36,341:INFO:Initializing setup()
2025-05-18 19:12:36,342:INFO:self.USI: 92e5
2025-05-18 19:12:36,342:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-18 19:12:36,342:INFO:Checking environment
2025-05-18 19:12:36,342:INFO:python_version: 3.11.0
2025-05-18 19:12:36,342:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-18 19:12:36,342:INFO:machine: arm64
2025-05-18 19:12:36,342:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-18 19:12:36,342:INFO:Memory: svmem(total=17179869184, available=2989883392, percent=82.6, used=5750636544, free=66093056, active=2945826816, inactive=2904801280, wired=2804809728)
2025-05-18 19:12:36,342:INFO:Physical Core: 12
2025-05-18 19:12:36,342:INFO:Logical Core: 12
2025-05-18 19:12:36,342:INFO:Checking libraries
2025-05-18 19:12:36,343:INFO:System:
2025-05-18 19:12:36,343:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-18 19:12:36,343:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-18 19:12:36,343:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-18 19:12:36,343:INFO:PyCaret required dependencies:
2025-05-18 19:12:36,343:INFO:                 pip: 22.3
2025-05-18 19:12:36,343:INFO:          setuptools: 65.5.0
2025-05-18 19:12:36,343:INFO:             pycaret: 3.3.2
2025-05-18 19:12:36,343:INFO:             IPython: 9.2.0
2025-05-18 19:12:36,343:INFO:          ipywidgets: 8.1.7
2025-05-18 19:12:36,343:INFO:                tqdm: 4.67.1
2025-05-18 19:12:36,343:INFO:               numpy: 1.26.4
2025-05-18 19:12:36,343:INFO:              pandas: 2.1.4
2025-05-18 19:12:36,343:INFO:              jinja2: 3.1.6
2025-05-18 19:12:36,343:INFO:               scipy: 1.11.4
2025-05-18 19:12:36,343:INFO:              joblib: 1.3.2
2025-05-18 19:12:36,343:INFO:             sklearn: 1.4.2
2025-05-18 19:12:36,343:INFO:                pyod: 2.0.5
2025-05-18 19:12:36,343:INFO:            imblearn: 0.13.0
2025-05-18 19:12:36,343:INFO:   category_encoders: 2.7.0
2025-05-18 19:12:36,343:INFO:            lightgbm: 4.6.0
2025-05-18 19:12:36,343:INFO:               numba: 0.61.2
2025-05-18 19:12:36,343:INFO:            requests: 2.32.3
2025-05-18 19:12:36,343:INFO:          matplotlib: 3.7.5
2025-05-18 19:12:36,343:INFO:          scikitplot: 0.3.7
2025-05-18 19:12:36,343:INFO:         yellowbrick: 1.5
2025-05-18 19:12:36,343:INFO:              plotly: 5.24.1
2025-05-18 19:12:36,343:INFO:    plotly-resampler: Not installed
2025-05-18 19:12:36,343:INFO:             kaleido: 0.2.1
2025-05-18 19:12:36,343:INFO:           schemdraw: 0.15
2025-05-18 19:12:36,343:INFO:         statsmodels: 0.14.4
2025-05-18 19:12:36,343:INFO:              sktime: 0.26.0
2025-05-18 19:12:36,343:INFO:               tbats: 1.1.3
2025-05-18 19:12:36,343:INFO:            pmdarima: 2.0.4
2025-05-18 19:12:36,343:INFO:              psutil: 7.0.0
2025-05-18 19:12:36,343:INFO:          markupsafe: 3.0.2
2025-05-18 19:12:36,343:INFO:             pickle5: Not installed
2025-05-18 19:12:36,343:INFO:         cloudpickle: 3.1.1
2025-05-18 19:12:36,343:INFO:         deprecation: 2.1.0
2025-05-18 19:12:36,343:INFO:              xxhash: 3.5.0
2025-05-18 19:12:36,343:INFO:           wurlitzer: 3.1.1
2025-05-18 19:12:36,343:INFO:PyCaret optional dependencies:
2025-05-18 19:12:36,344:INFO:                shap: 0.47.2
2025-05-18 19:12:36,344:INFO:           interpret: Not installed
2025-05-18 19:12:36,344:INFO:                umap: Not installed
2025-05-18 19:12:36,344:INFO:     ydata_profiling: Not installed
2025-05-18 19:12:36,344:INFO:  explainerdashboard: Not installed
2025-05-18 19:12:36,344:INFO:             autoviz: Not installed
2025-05-18 19:12:36,344:INFO:           fairlearn: Not installed
2025-05-18 19:12:36,344:INFO:          deepchecks: Not installed
2025-05-18 19:12:36,344:INFO:             xgboost: Not installed
2025-05-18 19:12:36,344:INFO:            catboost: 1.2.8
2025-05-18 19:12:36,344:INFO:              kmodes: Not installed
2025-05-18 19:12:36,344:INFO:             mlxtend: Not installed
2025-05-18 19:12:36,344:INFO:       statsforecast: Not installed
2025-05-18 19:12:36,344:INFO:        tune_sklearn: Not installed
2025-05-18 19:12:36,344:INFO:                 ray: Not installed
2025-05-18 19:12:36,344:INFO:            hyperopt: Not installed
2025-05-18 19:12:36,344:INFO:              optuna: 4.3.0
2025-05-18 19:12:36,344:INFO:               skopt: Not installed
2025-05-18 19:12:36,344:INFO:              mlflow: Not installed
2025-05-18 19:12:36,344:INFO:              gradio: Not installed
2025-05-18 19:12:36,344:INFO:             fastapi: Not installed
2025-05-18 19:12:36,344:INFO:             uvicorn: Not installed
2025-05-18 19:12:36,344:INFO:              m2cgen: Not installed
2025-05-18 19:12:36,344:INFO:           evidently: Not installed
2025-05-18 19:12:36,344:INFO:               fugue: Not installed
2025-05-18 19:12:36,344:INFO:           streamlit: Not installed
2025-05-18 19:12:36,344:INFO:             prophet: Not installed
2025-05-18 19:12:36,344:INFO:None
2025-05-18 19:12:36,344:INFO:Set up data.
2025-05-18 19:12:36,379:INFO:Set up folding strategy.
2025-05-18 19:12:36,379:INFO:Set up train/test split.
2025-05-18 19:12:36,396:INFO:Set up index.
2025-05-18 19:12:36,397:INFO:Assigning column types.
2025-05-18 19:12:36,402:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-18 19:12:36,422:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 19:12:36,425:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:12:36,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:12:36,440:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:12:36,461:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 19:12:36,461:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:12:36,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:12:36,473:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:12:36,473:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-18 19:12:36,491:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:12:36,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:12:36,503:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:12:36,521:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:12:36,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:12:36,533:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:12:36,533:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-18 19:12:36,562:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:12:36,562:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:12:36,590:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:12:36,590:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:12:36,593:INFO:Preparing preprocessing pipeline...
2025-05-18 19:12:36,595:INFO:Set up simple imputation.
2025-05-18 19:12:36,603:INFO:Set up encoding of ordinal features.
2025-05-18 19:12:36,613:INFO:Set up encoding of categorical features.
2025-05-18 19:12:36,613:INFO:Set up imbalanced handling.
2025-05-18 19:12:36,614:INFO:Set up column transformation.
2025-05-18 19:12:37,970:INFO:Finished creating preprocessing pipeline.
2025-05-18 19:12:37,988:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-18 19:12:37,988:INFO:Creating final display dataframe.
2025-05-18 19:12:38,459:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              92e5
2025-05-18 19:12:38,499:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:12:38,499:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:12:38,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:12:38,531:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:12:38,533:INFO:setup() successfully completed in 2.2s...............
2025-05-18 19:12:38,533:INFO:Initializing compare_models()
2025-05-18 19:12:38,533:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-18 19:12:38,533:INFO:Checking exceptions
2025-05-18 19:12:38,539:INFO:Preparing display monitor
2025-05-18 19:12:38,548:INFO:Initializing Logistic Regression
2025-05-18 19:12:38,549:INFO:Total runtime is 1.33514404296875e-06 minutes
2025-05-18 19:12:38,550:INFO:SubProcess create_model() called ==================================
2025-05-18 19:12:38,551:INFO:Initializing create_model()
2025-05-18 19:12:38,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:12:38,551:INFO:Checking exceptions
2025-05-18 19:12:38,551:INFO:Importing libraries
2025-05-18 19:12:38,551:INFO:Copying training dataset
2025-05-18 19:12:38,562:INFO:Defining folds
2025-05-18 19:12:38,562:INFO:Declaring metric variables
2025-05-18 19:12:38,563:INFO:Importing untrained model
2025-05-18 19:12:38,565:INFO:Logistic Regression Imported successfully
2025-05-18 19:12:38,567:INFO:Starting cross validation
2025-05-18 19:12:38,568:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:12:44,709:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:12:44,724:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:12:44,739:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:12:44,745:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:12:44,763:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:12:44,841:INFO:Calculating mean and std
2025-05-18 19:12:44,845:INFO:Creating metrics dataframe
2025-05-18 19:12:44,853:INFO:Uploading results into container
2025-05-18 19:12:44,853:INFO:Uploading model into container now
2025-05-18 19:12:44,854:INFO:_master_model_container: 1
2025-05-18 19:12:44,854:INFO:_display_container: 2
2025-05-18 19:12:44,856:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-18 19:12:44,856:INFO:create_model() successfully completed......................................
2025-05-18 19:12:45,459:INFO:SubProcess create_model() end ==================================
2025-05-18 19:12:45,459:INFO:Creating metrics dataframe
2025-05-18 19:12:45,462:INFO:Initializing K Neighbors Classifier
2025-05-18 19:12:45,462:INFO:Total runtime is 0.1152326504389445 minutes
2025-05-18 19:12:45,464:INFO:SubProcess create_model() called ==================================
2025-05-18 19:12:45,464:INFO:Initializing create_model()
2025-05-18 19:12:45,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:12:45,464:INFO:Checking exceptions
2025-05-18 19:12:45,464:INFO:Importing libraries
2025-05-18 19:12:45,464:INFO:Copying training dataset
2025-05-18 19:12:45,479:INFO:Defining folds
2025-05-18 19:12:45,479:INFO:Declaring metric variables
2025-05-18 19:12:45,480:INFO:Importing untrained model
2025-05-18 19:12:45,482:INFO:K Neighbors Classifier Imported successfully
2025-05-18 19:12:45,484:INFO:Starting cross validation
2025-05-18 19:12:45,485:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:12:51,539:INFO:Calculating mean and std
2025-05-18 19:12:51,540:INFO:Creating metrics dataframe
2025-05-18 19:12:51,543:INFO:Uploading results into container
2025-05-18 19:12:51,543:INFO:Uploading model into container now
2025-05-18 19:12:51,543:INFO:_master_model_container: 2
2025-05-18 19:12:51,543:INFO:_display_container: 2
2025-05-18 19:12:51,544:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-18 19:12:51,544:INFO:create_model() successfully completed......................................
2025-05-18 19:12:51,687:INFO:SubProcess create_model() end ==================================
2025-05-18 19:12:51,688:INFO:Creating metrics dataframe
2025-05-18 19:12:51,690:INFO:Initializing Naive Bayes
2025-05-18 19:12:51,691:INFO:Total runtime is 0.21903433402379352 minutes
2025-05-18 19:12:51,692:INFO:SubProcess create_model() called ==================================
2025-05-18 19:12:51,692:INFO:Initializing create_model()
2025-05-18 19:12:51,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:12:51,692:INFO:Checking exceptions
2025-05-18 19:12:51,692:INFO:Importing libraries
2025-05-18 19:12:51,692:INFO:Copying training dataset
2025-05-18 19:12:51,713:INFO:Defining folds
2025-05-18 19:12:51,713:INFO:Declaring metric variables
2025-05-18 19:12:51,715:INFO:Importing untrained model
2025-05-18 19:12:51,716:INFO:Naive Bayes Imported successfully
2025-05-18 19:12:51,718:INFO:Starting cross validation
2025-05-18 19:12:51,719:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:12:53,995:INFO:Calculating mean and std
2025-05-18 19:12:53,997:INFO:Creating metrics dataframe
2025-05-18 19:12:53,999:INFO:Uploading results into container
2025-05-18 19:12:53,999:INFO:Uploading model into container now
2025-05-18 19:12:54,002:INFO:_master_model_container: 3
2025-05-18 19:12:54,002:INFO:_display_container: 2
2025-05-18 19:12:54,003:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-18 19:12:54,003:INFO:create_model() successfully completed......................................
2025-05-18 19:12:54,216:INFO:SubProcess create_model() end ==================================
2025-05-18 19:12:54,216:INFO:Creating metrics dataframe
2025-05-18 19:12:54,219:INFO:Initializing Decision Tree Classifier
2025-05-18 19:12:54,219:INFO:Total runtime is 0.26117913325627645 minutes
2025-05-18 19:12:54,220:INFO:SubProcess create_model() called ==================================
2025-05-18 19:12:54,221:INFO:Initializing create_model()
2025-05-18 19:12:54,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:12:54,221:INFO:Checking exceptions
2025-05-18 19:12:54,221:INFO:Importing libraries
2025-05-18 19:12:54,221:INFO:Copying training dataset
2025-05-18 19:12:54,237:INFO:Defining folds
2025-05-18 19:12:54,237:INFO:Declaring metric variables
2025-05-18 19:12:54,239:INFO:Importing untrained model
2025-05-18 19:12:54,241:INFO:Decision Tree Classifier Imported successfully
2025-05-18 19:12:54,243:INFO:Starting cross validation
2025-05-18 19:12:54,245:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:12:55,967:INFO:Calculating mean and std
2025-05-18 19:12:55,968:INFO:Creating metrics dataframe
2025-05-18 19:12:55,969:INFO:Uploading results into container
2025-05-18 19:12:55,969:INFO:Uploading model into container now
2025-05-18 19:12:55,969:INFO:_master_model_container: 4
2025-05-18 19:12:55,969:INFO:_display_container: 2
2025-05-18 19:12:55,970:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-18 19:12:55,970:INFO:create_model() successfully completed......................................
2025-05-18 19:12:56,105:INFO:SubProcess create_model() end ==================================
2025-05-18 19:12:56,105:INFO:Creating metrics dataframe
2025-05-18 19:12:56,108:INFO:Initializing SVM - Linear Kernel
2025-05-18 19:12:56,108:INFO:Total runtime is 0.29265815019607544 minutes
2025-05-18 19:12:56,109:INFO:SubProcess create_model() called ==================================
2025-05-18 19:12:56,109:INFO:Initializing create_model()
2025-05-18 19:12:56,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:12:56,109:INFO:Checking exceptions
2025-05-18 19:12:56,109:INFO:Importing libraries
2025-05-18 19:12:56,110:INFO:Copying training dataset
2025-05-18 19:12:56,122:INFO:Defining folds
2025-05-18 19:12:56,122:INFO:Declaring metric variables
2025-05-18 19:12:56,123:INFO:Importing untrained model
2025-05-18 19:12:56,125:INFO:SVM - Linear Kernel Imported successfully
2025-05-18 19:12:56,127:INFO:Starting cross validation
2025-05-18 19:12:56,128:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:12:59,476:INFO:Calculating mean and std
2025-05-18 19:12:59,478:INFO:Creating metrics dataframe
2025-05-18 19:12:59,479:INFO:Uploading results into container
2025-05-18 19:12:59,479:INFO:Uploading model into container now
2025-05-18 19:12:59,479:INFO:_master_model_container: 5
2025-05-18 19:12:59,480:INFO:_display_container: 2
2025-05-18 19:12:59,480:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-18 19:12:59,480:INFO:create_model() successfully completed......................................
2025-05-18 19:12:59,619:INFO:SubProcess create_model() end ==================================
2025-05-18 19:12:59,619:INFO:Creating metrics dataframe
2025-05-18 19:12:59,622:INFO:Initializing Ridge Classifier
2025-05-18 19:12:59,622:INFO:Total runtime is 0.35123015244801836 minutes
2025-05-18 19:12:59,623:INFO:SubProcess create_model() called ==================================
2025-05-18 19:12:59,624:INFO:Initializing create_model()
2025-05-18 19:12:59,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:12:59,624:INFO:Checking exceptions
2025-05-18 19:12:59,624:INFO:Importing libraries
2025-05-18 19:12:59,624:INFO:Copying training dataset
2025-05-18 19:12:59,634:INFO:Defining folds
2025-05-18 19:12:59,634:INFO:Declaring metric variables
2025-05-18 19:12:59,635:INFO:Importing untrained model
2025-05-18 19:12:59,636:INFO:Ridge Classifier Imported successfully
2025-05-18 19:12:59,639:INFO:Starting cross validation
2025-05-18 19:12:59,640:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:13:00,783:INFO:Calculating mean and std
2025-05-18 19:13:00,784:INFO:Creating metrics dataframe
2025-05-18 19:13:00,785:INFO:Uploading results into container
2025-05-18 19:13:00,785:INFO:Uploading model into container now
2025-05-18 19:13:00,786:INFO:_master_model_container: 6
2025-05-18 19:13:00,786:INFO:_display_container: 2
2025-05-18 19:13:00,786:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-18 19:13:00,786:INFO:create_model() successfully completed......................................
2025-05-18 19:13:00,950:INFO:SubProcess create_model() end ==================================
2025-05-18 19:13:00,950:INFO:Creating metrics dataframe
2025-05-18 19:13:00,954:INFO:Initializing Random Forest Classifier
2025-05-18 19:13:00,954:INFO:Total runtime is 0.3734247326850891 minutes
2025-05-18 19:13:00,955:INFO:SubProcess create_model() called ==================================
2025-05-18 19:13:00,955:INFO:Initializing create_model()
2025-05-18 19:13:00,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:13:00,956:INFO:Checking exceptions
2025-05-18 19:13:00,956:INFO:Importing libraries
2025-05-18 19:13:00,956:INFO:Copying training dataset
2025-05-18 19:13:00,965:INFO:Defining folds
2025-05-18 19:13:00,965:INFO:Declaring metric variables
2025-05-18 19:13:00,966:INFO:Importing untrained model
2025-05-18 19:13:00,967:INFO:Random Forest Classifier Imported successfully
2025-05-18 19:13:00,970:INFO:Starting cross validation
2025-05-18 19:13:00,971:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:13:07,105:INFO:Calculating mean and std
2025-05-18 19:13:07,107:INFO:Creating metrics dataframe
2025-05-18 19:13:07,118:INFO:Uploading results into container
2025-05-18 19:13:07,118:INFO:Uploading model into container now
2025-05-18 19:13:07,119:INFO:_master_model_container: 7
2025-05-18 19:13:07,119:INFO:_display_container: 2
2025-05-18 19:13:07,120:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-18 19:13:07,121:INFO:create_model() successfully completed......................................
2025-05-18 19:13:07,386:INFO:SubProcess create_model() end ==================================
2025-05-18 19:13:07,386:INFO:Creating metrics dataframe
2025-05-18 19:13:07,390:INFO:Initializing Quadratic Discriminant Analysis
2025-05-18 19:13:07,390:INFO:Total runtime is 0.4806978861490885 minutes
2025-05-18 19:13:07,392:INFO:SubProcess create_model() called ==================================
2025-05-18 19:13:07,392:INFO:Initializing create_model()
2025-05-18 19:13:07,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:13:07,392:INFO:Checking exceptions
2025-05-18 19:13:07,392:INFO:Importing libraries
2025-05-18 19:13:07,392:INFO:Copying training dataset
2025-05-18 19:13:07,413:INFO:Defining folds
2025-05-18 19:13:07,413:INFO:Declaring metric variables
2025-05-18 19:13:07,415:INFO:Importing untrained model
2025-05-18 19:13:07,416:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 19:13:07,419:INFO:Starting cross validation
2025-05-18 19:13:07,421:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:13:08,547:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:13:08,551:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:13:08,593:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:13:08,612:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:13:08,645:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:13:08,654:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:13:08,657:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:13:08,687:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:13:08,706:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:13:08,722:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:13:08,736:INFO:Calculating mean and std
2025-05-18 19:13:08,737:INFO:Creating metrics dataframe
2025-05-18 19:13:08,738:INFO:Uploading results into container
2025-05-18 19:13:08,739:INFO:Uploading model into container now
2025-05-18 19:13:08,739:INFO:_master_model_container: 8
2025-05-18 19:13:08,739:INFO:_display_container: 2
2025-05-18 19:13:08,739:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 19:13:08,739:INFO:create_model() successfully completed......................................
2025-05-18 19:13:08,907:INFO:SubProcess create_model() end ==================================
2025-05-18 19:13:08,907:INFO:Creating metrics dataframe
2025-05-18 19:13:08,911:INFO:Initializing Ada Boost Classifier
2025-05-18 19:13:08,911:INFO:Total runtime is 0.5060504873593648 minutes
2025-05-18 19:13:08,913:INFO:SubProcess create_model() called ==================================
2025-05-18 19:13:08,913:INFO:Initializing create_model()
2025-05-18 19:13:08,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:13:08,914:INFO:Checking exceptions
2025-05-18 19:13:08,914:INFO:Importing libraries
2025-05-18 19:13:08,914:INFO:Copying training dataset
2025-05-18 19:13:08,926:INFO:Defining folds
2025-05-18 19:13:08,926:INFO:Declaring metric variables
2025-05-18 19:13:08,927:INFO:Importing untrained model
2025-05-18 19:13:08,929:INFO:Ada Boost Classifier Imported successfully
2025-05-18 19:13:08,931:INFO:Starting cross validation
2025-05-18 19:13:08,932:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:13:09,892:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:13:09,900:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:13:09,921:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:13:09,982:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:13:09,996:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:13:12,733:INFO:Calculating mean and std
2025-05-18 19:13:12,735:INFO:Creating metrics dataframe
2025-05-18 19:13:12,742:INFO:Uploading results into container
2025-05-18 19:13:12,743:INFO:Uploading model into container now
2025-05-18 19:13:12,743:INFO:_master_model_container: 9
2025-05-18 19:13:12,743:INFO:_display_container: 2
2025-05-18 19:13:12,744:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-18 19:13:12,744:INFO:create_model() successfully completed......................................
2025-05-18 19:13:12,991:INFO:SubProcess create_model() end ==================================
2025-05-18 19:13:12,992:INFO:Creating metrics dataframe
2025-05-18 19:13:12,996:INFO:Initializing Gradient Boosting Classifier
2025-05-18 19:13:12,996:INFO:Total runtime is 0.5741263508796691 minutes
2025-05-18 19:13:12,997:INFO:SubProcess create_model() called ==================================
2025-05-18 19:13:12,998:INFO:Initializing create_model()
2025-05-18 19:13:12,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:13:12,998:INFO:Checking exceptions
2025-05-18 19:13:12,998:INFO:Importing libraries
2025-05-18 19:13:12,998:INFO:Copying training dataset
2025-05-18 19:13:13,008:INFO:Defining folds
2025-05-18 19:13:13,008:INFO:Declaring metric variables
2025-05-18 19:13:13,010:INFO:Importing untrained model
2025-05-18 19:13:13,011:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 19:13:13,013:INFO:Starting cross validation
2025-05-18 19:13:13,015:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:13:26,832:INFO:Calculating mean and std
2025-05-18 19:13:26,834:INFO:Creating metrics dataframe
2025-05-18 19:13:26,836:INFO:Uploading results into container
2025-05-18 19:13:26,836:INFO:Uploading model into container now
2025-05-18 19:13:26,836:INFO:_master_model_container: 10
2025-05-18 19:13:26,836:INFO:_display_container: 2
2025-05-18 19:13:26,837:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 19:13:26,837:INFO:create_model() successfully completed......................................
2025-05-18 19:13:27,013:INFO:SubProcess create_model() end ==================================
2025-05-18 19:13:27,013:INFO:Creating metrics dataframe
2025-05-18 19:13:27,017:INFO:Initializing Linear Discriminant Analysis
2025-05-18 19:13:27,017:INFO:Total runtime is 0.8078149199485778 minutes
2025-05-18 19:13:27,019:INFO:SubProcess create_model() called ==================================
2025-05-18 19:13:27,019:INFO:Initializing create_model()
2025-05-18 19:13:27,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:13:27,019:INFO:Checking exceptions
2025-05-18 19:13:27,019:INFO:Importing libraries
2025-05-18 19:13:27,019:INFO:Copying training dataset
2025-05-18 19:13:27,029:INFO:Defining folds
2025-05-18 19:13:27,029:INFO:Declaring metric variables
2025-05-18 19:13:27,030:INFO:Importing untrained model
2025-05-18 19:13:27,031:INFO:Linear Discriminant Analysis Imported successfully
2025-05-18 19:13:27,034:INFO:Starting cross validation
2025-05-18 19:13:27,035:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:13:28,347:INFO:Calculating mean and std
2025-05-18 19:13:28,347:INFO:Creating metrics dataframe
2025-05-18 19:13:28,348:INFO:Uploading results into container
2025-05-18 19:13:28,349:INFO:Uploading model into container now
2025-05-18 19:13:28,349:INFO:_master_model_container: 11
2025-05-18 19:13:28,349:INFO:_display_container: 2
2025-05-18 19:13:28,349:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-18 19:13:28,349:INFO:create_model() successfully completed......................................
2025-05-18 19:13:28,513:INFO:SubProcess create_model() end ==================================
2025-05-18 19:13:28,513:INFO:Creating metrics dataframe
2025-05-18 19:13:28,517:INFO:Initializing Extra Trees Classifier
2025-05-18 19:13:28,517:INFO:Total runtime is 0.8328073859214782 minutes
2025-05-18 19:13:28,518:INFO:SubProcess create_model() called ==================================
2025-05-18 19:13:28,519:INFO:Initializing create_model()
2025-05-18 19:13:28,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:13:28,519:INFO:Checking exceptions
2025-05-18 19:13:28,519:INFO:Importing libraries
2025-05-18 19:13:28,519:INFO:Copying training dataset
2025-05-18 19:13:28,529:INFO:Defining folds
2025-05-18 19:13:28,529:INFO:Declaring metric variables
2025-05-18 19:13:28,531:INFO:Importing untrained model
2025-05-18 19:13:28,532:INFO:Extra Trees Classifier Imported successfully
2025-05-18 19:13:28,535:INFO:Starting cross validation
2025-05-18 19:13:28,536:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:13:33,901:INFO:Calculating mean and std
2025-05-18 19:13:33,905:INFO:Creating metrics dataframe
2025-05-18 19:13:33,910:INFO:Uploading results into container
2025-05-18 19:13:33,911:INFO:Uploading model into container now
2025-05-18 19:13:33,911:INFO:_master_model_container: 12
2025-05-18 19:13:33,912:INFO:_display_container: 2
2025-05-18 19:13:33,913:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-18 19:13:33,913:INFO:create_model() successfully completed......................................
2025-05-18 19:13:34,273:INFO:SubProcess create_model() end ==================================
2025-05-18 19:13:34,273:INFO:Creating metrics dataframe
2025-05-18 19:13:34,278:INFO:Initializing Light Gradient Boosting Machine
2025-05-18 19:13:34,278:INFO:Total runtime is 0.9288290858268737 minutes
2025-05-18 19:13:34,279:INFO:SubProcess create_model() called ==================================
2025-05-18 19:13:34,280:INFO:Initializing create_model()
2025-05-18 19:13:34,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:13:34,280:INFO:Checking exceptions
2025-05-18 19:13:34,280:INFO:Importing libraries
2025-05-18 19:13:34,280:INFO:Copying training dataset
2025-05-18 19:13:34,302:INFO:Defining folds
2025-05-18 19:13:34,303:INFO:Declaring metric variables
2025-05-18 19:13:34,304:INFO:Importing untrained model
2025-05-18 19:13:34,306:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 19:13:34,309:INFO:Starting cross validation
2025-05-18 19:13:34,311:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:13:38,793:INFO:Calculating mean and std
2025-05-18 19:13:38,797:INFO:Creating metrics dataframe
2025-05-18 19:13:38,803:INFO:Uploading results into container
2025-05-18 19:13:38,804:INFO:Uploading model into container now
2025-05-18 19:13:38,806:INFO:_master_model_container: 13
2025-05-18 19:13:38,806:INFO:_display_container: 2
2025-05-18 19:13:38,809:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:13:38,809:INFO:create_model() successfully completed......................................
2025-05-18 19:13:39,197:INFO:SubProcess create_model() end ==================================
2025-05-18 19:13:39,197:INFO:Creating metrics dataframe
2025-05-18 19:13:39,203:INFO:Initializing CatBoost Classifier
2025-05-18 19:13:39,203:INFO:Total runtime is 1.010913900534312 minutes
2025-05-18 19:13:39,205:INFO:SubProcess create_model() called ==================================
2025-05-18 19:13:39,205:INFO:Initializing create_model()
2025-05-18 19:13:39,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:13:39,205:INFO:Checking exceptions
2025-05-18 19:13:39,206:INFO:Importing libraries
2025-05-18 19:13:39,206:INFO:Copying training dataset
2025-05-18 19:13:39,235:INFO:Defining folds
2025-05-18 19:13:39,235:INFO:Declaring metric variables
2025-05-18 19:13:39,237:INFO:Importing untrained model
2025-05-18 19:13:39,239:INFO:CatBoost Classifier Imported successfully
2025-05-18 19:13:39,241:INFO:Starting cross validation
2025-05-18 19:13:39,245:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:14:00,380:INFO:Calculating mean and std
2025-05-18 19:14:00,383:INFO:Creating metrics dataframe
2025-05-18 19:14:00,390:INFO:Uploading results into container
2025-05-18 19:14:00,390:INFO:Uploading model into container now
2025-05-18 19:14:00,391:INFO:_master_model_container: 14
2025-05-18 19:14:00,391:INFO:_display_container: 2
2025-05-18 19:14:00,391:INFO:<catboost.core.CatBoostClassifier object at 0x36457ec50>
2025-05-18 19:14:00,391:INFO:create_model() successfully completed......................................
2025-05-18 19:14:00,666:INFO:SubProcess create_model() end ==================================
2025-05-18 19:14:00,666:INFO:Creating metrics dataframe
2025-05-18 19:14:00,671:INFO:Initializing Dummy Classifier
2025-05-18 19:14:00,671:INFO:Total runtime is 1.3687170505523683 minutes
2025-05-18 19:14:00,673:INFO:SubProcess create_model() called ==================================
2025-05-18 19:14:00,673:INFO:Initializing create_model()
2025-05-18 19:14:00,673:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356294250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:14:00,673:INFO:Checking exceptions
2025-05-18 19:14:00,673:INFO:Importing libraries
2025-05-18 19:14:00,673:INFO:Copying training dataset
2025-05-18 19:14:00,695:INFO:Defining folds
2025-05-18 19:14:00,695:INFO:Declaring metric variables
2025-05-18 19:14:00,697:INFO:Importing untrained model
2025-05-18 19:14:00,698:INFO:Dummy Classifier Imported successfully
2025-05-18 19:14:00,700:INFO:Starting cross validation
2025-05-18 19:14:00,702:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:14:01,911:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:14:01,912:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:14:01,992:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:14:02,022:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:14:02,029:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:14:02,035:INFO:Calculating mean and std
2025-05-18 19:14:02,036:INFO:Creating metrics dataframe
2025-05-18 19:14:02,037:INFO:Uploading results into container
2025-05-18 19:14:02,038:INFO:Uploading model into container now
2025-05-18 19:14:02,038:INFO:_master_model_container: 15
2025-05-18 19:14:02,038:INFO:_display_container: 2
2025-05-18 19:14:02,038:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-18 19:14:02,038:INFO:create_model() successfully completed......................................
2025-05-18 19:14:02,203:INFO:SubProcess create_model() end ==================================
2025-05-18 19:14:02,203:INFO:Creating metrics dataframe
2025-05-18 19:14:02,209:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-18 19:14:02,213:INFO:Initializing create_model()
2025-05-18 19:14:02,213:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:14:02,213:INFO:Checking exceptions
2025-05-18 19:14:02,214:INFO:Importing libraries
2025-05-18 19:14:02,214:INFO:Copying training dataset
2025-05-18 19:14:02,223:INFO:Defining folds
2025-05-18 19:14:02,223:INFO:Declaring metric variables
2025-05-18 19:14:02,223:INFO:Importing untrained model
2025-05-18 19:14:02,223:INFO:Declaring custom model
2025-05-18 19:14:02,224:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 19:14:02,225:INFO:Cross validation set to False
2025-05-18 19:14:02,225:INFO:Fitting Model
2025-05-18 19:14:03,658:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 19:14:03,668:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004506 seconds.
2025-05-18 19:14:03,668:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 19:14:03,668:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 19:14:03,668:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 19:14:03,668:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 19:14:03,669:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 19:14:04,485:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:14:04,485:INFO:create_model() successfully completed......................................
2025-05-18 19:14:04,642:INFO:Initializing create_model()
2025-05-18 19:14:04,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:14:04,642:INFO:Checking exceptions
2025-05-18 19:14:04,642:INFO:Importing libraries
2025-05-18 19:14:04,642:INFO:Copying training dataset
2025-05-18 19:14:04,653:INFO:Defining folds
2025-05-18 19:14:04,653:INFO:Declaring metric variables
2025-05-18 19:14:04,653:INFO:Importing untrained model
2025-05-18 19:14:04,653:INFO:Declaring custom model
2025-05-18 19:14:04,653:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 19:14:04,654:INFO:Cross validation set to False
2025-05-18 19:14:04,654:INFO:Fitting Model
2025-05-18 19:14:20,845:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 19:14:20,846:INFO:create_model() successfully completed......................................
2025-05-18 19:14:20,991:INFO:Initializing create_model()
2025-05-18 19:14:20,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:14:20,991:INFO:Checking exceptions
2025-05-18 19:14:20,991:INFO:Importing libraries
2025-05-18 19:14:20,991:INFO:Copying training dataset
2025-05-18 19:14:21,000:INFO:Defining folds
2025-05-18 19:14:21,000:INFO:Declaring metric variables
2025-05-18 19:14:21,000:INFO:Importing untrained model
2025-05-18 19:14:21,000:INFO:Declaring custom model
2025-05-18 19:14:21,001:INFO:Random Forest Classifier Imported successfully
2025-05-18 19:14:21,001:INFO:Cross validation set to False
2025-05-18 19:14:21,001:INFO:Fitting Model
2025-05-18 19:14:23,148:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-18 19:14:23,148:INFO:create_model() successfully completed......................................
2025-05-18 19:14:23,288:INFO:Initializing create_model()
2025-05-18 19:14:23,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=<catboost.core.CatBoostClassifier object at 0x36457ec50>, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:14:23,289:INFO:Checking exceptions
2025-05-18 19:14:23,289:INFO:Importing libraries
2025-05-18 19:14:23,289:INFO:Copying training dataset
2025-05-18 19:14:23,298:INFO:Defining folds
2025-05-18 19:14:23,298:INFO:Declaring metric variables
2025-05-18 19:14:23,298:INFO:Importing untrained model
2025-05-18 19:14:23,298:INFO:Declaring custom model
2025-05-18 19:14:23,298:INFO:CatBoost Classifier Imported successfully
2025-05-18 19:14:23,299:INFO:Cross validation set to False
2025-05-18 19:14:23,299:INFO:Fitting Model
2025-05-18 19:14:30,438:INFO:<catboost.core.CatBoostClassifier object at 0x36f212450>
2025-05-18 19:14:30,438:INFO:create_model() successfully completed......................................
2025-05-18 19:14:30,596:INFO:Initializing create_model()
2025-05-18 19:14:30,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:14:30,596:INFO:Checking exceptions
2025-05-18 19:14:30,597:INFO:Importing libraries
2025-05-18 19:14:30,597:INFO:Copying training dataset
2025-05-18 19:14:30,606:INFO:Defining folds
2025-05-18 19:14:30,606:INFO:Declaring metric variables
2025-05-18 19:14:30,606:INFO:Importing untrained model
2025-05-18 19:14:30,606:INFO:Declaring custom model
2025-05-18 19:14:30,606:INFO:Extra Trees Classifier Imported successfully
2025-05-18 19:14:30,607:INFO:Cross validation set to False
2025-05-18 19:14:30,607:INFO:Fitting Model
2025-05-18 19:14:32,299:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-18 19:14:32,299:INFO:create_model() successfully completed......................................
2025-05-18 19:14:32,453:INFO:_master_model_container: 15
2025-05-18 19:14:32,453:INFO:_display_container: 2
2025-05-18 19:14:32,454:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), <catboost.core.CatBoostClassifier object at 0x36f212450>, ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)]
2025-05-18 19:14:32,454:INFO:compare_models() successfully completed......................................
2025-05-18 19:14:32,456:INFO:Initializing evaluate_model()
2025-05-18 19:14:32,456:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-18 19:14:32,462:INFO:Initializing plot_model()
2025-05-18 19:14:32,462:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-18 19:14:32,462:INFO:Checking exceptions
2025-05-18 19:14:32,466:INFO:Preloading libraries
2025-05-18 19:14:32,468:INFO:Copying training dataset
2025-05-18 19:14:32,468:INFO:Plot type: pipeline
2025-05-18 19:14:32,531:INFO:Visual Rendered Successfully
2025-05-18 19:14:32,671:INFO:plot_model() successfully completed......................................
2025-05-18 19:14:32,672:INFO:Initializing tune_model()
2025-05-18 19:14:32,672:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3645b60d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=f1, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-18 19:14:32,672:INFO:Checking exceptions
2025-05-18 19:14:32,673:INFO:Soft dependency imported: optuna: 4.3.0
2025-05-18 19:14:32,714:INFO:Copying training dataset
2025-05-18 19:14:32,720:INFO:Checking base model
2025-05-18 19:14:32,721:INFO:Base model : Light Gradient Boosting Machine
2025-05-18 19:14:32,722:INFO:Declaring metric variables
2025-05-18 19:14:32,723:INFO:Defining Hyperparameters
2025-05-18 19:14:32,869:INFO:Tuning with n_jobs=-1
2025-05-18 19:14:32,871:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-05-18 19:14:32,871:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-05-18 19:14:32,871:INFO:Initializing optuna.integration.OptunaSearchCV
2025-05-18 19:17:35,353:INFO:PyCaret ClassificationExperiment
2025-05-18 19:17:35,353:INFO:Logging name: clf-default-name
2025-05-18 19:17:35,353:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-18 19:17:35,353:INFO:version 3.3.2
2025-05-18 19:17:35,353:INFO:Initializing setup()
2025-05-18 19:17:35,353:INFO:self.USI: 2361
2025-05-18 19:17:35,354:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-18 19:17:35,354:INFO:Checking environment
2025-05-18 19:17:35,354:INFO:python_version: 3.11.0
2025-05-18 19:17:35,354:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-18 19:17:35,354:INFO:machine: arm64
2025-05-18 19:17:35,354:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-18 19:17:35,354:INFO:Memory: svmem(total=17179869184, available=2760048640, percent=83.9, used=5574180864, free=62062592, active=2721267712, inactive=2597650432, wired=2852913152)
2025-05-18 19:17:35,354:INFO:Physical Core: 12
2025-05-18 19:17:35,354:INFO:Logical Core: 12
2025-05-18 19:17:35,354:INFO:Checking libraries
2025-05-18 19:17:35,354:INFO:System:
2025-05-18 19:17:35,354:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-18 19:17:35,354:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-18 19:17:35,354:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-18 19:17:35,354:INFO:PyCaret required dependencies:
2025-05-18 19:17:35,354:INFO:                 pip: 22.3
2025-05-18 19:17:35,354:INFO:          setuptools: 65.5.0
2025-05-18 19:17:35,354:INFO:             pycaret: 3.3.2
2025-05-18 19:17:35,354:INFO:             IPython: 9.2.0
2025-05-18 19:17:35,354:INFO:          ipywidgets: 8.1.7
2025-05-18 19:17:35,354:INFO:                tqdm: 4.67.1
2025-05-18 19:17:35,354:INFO:               numpy: 1.26.4
2025-05-18 19:17:35,354:INFO:              pandas: 2.1.4
2025-05-18 19:17:35,354:INFO:              jinja2: 3.1.6
2025-05-18 19:17:35,354:INFO:               scipy: 1.11.4
2025-05-18 19:17:35,354:INFO:              joblib: 1.3.2
2025-05-18 19:17:35,354:INFO:             sklearn: 1.4.2
2025-05-18 19:17:35,354:INFO:                pyod: 2.0.5
2025-05-18 19:17:35,354:INFO:            imblearn: 0.13.0
2025-05-18 19:17:35,354:INFO:   category_encoders: 2.7.0
2025-05-18 19:17:35,354:INFO:            lightgbm: 4.6.0
2025-05-18 19:17:35,354:INFO:               numba: 0.61.2
2025-05-18 19:17:35,354:INFO:            requests: 2.32.3
2025-05-18 19:17:35,354:INFO:          matplotlib: 3.7.5
2025-05-18 19:17:35,354:INFO:          scikitplot: 0.3.7
2025-05-18 19:17:35,354:INFO:         yellowbrick: 1.5
2025-05-18 19:17:35,354:INFO:              plotly: 5.24.1
2025-05-18 19:17:35,354:INFO:    plotly-resampler: Not installed
2025-05-18 19:17:35,354:INFO:             kaleido: 0.2.1
2025-05-18 19:17:35,354:INFO:           schemdraw: 0.15
2025-05-18 19:17:35,354:INFO:         statsmodels: 0.14.4
2025-05-18 19:17:35,354:INFO:              sktime: 0.26.0
2025-05-18 19:17:35,354:INFO:               tbats: 1.1.3
2025-05-18 19:17:35,354:INFO:            pmdarima: 2.0.4
2025-05-18 19:17:35,354:INFO:              psutil: 7.0.0
2025-05-18 19:17:35,354:INFO:          markupsafe: 3.0.2
2025-05-18 19:17:35,354:INFO:             pickle5: Not installed
2025-05-18 19:17:35,354:INFO:         cloudpickle: 3.1.1
2025-05-18 19:17:35,354:INFO:         deprecation: 2.1.0
2025-05-18 19:17:35,354:INFO:              xxhash: 3.5.0
2025-05-18 19:17:35,354:INFO:           wurlitzer: 3.1.1
2025-05-18 19:17:35,354:INFO:PyCaret optional dependencies:
2025-05-18 19:17:35,354:INFO:                shap: 0.47.2
2025-05-18 19:17:35,354:INFO:           interpret: Not installed
2025-05-18 19:17:35,354:INFO:                umap: Not installed
2025-05-18 19:17:35,354:INFO:     ydata_profiling: Not installed
2025-05-18 19:17:35,354:INFO:  explainerdashboard: Not installed
2025-05-18 19:17:35,355:INFO:             autoviz: Not installed
2025-05-18 19:17:35,355:INFO:           fairlearn: Not installed
2025-05-18 19:17:35,355:INFO:          deepchecks: Not installed
2025-05-18 19:17:35,355:INFO:             xgboost: Not installed
2025-05-18 19:17:35,355:INFO:            catboost: 1.2.8
2025-05-18 19:17:35,355:INFO:              kmodes: Not installed
2025-05-18 19:17:35,355:INFO:             mlxtend: Not installed
2025-05-18 19:17:35,355:INFO:       statsforecast: Not installed
2025-05-18 19:17:35,355:INFO:        tune_sklearn: Not installed
2025-05-18 19:17:35,355:INFO:                 ray: Not installed
2025-05-18 19:17:35,355:INFO:            hyperopt: Not installed
2025-05-18 19:17:35,355:INFO:              optuna: 4.3.0
2025-05-18 19:17:35,355:INFO:               skopt: Not installed
2025-05-18 19:17:35,355:INFO:              mlflow: Not installed
2025-05-18 19:17:35,355:INFO:              gradio: Not installed
2025-05-18 19:17:35,355:INFO:             fastapi: Not installed
2025-05-18 19:17:35,355:INFO:             uvicorn: Not installed
2025-05-18 19:17:35,355:INFO:              m2cgen: Not installed
2025-05-18 19:17:35,355:INFO:           evidently: Not installed
2025-05-18 19:17:35,355:INFO:               fugue: Not installed
2025-05-18 19:17:35,355:INFO:           streamlit: Not installed
2025-05-18 19:17:35,355:INFO:             prophet: Not installed
2025-05-18 19:17:35,355:INFO:None
2025-05-18 19:17:35,355:INFO:Set up data.
2025-05-18 19:17:35,389:INFO:Set up folding strategy.
2025-05-18 19:17:35,389:INFO:Set up train/test split.
2025-05-18 19:17:35,403:INFO:Set up index.
2025-05-18 19:17:35,404:INFO:Assigning column types.
2025-05-18 19:17:35,407:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-18 19:17:35,426:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 19:17:35,431:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:17:35,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:17:35,443:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:17:35,463:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 19:17:35,463:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:17:35,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:17:35,475:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:17:35,475:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-18 19:17:35,494:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:17:35,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:17:35,506:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:17:35,526:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:17:35,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:17:35,537:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:17:35,538:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-18 19:17:35,568:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:17:35,568:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:17:35,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:17:35,600:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:17:35,600:INFO:Preparing preprocessing pipeline...
2025-05-18 19:17:35,602:INFO:Set up simple imputation.
2025-05-18 19:17:35,609:INFO:Set up encoding of ordinal features.
2025-05-18 19:17:35,621:INFO:Set up encoding of categorical features.
2025-05-18 19:17:35,621:INFO:Set up imbalanced handling.
2025-05-18 19:17:35,621:INFO:Set up column transformation.
2025-05-18 19:17:35,913:INFO:Finished creating preprocessing pipeline.
2025-05-18 19:17:35,935:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-18 19:17:35,935:INFO:Creating final display dataframe.
2025-05-18 19:17:36,330:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              2361
2025-05-18 19:17:36,364:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:17:36,364:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:17:36,397:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:17:36,398:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:17:36,399:INFO:setup() successfully completed in 1.05s...............
2025-05-18 19:17:36,400:INFO:Initializing compare_models()
2025-05-18 19:17:36,400:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-18 19:17:36,400:INFO:Checking exceptions
2025-05-18 19:17:36,405:INFO:Preparing display monitor
2025-05-18 19:17:36,414:INFO:Initializing Logistic Regression
2025-05-18 19:17:36,415:INFO:Total runtime is 1.8715858459472655e-06 minutes
2025-05-18 19:17:36,417:INFO:SubProcess create_model() called ==================================
2025-05-18 19:17:36,417:INFO:Initializing create_model()
2025-05-18 19:17:36,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:17:36,417:INFO:Checking exceptions
2025-05-18 19:17:36,417:INFO:Importing libraries
2025-05-18 19:17:36,417:INFO:Copying training dataset
2025-05-18 19:17:36,428:INFO:Defining folds
2025-05-18 19:17:36,428:INFO:Declaring metric variables
2025-05-18 19:17:36,430:INFO:Importing untrained model
2025-05-18 19:17:36,432:INFO:Logistic Regression Imported successfully
2025-05-18 19:17:36,435:INFO:Starting cross validation
2025-05-18 19:17:36,436:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:17:40,598:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:17:40,628:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:17:40,631:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:17:40,710:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:17:40,911:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:17:40,984:INFO:Calculating mean and std
2025-05-18 19:17:40,992:INFO:Creating metrics dataframe
2025-05-18 19:17:40,995:INFO:Uploading results into container
2025-05-18 19:17:40,996:INFO:Uploading model into container now
2025-05-18 19:17:40,996:INFO:_master_model_container: 1
2025-05-18 19:17:40,996:INFO:_display_container: 2
2025-05-18 19:17:40,997:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-18 19:17:40,997:INFO:create_model() successfully completed......................................
2025-05-18 19:17:41,267:INFO:SubProcess create_model() end ==================================
2025-05-18 19:17:41,267:INFO:Creating metrics dataframe
2025-05-18 19:17:41,270:INFO:Initializing K Neighbors Classifier
2025-05-18 19:17:41,271:INFO:Total runtime is 0.08093565305074056 minutes
2025-05-18 19:17:41,272:INFO:SubProcess create_model() called ==================================
2025-05-18 19:17:41,273:INFO:Initializing create_model()
2025-05-18 19:17:41,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:17:41,273:INFO:Checking exceptions
2025-05-18 19:17:41,273:INFO:Importing libraries
2025-05-18 19:17:41,273:INFO:Copying training dataset
2025-05-18 19:17:41,289:INFO:Defining folds
2025-05-18 19:17:41,289:INFO:Declaring metric variables
2025-05-18 19:17:41,291:INFO:Importing untrained model
2025-05-18 19:17:41,293:INFO:K Neighbors Classifier Imported successfully
2025-05-18 19:17:41,295:INFO:Starting cross validation
2025-05-18 19:17:41,297:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:17:46,487:INFO:Calculating mean and std
2025-05-18 19:17:46,493:INFO:Creating metrics dataframe
2025-05-18 19:17:46,497:INFO:Uploading results into container
2025-05-18 19:17:46,498:INFO:Uploading model into container now
2025-05-18 19:17:46,498:INFO:_master_model_container: 2
2025-05-18 19:17:46,498:INFO:_display_container: 2
2025-05-18 19:17:46,499:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-18 19:17:46,499:INFO:create_model() successfully completed......................................
2025-05-18 19:17:46,756:INFO:SubProcess create_model() end ==================================
2025-05-18 19:17:46,756:INFO:Creating metrics dataframe
2025-05-18 19:17:46,760:INFO:Initializing Naive Bayes
2025-05-18 19:17:46,760:INFO:Total runtime is 0.1724189043045044 minutes
2025-05-18 19:17:46,761:INFO:SubProcess create_model() called ==================================
2025-05-18 19:17:46,761:INFO:Initializing create_model()
2025-05-18 19:17:46,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:17:46,761:INFO:Checking exceptions
2025-05-18 19:17:46,761:INFO:Importing libraries
2025-05-18 19:17:46,761:INFO:Copying training dataset
2025-05-18 19:17:46,775:INFO:Defining folds
2025-05-18 19:17:46,776:INFO:Declaring metric variables
2025-05-18 19:17:46,777:INFO:Importing untrained model
2025-05-18 19:17:46,778:INFO:Naive Bayes Imported successfully
2025-05-18 19:17:46,780:INFO:Starting cross validation
2025-05-18 19:17:46,782:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:17:48,084:INFO:Calculating mean and std
2025-05-18 19:17:48,085:INFO:Creating metrics dataframe
2025-05-18 19:17:48,086:INFO:Uploading results into container
2025-05-18 19:17:48,086:INFO:Uploading model into container now
2025-05-18 19:17:48,086:INFO:_master_model_container: 3
2025-05-18 19:17:48,086:INFO:_display_container: 2
2025-05-18 19:17:48,086:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-18 19:17:48,086:INFO:create_model() successfully completed......................................
2025-05-18 19:17:48,237:INFO:SubProcess create_model() end ==================================
2025-05-18 19:17:48,237:INFO:Creating metrics dataframe
2025-05-18 19:17:48,240:INFO:Initializing Decision Tree Classifier
2025-05-18 19:17:48,240:INFO:Total runtime is 0.19709910154342652 minutes
2025-05-18 19:17:48,242:INFO:SubProcess create_model() called ==================================
2025-05-18 19:17:48,242:INFO:Initializing create_model()
2025-05-18 19:17:48,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:17:48,243:INFO:Checking exceptions
2025-05-18 19:17:48,243:INFO:Importing libraries
2025-05-18 19:17:48,243:INFO:Copying training dataset
2025-05-18 19:17:48,254:INFO:Defining folds
2025-05-18 19:17:48,255:INFO:Declaring metric variables
2025-05-18 19:17:48,256:INFO:Importing untrained model
2025-05-18 19:17:48,257:INFO:Decision Tree Classifier Imported successfully
2025-05-18 19:17:48,260:INFO:Starting cross validation
2025-05-18 19:17:48,261:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:17:50,056:INFO:Calculating mean and std
2025-05-18 19:17:50,057:INFO:Creating metrics dataframe
2025-05-18 19:17:50,058:INFO:Uploading results into container
2025-05-18 19:17:50,059:INFO:Uploading model into container now
2025-05-18 19:17:50,059:INFO:_master_model_container: 4
2025-05-18 19:17:50,059:INFO:_display_container: 2
2025-05-18 19:17:50,059:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-18 19:17:50,059:INFO:create_model() successfully completed......................................
2025-05-18 19:17:50,217:INFO:SubProcess create_model() end ==================================
2025-05-18 19:17:50,217:INFO:Creating metrics dataframe
2025-05-18 19:17:50,220:INFO:Initializing SVM - Linear Kernel
2025-05-18 19:17:50,220:INFO:Total runtime is 0.23009331623713175 minutes
2025-05-18 19:17:50,221:INFO:SubProcess create_model() called ==================================
2025-05-18 19:17:50,221:INFO:Initializing create_model()
2025-05-18 19:17:50,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:17:50,222:INFO:Checking exceptions
2025-05-18 19:17:50,222:INFO:Importing libraries
2025-05-18 19:17:50,222:INFO:Copying training dataset
2025-05-18 19:17:50,231:INFO:Defining folds
2025-05-18 19:17:50,231:INFO:Declaring metric variables
2025-05-18 19:17:50,232:INFO:Importing untrained model
2025-05-18 19:17:50,233:INFO:SVM - Linear Kernel Imported successfully
2025-05-18 19:17:50,235:INFO:Starting cross validation
2025-05-18 19:17:50,236:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:17:53,819:INFO:Calculating mean and std
2025-05-18 19:17:53,820:INFO:Creating metrics dataframe
2025-05-18 19:17:53,821:INFO:Uploading results into container
2025-05-18 19:17:53,821:INFO:Uploading model into container now
2025-05-18 19:17:53,821:INFO:_master_model_container: 5
2025-05-18 19:17:53,821:INFO:_display_container: 2
2025-05-18 19:17:53,822:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-18 19:17:53,822:INFO:create_model() successfully completed......................................
2025-05-18 19:17:54,044:INFO:SubProcess create_model() end ==================================
2025-05-18 19:17:54,045:INFO:Creating metrics dataframe
2025-05-18 19:17:54,049:INFO:Initializing Ridge Classifier
2025-05-18 19:17:54,049:INFO:Total runtime is 0.293902321656545 minutes
2025-05-18 19:17:54,050:INFO:SubProcess create_model() called ==================================
2025-05-18 19:17:54,050:INFO:Initializing create_model()
2025-05-18 19:17:54,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:17:54,050:INFO:Checking exceptions
2025-05-18 19:17:54,050:INFO:Importing libraries
2025-05-18 19:17:54,050:INFO:Copying training dataset
2025-05-18 19:17:54,061:INFO:Defining folds
2025-05-18 19:17:54,061:INFO:Declaring metric variables
2025-05-18 19:17:54,062:INFO:Importing untrained model
2025-05-18 19:17:54,063:INFO:Ridge Classifier Imported successfully
2025-05-18 19:17:54,065:INFO:Starting cross validation
2025-05-18 19:17:54,066:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:17:55,238:INFO:Calculating mean and std
2025-05-18 19:17:55,239:INFO:Creating metrics dataframe
2025-05-18 19:17:55,240:INFO:Uploading results into container
2025-05-18 19:17:55,240:INFO:Uploading model into container now
2025-05-18 19:17:55,241:INFO:_master_model_container: 6
2025-05-18 19:17:55,241:INFO:_display_container: 2
2025-05-18 19:17:55,241:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-18 19:17:55,241:INFO:create_model() successfully completed......................................
2025-05-18 19:17:55,379:INFO:SubProcess create_model() end ==================================
2025-05-18 19:17:55,379:INFO:Creating metrics dataframe
2025-05-18 19:17:55,383:INFO:Initializing Random Forest Classifier
2025-05-18 19:17:55,383:INFO:Total runtime is 0.31613638401031496 minutes
2025-05-18 19:17:55,384:INFO:SubProcess create_model() called ==================================
2025-05-18 19:17:55,384:INFO:Initializing create_model()
2025-05-18 19:17:55,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:17:55,384:INFO:Checking exceptions
2025-05-18 19:17:55,384:INFO:Importing libraries
2025-05-18 19:17:55,384:INFO:Copying training dataset
2025-05-18 19:17:55,394:INFO:Defining folds
2025-05-18 19:17:55,394:INFO:Declaring metric variables
2025-05-18 19:17:55,396:INFO:Importing untrained model
2025-05-18 19:17:55,397:INFO:Random Forest Classifier Imported successfully
2025-05-18 19:17:55,399:INFO:Starting cross validation
2025-05-18 19:17:55,400:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:18:01,280:INFO:Calculating mean and std
2025-05-18 19:18:01,288:INFO:Creating metrics dataframe
2025-05-18 19:18:01,293:INFO:Uploading results into container
2025-05-18 19:18:01,294:INFO:Uploading model into container now
2025-05-18 19:18:01,294:INFO:_master_model_container: 7
2025-05-18 19:18:01,294:INFO:_display_container: 2
2025-05-18 19:18:01,295:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-18 19:18:01,295:INFO:create_model() successfully completed......................................
2025-05-18 19:18:01,479:INFO:SubProcess create_model() end ==================================
2025-05-18 19:18:01,479:INFO:Creating metrics dataframe
2025-05-18 19:18:01,483:INFO:Initializing Quadratic Discriminant Analysis
2025-05-18 19:18:01,483:INFO:Total runtime is 0.41780305306116744 minutes
2025-05-18 19:18:01,484:INFO:SubProcess create_model() called ==================================
2025-05-18 19:18:01,484:INFO:Initializing create_model()
2025-05-18 19:18:01,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:18:01,484:INFO:Checking exceptions
2025-05-18 19:18:01,484:INFO:Importing libraries
2025-05-18 19:18:01,484:INFO:Copying training dataset
2025-05-18 19:18:01,495:INFO:Defining folds
2025-05-18 19:18:01,495:INFO:Declaring metric variables
2025-05-18 19:18:01,497:INFO:Importing untrained model
2025-05-18 19:18:01,498:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 19:18:01,500:INFO:Starting cross validation
2025-05-18 19:18:01,501:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:18:02,537:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:18:02,542:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:18:02,574:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:18:02,623:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:18:02,628:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:18:02,630:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:18:02,632:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:18:02,658:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:18:02,703:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:18:02,706:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:18:02,717:INFO:Calculating mean and std
2025-05-18 19:18:02,718:INFO:Creating metrics dataframe
2025-05-18 19:18:02,718:INFO:Uploading results into container
2025-05-18 19:18:02,719:INFO:Uploading model into container now
2025-05-18 19:18:02,719:INFO:_master_model_container: 8
2025-05-18 19:18:02,719:INFO:_display_container: 2
2025-05-18 19:18:02,719:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 19:18:02,719:INFO:create_model() successfully completed......................................
2025-05-18 19:18:02,872:INFO:SubProcess create_model() end ==================================
2025-05-18 19:18:02,873:INFO:Creating metrics dataframe
2025-05-18 19:18:02,876:INFO:Initializing Ada Boost Classifier
2025-05-18 19:18:02,876:INFO:Total runtime is 0.44103040297826135 minutes
2025-05-18 19:18:02,878:INFO:SubProcess create_model() called ==================================
2025-05-18 19:18:02,878:INFO:Initializing create_model()
2025-05-18 19:18:02,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:18:02,878:INFO:Checking exceptions
2025-05-18 19:18:02,878:INFO:Importing libraries
2025-05-18 19:18:02,878:INFO:Copying training dataset
2025-05-18 19:18:02,890:INFO:Defining folds
2025-05-18 19:18:02,890:INFO:Declaring metric variables
2025-05-18 19:18:02,891:INFO:Importing untrained model
2025-05-18 19:18:02,893:INFO:Ada Boost Classifier Imported successfully
2025-05-18 19:18:02,895:INFO:Starting cross validation
2025-05-18 19:18:02,896:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:18:03,902:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:18:03,917:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:18:03,955:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:18:03,993:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:18:04,006:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:18:06,809:INFO:Calculating mean and std
2025-05-18 19:18:06,810:INFO:Creating metrics dataframe
2025-05-18 19:18:06,811:INFO:Uploading results into container
2025-05-18 19:18:06,811:INFO:Uploading model into container now
2025-05-18 19:18:06,811:INFO:_master_model_container: 9
2025-05-18 19:18:06,811:INFO:_display_container: 2
2025-05-18 19:18:06,811:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-18 19:18:06,811:INFO:create_model() successfully completed......................................
2025-05-18 19:18:06,978:INFO:SubProcess create_model() end ==================================
2025-05-18 19:18:06,978:INFO:Creating metrics dataframe
2025-05-18 19:18:06,982:INFO:Initializing Gradient Boosting Classifier
2025-05-18 19:18:06,982:INFO:Total runtime is 0.509463385740916 minutes
2025-05-18 19:18:06,984:INFO:SubProcess create_model() called ==================================
2025-05-18 19:18:06,984:INFO:Initializing create_model()
2025-05-18 19:18:06,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:18:06,984:INFO:Checking exceptions
2025-05-18 19:18:06,984:INFO:Importing libraries
2025-05-18 19:18:06,985:INFO:Copying training dataset
2025-05-18 19:18:07,000:INFO:Defining folds
2025-05-18 19:18:07,000:INFO:Declaring metric variables
2025-05-18 19:18:07,002:INFO:Importing untrained model
2025-05-18 19:18:07,003:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 19:18:07,006:INFO:Starting cross validation
2025-05-18 19:18:07,007:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:18:20,720:INFO:Calculating mean and std
2025-05-18 19:18:20,724:INFO:Creating metrics dataframe
2025-05-18 19:18:20,733:INFO:Uploading results into container
2025-05-18 19:18:20,734:INFO:Uploading model into container now
2025-05-18 19:18:20,734:INFO:_master_model_container: 10
2025-05-18 19:18:20,734:INFO:_display_container: 2
2025-05-18 19:18:20,735:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 19:18:20,735:INFO:create_model() successfully completed......................................
2025-05-18 19:18:20,970:INFO:SubProcess create_model() end ==================================
2025-05-18 19:18:20,970:INFO:Creating metrics dataframe
2025-05-18 19:18:20,975:INFO:Initializing Linear Discriminant Analysis
2025-05-18 19:18:20,975:INFO:Total runtime is 0.7426716526349386 minutes
2025-05-18 19:18:20,976:INFO:SubProcess create_model() called ==================================
2025-05-18 19:18:20,976:INFO:Initializing create_model()
2025-05-18 19:18:20,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:18:20,976:INFO:Checking exceptions
2025-05-18 19:18:20,976:INFO:Importing libraries
2025-05-18 19:18:20,976:INFO:Copying training dataset
2025-05-18 19:18:20,986:INFO:Defining folds
2025-05-18 19:18:20,986:INFO:Declaring metric variables
2025-05-18 19:18:20,988:INFO:Importing untrained model
2025-05-18 19:18:20,989:INFO:Linear Discriminant Analysis Imported successfully
2025-05-18 19:18:20,991:INFO:Starting cross validation
2025-05-18 19:18:20,992:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:18:22,236:INFO:Calculating mean and std
2025-05-18 19:18:22,236:INFO:Creating metrics dataframe
2025-05-18 19:18:22,237:INFO:Uploading results into container
2025-05-18 19:18:22,237:INFO:Uploading model into container now
2025-05-18 19:18:22,238:INFO:_master_model_container: 11
2025-05-18 19:18:22,238:INFO:_display_container: 2
2025-05-18 19:18:22,238:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-18 19:18:22,238:INFO:create_model() successfully completed......................................
2025-05-18 19:18:22,383:INFO:SubProcess create_model() end ==================================
2025-05-18 19:18:22,383:INFO:Creating metrics dataframe
2025-05-18 19:18:22,387:INFO:Initializing Extra Trees Classifier
2025-05-18 19:18:22,387:INFO:Total runtime is 0.7662052869796754 minutes
2025-05-18 19:18:22,388:INFO:SubProcess create_model() called ==================================
2025-05-18 19:18:22,388:INFO:Initializing create_model()
2025-05-18 19:18:22,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:18:22,388:INFO:Checking exceptions
2025-05-18 19:18:22,388:INFO:Importing libraries
2025-05-18 19:18:22,389:INFO:Copying training dataset
2025-05-18 19:18:22,399:INFO:Defining folds
2025-05-18 19:18:22,399:INFO:Declaring metric variables
2025-05-18 19:18:22,400:INFO:Importing untrained model
2025-05-18 19:18:22,401:INFO:Extra Trees Classifier Imported successfully
2025-05-18 19:18:22,403:INFO:Starting cross validation
2025-05-18 19:18:22,404:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:18:27,469:INFO:Calculating mean and std
2025-05-18 19:18:27,473:INFO:Creating metrics dataframe
2025-05-18 19:18:27,485:INFO:Uploading results into container
2025-05-18 19:18:27,486:INFO:Uploading model into container now
2025-05-18 19:18:27,487:INFO:_master_model_container: 12
2025-05-18 19:18:27,487:INFO:_display_container: 2
2025-05-18 19:18:27,488:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-18 19:18:27,488:INFO:create_model() successfully completed......................................
2025-05-18 19:18:27,792:INFO:SubProcess create_model() end ==================================
2025-05-18 19:18:27,793:INFO:Creating metrics dataframe
2025-05-18 19:18:27,797:INFO:Initializing Light Gradient Boosting Machine
2025-05-18 19:18:27,798:INFO:Total runtime is 0.8563850204149883 minutes
2025-05-18 19:18:27,799:INFO:SubProcess create_model() called ==================================
2025-05-18 19:18:27,800:INFO:Initializing create_model()
2025-05-18 19:18:27,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:18:27,800:INFO:Checking exceptions
2025-05-18 19:18:27,801:INFO:Importing libraries
2025-05-18 19:18:27,801:INFO:Copying training dataset
2025-05-18 19:18:27,822:INFO:Defining folds
2025-05-18 19:18:27,822:INFO:Declaring metric variables
2025-05-18 19:18:27,824:INFO:Importing untrained model
2025-05-18 19:18:27,829:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 19:18:27,832:INFO:Starting cross validation
2025-05-18 19:18:27,834:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:18:32,104:INFO:Calculating mean and std
2025-05-18 19:18:32,105:INFO:Creating metrics dataframe
2025-05-18 19:18:32,106:INFO:Uploading results into container
2025-05-18 19:18:32,106:INFO:Uploading model into container now
2025-05-18 19:18:32,107:INFO:_master_model_container: 13
2025-05-18 19:18:32,107:INFO:_display_container: 2
2025-05-18 19:18:32,107:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:18:32,107:INFO:create_model() successfully completed......................................
2025-05-18 19:18:32,260:INFO:SubProcess create_model() end ==================================
2025-05-18 19:18:32,260:INFO:Creating metrics dataframe
2025-05-18 19:18:32,264:INFO:Initializing CatBoost Classifier
2025-05-18 19:18:32,264:INFO:Total runtime is 0.9308300058046978 minutes
2025-05-18 19:18:32,266:INFO:SubProcess create_model() called ==================================
2025-05-18 19:18:32,266:INFO:Initializing create_model()
2025-05-18 19:18:32,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:18:32,266:INFO:Checking exceptions
2025-05-18 19:18:32,266:INFO:Importing libraries
2025-05-18 19:18:32,266:INFO:Copying training dataset
2025-05-18 19:18:32,275:INFO:Defining folds
2025-05-18 19:18:32,275:INFO:Declaring metric variables
2025-05-18 19:18:32,277:INFO:Importing untrained model
2025-05-18 19:18:32,278:INFO:CatBoost Classifier Imported successfully
2025-05-18 19:18:32,280:INFO:Starting cross validation
2025-05-18 19:18:32,281:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:18:48,895:INFO:Calculating mean and std
2025-05-18 19:18:48,897:INFO:Creating metrics dataframe
2025-05-18 19:18:48,901:INFO:Uploading results into container
2025-05-18 19:18:48,902:INFO:Uploading model into container now
2025-05-18 19:18:48,903:INFO:_master_model_container: 14
2025-05-18 19:18:48,903:INFO:_display_container: 2
2025-05-18 19:18:48,903:INFO:<catboost.core.CatBoostClassifier object at 0x363da5290>
2025-05-18 19:18:48,903:INFO:create_model() successfully completed......................................
2025-05-18 19:18:49,087:INFO:SubProcess create_model() end ==================================
2025-05-18 19:18:49,088:INFO:Creating metrics dataframe
2025-05-18 19:18:49,092:INFO:Initializing Dummy Classifier
2025-05-18 19:18:49,092:INFO:Total runtime is 1.2112924218177796 minutes
2025-05-18 19:18:49,093:INFO:SubProcess create_model() called ==================================
2025-05-18 19:18:49,093:INFO:Initializing create_model()
2025-05-18 19:18:49,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f7ce890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:18:49,094:INFO:Checking exceptions
2025-05-18 19:18:49,094:INFO:Importing libraries
2025-05-18 19:18:49,094:INFO:Copying training dataset
2025-05-18 19:18:49,103:INFO:Defining folds
2025-05-18 19:18:49,103:INFO:Declaring metric variables
2025-05-18 19:18:49,104:INFO:Importing untrained model
2025-05-18 19:18:49,105:INFO:Dummy Classifier Imported successfully
2025-05-18 19:18:49,107:INFO:Starting cross validation
2025-05-18 19:18:49,108:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:18:50,145:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:18:50,171:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:18:50,188:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:18:50,197:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:18:50,234:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:18:50,240:INFO:Calculating mean and std
2025-05-18 19:18:50,241:INFO:Creating metrics dataframe
2025-05-18 19:18:50,242:INFO:Uploading results into container
2025-05-18 19:18:50,242:INFO:Uploading model into container now
2025-05-18 19:18:50,242:INFO:_master_model_container: 15
2025-05-18 19:18:50,243:INFO:_display_container: 2
2025-05-18 19:18:50,243:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-18 19:18:50,243:INFO:create_model() successfully completed......................................
2025-05-18 19:18:50,386:INFO:SubProcess create_model() end ==================================
2025-05-18 19:18:50,386:INFO:Creating metrics dataframe
2025-05-18 19:18:50,391:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-18 19:18:50,394:INFO:Initializing create_model()
2025-05-18 19:18:50,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:18:50,394:INFO:Checking exceptions
2025-05-18 19:18:50,395:INFO:Importing libraries
2025-05-18 19:18:50,395:INFO:Copying training dataset
2025-05-18 19:18:50,404:INFO:Defining folds
2025-05-18 19:18:50,404:INFO:Declaring metric variables
2025-05-18 19:18:50,404:INFO:Importing untrained model
2025-05-18 19:18:50,404:INFO:Declaring custom model
2025-05-18 19:18:50,404:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 19:18:50,405:INFO:Cross validation set to False
2025-05-18 19:18:50,405:INFO:Fitting Model
2025-05-18 19:18:51,761:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 19:18:51,770:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004448 seconds.
2025-05-18 19:18:51,770:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 19:18:51,770:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 19:18:51,770:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 19:18:51,770:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 19:18:51,771:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 19:18:52,532:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:18:52,532:INFO:create_model() successfully completed......................................
2025-05-18 19:18:52,680:INFO:Initializing create_model()
2025-05-18 19:18:52,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:18:52,680:INFO:Checking exceptions
2025-05-18 19:18:52,681:INFO:Importing libraries
2025-05-18 19:18:52,681:INFO:Copying training dataset
2025-05-18 19:18:52,690:INFO:Defining folds
2025-05-18 19:18:52,690:INFO:Declaring metric variables
2025-05-18 19:18:52,690:INFO:Importing untrained model
2025-05-18 19:18:52,690:INFO:Declaring custom model
2025-05-18 19:18:52,690:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 19:18:52,691:INFO:Cross validation set to False
2025-05-18 19:18:52,691:INFO:Fitting Model
2025-05-18 19:19:08,569:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 19:19:08,570:INFO:create_model() successfully completed......................................
2025-05-18 19:19:08,708:INFO:Initializing create_model()
2025-05-18 19:19:08,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:19:08,709:INFO:Checking exceptions
2025-05-18 19:19:08,709:INFO:Importing libraries
2025-05-18 19:19:08,709:INFO:Copying training dataset
2025-05-18 19:19:08,718:INFO:Defining folds
2025-05-18 19:19:08,718:INFO:Declaring metric variables
2025-05-18 19:19:08,718:INFO:Importing untrained model
2025-05-18 19:19:08,718:INFO:Declaring custom model
2025-05-18 19:19:08,718:INFO:Random Forest Classifier Imported successfully
2025-05-18 19:19:08,719:INFO:Cross validation set to False
2025-05-18 19:19:08,719:INFO:Fitting Model
2025-05-18 19:19:10,819:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-18 19:19:10,819:INFO:create_model() successfully completed......................................
2025-05-18 19:19:10,970:INFO:Initializing create_model()
2025-05-18 19:19:10,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=<catboost.core.CatBoostClassifier object at 0x363da5290>, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:19:10,970:INFO:Checking exceptions
2025-05-18 19:19:10,971:INFO:Importing libraries
2025-05-18 19:19:10,971:INFO:Copying training dataset
2025-05-18 19:19:10,980:INFO:Defining folds
2025-05-18 19:19:10,980:INFO:Declaring metric variables
2025-05-18 19:19:10,980:INFO:Importing untrained model
2025-05-18 19:19:10,980:INFO:Declaring custom model
2025-05-18 19:19:10,980:INFO:CatBoost Classifier Imported successfully
2025-05-18 19:19:10,981:INFO:Cross validation set to False
2025-05-18 19:19:10,981:INFO:Fitting Model
2025-05-18 19:19:17,936:INFO:<catboost.core.CatBoostClassifier object at 0x3814905d0>
2025-05-18 19:19:17,937:INFO:create_model() successfully completed......................................
2025-05-18 19:19:18,085:INFO:Initializing create_model()
2025-05-18 19:19:18,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:19:18,086:INFO:Checking exceptions
2025-05-18 19:19:18,086:INFO:Importing libraries
2025-05-18 19:19:18,086:INFO:Copying training dataset
2025-05-18 19:19:18,095:INFO:Defining folds
2025-05-18 19:19:18,095:INFO:Declaring metric variables
2025-05-18 19:19:18,095:INFO:Importing untrained model
2025-05-18 19:19:18,095:INFO:Declaring custom model
2025-05-18 19:19:18,096:INFO:Extra Trees Classifier Imported successfully
2025-05-18 19:19:18,096:INFO:Cross validation set to False
2025-05-18 19:19:18,096:INFO:Fitting Model
2025-05-18 19:19:19,730:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-18 19:19:19,730:INFO:create_model() successfully completed......................................
2025-05-18 19:19:19,902:INFO:_master_model_container: 15
2025-05-18 19:19:19,903:INFO:_display_container: 2
2025-05-18 19:19:19,903:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), <catboost.core.CatBoostClassifier object at 0x3814905d0>, ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)]
2025-05-18 19:19:19,903:INFO:compare_models() successfully completed......................................
2025-05-18 19:19:19,913:INFO:Initializing evaluate_model()
2025-05-18 19:19:19,913:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-18 19:19:19,920:INFO:Initializing plot_model()
2025-05-18 19:19:19,920:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-18 19:19:19,920:INFO:Checking exceptions
2025-05-18 19:19:19,923:INFO:Preloading libraries
2025-05-18 19:19:19,926:INFO:Copying training dataset
2025-05-18 19:19:19,926:INFO:Plot type: pipeline
2025-05-18 19:19:19,985:INFO:Visual Rendered Successfully
2025-05-18 19:19:20,129:INFO:plot_model() successfully completed......................................
2025-05-18 19:19:20,131:INFO:Initializing tune_model()
2025-05-18 19:19:20,131:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=f1, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-18 19:19:20,131:INFO:Checking exceptions
2025-05-18 19:19:20,131:INFO:Soft dependency imported: optuna: 4.3.0
2025-05-18 19:19:20,140:INFO:Copying training dataset
2025-05-18 19:19:20,147:INFO:Checking base model
2025-05-18 19:19:20,147:INFO:Base model : Light Gradient Boosting Machine
2025-05-18 19:19:20,149:INFO:Declaring metric variables
2025-05-18 19:19:20,150:INFO:Defining Hyperparameters
2025-05-18 19:19:20,293:INFO:Tuning with n_jobs=-1
2025-05-18 19:19:20,294:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-05-18 19:19:20,294:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.
  warnings.warn(

2025-05-18 19:19:20,294:INFO:Initializing optuna.integration.OptunaSearchCV
2025-05-18 19:19:20,302:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2025-05-18 19:40:55,738:INFO:best_params: {'actual_estimator__num_leaves': 109, 'actual_estimator__learning_rate': 5.135960766834039e-06, 'actual_estimator__n_estimators': 286, 'actual_estimator__min_split_gain': 0.45512963531918005, 'actual_estimator__reg_alpha': 0.007590176585633129, 'actual_estimator__reg_lambda': 1.40132877509976, 'actual_estimator__feature_fraction': 0.7609253692808252, 'actual_estimator__bagging_fraction': 0.6124590420467294, 'actual_estimator__bagging_freq': 2, 'actual_estimator__min_child_samples': 21}
2025-05-18 19:40:55,744:INFO:Hyperparameter search completed
2025-05-18 19:40:55,744:INFO:SubProcess create_model() called ==================================
2025-05-18 19:40:55,745:INFO:Initializing create_model()
2025-05-18 19:40:55,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3560f1550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'num_leaves': 109, 'learning_rate': 5.135960766834039e-06, 'n_estimators': 286, 'min_split_gain': 0.45512963531918005, 'reg_alpha': 0.007590176585633129, 'reg_lambda': 1.40132877509976, 'feature_fraction': 0.7609253692808252, 'bagging_fraction': 0.6124590420467294, 'bagging_freq': 2, 'min_child_samples': 21})
2025-05-18 19:40:55,745:INFO:Checking exceptions
2025-05-18 19:40:55,745:INFO:Importing libraries
2025-05-18 19:40:55,745:INFO:Copying training dataset
2025-05-18 19:40:55,755:INFO:Defining folds
2025-05-18 19:40:55,755:INFO:Declaring metric variables
2025-05-18 19:40:55,758:INFO:Importing untrained model
2025-05-18 19:40:55,758:INFO:Declaring custom model
2025-05-18 19:40:55,761:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 19:40:55,764:INFO:Starting cross validation
2025-05-18 19:40:55,765:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:41:26,372:INFO:Calculating mean and std
2025-05-18 19:41:26,381:INFO:Creating metrics dataframe
2025-05-18 19:41:26,392:INFO:Finalizing model
2025-05-18 19:41:27,655:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-05-18 19:41:27,655:INFO:[LightGBM] [Warning] feature_fraction is set=0.7609253692808252, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609253692808252
2025-05-18 19:41:27,655:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6124590420467294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6124590420467294
2025-05-18 19:41:27,687:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-05-18 19:41:27,688:INFO:[LightGBM] [Warning] feature_fraction is set=0.7609253692808252, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609253692808252
2025-05-18 19:41:27,688:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6124590420467294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6124590420467294
2025-05-18 19:41:27,688:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 19:41:27,700:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005893 seconds.
2025-05-18 19:41:27,700:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 19:41:27,700:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 19:41:27,700:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 19:41:27,701:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 19:41:27,702:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 19:41:38,425:INFO:Uploading results into container
2025-05-18 19:41:38,426:INFO:Uploading model into container now
2025-05-18 19:41:38,426:INFO:_master_model_container: 16
2025-05-18 19:41:38,426:INFO:_display_container: 3
2025-05-18 19:41:38,427:INFO:LGBMClassifier(bagging_fraction=0.6124590420467294, bagging_freq=2,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7609253692808252, importance_type='split',
               learning_rate=5.135960766834039e-06, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001,
               min_split_gain=0.45512963531918005, n_estimators=286, n_jobs=-1,
               num_leaves=109, objective=None, random_state=42,
               reg_alpha=0.007590176585633129, reg_lambda=1.40132877509976,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:41:38,427:INFO:create_model() successfully completed......................................
2025-05-18 19:41:38,621:INFO:SubProcess create_model() end ==================================
2025-05-18 19:41:38,621:INFO:choose_better activated
2025-05-18 19:41:38,622:INFO:SubProcess create_model() called ==================================
2025-05-18 19:41:38,623:INFO:Initializing create_model()
2025-05-18 19:41:38,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:41:38,623:INFO:Checking exceptions
2025-05-18 19:41:38,624:INFO:Importing libraries
2025-05-18 19:41:38,624:INFO:Copying training dataset
2025-05-18 19:41:38,633:INFO:Defining folds
2025-05-18 19:41:38,633:INFO:Declaring metric variables
2025-05-18 19:41:38,633:INFO:Importing untrained model
2025-05-18 19:41:38,633:INFO:Declaring custom model
2025-05-18 19:41:38,634:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 19:41:38,634:INFO:Starting cross validation
2025-05-18 19:41:38,634:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:41:43,095:INFO:Calculating mean and std
2025-05-18 19:41:43,095:INFO:Creating metrics dataframe
2025-05-18 19:41:43,096:INFO:Finalizing model
2025-05-18 19:41:44,106:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 19:41:44,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005087 seconds.
2025-05-18 19:41:44,116:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 19:41:44,116:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 19:41:44,116:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 19:41:44,116:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 19:41:44,117:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 19:41:45,178:INFO:Uploading results into container
2025-05-18 19:41:45,179:INFO:Uploading model into container now
2025-05-18 19:41:45,179:INFO:_master_model_container: 17
2025-05-18 19:41:45,179:INFO:_display_container: 4
2025-05-18 19:41:45,179:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:41:45,179:INFO:create_model() successfully completed......................................
2025-05-18 19:41:45,322:INFO:SubProcess create_model() end ==================================
2025-05-18 19:41:45,323:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-18 19:41:45,323:INFO:LGBMClassifier(bagging_fraction=0.6124590420467294, bagging_freq=2,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7609253692808252, importance_type='split',
               learning_rate=5.135960766834039e-06, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001,
               min_split_gain=0.45512963531918005, n_estimators=286, n_jobs=-1,
               num_leaves=109, objective=None, random_state=42,
               reg_alpha=0.007590176585633129, reg_lambda=1.40132877509976,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4907
2025-05-18 19:41:45,323:INFO:LGBMClassifier(bagging_fraction=0.6124590420467294, bagging_freq=2,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7609253692808252, importance_type='split',
               learning_rate=5.135960766834039e-06, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001,
               min_split_gain=0.45512963531918005, n_estimators=286, n_jobs=-1,
               num_leaves=109, objective=None, random_state=42,
               reg_alpha=0.007590176585633129, reg_lambda=1.40132877509976,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-18 19:41:45,323:INFO:choose_better completed
2025-05-18 19:41:45,327:INFO:_master_model_container: 17
2025-05-18 19:41:45,327:INFO:_display_container: 3
2025-05-18 19:41:45,327:INFO:LGBMClassifier(bagging_fraction=0.6124590420467294, bagging_freq=2,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7609253692808252, importance_type='split',
               learning_rate=5.135960766834039e-06, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001,
               min_split_gain=0.45512963531918005, n_estimators=286, n_jobs=-1,
               num_leaves=109, objective=None, random_state=42,
               reg_alpha=0.007590176585633129, reg_lambda=1.40132877509976,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:41:45,328:INFO:tune_model() successfully completed......................................
2025-05-18 19:41:45,470:INFO:Initializing evaluate_model()
2025-05-18 19:41:45,470:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=LGBMClassifier(bagging_fraction=0.6124590420467294, bagging_freq=2,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7609253692808252, importance_type='split',
               learning_rate=5.135960766834039e-06, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001,
               min_split_gain=0.45512963531918005, n_estimators=286, n_jobs=-1,
               num_leaves=109, objective=None, random_state=42,
               reg_alpha=0.007590176585633129, reg_lambda=1.40132877509976,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-18 19:41:45,476:INFO:Initializing plot_model()
2025-05-18 19:41:45,476:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=LGBMClassifier(bagging_fraction=0.6124590420467294, bagging_freq=2,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7609253692808252, importance_type='split',
               learning_rate=5.135960766834039e-06, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001,
               min_split_gain=0.45512963531918005, n_estimators=286, n_jobs=-1,
               num_leaves=109, objective=None, random_state=42,
               reg_alpha=0.007590176585633129, reg_lambda=1.40132877509976,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-18 19:41:45,476:INFO:Checking exceptions
2025-05-18 19:41:45,480:INFO:Preloading libraries
2025-05-18 19:41:45,494:INFO:Copying training dataset
2025-05-18 19:41:45,494:INFO:Plot type: pipeline
2025-05-18 19:41:45,552:INFO:Visual Rendered Successfully
2025-05-18 19:41:45,713:INFO:plot_model() successfully completed......................................
2025-05-18 19:41:45,715:INFO:Initializing interpret_model()
2025-05-18 19:41:45,715:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=LGBMClassifier(bagging_fraction=0.6124590420467294, bagging_freq=2,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7609253692808252, importance_type='split',
               learning_rate=5.135960766834039e-06, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001,
               min_split_gain=0.45512963531918005, n_estimators=286, n_jobs=-1,
               num_leaves=109, objective=None, random_state=42,
               reg_alpha=0.007590176585633129, reg_lambda=1.40132877509976,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-18 19:41:45,715:INFO:Checking exceptions
2025-05-18 19:41:45,715:INFO:Soft dependency imported: shap: 0.47.2
2025-05-18 19:41:45,797:INFO:plot type: summary
2025-05-18 19:41:45,797:INFO:Creating TreeExplainer
2025-05-18 19:41:46,226:INFO:Compiling shap values
2025-05-18 19:42:00,351:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray
  warnings.warn(

2025-05-18 19:42:00,352:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-05-18 19:42:01,949:INFO:Visual Rendered Successfully
2025-05-18 19:42:01,950:INFO:interpret_model() successfully completed......................................
2025-05-18 19:42:02,161:INFO:Initializing finalize_model()
2025-05-18 19:42:02,161:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=LGBMClassifier(bagging_fraction=0.6124590420467294, bagging_freq=2,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7609253692808252, importance_type='split',
               learning_rate=5.135960766834039e-06, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001,
               min_split_gain=0.45512963531918005, n_estimators=286, n_jobs=-1,
               num_leaves=109, objective=None, random_state=42,
               reg_alpha=0.007590176585633129, reg_lambda=1.40132877509976,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-18 19:42:02,161:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6124590420467294, bagging_freq=2,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7609253692808252, importance_type='split',
               learning_rate=5.135960766834039e-06, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001,
               min_split_gain=0.45512963531918005, n_estimators=286, n_jobs=-1,
               num_leaves=109, objective=None, random_state=42,
               reg_alpha=0.007590176585633129, reg_lambda=1.40132877509976,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:42:02,167:INFO:Initializing create_model()
2025-05-18 19:42:02,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=LGBMClassifier(bagging_fraction=0.6124590420467294, bagging_freq=2,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7609253692808252, importance_type='split',
               learning_rate=5.135960766834039e-06, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001,
               min_split_gain=0.45512963531918005, n_estimators=286, n_jobs=-1,
               num_leaves=109, objective=None, random_state=42,
               reg_alpha=0.007590176585633129, reg_lambda=1.40132877509976,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:42:02,167:INFO:Checking exceptions
2025-05-18 19:42:02,168:INFO:Importing libraries
2025-05-18 19:42:02,168:INFO:Copying training dataset
2025-05-18 19:42:02,168:INFO:Defining folds
2025-05-18 19:42:02,168:INFO:Declaring metric variables
2025-05-18 19:42:02,168:INFO:Importing untrained model
2025-05-18 19:42:02,168:INFO:Declaring custom model
2025-05-18 19:42:02,169:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 19:42:02,170:INFO:Cross validation set to False
2025-05-18 19:42:02,170:INFO:Fitting Model
2025-05-18 19:42:03,819:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-05-18 19:42:03,819:INFO:[LightGBM] [Warning] feature_fraction is set=0.7609253692808252, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609253692808252
2025-05-18 19:42:03,819:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6124590420467294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6124590420467294
2025-05-18 19:42:03,922:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-05-18 19:42:03,922:INFO:[LightGBM] [Warning] feature_fraction is set=0.7609253692808252, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7609253692808252
2025-05-18 19:42:03,922:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6124590420467294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6124590420467294
2025-05-18 19:42:03,923:INFO:[LightGBM] [Info] Number of positive: 61360, number of negative: 61360
2025-05-18 19:42:03,937:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007140 seconds.
2025-05-18 19:42:03,937:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 19:42:03,937:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 19:42:03,937:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 19:42:03,938:INFO:[LightGBM] [Info] Number of data points in the train set: 122720, number of used features: 28
2025-05-18 19:42:03,938:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 19:42:15,634:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                importance_type='split',
                                learning_rate=5.135960766834039e-06,
                                max_depth=-1, min_child_samples=21,
                                min_child_weight=0.001,
                                min_split_gain=0.45512963531918005,
                                n_estimators=286, n_jobs=-1, num_leaves=109,
                                objective=None, random_state=42,
                                reg_alpha=0.007590176585633129,
                                reg_lambda=1.40132877509976, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-18 19:42:15,635:INFO:create_model() successfully completed......................................
2025-05-18 19:42:15,834:INFO:_master_model_container: 17
2025-05-18 19:42:15,834:INFO:_display_container: 3
2025-05-18 19:42:15,855:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                importance_type='split',
                                learning_rate=5.135960766834039e-06,
                                max_depth=-1, min_child_samples=21,
                                min_child_weight=0.001,
                                min_split_gain=0.45512963531918005,
                                n_estimators=286, n_jobs=-1, num_leaves=109,
                                objective=None, random_state=42,
                                reg_alpha=0.007590176585633129,
                                reg_lambda=1.40132877509976, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-18 19:42:15,855:INFO:finalize_model() successfully completed......................................
2025-05-18 19:42:16,058:INFO:Initializing save_model()
2025-05-18 19:42:16,058:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                importance_type='split',
                                learning_rate=5.135960766834039e-06,
                                max_depth=-1, min_child_samples=21,
                                min_child_weight=0.001,
                                min_split_gain=0.45512963531918005,
                                n_estimators=286, n_jobs=-1, num_leaves=109,
                                objective=None, random_state=42,
                                reg_alpha=0.007590176585633129,
                                reg_lambda=1.40132877509976, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-18 19:42:16,058:INFO:Adding model into prep_pipe
2025-05-18 19:42:16,058:WARNING:Only Model saved as it was a pipeline.
2025-05-18 19:42:16,078:INFO:final_cancer_model.pkl saved in current working directory
2025-05-18 19:42:16,098:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                importance_type='split',
                                learning_rate=5.135960766834039e-06,
                                max_depth=-1, min_child_samples=21,
                                min_child_weight=0.001,
                                min_split_gain=0.45512963531918005,
                                n_estimators=286, n_jobs=-1, num_leaves=109,
                                objective=None, random_state=42,
                                reg_alpha=0.007590176585633129,
                                reg_lambda=1.40132877509976, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-18 19:42:16,098:INFO:save_model() successfully completed......................................
2025-05-18 19:42:16,263:INFO:Initializing predict_model()
2025-05-18 19:42:16,263:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                importance_type='split',
                                learning_rate=5.135960766834039e-06,
                                max_depth=-1, min_child_samples=21,
                                min_child_weight=0.001,
                                min_split_gain=0.45512963531918005,
                                n_estimators=286, n_jobs=-1, num_leaves=109,
                                objective=None, random_state=42,
                                reg_alpha=0.007590176585633129,
                                reg_lambda=1.40132877509976, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x37352a3e0>)
2025-05-18 19:42:16,263:INFO:Checking exceptions
2025-05-18 19:42:16,263:INFO:Preloading libraries
2025-05-18 19:42:16,264:INFO:Set up data.
2025-05-18 19:42:16,284:INFO:Set up index.
2025-05-18 19:42:17,014:INFO:Initializing stack_models()
2025-05-18 19:42:17,014:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=False, optimize=f1, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-18 19:42:17,014:INFO:Checking exceptions
2025-05-18 19:42:17,018:INFO:Defining meta model
2025-05-18 19:42:17,025:INFO:Getting model names
2025-05-18 19:42:17,025:INFO:[('Light Gradient Boosting Machine', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)), ('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('Random Forest Classifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False))]
2025-05-18 19:42:17,026:INFO:SubProcess create_model() called ==================================
2025-05-18 19:42:17,029:INFO:Initializing create_model()
2025-05-18 19:42:17,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                       random_state=42,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356197f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:42:17,029:INFO:Checking exceptions
2025-05-18 19:42:17,029:INFO:Importing libraries
2025-05-18 19:42:17,029:INFO:Copying training dataset
2025-05-18 19:42:17,039:INFO:Defining folds
2025-05-18 19:42:17,039:INFO:Declaring metric variables
2025-05-18 19:42:17,040:INFO:Importing untrained model
2025-05-18 19:42:17,040:INFO:Declaring custom model
2025-05-18 19:42:17,042:INFO:Stacking Classifier Imported successfully
2025-05-18 19:42:17,044:INFO:Starting cross validation
2025-05-18 19:42:17,045:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:43:35,294:INFO:Calculating mean and std
2025-05-18 19:43:35,299:INFO:Creating metrics dataframe
2025-05-18 19:43:35,305:INFO:Finalizing model
2025-05-18 19:44:09,124:INFO:Uploading results into container
2025-05-18 19:44:09,127:INFO:Uploading model into container now
2025-05-18 19:44:09,128:INFO:_master_model_container: 18
2025-05-18 19:44:09,128:INFO:_display_container: 4
2025-05-18 19:44:09,131:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                       random_state=42,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2025-05-18 19:44:09,131:INFO:create_model() successfully completed......................................
2025-05-18 19:44:09,401:INFO:SubProcess create_model() end ==================================
2025-05-18 19:44:09,405:INFO:_master_model_container: 18
2025-05-18 19:44:09,405:INFO:_display_container: 4
2025-05-18 19:44:09,408:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                       random_state=42,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2025-05-18 19:44:09,408:INFO:stack_models() successfully completed......................................
2025-05-18 19:44:09,578:INFO:Initializing evaluate_model()
2025-05-18 19:44:09,578:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                       random_state=42,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-18 19:44:09,589:INFO:Initializing plot_model()
2025-05-18 19:44:09,589:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                       random_state=42,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-18 19:44:09,589:INFO:Checking exceptions
2025-05-18 19:44:09,595:INFO:Preloading libraries
2025-05-18 19:44:09,724:INFO:Copying training dataset
2025-05-18 19:44:09,724:INFO:Plot type: pipeline
2025-05-18 19:44:09,790:INFO:Visual Rendered Successfully
2025-05-18 19:44:09,963:INFO:plot_model() successfully completed......................................
2025-05-18 19:44:09,968:INFO:Initializing predict_model()
2025-05-18 19:44:09,968:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                       random_state=42,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x363ca2fc0>)
2025-05-18 19:44:09,968:INFO:Checking exceptions
2025-05-18 19:44:09,968:INFO:Preloading libraries
2025-05-18 19:44:09,970:INFO:Set up data.
2025-05-18 19:44:09,990:INFO:Set up index.
2025-05-18 19:44:10,758:INFO:Initializing plot_model()
2025-05-18 19:44:10,758:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                       random_state=42,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-18 19:44:10,758:INFO:Checking exceptions
2025-05-18 19:44:10,763:INFO:Preloading libraries
2025-05-18 19:44:10,828:INFO:Copying training dataset
2025-05-18 19:44:10,828:INFO:Plot type: confusion_matrix
2025-05-18 19:44:11,082:INFO:Fitting Model
2025-05-18 19:44:11,083:INFO:Scoring test/hold-out set
2025-05-18 19:44:11,315:INFO:Visual Rendered Successfully
2025-05-18 19:44:11,493:INFO:plot_model() successfully completed......................................
2025-05-18 19:44:11,497:INFO:Initializing plot_model()
2025-05-18 19:44:11,497:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                       random_state=42,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-18 19:44:11,497:INFO:Checking exceptions
2025-05-18 19:44:11,502:INFO:Preloading libraries
2025-05-18 19:44:11,558:INFO:Copying training dataset
2025-05-18 19:44:11,558:INFO:Plot type: auc
2025-05-18 19:44:11,784:INFO:Fitting Model
2025-05-18 19:44:11,786:INFO:Scoring test/hold-out set
2025-05-18 19:44:12,067:INFO:Visual Rendered Successfully
2025-05-18 19:44:12,241:INFO:plot_model() successfully completed......................................
2025-05-18 19:44:12,248:INFO:Initializing plot_model()
2025-05-18 19:44:12,248:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32f75f4d0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=42, reg_alpha=0.0,
                                               reg...
                                                       random_state=42,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-18 19:44:12,248:INFO:Checking exceptions
2025-05-18 19:46:51,145:INFO:PyCaret ClassificationExperiment
2025-05-18 19:46:51,145:INFO:Logging name: clf-default-name
2025-05-18 19:46:51,145:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-18 19:46:51,145:INFO:version 3.3.2
2025-05-18 19:46:51,145:INFO:Initializing setup()
2025-05-18 19:46:51,145:INFO:self.USI: 64c6
2025-05-18 19:46:51,145:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-18 19:46:51,145:INFO:Checking environment
2025-05-18 19:46:51,145:INFO:python_version: 3.11.0
2025-05-18 19:46:51,145:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-18 19:46:51,145:INFO:machine: arm64
2025-05-18 19:46:51,145:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-18 19:46:51,145:INFO:Memory: svmem(total=17179869184, available=3071082496, percent=82.1, used=5838848000, free=65421312, active=3028795392, inactive=2986229760, wired=2810052608)
2025-05-18 19:46:51,145:INFO:Physical Core: 12
2025-05-18 19:46:51,145:INFO:Logical Core: 12
2025-05-18 19:46:51,145:INFO:Checking libraries
2025-05-18 19:46:51,145:INFO:System:
2025-05-18 19:46:51,145:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-18 19:46:51,145:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-18 19:46:51,145:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-18 19:46:51,145:INFO:PyCaret required dependencies:
2025-05-18 19:46:51,145:INFO:                 pip: 22.3
2025-05-18 19:46:51,145:INFO:          setuptools: 65.5.0
2025-05-18 19:46:51,145:INFO:             pycaret: 3.3.2
2025-05-18 19:46:51,145:INFO:             IPython: 9.2.0
2025-05-18 19:46:51,145:INFO:          ipywidgets: 8.1.7
2025-05-18 19:46:51,145:INFO:                tqdm: 4.67.1
2025-05-18 19:46:51,145:INFO:               numpy: 1.26.4
2025-05-18 19:46:51,145:INFO:              pandas: 2.1.4
2025-05-18 19:46:51,145:INFO:              jinja2: 3.1.6
2025-05-18 19:46:51,145:INFO:               scipy: 1.11.4
2025-05-18 19:46:51,145:INFO:              joblib: 1.3.2
2025-05-18 19:46:51,145:INFO:             sklearn: 1.4.2
2025-05-18 19:46:51,145:INFO:                pyod: 2.0.5
2025-05-18 19:46:51,145:INFO:            imblearn: 0.13.0
2025-05-18 19:46:51,145:INFO:   category_encoders: 2.7.0
2025-05-18 19:46:51,145:INFO:            lightgbm: 4.6.0
2025-05-18 19:46:51,145:INFO:               numba: 0.61.2
2025-05-18 19:46:51,146:INFO:            requests: 2.32.3
2025-05-18 19:46:51,146:INFO:          matplotlib: 3.7.5
2025-05-18 19:46:51,146:INFO:          scikitplot: 0.3.7
2025-05-18 19:46:51,146:INFO:         yellowbrick: 1.5
2025-05-18 19:46:51,146:INFO:              plotly: 5.24.1
2025-05-18 19:46:51,146:INFO:    plotly-resampler: Not installed
2025-05-18 19:46:51,146:INFO:             kaleido: 0.2.1
2025-05-18 19:46:51,146:INFO:           schemdraw: 0.15
2025-05-18 19:46:51,146:INFO:         statsmodels: 0.14.4
2025-05-18 19:46:51,146:INFO:              sktime: 0.26.0
2025-05-18 19:46:51,146:INFO:               tbats: 1.1.3
2025-05-18 19:46:51,146:INFO:            pmdarima: 2.0.4
2025-05-18 19:46:51,146:INFO:              psutil: 7.0.0
2025-05-18 19:46:51,146:INFO:          markupsafe: 3.0.2
2025-05-18 19:46:51,146:INFO:             pickle5: Not installed
2025-05-18 19:46:51,146:INFO:         cloudpickle: 3.1.1
2025-05-18 19:46:51,146:INFO:         deprecation: 2.1.0
2025-05-18 19:46:51,146:INFO:              xxhash: 3.5.0
2025-05-18 19:46:51,146:INFO:           wurlitzer: 3.1.1
2025-05-18 19:46:51,146:INFO:PyCaret optional dependencies:
2025-05-18 19:46:51,146:INFO:                shap: 0.47.2
2025-05-18 19:46:51,146:INFO:           interpret: Not installed
2025-05-18 19:46:51,146:INFO:                umap: Not installed
2025-05-18 19:46:51,146:INFO:     ydata_profiling: Not installed
2025-05-18 19:46:51,146:INFO:  explainerdashboard: Not installed
2025-05-18 19:46:51,146:INFO:             autoviz: Not installed
2025-05-18 19:46:51,146:INFO:           fairlearn: Not installed
2025-05-18 19:46:51,146:INFO:          deepchecks: Not installed
2025-05-18 19:46:51,146:INFO:             xgboost: Not installed
2025-05-18 19:46:51,146:INFO:            catboost: 1.2.8
2025-05-18 19:46:51,146:INFO:              kmodes: Not installed
2025-05-18 19:46:51,146:INFO:             mlxtend: Not installed
2025-05-18 19:46:51,146:INFO:       statsforecast: Not installed
2025-05-18 19:46:51,146:INFO:        tune_sklearn: Not installed
2025-05-18 19:46:51,146:INFO:                 ray: Not installed
2025-05-18 19:46:51,146:INFO:            hyperopt: Not installed
2025-05-18 19:46:51,146:INFO:              optuna: 4.3.0
2025-05-18 19:46:51,146:INFO:               skopt: Not installed
2025-05-18 19:46:51,146:INFO:              mlflow: Not installed
2025-05-18 19:46:51,146:INFO:              gradio: Not installed
2025-05-18 19:46:51,146:INFO:             fastapi: Not installed
2025-05-18 19:46:51,146:INFO:             uvicorn: Not installed
2025-05-18 19:46:51,146:INFO:              m2cgen: Not installed
2025-05-18 19:46:51,146:INFO:           evidently: Not installed
2025-05-18 19:46:51,146:INFO:               fugue: Not installed
2025-05-18 19:46:51,146:INFO:           streamlit: Not installed
2025-05-18 19:46:51,146:INFO:             prophet: Not installed
2025-05-18 19:46:51,146:INFO:None
2025-05-18 19:46:51,146:INFO:Set up data.
2025-05-18 19:46:51,178:INFO:Set up folding strategy.
2025-05-18 19:46:51,178:INFO:Set up train/test split.
2025-05-18 19:46:51,194:INFO:Set up index.
2025-05-18 19:46:51,194:INFO:Assigning column types.
2025-05-18 19:46:51,198:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-18 19:46:51,216:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 19:46:51,216:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:46:51,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:46:51,227:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:46:51,247:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 19:46:51,247:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:46:51,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:46:51,258:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:46:51,258:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-18 19:46:51,276:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:46:51,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:46:51,287:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:46:51,304:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:46:51,315:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:46:51,315:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:46:51,315:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-18 19:46:51,345:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:46:51,345:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:46:51,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:46:51,375:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:46:51,376:INFO:Preparing preprocessing pipeline...
2025-05-18 19:46:51,377:INFO:Set up simple imputation.
2025-05-18 19:46:51,387:INFO:Set up encoding of ordinal features.
2025-05-18 19:46:51,397:INFO:Set up encoding of categorical features.
2025-05-18 19:46:51,397:INFO:Set up imbalanced handling.
2025-05-18 19:46:51,397:INFO:Set up column transformation.
2025-05-18 19:46:51,689:INFO:Finished creating preprocessing pipeline.
2025-05-18 19:46:51,709:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-18 19:46:51,709:INFO:Creating final display dataframe.
2025-05-18 19:46:51,938:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              64c6
2025-05-18 19:46:51,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:46:51,972:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:46:52,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:46:52,003:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:46:52,004:INFO:setup() successfully completed in 0.86s...............
2025-05-18 19:46:52,004:INFO:Initializing compare_models()
2025-05-18 19:46:52,005:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-18 19:46:52,005:INFO:Checking exceptions
2025-05-18 19:46:52,010:INFO:Preparing display monitor
2025-05-18 19:46:52,018:INFO:Initializing Logistic Regression
2025-05-18 19:46:52,018:INFO:Total runtime is 1.4861424763997396e-06 minutes
2025-05-18 19:46:52,020:INFO:SubProcess create_model() called ==================================
2025-05-18 19:46:52,020:INFO:Initializing create_model()
2025-05-18 19:46:52,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:46:52,020:INFO:Checking exceptions
2025-05-18 19:46:52,020:INFO:Importing libraries
2025-05-18 19:46:52,020:INFO:Copying training dataset
2025-05-18 19:46:52,031:INFO:Defining folds
2025-05-18 19:46:52,031:INFO:Declaring metric variables
2025-05-18 19:46:52,033:INFO:Importing untrained model
2025-05-18 19:46:52,034:INFO:Logistic Regression Imported successfully
2025-05-18 19:46:52,037:INFO:Starting cross validation
2025-05-18 19:46:52,038:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:46:55,899:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:46:55,939:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:46:56,005:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:46:56,665:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:46:56,843:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:46:56,907:INFO:Calculating mean and std
2025-05-18 19:46:56,909:INFO:Creating metrics dataframe
2025-05-18 19:46:56,911:INFO:Uploading results into container
2025-05-18 19:46:56,912:INFO:Uploading model into container now
2025-05-18 19:46:56,912:INFO:_master_model_container: 1
2025-05-18 19:46:56,912:INFO:_display_container: 2
2025-05-18 19:46:56,912:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-18 19:46:56,912:INFO:create_model() successfully completed......................................
2025-05-18 19:46:57,154:INFO:SubProcess create_model() end ==================================
2025-05-18 19:46:57,154:INFO:Creating metrics dataframe
2025-05-18 19:46:57,157:INFO:Initializing K Neighbors Classifier
2025-05-18 19:46:57,157:INFO:Total runtime is 0.08564931948979695 minutes
2025-05-18 19:46:57,158:INFO:SubProcess create_model() called ==================================
2025-05-18 19:46:57,159:INFO:Initializing create_model()
2025-05-18 19:46:57,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:46:57,159:INFO:Checking exceptions
2025-05-18 19:46:57,159:INFO:Importing libraries
2025-05-18 19:46:57,159:INFO:Copying training dataset
2025-05-18 19:46:57,173:INFO:Defining folds
2025-05-18 19:46:57,173:INFO:Declaring metric variables
2025-05-18 19:46:57,174:INFO:Importing untrained model
2025-05-18 19:46:57,175:INFO:K Neighbors Classifier Imported successfully
2025-05-18 19:46:57,178:INFO:Starting cross validation
2025-05-18 19:46:57,179:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:47:03,601:INFO:Calculating mean and std
2025-05-18 19:47:03,606:INFO:Creating metrics dataframe
2025-05-18 19:47:03,612:INFO:Uploading results into container
2025-05-18 19:47:03,613:INFO:Uploading model into container now
2025-05-18 19:47:03,615:INFO:_master_model_container: 2
2025-05-18 19:47:03,615:INFO:_display_container: 2
2025-05-18 19:47:03,617:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-18 19:47:03,617:INFO:create_model() successfully completed......................................
2025-05-18 19:47:03,918:INFO:SubProcess create_model() end ==================================
2025-05-18 19:47:03,918:INFO:Creating metrics dataframe
2025-05-18 19:47:03,922:INFO:Initializing Naive Bayes
2025-05-18 19:47:03,922:INFO:Total runtime is 0.19839311838150026 minutes
2025-05-18 19:47:03,923:INFO:SubProcess create_model() called ==================================
2025-05-18 19:47:03,923:INFO:Initializing create_model()
2025-05-18 19:47:03,923:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:47:03,923:INFO:Checking exceptions
2025-05-18 19:47:03,923:INFO:Importing libraries
2025-05-18 19:47:03,924:INFO:Copying training dataset
2025-05-18 19:47:03,945:INFO:Defining folds
2025-05-18 19:47:03,946:INFO:Declaring metric variables
2025-05-18 19:47:03,947:INFO:Importing untrained model
2025-05-18 19:47:03,948:INFO:Naive Bayes Imported successfully
2025-05-18 19:47:03,951:INFO:Starting cross validation
2025-05-18 19:47:03,952:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:47:06,466:INFO:Calculating mean and std
2025-05-18 19:47:06,468:INFO:Creating metrics dataframe
2025-05-18 19:47:06,469:INFO:Uploading results into container
2025-05-18 19:47:06,470:INFO:Uploading model into container now
2025-05-18 19:47:06,470:INFO:_master_model_container: 3
2025-05-18 19:47:06,470:INFO:_display_container: 2
2025-05-18 19:47:06,471:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-18 19:47:06,471:INFO:create_model() successfully completed......................................
2025-05-18 19:47:06,641:INFO:SubProcess create_model() end ==================================
2025-05-18 19:47:06,641:INFO:Creating metrics dataframe
2025-05-18 19:47:06,645:INFO:Initializing Decision Tree Classifier
2025-05-18 19:47:06,645:INFO:Total runtime is 0.24377841949462892 minutes
2025-05-18 19:47:06,646:INFO:SubProcess create_model() called ==================================
2025-05-18 19:47:06,646:INFO:Initializing create_model()
2025-05-18 19:47:06,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:47:06,647:INFO:Checking exceptions
2025-05-18 19:47:06,647:INFO:Importing libraries
2025-05-18 19:47:06,647:INFO:Copying training dataset
2025-05-18 19:47:06,660:INFO:Defining folds
2025-05-18 19:47:06,660:INFO:Declaring metric variables
2025-05-18 19:47:06,662:INFO:Importing untrained model
2025-05-18 19:47:06,663:INFO:Decision Tree Classifier Imported successfully
2025-05-18 19:47:06,666:INFO:Starting cross validation
2025-05-18 19:47:06,667:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:47:09,691:INFO:Calculating mean and std
2025-05-18 19:47:09,692:INFO:Creating metrics dataframe
2025-05-18 19:47:09,693:INFO:Uploading results into container
2025-05-18 19:47:09,694:INFO:Uploading model into container now
2025-05-18 19:47:09,694:INFO:_master_model_container: 4
2025-05-18 19:47:09,694:INFO:_display_container: 2
2025-05-18 19:47:09,694:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-18 19:47:09,694:INFO:create_model() successfully completed......................................
2025-05-18 19:47:09,939:INFO:SubProcess create_model() end ==================================
2025-05-18 19:47:09,939:INFO:Creating metrics dataframe
2025-05-18 19:47:09,943:INFO:Initializing SVM - Linear Kernel
2025-05-18 19:47:09,943:INFO:Total runtime is 0.2987401525179545 minutes
2025-05-18 19:47:09,944:INFO:SubProcess create_model() called ==================================
2025-05-18 19:47:09,944:INFO:Initializing create_model()
2025-05-18 19:47:09,944:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:47:09,944:INFO:Checking exceptions
2025-05-18 19:47:09,944:INFO:Importing libraries
2025-05-18 19:47:09,944:INFO:Copying training dataset
2025-05-18 19:47:09,955:INFO:Defining folds
2025-05-18 19:47:09,955:INFO:Declaring metric variables
2025-05-18 19:47:09,957:INFO:Importing untrained model
2025-05-18 19:47:09,958:INFO:SVM - Linear Kernel Imported successfully
2025-05-18 19:47:09,960:INFO:Starting cross validation
2025-05-18 19:47:09,961:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:47:13,443:INFO:Calculating mean and std
2025-05-18 19:47:13,443:INFO:Creating metrics dataframe
2025-05-18 19:47:13,444:INFO:Uploading results into container
2025-05-18 19:47:13,444:INFO:Uploading model into container now
2025-05-18 19:47:13,445:INFO:_master_model_container: 5
2025-05-18 19:47:13,445:INFO:_display_container: 2
2025-05-18 19:47:13,445:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-18 19:47:13,445:INFO:create_model() successfully completed......................................
2025-05-18 19:47:13,589:INFO:SubProcess create_model() end ==================================
2025-05-18 19:47:13,589:INFO:Creating metrics dataframe
2025-05-18 19:47:13,593:INFO:Initializing Ridge Classifier
2025-05-18 19:47:13,593:INFO:Total runtime is 0.35957336823145547 minutes
2025-05-18 19:47:13,594:INFO:SubProcess create_model() called ==================================
2025-05-18 19:47:13,594:INFO:Initializing create_model()
2025-05-18 19:47:13,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:47:13,594:INFO:Checking exceptions
2025-05-18 19:47:13,594:INFO:Importing libraries
2025-05-18 19:47:13,594:INFO:Copying training dataset
2025-05-18 19:47:13,603:INFO:Defining folds
2025-05-18 19:47:13,603:INFO:Declaring metric variables
2025-05-18 19:47:13,604:INFO:Importing untrained model
2025-05-18 19:47:13,606:INFO:Ridge Classifier Imported successfully
2025-05-18 19:47:13,607:INFO:Starting cross validation
2025-05-18 19:47:13,608:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:47:14,754:INFO:Calculating mean and std
2025-05-18 19:47:14,759:INFO:Creating metrics dataframe
2025-05-18 19:47:14,765:INFO:Uploading results into container
2025-05-18 19:47:14,765:INFO:Uploading model into container now
2025-05-18 19:47:14,766:INFO:_master_model_container: 6
2025-05-18 19:47:14,766:INFO:_display_container: 2
2025-05-18 19:47:14,766:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-18 19:47:14,766:INFO:create_model() successfully completed......................................
2025-05-18 19:47:14,948:INFO:SubProcess create_model() end ==================================
2025-05-18 19:47:14,948:INFO:Creating metrics dataframe
2025-05-18 19:47:14,951:INFO:Initializing Random Forest Classifier
2025-05-18 19:47:14,951:INFO:Total runtime is 0.38222186962763466 minutes
2025-05-18 19:47:14,953:INFO:SubProcess create_model() called ==================================
2025-05-18 19:47:14,953:INFO:Initializing create_model()
2025-05-18 19:47:14,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:47:14,953:INFO:Checking exceptions
2025-05-18 19:47:14,953:INFO:Importing libraries
2025-05-18 19:47:14,953:INFO:Copying training dataset
2025-05-18 19:47:14,962:INFO:Defining folds
2025-05-18 19:47:14,962:INFO:Declaring metric variables
2025-05-18 19:47:14,963:INFO:Importing untrained model
2025-05-18 19:47:14,964:INFO:Random Forest Classifier Imported successfully
2025-05-18 19:47:14,966:INFO:Starting cross validation
2025-05-18 19:47:14,967:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:47:21,029:INFO:Calculating mean and std
2025-05-18 19:47:21,030:INFO:Creating metrics dataframe
2025-05-18 19:47:21,032:INFO:Uploading results into container
2025-05-18 19:47:21,032:INFO:Uploading model into container now
2025-05-18 19:47:21,032:INFO:_master_model_container: 7
2025-05-18 19:47:21,032:INFO:_display_container: 2
2025-05-18 19:47:21,032:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-18 19:47:21,033:INFO:create_model() successfully completed......................................
2025-05-18 19:47:21,282:INFO:SubProcess create_model() end ==================================
2025-05-18 19:47:21,282:INFO:Creating metrics dataframe
2025-05-18 19:47:21,285:INFO:Initializing Quadratic Discriminant Analysis
2025-05-18 19:47:21,286:INFO:Total runtime is 0.48778978586196897 minutes
2025-05-18 19:47:21,287:INFO:SubProcess create_model() called ==================================
2025-05-18 19:47:21,287:INFO:Initializing create_model()
2025-05-18 19:47:21,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:47:21,287:INFO:Checking exceptions
2025-05-18 19:47:21,287:INFO:Importing libraries
2025-05-18 19:47:21,287:INFO:Copying training dataset
2025-05-18 19:47:21,299:INFO:Defining folds
2025-05-18 19:47:21,299:INFO:Declaring metric variables
2025-05-18 19:47:21,300:INFO:Importing untrained model
2025-05-18 19:47:21,301:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 19:47:21,303:INFO:Starting cross validation
2025-05-18 19:47:21,304:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:47:22,373:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:47:22,377:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:47:22,428:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:47:22,450:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:47:22,456:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:47:22,459:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:47:22,488:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:47:22,506:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:47:22,525:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:47:22,558:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:47:22,571:INFO:Calculating mean and std
2025-05-18 19:47:22,571:INFO:Creating metrics dataframe
2025-05-18 19:47:22,572:INFO:Uploading results into container
2025-05-18 19:47:22,573:INFO:Uploading model into container now
2025-05-18 19:47:22,573:INFO:_master_model_container: 8
2025-05-18 19:47:22,573:INFO:_display_container: 2
2025-05-18 19:47:22,573:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 19:47:22,573:INFO:create_model() successfully completed......................................
2025-05-18 19:47:22,720:INFO:SubProcess create_model() end ==================================
2025-05-18 19:47:22,720:INFO:Creating metrics dataframe
2025-05-18 19:47:22,724:INFO:Initializing Ada Boost Classifier
2025-05-18 19:47:22,724:INFO:Total runtime is 0.5117635051409404 minutes
2025-05-18 19:47:22,725:INFO:SubProcess create_model() called ==================================
2025-05-18 19:47:22,725:INFO:Initializing create_model()
2025-05-18 19:47:22,725:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:47:22,725:INFO:Checking exceptions
2025-05-18 19:47:22,725:INFO:Importing libraries
2025-05-18 19:47:22,725:INFO:Copying training dataset
2025-05-18 19:47:22,736:INFO:Defining folds
2025-05-18 19:47:22,736:INFO:Declaring metric variables
2025-05-18 19:47:22,737:INFO:Importing untrained model
2025-05-18 19:47:22,738:INFO:Ada Boost Classifier Imported successfully
2025-05-18 19:47:22,740:INFO:Starting cross validation
2025-05-18 19:47:22,741:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:47:23,752:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:47:23,763:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:47:23,792:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:47:23,807:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:47:23,847:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:47:26,619:INFO:Calculating mean and std
2025-05-18 19:47:26,620:INFO:Creating metrics dataframe
2025-05-18 19:47:26,621:INFO:Uploading results into container
2025-05-18 19:47:26,621:INFO:Uploading model into container now
2025-05-18 19:47:26,621:INFO:_master_model_container: 9
2025-05-18 19:47:26,621:INFO:_display_container: 2
2025-05-18 19:47:26,622:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-18 19:47:26,622:INFO:create_model() successfully completed......................................
2025-05-18 19:47:26,781:INFO:SubProcess create_model() end ==================================
2025-05-18 19:47:26,781:INFO:Creating metrics dataframe
2025-05-18 19:47:26,785:INFO:Initializing Gradient Boosting Classifier
2025-05-18 19:47:26,785:INFO:Total runtime is 0.5794462362925212 minutes
2025-05-18 19:47:26,786:INFO:SubProcess create_model() called ==================================
2025-05-18 19:47:26,786:INFO:Initializing create_model()
2025-05-18 19:47:26,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:47:26,786:INFO:Checking exceptions
2025-05-18 19:47:26,787:INFO:Importing libraries
2025-05-18 19:47:26,787:INFO:Copying training dataset
2025-05-18 19:47:26,796:INFO:Defining folds
2025-05-18 19:47:26,796:INFO:Declaring metric variables
2025-05-18 19:47:26,797:INFO:Importing untrained model
2025-05-18 19:47:26,799:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 19:47:26,801:INFO:Starting cross validation
2025-05-18 19:47:26,802:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:47:40,535:INFO:Calculating mean and std
2025-05-18 19:47:40,538:INFO:Creating metrics dataframe
2025-05-18 19:47:40,541:INFO:Uploading results into container
2025-05-18 19:47:40,542:INFO:Uploading model into container now
2025-05-18 19:47:40,543:INFO:_master_model_container: 10
2025-05-18 19:47:40,543:INFO:_display_container: 2
2025-05-18 19:47:40,543:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 19:47:40,543:INFO:create_model() successfully completed......................................
2025-05-18 19:47:40,772:INFO:SubProcess create_model() end ==================================
2025-05-18 19:47:40,772:INFO:Creating metrics dataframe
2025-05-18 19:47:40,776:INFO:Initializing Linear Discriminant Analysis
2025-05-18 19:47:40,777:INFO:Total runtime is 0.8126397848129273 minutes
2025-05-18 19:47:40,778:INFO:SubProcess create_model() called ==================================
2025-05-18 19:47:40,778:INFO:Initializing create_model()
2025-05-18 19:47:40,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:47:40,778:INFO:Checking exceptions
2025-05-18 19:47:40,778:INFO:Importing libraries
2025-05-18 19:47:40,778:INFO:Copying training dataset
2025-05-18 19:47:40,790:INFO:Defining folds
2025-05-18 19:47:40,790:INFO:Declaring metric variables
2025-05-18 19:47:40,791:INFO:Importing untrained model
2025-05-18 19:47:40,792:INFO:Linear Discriminant Analysis Imported successfully
2025-05-18 19:47:40,794:INFO:Starting cross validation
2025-05-18 19:47:40,795:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:47:42,045:INFO:Calculating mean and std
2025-05-18 19:47:42,046:INFO:Creating metrics dataframe
2025-05-18 19:47:42,047:INFO:Uploading results into container
2025-05-18 19:47:42,047:INFO:Uploading model into container now
2025-05-18 19:47:42,047:INFO:_master_model_container: 11
2025-05-18 19:47:42,047:INFO:_display_container: 2
2025-05-18 19:47:42,048:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-18 19:47:42,048:INFO:create_model() successfully completed......................................
2025-05-18 19:47:42,196:INFO:SubProcess create_model() end ==================================
2025-05-18 19:47:42,196:INFO:Creating metrics dataframe
2025-05-18 19:47:42,200:INFO:Initializing Extra Trees Classifier
2025-05-18 19:47:42,200:INFO:Total runtime is 0.8363690853118897 minutes
2025-05-18 19:47:42,202:INFO:SubProcess create_model() called ==================================
2025-05-18 19:47:42,202:INFO:Initializing create_model()
2025-05-18 19:47:42,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:47:42,202:INFO:Checking exceptions
2025-05-18 19:47:42,202:INFO:Importing libraries
2025-05-18 19:47:42,202:INFO:Copying training dataset
2025-05-18 19:47:42,212:INFO:Defining folds
2025-05-18 19:47:42,212:INFO:Declaring metric variables
2025-05-18 19:47:42,214:INFO:Importing untrained model
2025-05-18 19:47:42,215:INFO:Extra Trees Classifier Imported successfully
2025-05-18 19:47:42,217:INFO:Starting cross validation
2025-05-18 19:47:42,218:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:47:46,709:INFO:Calculating mean and std
2025-05-18 19:47:46,712:INFO:Creating metrics dataframe
2025-05-18 19:47:46,717:INFO:Uploading results into container
2025-05-18 19:47:46,717:INFO:Uploading model into container now
2025-05-18 19:47:46,719:INFO:_master_model_container: 12
2025-05-18 19:47:46,719:INFO:_display_container: 2
2025-05-18 19:47:46,720:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-18 19:47:46,720:INFO:create_model() successfully completed......................................
2025-05-18 19:47:47,014:INFO:SubProcess create_model() end ==================================
2025-05-18 19:47:47,014:INFO:Creating metrics dataframe
2025-05-18 19:47:47,018:INFO:Initializing Light Gradient Boosting Machine
2025-05-18 19:47:47,018:INFO:Total runtime is 0.9166685183842977 minutes
2025-05-18 19:47:47,020:INFO:SubProcess create_model() called ==================================
2025-05-18 19:47:47,020:INFO:Initializing create_model()
2025-05-18 19:47:47,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:47:47,020:INFO:Checking exceptions
2025-05-18 19:47:47,020:INFO:Importing libraries
2025-05-18 19:47:47,020:INFO:Copying training dataset
2025-05-18 19:47:47,031:INFO:Defining folds
2025-05-18 19:47:47,031:INFO:Declaring metric variables
2025-05-18 19:47:47,032:INFO:Importing untrained model
2025-05-18 19:47:47,033:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 19:47:47,036:INFO:Starting cross validation
2025-05-18 19:47:47,037:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:47:51,258:INFO:Calculating mean and std
2025-05-18 19:47:51,259:INFO:Creating metrics dataframe
2025-05-18 19:47:51,259:INFO:Uploading results into container
2025-05-18 19:47:51,260:INFO:Uploading model into container now
2025-05-18 19:47:51,260:INFO:_master_model_container: 13
2025-05-18 19:47:51,260:INFO:_display_container: 2
2025-05-18 19:47:51,260:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:47:51,260:INFO:create_model() successfully completed......................................
2025-05-18 19:47:51,414:INFO:SubProcess create_model() end ==================================
2025-05-18 19:47:51,414:INFO:Creating metrics dataframe
2025-05-18 19:47:51,419:INFO:Initializing CatBoost Classifier
2025-05-18 19:47:51,419:INFO:Total runtime is 0.9900123039881389 minutes
2025-05-18 19:47:51,420:INFO:SubProcess create_model() called ==================================
2025-05-18 19:47:51,420:INFO:Initializing create_model()
2025-05-18 19:47:51,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:47:51,420:INFO:Checking exceptions
2025-05-18 19:47:51,420:INFO:Importing libraries
2025-05-18 19:47:51,420:INFO:Copying training dataset
2025-05-18 19:47:51,430:INFO:Defining folds
2025-05-18 19:47:51,430:INFO:Declaring metric variables
2025-05-18 19:47:51,431:INFO:Importing untrained model
2025-05-18 19:47:51,433:INFO:CatBoost Classifier Imported successfully
2025-05-18 19:47:51,435:INFO:Starting cross validation
2025-05-18 19:47:51,435:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:48:08,304:INFO:Calculating mean and std
2025-05-18 19:48:08,308:INFO:Creating metrics dataframe
2025-05-18 19:48:08,311:INFO:Uploading results into container
2025-05-18 19:48:08,311:INFO:Uploading model into container now
2025-05-18 19:48:08,312:INFO:_master_model_container: 14
2025-05-18 19:48:08,313:INFO:_display_container: 2
2025-05-18 19:48:08,313:INFO:<catboost.core.CatBoostClassifier object at 0x36454bed0>
2025-05-18 19:48:08,313:INFO:create_model() successfully completed......................................
2025-05-18 19:48:08,666:INFO:SubProcess create_model() end ==================================
2025-05-18 19:48:08,666:INFO:Creating metrics dataframe
2025-05-18 19:48:08,672:INFO:Initializing Dummy Classifier
2025-05-18 19:48:08,672:INFO:Total runtime is 1.2775667866071065 minutes
2025-05-18 19:48:08,674:INFO:SubProcess create_model() called ==================================
2025-05-18 19:48:08,674:INFO:Initializing create_model()
2025-05-18 19:48:08,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3562be890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:48:08,674:INFO:Checking exceptions
2025-05-18 19:48:08,674:INFO:Importing libraries
2025-05-18 19:48:08,674:INFO:Copying training dataset
2025-05-18 19:48:08,689:INFO:Defining folds
2025-05-18 19:48:08,690:INFO:Declaring metric variables
2025-05-18 19:48:08,691:INFO:Importing untrained model
2025-05-18 19:48:08,693:INFO:Dummy Classifier Imported successfully
2025-05-18 19:48:08,695:INFO:Starting cross validation
2025-05-18 19:48:08,697:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:48:09,932:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:48:09,944:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:48:09,997:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:48:10,028:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:48:10,086:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:48:10,093:INFO:Calculating mean and std
2025-05-18 19:48:10,093:INFO:Creating metrics dataframe
2025-05-18 19:48:10,094:INFO:Uploading results into container
2025-05-18 19:48:10,094:INFO:Uploading model into container now
2025-05-18 19:48:10,095:INFO:_master_model_container: 15
2025-05-18 19:48:10,095:INFO:_display_container: 2
2025-05-18 19:48:10,095:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-18 19:48:10,095:INFO:create_model() successfully completed......................................
2025-05-18 19:48:10,250:INFO:SubProcess create_model() end ==================================
2025-05-18 19:48:10,251:INFO:Creating metrics dataframe
2025-05-18 19:48:10,255:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-18 19:48:10,259:INFO:Initializing create_model()
2025-05-18 19:48:10,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:48:10,259:INFO:Checking exceptions
2025-05-18 19:48:10,260:INFO:Importing libraries
2025-05-18 19:48:10,260:INFO:Copying training dataset
2025-05-18 19:48:10,270:INFO:Defining folds
2025-05-18 19:48:10,270:INFO:Declaring metric variables
2025-05-18 19:48:10,270:INFO:Importing untrained model
2025-05-18 19:48:10,270:INFO:Declaring custom model
2025-05-18 19:48:10,271:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 19:48:10,272:INFO:Cross validation set to False
2025-05-18 19:48:10,272:INFO:Fitting Model
2025-05-18 19:48:11,610:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 19:48:11,619:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004036 seconds.
2025-05-18 19:48:11,619:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 19:48:11,619:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 19:48:11,619:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 19:48:11,620:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 19:48:11,620:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 19:48:12,701:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:48:12,701:INFO:create_model() successfully completed......................................
2025-05-18 19:48:12,876:INFO:Initializing create_model()
2025-05-18 19:48:12,876:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:48:12,876:INFO:Checking exceptions
2025-05-18 19:48:12,876:INFO:Importing libraries
2025-05-18 19:48:12,877:INFO:Copying training dataset
2025-05-18 19:48:12,886:INFO:Defining folds
2025-05-18 19:48:12,886:INFO:Declaring metric variables
2025-05-18 19:48:12,886:INFO:Importing untrained model
2025-05-18 19:48:12,886:INFO:Declaring custom model
2025-05-18 19:48:12,886:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 19:48:12,887:INFO:Cross validation set to False
2025-05-18 19:48:12,887:INFO:Fitting Model
2025-05-18 19:48:28,868:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 19:48:28,868:INFO:create_model() successfully completed......................................
2025-05-18 19:48:29,047:INFO:Initializing create_model()
2025-05-18 19:48:29,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:48:29,047:INFO:Checking exceptions
2025-05-18 19:48:29,048:INFO:Importing libraries
2025-05-18 19:48:29,048:INFO:Copying training dataset
2025-05-18 19:48:29,057:INFO:Defining folds
2025-05-18 19:48:29,057:INFO:Declaring metric variables
2025-05-18 19:48:29,057:INFO:Importing untrained model
2025-05-18 19:48:29,057:INFO:Declaring custom model
2025-05-18 19:48:29,057:INFO:Random Forest Classifier Imported successfully
2025-05-18 19:48:29,058:INFO:Cross validation set to False
2025-05-18 19:48:29,058:INFO:Fitting Model
2025-05-18 19:48:31,368:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-18 19:48:31,368:INFO:create_model() successfully completed......................................
2025-05-18 19:48:31,545:INFO:_master_model_container: 15
2025-05-18 19:48:31,545:INFO:_display_container: 2
2025-05-18 19:48:31,546:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-18 19:48:31,546:INFO:compare_models() successfully completed......................................
2025-05-18 19:48:31,566:INFO:Initializing evaluate_model()
2025-05-18 19:48:31,566:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-18 19:48:31,573:INFO:Initializing plot_model()
2025-05-18 19:48:31,574:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-18 19:48:31,574:INFO:Checking exceptions
2025-05-18 19:48:31,579:INFO:Preloading libraries
2025-05-18 19:48:31,583:INFO:Copying training dataset
2025-05-18 19:48:31,583:INFO:Plot type: pipeline
2025-05-18 19:48:31,648:INFO:Visual Rendered Successfully
2025-05-18 19:48:31,814:INFO:plot_model() successfully completed......................................
2025-05-18 19:48:31,816:INFO:Initializing tune_model()
2025-05-18 19:48:31,816:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-18 19:48:31,816:INFO:Checking exceptions
2025-05-18 19:48:31,826:INFO:Copying training dataset
2025-05-18 19:48:31,833:INFO:Checking base model
2025-05-18 19:48:31,833:INFO:Base model : Light Gradient Boosting Machine
2025-05-18 19:48:31,834:INFO:Declaring metric variables
2025-05-18 19:48:31,836:INFO:Defining Hyperparameters
2025-05-18 19:48:31,991:INFO:Tuning with n_jobs=-1
2025-05-18 19:48:31,991:INFO:Initializing RandomizedSearchCV
2025-05-18 19:49:09,712:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-18 19:49:09,716:INFO:Hyperparameter search completed
2025-05-18 19:49:09,718:INFO:SubProcess create_model() called ==================================
2025-05-18 19:49:09,719:INFO:Initializing create_model()
2025-05-18 19:49:09,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373c9bed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-18 19:49:09,719:INFO:Checking exceptions
2025-05-18 19:49:09,719:INFO:Importing libraries
2025-05-18 19:49:09,719:INFO:Copying training dataset
2025-05-18 19:49:09,734:INFO:Defining folds
2025-05-18 19:49:09,734:INFO:Declaring metric variables
2025-05-18 19:49:09,737:INFO:Importing untrained model
2025-05-18 19:49:09,737:INFO:Declaring custom model
2025-05-18 19:49:09,739:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 19:49:09,741:INFO:Starting cross validation
2025-05-18 19:49:09,743:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:49:16,158:INFO:Calculating mean and std
2025-05-18 19:49:16,159:INFO:Creating metrics dataframe
2025-05-18 19:49:16,162:INFO:Finalizing model
2025-05-18 19:49:17,237:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-18 19:49:17,237:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-18 19:49:17,237:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-18 19:49:17,275:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-18 19:49:17,275:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-18 19:49:17,275:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-18 19:49:17,275:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 19:49:17,285:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005342 seconds.
2025-05-18 19:49:17,285:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 19:49:17,285:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 19:49:17,285:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 19:49:17,286:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 19:49:17,286:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 19:49:19,355:INFO:Uploading results into container
2025-05-18 19:49:19,355:INFO:Uploading model into container now
2025-05-18 19:49:19,356:INFO:_master_model_container: 16
2025-05-18 19:49:19,356:INFO:_display_container: 3
2025-05-18 19:49:19,356:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:49:19,356:INFO:create_model() successfully completed......................................
2025-05-18 19:49:19,583:INFO:SubProcess create_model() end ==================================
2025-05-18 19:49:19,584:INFO:choose_better activated
2025-05-18 19:49:19,585:INFO:SubProcess create_model() called ==================================
2025-05-18 19:49:19,586:INFO:Initializing create_model()
2025-05-18 19:49:19,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:49:19,586:INFO:Checking exceptions
2025-05-18 19:49:19,587:INFO:Importing libraries
2025-05-18 19:49:19,587:INFO:Copying training dataset
2025-05-18 19:49:19,596:INFO:Defining folds
2025-05-18 19:49:19,596:INFO:Declaring metric variables
2025-05-18 19:49:19,596:INFO:Importing untrained model
2025-05-18 19:49:19,596:INFO:Declaring custom model
2025-05-18 19:49:19,596:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 19:49:19,597:INFO:Starting cross validation
2025-05-18 19:49:19,597:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:49:23,764:INFO:Calculating mean and std
2025-05-18 19:49:23,766:INFO:Creating metrics dataframe
2025-05-18 19:49:23,767:INFO:Finalizing model
2025-05-18 19:49:24,790:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 19:49:24,800:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004878 seconds.
2025-05-18 19:49:24,800:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 19:49:24,800:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 19:49:24,800:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 19:49:24,800:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 19:49:24,800:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 19:49:25,864:INFO:Uploading results into container
2025-05-18 19:49:25,864:INFO:Uploading model into container now
2025-05-18 19:49:25,865:INFO:_master_model_container: 17
2025-05-18 19:49:25,865:INFO:_display_container: 4
2025-05-18 19:49:25,865:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:49:25,865:INFO:create_model() successfully completed......................................
2025-05-18 19:49:26,023:INFO:SubProcess create_model() end ==================================
2025-05-18 19:49:26,023:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-18 19:49:26,024:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-18 19:49:26,024:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-18 19:49:26,024:INFO:choose_better completed
2025-05-18 19:49:26,028:INFO:_master_model_container: 17
2025-05-18 19:49:26,028:INFO:_display_container: 3
2025-05-18 19:49:26,028:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:49:26,028:INFO:tune_model() successfully completed......................................
2025-05-18 19:49:26,173:INFO:Initializing evaluate_model()
2025-05-18 19:49:26,173:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-18 19:49:26,181:INFO:Initializing plot_model()
2025-05-18 19:49:26,181:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-18 19:49:26,181:INFO:Checking exceptions
2025-05-18 19:49:26,185:INFO:Preloading libraries
2025-05-18 19:49:26,188:INFO:Copying training dataset
2025-05-18 19:49:26,188:INFO:Plot type: pipeline
2025-05-18 19:49:26,243:INFO:Visual Rendered Successfully
2025-05-18 19:49:26,395:INFO:plot_model() successfully completed......................................
2025-05-18 19:49:26,397:INFO:Initializing interpret_model()
2025-05-18 19:49:26,397:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-18 19:49:26,397:INFO:Checking exceptions
2025-05-18 19:49:26,397:INFO:Soft dependency imported: shap: 0.47.2
2025-05-18 19:49:26,476:INFO:plot type: summary
2025-05-18 19:49:26,477:INFO:Creating TreeExplainer
2025-05-18 19:49:26,552:INFO:Compiling shap values
2025-05-18 19:49:27,752:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray
  warnings.warn(

2025-05-18 19:49:27,753:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap_plot = shap.summary_plot(shap_values, test_X, show=show, **kwargs)

2025-05-18 19:49:29,009:INFO:Visual Rendered Successfully
2025-05-18 19:49:29,009:INFO:interpret_model() successfully completed......................................
2025-05-18 19:49:29,159:INFO:Initializing finalize_model()
2025-05-18 19:49:29,159:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-18 19:49:29,160:INFO:Finalizing LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:49:29,163:INFO:Initializing create_model()
2025-05-18 19:49:29,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:49:29,163:INFO:Checking exceptions
2025-05-18 19:49:29,164:INFO:Importing libraries
2025-05-18 19:49:29,164:INFO:Copying training dataset
2025-05-18 19:49:29,164:INFO:Defining folds
2025-05-18 19:49:29,164:INFO:Declaring metric variables
2025-05-18 19:49:29,164:INFO:Importing untrained model
2025-05-18 19:49:29,165:INFO:Declaring custom model
2025-05-18 19:49:29,165:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 19:49:29,166:INFO:Cross validation set to False
2025-05-18 19:49:29,166:INFO:Fitting Model
2025-05-18 19:49:30,540:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-18 19:49:30,540:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-18 19:49:30,540:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-18 19:49:30,583:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-18 19:49:30,583:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-18 19:49:30,583:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-18 19:49:30,584:INFO:[LightGBM] [Info] Number of positive: 61360, number of negative: 61360
2025-05-18 19:49:30,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006138 seconds.
2025-05-18 19:49:30,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 19:49:30,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 19:49:30,597:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 19:49:30,597:INFO:[LightGBM] [Info] Number of data points in the train set: 122720, number of used features: 28
2025-05-18 19:49:30,597:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 19:49:32,709:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-18 19:49:32,709:INFO:create_model() successfully completed......................................
2025-05-18 19:49:32,867:INFO:_master_model_container: 17
2025-05-18 19:49:32,867:INFO:_display_container: 3
2025-05-18 19:49:32,889:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-18 19:49:32,889:INFO:finalize_model() successfully completed......................................
2025-05-18 19:49:33,084:INFO:Initializing save_model()
2025-05-18 19:49:33,084:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-18 19:49:33,084:INFO:Adding model into prep_pipe
2025-05-18 19:49:33,084:WARNING:Only Model saved as it was a pipeline.
2025-05-18 19:49:33,091:INFO:final_cancer_model.pkl saved in current working directory
2025-05-18 19:49:33,111:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-18 19:49:33,111:INFO:save_model() successfully completed......................................
2025-05-18 19:49:33,292:INFO:Initializing predict_model()
2025-05-18 19:49:33,292:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x37384bba0>)
2025-05-18 19:49:33,292:INFO:Checking exceptions
2025-05-18 19:49:33,292:INFO:Preloading libraries
2025-05-18 19:49:33,293:INFO:Set up data.
2025-05-18 19:49:33,313:INFO:Set up index.
2025-05-18 19:49:33,742:INFO:Initializing blend_models()
2025-05-18 19:49:33,742:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-18 19:49:33,742:INFO:Checking exceptions
2025-05-18 19:49:33,749:INFO:Importing libraries
2025-05-18 19:49:33,749:INFO:Copying training dataset
2025-05-18 19:49:33,751:INFO:Getting model names
2025-05-18 19:49:33,752:INFO:SubProcess create_model() called ==================================
2025-05-18 19:49:33,754:INFO:Initializing create_model()
2025-05-18 19:49:33,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3561956d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:49:33,754:INFO:Checking exceptions
2025-05-18 19:49:33,754:INFO:Importing libraries
2025-05-18 19:49:33,754:INFO:Copying training dataset
2025-05-18 19:49:33,763:INFO:Defining folds
2025-05-18 19:49:33,763:INFO:Declaring metric variables
2025-05-18 19:49:33,764:INFO:Importing untrained model
2025-05-18 19:49:33,764:INFO:Declaring custom model
2025-05-18 19:49:33,766:INFO:Voting Classifier Imported successfully
2025-05-18 19:49:33,768:INFO:Starting cross validation
2025-05-18 19:49:33,769:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:49:50,143:INFO:Calculating mean and std
2025-05-18 19:49:50,148:INFO:Creating metrics dataframe
2025-05-18 19:49:50,155:INFO:Finalizing model
2025-05-18 19:50:06,963:INFO:Uploading results into container
2025-05-18 19:50:06,965:INFO:Uploading model into container now
2025-05-18 19:50:06,966:INFO:_master_model_container: 18
2025-05-18 19:50:06,966:INFO:_display_container: 4
2025-05-18 19:50:06,968:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-18 19:50:06,968:INFO:create_model() successfully completed......................................
2025-05-18 19:50:07,222:INFO:SubProcess create_model() end ==================================
2025-05-18 19:50:07,226:INFO:_master_model_container: 18
2025-05-18 19:50:07,226:INFO:_display_container: 4
2025-05-18 19:50:07,228:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-18 19:50:07,228:INFO:blend_models() successfully completed......................................
2025-05-18 19:50:07,400:INFO:Initializing evaluate_model()
2025-05-18 19:50:07,400:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-18 19:50:07,409:INFO:Initializing plot_model()
2025-05-18 19:50:07,409:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-18 19:50:07,409:INFO:Checking exceptions
2025-05-18 19:50:07,413:INFO:Preloading libraries
2025-05-18 19:50:07,518:INFO:Copying training dataset
2025-05-18 19:50:07,518:INFO:Plot type: pipeline
2025-05-18 19:50:07,578:INFO:Visual Rendered Successfully
2025-05-18 19:50:07,728:INFO:plot_model() successfully completed......................................
2025-05-18 19:50:07,733:INFO:Initializing predict_model()
2025-05-18 19:50:07,733:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x33005efc0>)
2025-05-18 19:50:07,733:INFO:Checking exceptions
2025-05-18 19:50:07,733:INFO:Preloading libraries
2025-05-18 19:50:07,734:INFO:Set up data.
2025-05-18 19:50:07,760:INFO:Set up index.
2025-05-18 19:50:08,313:INFO:Initializing plot_model()
2025-05-18 19:50:08,313:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-18 19:50:08,313:INFO:Checking exceptions
2025-05-18 19:50:08,318:INFO:Preloading libraries
2025-05-18 19:50:08,320:INFO:Copying training dataset
2025-05-18 19:50:08,320:INFO:Plot type: confusion_matrix
2025-05-18 19:50:08,538:INFO:Fitting Model
2025-05-18 19:50:08,539:INFO:Scoring test/hold-out set
2025-05-18 19:50:08,615:INFO:Visual Rendered Successfully
2025-05-18 19:50:08,771:INFO:plot_model() successfully completed......................................
2025-05-18 19:50:08,772:INFO:Initializing plot_model()
2025-05-18 19:50:08,772:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-18 19:50:08,772:INFO:Checking exceptions
2025-05-18 19:50:08,776:INFO:Preloading libraries
2025-05-18 19:50:08,778:INFO:Copying training dataset
2025-05-18 19:50:08,778:INFO:Plot type: auc
2025-05-18 19:50:09,003:INFO:Fitting Model
2025-05-18 19:50:09,004:INFO:Scoring test/hold-out set
2025-05-18 19:50:09,138:INFO:Visual Rendered Successfully
2025-05-18 19:50:09,298:INFO:plot_model() successfully completed......................................
2025-05-18 19:50:09,299:INFO:Initializing plot_model()
2025-05-18 19:50:09,299:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x356845c50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-18 19:50:09,299:INFO:Checking exceptions
2025-05-18 19:50:09,303:INFO:Preloading libraries
2025-05-18 19:50:09,305:INFO:Copying training dataset
2025-05-18 19:50:09,305:INFO:Plot type: feature
2025-05-18 19:50:09,306:WARNING:No coef_ found. Trying feature_importances_
2025-05-18 19:50:09,378:INFO:Visual Rendered Successfully
2025-05-18 19:50:09,540:INFO:plot_model() successfully completed......................................
2025-05-18 19:55:15,802:INFO:PyCaret ClassificationExperiment
2025-05-18 19:55:15,802:INFO:Logging name: clf-default-name
2025-05-18 19:55:15,803:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-18 19:55:15,803:INFO:version 3.3.2
2025-05-18 19:55:15,803:INFO:Initializing setup()
2025-05-18 19:55:15,803:INFO:self.USI: 45a5
2025-05-18 19:55:15,803:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-18 19:55:15,803:INFO:Checking environment
2025-05-18 19:55:15,803:INFO:python_version: 3.11.0
2025-05-18 19:55:15,803:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-18 19:55:15,803:INFO:machine: arm64
2025-05-18 19:55:15,803:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-18 19:55:15,803:INFO:Memory: svmem(total=17179869184, available=4144283648, percent=75.9, used=6916997120, free=60080128, active=4108713984, inactive=4078534656, wired=2808283136)
2025-05-18 19:55:15,803:INFO:Physical Core: 12
2025-05-18 19:55:15,803:INFO:Logical Core: 12
2025-05-18 19:55:15,803:INFO:Checking libraries
2025-05-18 19:55:15,803:INFO:System:
2025-05-18 19:55:15,803:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-18 19:55:15,803:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-18 19:55:15,803:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-18 19:55:15,803:INFO:PyCaret required dependencies:
2025-05-18 19:55:15,803:INFO:                 pip: 22.3
2025-05-18 19:55:15,803:INFO:          setuptools: 65.5.0
2025-05-18 19:55:15,803:INFO:             pycaret: 3.3.2
2025-05-18 19:55:15,803:INFO:             IPython: 9.2.0
2025-05-18 19:55:15,803:INFO:          ipywidgets: 8.1.7
2025-05-18 19:55:15,803:INFO:                tqdm: 4.67.1
2025-05-18 19:55:15,803:INFO:               numpy: 1.26.4
2025-05-18 19:55:15,803:INFO:              pandas: 2.1.4
2025-05-18 19:55:15,803:INFO:              jinja2: 3.1.6
2025-05-18 19:55:15,803:INFO:               scipy: 1.11.4
2025-05-18 19:55:15,803:INFO:              joblib: 1.3.2
2025-05-18 19:55:15,803:INFO:             sklearn: 1.4.2
2025-05-18 19:55:15,803:INFO:                pyod: 2.0.5
2025-05-18 19:55:15,803:INFO:            imblearn: 0.13.0
2025-05-18 19:55:15,803:INFO:   category_encoders: 2.7.0
2025-05-18 19:55:15,803:INFO:            lightgbm: 4.6.0
2025-05-18 19:55:15,803:INFO:               numba: 0.61.2
2025-05-18 19:55:15,803:INFO:            requests: 2.32.3
2025-05-18 19:55:15,803:INFO:          matplotlib: 3.7.5
2025-05-18 19:55:15,803:INFO:          scikitplot: 0.3.7
2025-05-18 19:55:15,803:INFO:         yellowbrick: 1.5
2025-05-18 19:55:15,803:INFO:              plotly: 5.24.1
2025-05-18 19:55:15,804:INFO:    plotly-resampler: Not installed
2025-05-18 19:55:15,804:INFO:             kaleido: 0.2.1
2025-05-18 19:55:15,804:INFO:           schemdraw: 0.15
2025-05-18 19:55:15,804:INFO:         statsmodels: 0.14.4
2025-05-18 19:55:15,804:INFO:              sktime: 0.26.0
2025-05-18 19:55:15,804:INFO:               tbats: 1.1.3
2025-05-18 19:55:15,804:INFO:            pmdarima: 2.0.4
2025-05-18 19:55:15,804:INFO:              psutil: 7.0.0
2025-05-18 19:55:15,804:INFO:          markupsafe: 3.0.2
2025-05-18 19:55:15,804:INFO:             pickle5: Not installed
2025-05-18 19:55:15,804:INFO:         cloudpickle: 3.1.1
2025-05-18 19:55:15,804:INFO:         deprecation: 2.1.0
2025-05-18 19:55:15,804:INFO:              xxhash: 3.5.0
2025-05-18 19:55:15,804:INFO:           wurlitzer: 3.1.1
2025-05-18 19:55:15,804:INFO:PyCaret optional dependencies:
2025-05-18 19:55:15,804:INFO:                shap: 0.47.2
2025-05-18 19:55:15,804:INFO:           interpret: Not installed
2025-05-18 19:55:15,804:INFO:                umap: Not installed
2025-05-18 19:55:15,804:INFO:     ydata_profiling: Not installed
2025-05-18 19:55:15,804:INFO:  explainerdashboard: Not installed
2025-05-18 19:55:15,804:INFO:             autoviz: Not installed
2025-05-18 19:55:15,804:INFO:           fairlearn: Not installed
2025-05-18 19:55:15,804:INFO:          deepchecks: Not installed
2025-05-18 19:55:15,804:INFO:             xgboost: Not installed
2025-05-18 19:55:15,804:INFO:            catboost: 1.2.8
2025-05-18 19:55:15,804:INFO:              kmodes: Not installed
2025-05-18 19:55:15,804:INFO:             mlxtend: Not installed
2025-05-18 19:55:15,804:INFO:       statsforecast: Not installed
2025-05-18 19:55:15,804:INFO:        tune_sklearn: Not installed
2025-05-18 19:55:15,804:INFO:                 ray: Not installed
2025-05-18 19:55:15,804:INFO:            hyperopt: Not installed
2025-05-18 19:55:15,804:INFO:              optuna: 4.3.0
2025-05-18 19:55:15,804:INFO:               skopt: Not installed
2025-05-18 19:55:15,804:INFO:              mlflow: Not installed
2025-05-18 19:55:15,804:INFO:              gradio: Not installed
2025-05-18 19:55:15,804:INFO:             fastapi: Not installed
2025-05-18 19:55:15,804:INFO:             uvicorn: Not installed
2025-05-18 19:55:15,804:INFO:              m2cgen: Not installed
2025-05-18 19:55:15,804:INFO:           evidently: Not installed
2025-05-18 19:55:15,804:INFO:               fugue: Not installed
2025-05-18 19:55:15,804:INFO:           streamlit: Not installed
2025-05-18 19:55:15,804:INFO:             prophet: Not installed
2025-05-18 19:55:15,804:INFO:None
2025-05-18 19:55:15,804:INFO:Set up data.
2025-05-18 19:55:15,845:INFO:Set up folding strategy.
2025-05-18 19:55:15,845:INFO:Set up train/test split.
2025-05-18 19:55:15,864:INFO:Set up index.
2025-05-18 19:55:15,864:INFO:Assigning column types.
2025-05-18 19:55:15,869:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-18 19:55:15,888:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 19:55:15,889:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:55:15,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:55:15,901:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:55:15,921:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 19:55:15,921:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:55:15,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:55:15,932:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:55:15,933:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-18 19:55:15,951:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:55:15,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:55:15,963:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:55:15,981:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 19:55:15,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:55:15,993:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:55:15,993:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-18 19:55:16,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:55:16,024:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:55:16,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:55:16,054:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:55:16,055:INFO:Preparing preprocessing pipeline...
2025-05-18 19:55:16,057:INFO:Set up simple imputation.
2025-05-18 19:55:16,064:INFO:Set up encoding of ordinal features.
2025-05-18 19:55:16,076:INFO:Set up encoding of categorical features.
2025-05-18 19:55:16,076:INFO:Set up imbalanced handling.
2025-05-18 19:55:16,076:INFO:Set up column transformation.
2025-05-18 19:55:16,387:INFO:Finished creating preprocessing pipeline.
2025-05-18 19:55:16,408:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-18 19:55:16,408:INFO:Creating final display dataframe.
2025-05-18 19:55:16,609:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             smote
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              45a5
2025-05-18 19:55:16,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:55:16,645:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:55:16,676:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 19:55:16,676:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 19:55:16,678:INFO:setup() successfully completed in 0.88s...............
2025-05-18 19:55:16,678:INFO:Initializing compare_models()
2025-05-18 19:55:16,678:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-18 19:55:16,678:INFO:Checking exceptions
2025-05-18 19:55:16,684:INFO:Preparing display monitor
2025-05-18 19:55:16,701:INFO:Initializing Logistic Regression
2025-05-18 19:55:16,701:INFO:Total runtime is 3.520647684733073e-06 minutes
2025-05-18 19:55:16,702:INFO:SubProcess create_model() called ==================================
2025-05-18 19:55:16,703:INFO:Initializing create_model()
2025-05-18 19:55:16,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:55:16,703:INFO:Checking exceptions
2025-05-18 19:55:16,703:INFO:Importing libraries
2025-05-18 19:55:16,703:INFO:Copying training dataset
2025-05-18 19:55:16,713:INFO:Defining folds
2025-05-18 19:55:16,713:INFO:Declaring metric variables
2025-05-18 19:55:16,715:INFO:Importing untrained model
2025-05-18 19:55:16,716:INFO:Logistic Regression Imported successfully
2025-05-18 19:55:16,718:INFO:Starting cross validation
2025-05-18 19:55:16,720:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:55:22,452:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:55:22,562:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:55:22,572:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:55:22,578:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:55:22,681:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 19:55:22,740:INFO:Calculating mean and std
2025-05-18 19:55:22,741:INFO:Creating metrics dataframe
2025-05-18 19:55:22,743:INFO:Uploading results into container
2025-05-18 19:55:22,744:INFO:Uploading model into container now
2025-05-18 19:55:22,744:INFO:_master_model_container: 1
2025-05-18 19:55:22,744:INFO:_display_container: 2
2025-05-18 19:55:22,745:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-18 19:55:22,745:INFO:create_model() successfully completed......................................
2025-05-18 19:55:22,979:INFO:SubProcess create_model() end ==================================
2025-05-18 19:55:22,979:INFO:Creating metrics dataframe
2025-05-18 19:55:22,982:INFO:Initializing K Neighbors Classifier
2025-05-18 19:55:22,982:INFO:Total runtime is 0.10469453732172648 minutes
2025-05-18 19:55:22,983:INFO:SubProcess create_model() called ==================================
2025-05-18 19:55:22,984:INFO:Initializing create_model()
2025-05-18 19:55:22,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:55:22,984:INFO:Checking exceptions
2025-05-18 19:55:22,984:INFO:Importing libraries
2025-05-18 19:55:22,984:INFO:Copying training dataset
2025-05-18 19:55:22,993:INFO:Defining folds
2025-05-18 19:55:22,994:INFO:Declaring metric variables
2025-05-18 19:55:22,995:INFO:Importing untrained model
2025-05-18 19:55:22,996:INFO:K Neighbors Classifier Imported successfully
2025-05-18 19:55:22,998:INFO:Starting cross validation
2025-05-18 19:55:22,999:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:55:29,344:INFO:Calculating mean and std
2025-05-18 19:55:29,348:INFO:Creating metrics dataframe
2025-05-18 19:55:29,351:INFO:Uploading results into container
2025-05-18 19:55:29,352:INFO:Uploading model into container now
2025-05-18 19:55:29,352:INFO:_master_model_container: 2
2025-05-18 19:55:29,352:INFO:_display_container: 2
2025-05-18 19:55:29,352:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-18 19:55:29,353:INFO:create_model() successfully completed......................................
2025-05-18 19:55:29,628:INFO:SubProcess create_model() end ==================================
2025-05-18 19:55:29,628:INFO:Creating metrics dataframe
2025-05-18 19:55:29,632:INFO:Initializing Naive Bayes
2025-05-18 19:55:29,632:INFO:Total runtime is 0.2155188202857971 minutes
2025-05-18 19:55:29,633:INFO:SubProcess create_model() called ==================================
2025-05-18 19:55:29,633:INFO:Initializing create_model()
2025-05-18 19:55:29,633:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:55:29,633:INFO:Checking exceptions
2025-05-18 19:55:29,634:INFO:Importing libraries
2025-05-18 19:55:29,634:INFO:Copying training dataset
2025-05-18 19:55:29,647:INFO:Defining folds
2025-05-18 19:55:29,647:INFO:Declaring metric variables
2025-05-18 19:55:29,648:INFO:Importing untrained model
2025-05-18 19:55:29,650:INFO:Naive Bayes Imported successfully
2025-05-18 19:55:29,653:INFO:Starting cross validation
2025-05-18 19:55:29,654:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:55:30,860:INFO:Calculating mean and std
2025-05-18 19:55:30,860:INFO:Creating metrics dataframe
2025-05-18 19:55:30,861:INFO:Uploading results into container
2025-05-18 19:55:30,862:INFO:Uploading model into container now
2025-05-18 19:55:30,862:INFO:_master_model_container: 3
2025-05-18 19:55:30,862:INFO:_display_container: 2
2025-05-18 19:55:30,862:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-18 19:55:30,862:INFO:create_model() successfully completed......................................
2025-05-18 19:55:31,026:INFO:SubProcess create_model() end ==================================
2025-05-18 19:55:31,027:INFO:Creating metrics dataframe
2025-05-18 19:55:31,029:INFO:Initializing Decision Tree Classifier
2025-05-18 19:55:31,030:INFO:Total runtime is 0.2388174851735433 minutes
2025-05-18 19:55:31,031:INFO:SubProcess create_model() called ==================================
2025-05-18 19:55:31,031:INFO:Initializing create_model()
2025-05-18 19:55:31,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:55:31,031:INFO:Checking exceptions
2025-05-18 19:55:31,031:INFO:Importing libraries
2025-05-18 19:55:31,031:INFO:Copying training dataset
2025-05-18 19:55:31,041:INFO:Defining folds
2025-05-18 19:55:31,041:INFO:Declaring metric variables
2025-05-18 19:55:31,042:INFO:Importing untrained model
2025-05-18 19:55:31,043:INFO:Decision Tree Classifier Imported successfully
2025-05-18 19:55:31,045:INFO:Starting cross validation
2025-05-18 19:55:31,046:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:55:33,923:INFO:Calculating mean and std
2025-05-18 19:55:33,924:INFO:Creating metrics dataframe
2025-05-18 19:55:33,925:INFO:Uploading results into container
2025-05-18 19:55:33,925:INFO:Uploading model into container now
2025-05-18 19:55:33,926:INFO:_master_model_container: 4
2025-05-18 19:55:33,926:INFO:_display_container: 2
2025-05-18 19:55:33,926:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-18 19:55:33,926:INFO:create_model() successfully completed......................................
2025-05-18 19:55:34,090:INFO:SubProcess create_model() end ==================================
2025-05-18 19:55:34,090:INFO:Creating metrics dataframe
2025-05-18 19:55:34,093:INFO:Initializing SVM - Linear Kernel
2025-05-18 19:55:34,093:INFO:Total runtime is 0.28987762133280437 minutes
2025-05-18 19:55:34,094:INFO:SubProcess create_model() called ==================================
2025-05-18 19:55:34,095:INFO:Initializing create_model()
2025-05-18 19:55:34,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:55:34,095:INFO:Checking exceptions
2025-05-18 19:55:34,095:INFO:Importing libraries
2025-05-18 19:55:34,095:INFO:Copying training dataset
2025-05-18 19:55:34,104:INFO:Defining folds
2025-05-18 19:55:34,104:INFO:Declaring metric variables
2025-05-18 19:55:34,105:INFO:Importing untrained model
2025-05-18 19:55:34,106:INFO:SVM - Linear Kernel Imported successfully
2025-05-18 19:55:34,108:INFO:Starting cross validation
2025-05-18 19:55:34,109:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:55:38,096:INFO:Calculating mean and std
2025-05-18 19:55:38,098:INFO:Creating metrics dataframe
2025-05-18 19:55:38,102:INFO:Uploading results into container
2025-05-18 19:55:38,102:INFO:Uploading model into container now
2025-05-18 19:55:38,103:INFO:_master_model_container: 5
2025-05-18 19:55:38,103:INFO:_display_container: 2
2025-05-18 19:55:38,104:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-18 19:55:38,104:INFO:create_model() successfully completed......................................
2025-05-18 19:55:38,350:INFO:SubProcess create_model() end ==================================
2025-05-18 19:55:38,350:INFO:Creating metrics dataframe
2025-05-18 19:55:38,354:INFO:Initializing Ridge Classifier
2025-05-18 19:55:38,354:INFO:Total runtime is 0.36089261770248415 minutes
2025-05-18 19:55:38,355:INFO:SubProcess create_model() called ==================================
2025-05-18 19:55:38,356:INFO:Initializing create_model()
2025-05-18 19:55:38,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:55:38,356:INFO:Checking exceptions
2025-05-18 19:55:38,356:INFO:Importing libraries
2025-05-18 19:55:38,356:INFO:Copying training dataset
2025-05-18 19:55:38,366:INFO:Defining folds
2025-05-18 19:55:38,366:INFO:Declaring metric variables
2025-05-18 19:55:38,367:INFO:Importing untrained model
2025-05-18 19:55:38,368:INFO:Ridge Classifier Imported successfully
2025-05-18 19:55:38,371:INFO:Starting cross validation
2025-05-18 19:55:38,372:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:55:39,618:INFO:Calculating mean and std
2025-05-18 19:55:39,618:INFO:Creating metrics dataframe
2025-05-18 19:55:39,619:INFO:Uploading results into container
2025-05-18 19:55:39,619:INFO:Uploading model into container now
2025-05-18 19:55:39,620:INFO:_master_model_container: 6
2025-05-18 19:55:39,620:INFO:_display_container: 2
2025-05-18 19:55:39,620:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-18 19:55:39,620:INFO:create_model() successfully completed......................................
2025-05-18 19:55:39,782:INFO:SubProcess create_model() end ==================================
2025-05-18 19:55:39,782:INFO:Creating metrics dataframe
2025-05-18 19:55:39,785:INFO:Initializing Random Forest Classifier
2025-05-18 19:55:39,785:INFO:Total runtime is 0.3847465872764588 minutes
2025-05-18 19:55:39,787:INFO:SubProcess create_model() called ==================================
2025-05-18 19:55:39,787:INFO:Initializing create_model()
2025-05-18 19:55:39,787:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:55:39,787:INFO:Checking exceptions
2025-05-18 19:55:39,787:INFO:Importing libraries
2025-05-18 19:55:39,787:INFO:Copying training dataset
2025-05-18 19:55:39,798:INFO:Defining folds
2025-05-18 19:55:39,798:INFO:Declaring metric variables
2025-05-18 19:55:39,799:INFO:Importing untrained model
2025-05-18 19:55:39,801:INFO:Random Forest Classifier Imported successfully
2025-05-18 19:55:39,803:INFO:Starting cross validation
2025-05-18 19:55:39,804:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:55:46,087:INFO:Calculating mean and std
2025-05-18 19:55:46,092:INFO:Creating metrics dataframe
2025-05-18 19:55:46,097:INFO:Uploading results into container
2025-05-18 19:55:46,097:INFO:Uploading model into container now
2025-05-18 19:55:46,098:INFO:_master_model_container: 7
2025-05-18 19:55:46,098:INFO:_display_container: 2
2025-05-18 19:55:46,100:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-18 19:55:46,100:INFO:create_model() successfully completed......................................
2025-05-18 19:55:46,363:INFO:SubProcess create_model() end ==================================
2025-05-18 19:55:46,363:INFO:Creating metrics dataframe
2025-05-18 19:55:46,369:INFO:Initializing Quadratic Discriminant Analysis
2025-05-18 19:55:46,369:INFO:Total runtime is 0.4944686849912008 minutes
2025-05-18 19:55:46,370:INFO:SubProcess create_model() called ==================================
2025-05-18 19:55:46,370:INFO:Initializing create_model()
2025-05-18 19:55:46,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:55:46,370:INFO:Checking exceptions
2025-05-18 19:55:46,370:INFO:Importing libraries
2025-05-18 19:55:46,370:INFO:Copying training dataset
2025-05-18 19:55:46,382:INFO:Defining folds
2025-05-18 19:55:46,383:INFO:Declaring metric variables
2025-05-18 19:55:46,384:INFO:Importing untrained model
2025-05-18 19:55:46,385:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 19:55:46,387:INFO:Starting cross validation
2025-05-18 19:55:46,389:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:55:47,429:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:55:47,452:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:55:47,453:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:55:47,482:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:55:47,517:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:55:47,532:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 19:55:47,533:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:55:47,535:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:55:47,558:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:55:47,601:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:55:47,613:INFO:Calculating mean and std
2025-05-18 19:55:47,614:INFO:Creating metrics dataframe
2025-05-18 19:55:47,614:INFO:Uploading results into container
2025-05-18 19:55:47,615:INFO:Uploading model into container now
2025-05-18 19:55:47,615:INFO:_master_model_container: 8
2025-05-18 19:55:47,615:INFO:_display_container: 2
2025-05-18 19:55:47,615:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 19:55:47,615:INFO:create_model() successfully completed......................................
2025-05-18 19:55:47,763:INFO:SubProcess create_model() end ==================================
2025-05-18 19:55:47,763:INFO:Creating metrics dataframe
2025-05-18 19:55:47,767:INFO:Initializing Ada Boost Classifier
2025-05-18 19:55:47,767:INFO:Total runtime is 0.5177717526753743 minutes
2025-05-18 19:55:47,768:INFO:SubProcess create_model() called ==================================
2025-05-18 19:55:47,768:INFO:Initializing create_model()
2025-05-18 19:55:47,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:55:47,768:INFO:Checking exceptions
2025-05-18 19:55:47,768:INFO:Importing libraries
2025-05-18 19:55:47,768:INFO:Copying training dataset
2025-05-18 19:55:47,778:INFO:Defining folds
2025-05-18 19:55:47,778:INFO:Declaring metric variables
2025-05-18 19:55:47,779:INFO:Importing untrained model
2025-05-18 19:55:47,780:INFO:Ada Boost Classifier Imported successfully
2025-05-18 19:55:47,782:INFO:Starting cross validation
2025-05-18 19:55:47,783:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:55:48,810:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:55:48,854:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:55:48,875:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:55:48,886:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:55:48,910:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 19:55:51,607:INFO:Calculating mean and std
2025-05-18 19:55:51,609:INFO:Creating metrics dataframe
2025-05-18 19:55:51,610:INFO:Uploading results into container
2025-05-18 19:55:51,610:INFO:Uploading model into container now
2025-05-18 19:55:51,611:INFO:_master_model_container: 9
2025-05-18 19:55:51,611:INFO:_display_container: 2
2025-05-18 19:55:51,611:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-18 19:55:51,611:INFO:create_model() successfully completed......................................
2025-05-18 19:55:51,765:INFO:SubProcess create_model() end ==================================
2025-05-18 19:55:51,765:INFO:Creating metrics dataframe
2025-05-18 19:55:51,769:INFO:Initializing Gradient Boosting Classifier
2025-05-18 19:55:51,769:INFO:Total runtime is 0.584475568930308 minutes
2025-05-18 19:55:51,770:INFO:SubProcess create_model() called ==================================
2025-05-18 19:55:51,770:INFO:Initializing create_model()
2025-05-18 19:55:51,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:55:51,770:INFO:Checking exceptions
2025-05-18 19:55:51,770:INFO:Importing libraries
2025-05-18 19:55:51,770:INFO:Copying training dataset
2025-05-18 19:55:51,780:INFO:Defining folds
2025-05-18 19:55:51,780:INFO:Declaring metric variables
2025-05-18 19:55:51,781:INFO:Importing untrained model
2025-05-18 19:55:51,782:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 19:55:51,784:INFO:Starting cross validation
2025-05-18 19:55:51,785:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:56:05,436:INFO:Calculating mean and std
2025-05-18 19:56:05,436:INFO:Creating metrics dataframe
2025-05-18 19:56:05,437:INFO:Uploading results into container
2025-05-18 19:56:05,438:INFO:Uploading model into container now
2025-05-18 19:56:05,438:INFO:_master_model_container: 10
2025-05-18 19:56:05,438:INFO:_display_container: 2
2025-05-18 19:56:05,438:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 19:56:05,438:INFO:create_model() successfully completed......................................
2025-05-18 19:56:05,684:INFO:SubProcess create_model() end ==================================
2025-05-18 19:56:05,684:INFO:Creating metrics dataframe
2025-05-18 19:56:05,688:INFO:Initializing Linear Discriminant Analysis
2025-05-18 19:56:05,688:INFO:Total runtime is 0.8164575378100077 minutes
2025-05-18 19:56:05,689:INFO:SubProcess create_model() called ==================================
2025-05-18 19:56:05,689:INFO:Initializing create_model()
2025-05-18 19:56:05,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:56:05,690:INFO:Checking exceptions
2025-05-18 19:56:05,690:INFO:Importing libraries
2025-05-18 19:56:05,690:INFO:Copying training dataset
2025-05-18 19:56:05,701:INFO:Defining folds
2025-05-18 19:56:05,701:INFO:Declaring metric variables
2025-05-18 19:56:05,702:INFO:Importing untrained model
2025-05-18 19:56:05,704:INFO:Linear Discriminant Analysis Imported successfully
2025-05-18 19:56:05,706:INFO:Starting cross validation
2025-05-18 19:56:05,707:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:56:06,996:INFO:Calculating mean and std
2025-05-18 19:56:06,998:INFO:Creating metrics dataframe
2025-05-18 19:56:07,001:INFO:Uploading results into container
2025-05-18 19:56:07,002:INFO:Uploading model into container now
2025-05-18 19:56:07,003:INFO:_master_model_container: 11
2025-05-18 19:56:07,003:INFO:_display_container: 2
2025-05-18 19:56:07,004:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-18 19:56:07,004:INFO:create_model() successfully completed......................................
2025-05-18 19:56:07,166:INFO:SubProcess create_model() end ==================================
2025-05-18 19:56:07,166:INFO:Creating metrics dataframe
2025-05-18 19:56:07,170:INFO:Initializing Extra Trees Classifier
2025-05-18 19:56:07,170:INFO:Total runtime is 0.8411609371503195 minutes
2025-05-18 19:56:07,171:INFO:SubProcess create_model() called ==================================
2025-05-18 19:56:07,172:INFO:Initializing create_model()
2025-05-18 19:56:07,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:56:07,172:INFO:Checking exceptions
2025-05-18 19:56:07,172:INFO:Importing libraries
2025-05-18 19:56:07,172:INFO:Copying training dataset
2025-05-18 19:56:07,182:INFO:Defining folds
2025-05-18 19:56:07,182:INFO:Declaring metric variables
2025-05-18 19:56:07,183:INFO:Importing untrained model
2025-05-18 19:56:07,185:INFO:Extra Trees Classifier Imported successfully
2025-05-18 19:56:07,187:INFO:Starting cross validation
2025-05-18 19:56:07,188:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:56:12,400:INFO:Calculating mean and std
2025-05-18 19:56:12,411:INFO:Creating metrics dataframe
2025-05-18 19:56:12,417:INFO:Uploading results into container
2025-05-18 19:56:12,418:INFO:Uploading model into container now
2025-05-18 19:56:12,418:INFO:_master_model_container: 12
2025-05-18 19:56:12,418:INFO:_display_container: 2
2025-05-18 19:56:12,420:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-18 19:56:12,420:INFO:create_model() successfully completed......................................
2025-05-18 19:56:12,714:INFO:SubProcess create_model() end ==================================
2025-05-18 19:56:12,715:INFO:Creating metrics dataframe
2025-05-18 19:56:12,719:INFO:Initializing Light Gradient Boosting Machine
2025-05-18 19:56:12,719:INFO:Total runtime is 0.9336487690607708 minutes
2025-05-18 19:56:12,721:INFO:SubProcess create_model() called ==================================
2025-05-18 19:56:12,722:INFO:Initializing create_model()
2025-05-18 19:56:12,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:56:12,722:INFO:Checking exceptions
2025-05-18 19:56:12,722:INFO:Importing libraries
2025-05-18 19:56:12,722:INFO:Copying training dataset
2025-05-18 19:56:12,742:INFO:Defining folds
2025-05-18 19:56:12,742:INFO:Declaring metric variables
2025-05-18 19:56:12,744:INFO:Importing untrained model
2025-05-18 19:56:12,746:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 19:56:12,748:INFO:Starting cross validation
2025-05-18 19:56:12,749:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:56:17,035:INFO:Calculating mean and std
2025-05-18 19:56:17,035:INFO:Creating metrics dataframe
2025-05-18 19:56:17,036:INFO:Uploading results into container
2025-05-18 19:56:17,037:INFO:Uploading model into container now
2025-05-18 19:56:17,037:INFO:_master_model_container: 13
2025-05-18 19:56:17,037:INFO:_display_container: 2
2025-05-18 19:56:17,037:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:56:17,037:INFO:create_model() successfully completed......................................
2025-05-18 19:56:17,185:INFO:SubProcess create_model() end ==================================
2025-05-18 19:56:17,185:INFO:Creating metrics dataframe
2025-05-18 19:56:17,189:INFO:Initializing CatBoost Classifier
2025-05-18 19:56:17,189:INFO:Total runtime is 1.0081393361091615 minutes
2025-05-18 19:56:17,190:INFO:SubProcess create_model() called ==================================
2025-05-18 19:56:17,190:INFO:Initializing create_model()
2025-05-18 19:56:17,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:56:17,190:INFO:Checking exceptions
2025-05-18 19:56:17,190:INFO:Importing libraries
2025-05-18 19:56:17,190:INFO:Copying training dataset
2025-05-18 19:56:17,200:INFO:Defining folds
2025-05-18 19:56:17,200:INFO:Declaring metric variables
2025-05-18 19:56:17,201:INFO:Importing untrained model
2025-05-18 19:56:17,202:INFO:CatBoost Classifier Imported successfully
2025-05-18 19:56:17,204:INFO:Starting cross validation
2025-05-18 19:56:17,205:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:56:35,402:INFO:Calculating mean and std
2025-05-18 19:56:35,405:INFO:Creating metrics dataframe
2025-05-18 19:56:35,412:INFO:Uploading results into container
2025-05-18 19:56:35,413:INFO:Uploading model into container now
2025-05-18 19:56:35,414:INFO:_master_model_container: 14
2025-05-18 19:56:35,414:INFO:_display_container: 2
2025-05-18 19:56:35,414:INFO:<catboost.core.CatBoostClassifier object at 0x3733a81d0>
2025-05-18 19:56:35,414:INFO:create_model() successfully completed......................................
2025-05-18 19:56:35,690:INFO:SubProcess create_model() end ==================================
2025-05-18 19:56:35,690:INFO:Creating metrics dataframe
2025-05-18 19:56:35,695:INFO:Initializing Dummy Classifier
2025-05-18 19:56:35,695:INFO:Total runtime is 1.316572133700053 minutes
2025-05-18 19:56:35,696:INFO:SubProcess create_model() called ==================================
2025-05-18 19:56:35,696:INFO:Initializing create_model()
2025-05-18 19:56:35,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x35646c890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:56:35,697:INFO:Checking exceptions
2025-05-18 19:56:35,697:INFO:Importing libraries
2025-05-18 19:56:35,697:INFO:Copying training dataset
2025-05-18 19:56:35,710:INFO:Defining folds
2025-05-18 19:56:35,710:INFO:Declaring metric variables
2025-05-18 19:56:35,712:INFO:Importing untrained model
2025-05-18 19:56:35,713:INFO:Dummy Classifier Imported successfully
2025-05-18 19:56:35,716:INFO:Starting cross validation
2025-05-18 19:56:35,717:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 19:56:36,841:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:56:36,867:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:56:36,904:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:56:36,920:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:56:36,927:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 19:56:36,936:INFO:Calculating mean and std
2025-05-18 19:56:36,937:INFO:Creating metrics dataframe
2025-05-18 19:56:36,938:INFO:Uploading results into container
2025-05-18 19:56:36,938:INFO:Uploading model into container now
2025-05-18 19:56:36,938:INFO:_master_model_container: 15
2025-05-18 19:56:36,939:INFO:_display_container: 2
2025-05-18 19:56:36,939:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-18 19:56:36,939:INFO:create_model() successfully completed......................................
2025-05-18 19:56:37,114:INFO:SubProcess create_model() end ==================================
2025-05-18 19:56:37,114:INFO:Creating metrics dataframe
2025-05-18 19:56:37,119:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-18 19:56:37,123:INFO:Initializing create_model()
2025-05-18 19:56:37,123:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:56:37,123:INFO:Checking exceptions
2025-05-18 19:56:37,123:INFO:Importing libraries
2025-05-18 19:56:37,124:INFO:Copying training dataset
2025-05-18 19:56:37,133:INFO:Defining folds
2025-05-18 19:56:37,133:INFO:Declaring metric variables
2025-05-18 19:56:37,133:INFO:Importing untrained model
2025-05-18 19:56:37,133:INFO:Declaring custom model
2025-05-18 19:56:37,134:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 19:56:37,134:INFO:Cross validation set to False
2025-05-18 19:56:37,134:INFO:Fitting Model
2025-05-18 19:56:38,513:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 19:56:38,524:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005962 seconds.
2025-05-18 19:56:38,524:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 19:56:38,524:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 19:56:38,525:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 19:56:38,525:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 19:56:38,525:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 19:56:39,610:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 19:56:39,611:INFO:create_model() successfully completed......................................
2025-05-18 19:56:39,784:INFO:Initializing create_model()
2025-05-18 19:56:39,784:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:56:39,784:INFO:Checking exceptions
2025-05-18 19:56:39,785:INFO:Importing libraries
2025-05-18 19:56:39,785:INFO:Copying training dataset
2025-05-18 19:56:39,794:INFO:Defining folds
2025-05-18 19:56:39,795:INFO:Declaring metric variables
2025-05-18 19:56:39,795:INFO:Importing untrained model
2025-05-18 19:56:39,795:INFO:Declaring custom model
2025-05-18 19:56:39,795:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 19:56:39,796:INFO:Cross validation set to False
2025-05-18 19:56:39,796:INFO:Fitting Model
2025-05-18 19:56:56,022:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 19:56:56,023:INFO:create_model() successfully completed......................................
2025-05-18 19:56:56,328:INFO:Initializing create_model()
2025-05-18 19:56:56,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 19:56:56,328:INFO:Checking exceptions
2025-05-18 19:56:56,329:INFO:Importing libraries
2025-05-18 19:56:56,329:INFO:Copying training dataset
2025-05-18 19:56:56,340:INFO:Defining folds
2025-05-18 19:56:56,340:INFO:Declaring metric variables
2025-05-18 19:56:56,340:INFO:Importing untrained model
2025-05-18 19:56:56,340:INFO:Declaring custom model
2025-05-18 19:56:56,340:INFO:Random Forest Classifier Imported successfully
2025-05-18 19:56:56,341:INFO:Cross validation set to False
2025-05-18 19:56:56,341:INFO:Fitting Model
2025-05-18 19:56:58,510:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-18 19:56:58,510:INFO:create_model() successfully completed......................................
2025-05-18 19:56:58,670:INFO:_master_model_container: 15
2025-05-18 19:56:58,670:INFO:_display_container: 2
2025-05-18 19:56:58,671:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-18 19:56:58,671:INFO:compare_models() successfully completed......................................
2025-05-18 19:56:58,675:INFO:Initializing evaluate_model()
2025-05-18 19:56:58,675:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-18 19:56:58,682:INFO:Initializing plot_model()
2025-05-18 19:56:58,682:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-18 19:56:58,682:INFO:Checking exceptions
2025-05-18 19:56:58,685:INFO:Preloading libraries
2025-05-18 19:56:58,688:INFO:Copying training dataset
2025-05-18 19:56:58,688:INFO:Plot type: pipeline
2025-05-18 19:56:58,743:INFO:Visual Rendered Successfully
2025-05-18 19:56:58,913:INFO:plot_model() successfully completed......................................
2025-05-18 19:56:58,915:INFO:Initializing tune_model()
2025-05-18 19:56:58,915:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3562fc110>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-18 19:56:58,915:INFO:Checking exceptions
2025-05-18 19:56:58,926:INFO:Copying training dataset
2025-05-18 19:56:58,933:INFO:Checking base model
2025-05-18 19:56:58,933:INFO:Base model : Light Gradient Boosting Machine
2025-05-18 19:56:58,935:INFO:Declaring metric variables
2025-05-18 19:56:58,936:INFO:Defining Hyperparameters
2025-05-18 19:56:59,107:INFO:Tuning with n_jobs=-1
2025-05-18 19:56:59,107:INFO:Initializing RandomizedSearchCV
2025-05-18 20:41:25,547:INFO:PyCaret ClassificationExperiment
2025-05-18 20:41:25,548:INFO:Logging name: clf-default-name
2025-05-18 20:41:25,548:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-18 20:41:25,548:INFO:version 3.3.2
2025-05-18 20:41:25,548:INFO:Initializing setup()
2025-05-18 20:41:25,548:INFO:self.USI: fa1d
2025-05-18 20:41:25,548:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-18 20:41:25,548:INFO:Checking environment
2025-05-18 20:41:25,548:INFO:python_version: 3.11.0
2025-05-18 20:41:25,548:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-18 20:41:25,548:INFO:machine: arm64
2025-05-18 20:41:25,548:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-18 20:41:25,548:INFO:Memory: svmem(total=17179869184, available=3617767424, percent=78.9, used=6344507392, free=61112320, active=3573383168, inactive=3533406208, wired=2771124224)
2025-05-18 20:41:25,548:INFO:Physical Core: 12
2025-05-18 20:41:25,548:INFO:Logical Core: 12
2025-05-18 20:41:25,548:INFO:Checking libraries
2025-05-18 20:41:25,548:INFO:System:
2025-05-18 20:41:25,548:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-18 20:41:25,548:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-18 20:41:25,548:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-18 20:41:25,548:INFO:PyCaret required dependencies:
2025-05-18 20:41:25,548:INFO:                 pip: 22.3
2025-05-18 20:41:25,548:INFO:          setuptools: 65.5.0
2025-05-18 20:41:25,548:INFO:             pycaret: 3.3.2
2025-05-18 20:41:25,548:INFO:             IPython: 9.2.0
2025-05-18 20:41:25,548:INFO:          ipywidgets: 8.1.7
2025-05-18 20:41:25,548:INFO:                tqdm: 4.67.1
2025-05-18 20:41:25,548:INFO:               numpy: 1.26.4
2025-05-18 20:41:25,548:INFO:              pandas: 2.1.4
2025-05-18 20:41:25,548:INFO:              jinja2: 3.1.6
2025-05-18 20:41:25,548:INFO:               scipy: 1.11.4
2025-05-18 20:41:25,548:INFO:              joblib: 1.3.2
2025-05-18 20:41:25,548:INFO:             sklearn: 1.4.2
2025-05-18 20:41:25,548:INFO:                pyod: 2.0.5
2025-05-18 20:41:25,548:INFO:            imblearn: 0.13.0
2025-05-18 20:41:25,548:INFO:   category_encoders: 2.7.0
2025-05-18 20:41:25,548:INFO:            lightgbm: 4.6.0
2025-05-18 20:41:25,548:INFO:               numba: 0.61.2
2025-05-18 20:41:25,548:INFO:            requests: 2.32.3
2025-05-18 20:41:25,548:INFO:          matplotlib: 3.7.5
2025-05-18 20:41:25,548:INFO:          scikitplot: 0.3.7
2025-05-18 20:41:25,548:INFO:         yellowbrick: 1.5
2025-05-18 20:41:25,548:INFO:              plotly: 5.24.1
2025-05-18 20:41:25,548:INFO:    plotly-resampler: Not installed
2025-05-18 20:41:25,548:INFO:             kaleido: 0.2.1
2025-05-18 20:41:25,548:INFO:           schemdraw: 0.15
2025-05-18 20:41:25,548:INFO:         statsmodels: 0.14.4
2025-05-18 20:41:25,548:INFO:              sktime: 0.26.0
2025-05-18 20:41:25,548:INFO:               tbats: 1.1.3
2025-05-18 20:41:25,548:INFO:            pmdarima: 2.0.4
2025-05-18 20:41:25,548:INFO:              psutil: 7.0.0
2025-05-18 20:41:25,548:INFO:          markupsafe: 3.0.2
2025-05-18 20:41:25,548:INFO:             pickle5: Not installed
2025-05-18 20:41:25,548:INFO:         cloudpickle: 3.1.1
2025-05-18 20:41:25,548:INFO:         deprecation: 2.1.0
2025-05-18 20:41:25,549:INFO:              xxhash: 3.5.0
2025-05-18 20:41:25,549:INFO:           wurlitzer: 3.1.1
2025-05-18 20:41:25,549:INFO:PyCaret optional dependencies:
2025-05-18 20:41:25,549:INFO:                shap: 0.47.2
2025-05-18 20:41:25,549:INFO:           interpret: Not installed
2025-05-18 20:41:25,549:INFO:                umap: Not installed
2025-05-18 20:41:25,549:INFO:     ydata_profiling: Not installed
2025-05-18 20:41:25,549:INFO:  explainerdashboard: Not installed
2025-05-18 20:41:25,549:INFO:             autoviz: Not installed
2025-05-18 20:41:25,549:INFO:           fairlearn: Not installed
2025-05-18 20:41:25,549:INFO:          deepchecks: Not installed
2025-05-18 20:41:25,549:INFO:             xgboost: Not installed
2025-05-18 20:41:25,549:INFO:            catboost: 1.2.8
2025-05-18 20:41:25,549:INFO:              kmodes: Not installed
2025-05-18 20:41:25,549:INFO:             mlxtend: Not installed
2025-05-18 20:41:25,549:INFO:       statsforecast: Not installed
2025-05-18 20:41:25,549:INFO:        tune_sklearn: Not installed
2025-05-18 20:41:25,549:INFO:                 ray: Not installed
2025-05-18 20:41:25,549:INFO:            hyperopt: Not installed
2025-05-18 20:41:25,549:INFO:              optuna: 4.3.0
2025-05-18 20:41:25,549:INFO:               skopt: Not installed
2025-05-18 20:41:25,549:INFO:              mlflow: Not installed
2025-05-18 20:41:25,549:INFO:              gradio: Not installed
2025-05-18 20:41:25,549:INFO:             fastapi: Not installed
2025-05-18 20:41:25,549:INFO:             uvicorn: Not installed
2025-05-18 20:41:25,549:INFO:              m2cgen: Not installed
2025-05-18 20:41:25,549:INFO:           evidently: Not installed
2025-05-18 20:41:25,549:INFO:               fugue: Not installed
2025-05-18 20:41:25,549:INFO:           streamlit: Not installed
2025-05-18 20:41:25,549:INFO:             prophet: Not installed
2025-05-18 20:41:25,549:INFO:None
2025-05-18 20:41:25,549:INFO:Set up data.
2025-05-18 20:41:25,579:INFO:Set up folding strategy.
2025-05-18 20:41:25,579:INFO:Set up train/test split.
2025-05-18 20:41:25,593:INFO:Set up index.
2025-05-18 20:41:25,593:INFO:Assigning column types.
2025-05-18 20:41:25,597:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-18 20:41:25,615:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 20:41:25,616:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 20:41:25,627:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:41:25,628:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:41:25,646:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 20:41:25,646:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 20:41:25,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:41:25,658:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:41:25,658:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-18 20:41:25,677:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 20:41:25,688:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:41:25,688:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:41:25,706:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 20:41:25,717:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:41:25,717:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:41:25,717:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-18 20:41:25,749:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:41:25,749:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:41:25,778:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:41:25,778:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:41:25,779:INFO:Preparing preprocessing pipeline...
2025-05-18 20:41:25,780:INFO:Set up simple imputation.
2025-05-18 20:41:25,787:INFO:Set up encoding of ordinal features.
2025-05-18 20:41:25,797:INFO:Set up encoding of categorical features.
2025-05-18 20:41:25,797:INFO:Set up imbalanced handling.
2025-05-18 20:41:25,797:INFO:Set up column transformation.
2025-05-18 20:41:25,797:INFO:Set up feature selection.
2025-05-18 20:41:25,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:41:25,828:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:41:27,911:INFO:Finished creating preprocessing pipeline.
2025-05-18 20:41:27,933:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=12,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-05-18 20:41:27,933:INFO:Creating final display dataframe.
2025-05-18 20:41:28,339:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 13)
5   Transformed train set shape       (85902, 13)
6    Transformed test set shape       (20919, 13)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19            Feature selection              True
20     Feature selection method           classic
21  Feature selection estimator          lightgbm
22  Number of features selected               0.8
23               Fold Generator   StratifiedKFold
24                  Fold Number                 5
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              fa1d
2025-05-18 20:41:28,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:41:28,375:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:41:28,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:41:28,405:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:41:28,406:INFO:setup() successfully completed in 2.86s...............
2025-05-18 20:41:28,407:INFO:Initializing compare_models()
2025-05-18 20:41:28,407:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-18 20:41:28,407:INFO:Checking exceptions
2025-05-18 20:41:28,412:INFO:Preparing display monitor
2025-05-18 20:41:28,420:INFO:Initializing Logistic Regression
2025-05-18 20:41:28,421:INFO:Total runtime is 2.7338663736979167e-06 minutes
2025-05-18 20:41:28,422:INFO:SubProcess create_model() called ==================================
2025-05-18 20:41:28,422:INFO:Initializing create_model()
2025-05-18 20:41:28,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:41:28,422:INFO:Checking exceptions
2025-05-18 20:41:28,422:INFO:Importing libraries
2025-05-18 20:41:28,422:INFO:Copying training dataset
2025-05-18 20:41:28,432:INFO:Defining folds
2025-05-18 20:41:28,432:INFO:Declaring metric variables
2025-05-18 20:41:28,434:INFO:Importing untrained model
2025-05-18 20:41:28,435:INFO:Logistic Regression Imported successfully
2025-05-18 20:41:28,439:INFO:Starting cross validation
2025-05-18 20:41:28,443:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:41:35,097:INFO:Calculating mean and std
2025-05-18 20:41:35,101:INFO:Creating metrics dataframe
2025-05-18 20:41:35,107:INFO:Uploading results into container
2025-05-18 20:41:35,108:INFO:Uploading model into container now
2025-05-18 20:41:35,110:INFO:_master_model_container: 1
2025-05-18 20:41:35,110:INFO:_display_container: 2
2025-05-18 20:41:35,111:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-18 20:41:35,111:INFO:create_model() successfully completed......................................
2025-05-18 20:41:35,408:INFO:SubProcess create_model() end ==================================
2025-05-18 20:41:35,408:INFO:Creating metrics dataframe
2025-05-18 20:41:35,412:INFO:Initializing K Neighbors Classifier
2025-05-18 20:41:35,412:INFO:Total runtime is 0.11652448177337647 minutes
2025-05-18 20:41:35,414:INFO:SubProcess create_model() called ==================================
2025-05-18 20:41:35,414:INFO:Initializing create_model()
2025-05-18 20:41:35,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:41:35,414:INFO:Checking exceptions
2025-05-18 20:41:35,414:INFO:Importing libraries
2025-05-18 20:41:35,415:INFO:Copying training dataset
2025-05-18 20:41:35,436:INFO:Defining folds
2025-05-18 20:41:35,436:INFO:Declaring metric variables
2025-05-18 20:41:35,438:INFO:Importing untrained model
2025-05-18 20:41:35,439:INFO:K Neighbors Classifier Imported successfully
2025-05-18 20:41:35,442:INFO:Starting cross validation
2025-05-18 20:41:35,447:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:41:41,208:INFO:Calculating mean and std
2025-05-18 20:41:41,209:INFO:Creating metrics dataframe
2025-05-18 20:41:41,211:INFO:Uploading results into container
2025-05-18 20:41:41,211:INFO:Uploading model into container now
2025-05-18 20:41:41,211:INFO:_master_model_container: 2
2025-05-18 20:41:41,211:INFO:_display_container: 2
2025-05-18 20:41:41,212:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-18 20:41:41,212:INFO:create_model() successfully completed......................................
2025-05-18 20:41:41,399:INFO:SubProcess create_model() end ==================================
2025-05-18 20:41:41,399:INFO:Creating metrics dataframe
2025-05-18 20:41:41,402:INFO:Initializing Naive Bayes
2025-05-18 20:41:41,402:INFO:Total runtime is 0.2163609306017558 minutes
2025-05-18 20:41:41,404:INFO:SubProcess create_model() called ==================================
2025-05-18 20:41:41,404:INFO:Initializing create_model()
2025-05-18 20:41:41,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:41:41,404:INFO:Checking exceptions
2025-05-18 20:41:41,404:INFO:Importing libraries
2025-05-18 20:41:41,404:INFO:Copying training dataset
2025-05-18 20:41:41,414:INFO:Defining folds
2025-05-18 20:41:41,414:INFO:Declaring metric variables
2025-05-18 20:41:41,416:INFO:Importing untrained model
2025-05-18 20:41:41,417:INFO:Naive Bayes Imported successfully
2025-05-18 20:41:41,420:INFO:Starting cross validation
2025-05-18 20:41:41,424:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:41:45,611:INFO:Calculating mean and std
2025-05-18 20:41:45,612:INFO:Creating metrics dataframe
2025-05-18 20:41:45,614:INFO:Uploading results into container
2025-05-18 20:41:45,615:INFO:Uploading model into container now
2025-05-18 20:41:45,615:INFO:_master_model_container: 3
2025-05-18 20:41:45,615:INFO:_display_container: 2
2025-05-18 20:41:45,615:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-18 20:41:45,615:INFO:create_model() successfully completed......................................
2025-05-18 20:41:45,879:INFO:SubProcess create_model() end ==================================
2025-05-18 20:41:45,879:INFO:Creating metrics dataframe
2025-05-18 20:41:45,883:INFO:Initializing Decision Tree Classifier
2025-05-18 20:41:45,883:INFO:Total runtime is 0.2910426179567973 minutes
2025-05-18 20:41:45,884:INFO:SubProcess create_model() called ==================================
2025-05-18 20:41:45,884:INFO:Initializing create_model()
2025-05-18 20:41:45,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:41:45,885:INFO:Checking exceptions
2025-05-18 20:41:45,885:INFO:Importing libraries
2025-05-18 20:41:45,885:INFO:Copying training dataset
2025-05-18 20:41:45,903:INFO:Defining folds
2025-05-18 20:41:45,903:INFO:Declaring metric variables
2025-05-18 20:41:45,905:INFO:Importing untrained model
2025-05-18 20:41:45,906:INFO:Decision Tree Classifier Imported successfully
2025-05-18 20:41:45,908:INFO:Starting cross validation
2025-05-18 20:41:45,912:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:41:50,795:INFO:Calculating mean and std
2025-05-18 20:41:50,805:INFO:Creating metrics dataframe
2025-05-18 20:41:50,809:INFO:Uploading results into container
2025-05-18 20:41:50,810:INFO:Uploading model into container now
2025-05-18 20:41:50,810:INFO:_master_model_container: 4
2025-05-18 20:41:50,810:INFO:_display_container: 2
2025-05-18 20:41:50,812:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-18 20:41:50,812:INFO:create_model() successfully completed......................................
2025-05-18 20:41:51,007:INFO:SubProcess create_model() end ==================================
2025-05-18 20:41:51,007:INFO:Creating metrics dataframe
2025-05-18 20:41:51,011:INFO:Initializing SVM - Linear Kernel
2025-05-18 20:41:51,011:INFO:Total runtime is 0.37651388247807827 minutes
2025-05-18 20:41:51,013:INFO:SubProcess create_model() called ==================================
2025-05-18 20:41:51,013:INFO:Initializing create_model()
2025-05-18 20:41:51,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:41:51,013:INFO:Checking exceptions
2025-05-18 20:41:51,013:INFO:Importing libraries
2025-05-18 20:41:51,013:INFO:Copying training dataset
2025-05-18 20:41:51,023:INFO:Defining folds
2025-05-18 20:41:51,023:INFO:Declaring metric variables
2025-05-18 20:41:51,025:INFO:Importing untrained model
2025-05-18 20:41:51,026:INFO:SVM - Linear Kernel Imported successfully
2025-05-18 20:41:51,029:INFO:Starting cross validation
2025-05-18 20:41:51,033:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:41:55,890:INFO:Calculating mean and std
2025-05-18 20:41:55,891:INFO:Creating metrics dataframe
2025-05-18 20:41:55,892:INFO:Uploading results into container
2025-05-18 20:41:55,892:INFO:Uploading model into container now
2025-05-18 20:41:55,893:INFO:_master_model_container: 5
2025-05-18 20:41:55,893:INFO:_display_container: 2
2025-05-18 20:41:55,893:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-18 20:41:55,893:INFO:create_model() successfully completed......................................
2025-05-18 20:41:56,113:INFO:SubProcess create_model() end ==================================
2025-05-18 20:41:56,113:INFO:Creating metrics dataframe
2025-05-18 20:41:56,117:INFO:Initializing Ridge Classifier
2025-05-18 20:41:56,117:INFO:Total runtime is 0.4616061647733053 minutes
2025-05-18 20:41:56,118:INFO:SubProcess create_model() called ==================================
2025-05-18 20:41:56,118:INFO:Initializing create_model()
2025-05-18 20:41:56,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:41:56,118:INFO:Checking exceptions
2025-05-18 20:41:56,118:INFO:Importing libraries
2025-05-18 20:41:56,118:INFO:Copying training dataset
2025-05-18 20:41:56,136:INFO:Defining folds
2025-05-18 20:41:56,136:INFO:Declaring metric variables
2025-05-18 20:41:56,138:INFO:Importing untrained model
2025-05-18 20:41:56,139:INFO:Ridge Classifier Imported successfully
2025-05-18 20:41:56,141:INFO:Starting cross validation
2025-05-18 20:41:56,147:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:42:00,217:INFO:Calculating mean and std
2025-05-18 20:42:00,220:INFO:Creating metrics dataframe
2025-05-18 20:42:00,223:INFO:Uploading results into container
2025-05-18 20:42:00,224:INFO:Uploading model into container now
2025-05-18 20:42:00,224:INFO:_master_model_container: 6
2025-05-18 20:42:00,224:INFO:_display_container: 2
2025-05-18 20:42:00,226:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-18 20:42:00,226:INFO:create_model() successfully completed......................................
2025-05-18 20:42:00,433:INFO:SubProcess create_model() end ==================================
2025-05-18 20:42:00,433:INFO:Creating metrics dataframe
2025-05-18 20:42:00,437:INFO:Initializing Random Forest Classifier
2025-05-18 20:42:00,437:INFO:Total runtime is 0.5336107651392619 minutes
2025-05-18 20:42:00,439:INFO:SubProcess create_model() called ==================================
2025-05-18 20:42:00,439:INFO:Initializing create_model()
2025-05-18 20:42:00,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:42:00,439:INFO:Checking exceptions
2025-05-18 20:42:00,439:INFO:Importing libraries
2025-05-18 20:42:00,439:INFO:Copying training dataset
2025-05-18 20:42:00,454:INFO:Defining folds
2025-05-18 20:42:00,455:INFO:Declaring metric variables
2025-05-18 20:42:00,457:INFO:Importing untrained model
2025-05-18 20:42:00,458:INFO:Random Forest Classifier Imported successfully
2025-05-18 20:42:00,461:INFO:Starting cross validation
2025-05-18 20:42:00,465:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:42:09,899:INFO:Calculating mean and std
2025-05-18 20:42:09,902:INFO:Creating metrics dataframe
2025-05-18 20:42:09,914:INFO:Uploading results into container
2025-05-18 20:42:09,915:INFO:Uploading model into container now
2025-05-18 20:42:09,916:INFO:_master_model_container: 7
2025-05-18 20:42:09,916:INFO:_display_container: 2
2025-05-18 20:42:09,916:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-18 20:42:09,916:INFO:create_model() successfully completed......................................
2025-05-18 20:42:10,183:INFO:SubProcess create_model() end ==================================
2025-05-18 20:42:10,183:INFO:Creating metrics dataframe
2025-05-18 20:42:10,187:INFO:Initializing Quadratic Discriminant Analysis
2025-05-18 20:42:10,187:INFO:Total runtime is 0.6961175839106242 minutes
2025-05-18 20:42:10,189:INFO:SubProcess create_model() called ==================================
2025-05-18 20:42:10,189:INFO:Initializing create_model()
2025-05-18 20:42:10,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:42:10,189:INFO:Checking exceptions
2025-05-18 20:42:10,189:INFO:Importing libraries
2025-05-18 20:42:10,189:INFO:Copying training dataset
2025-05-18 20:42:10,201:INFO:Defining folds
2025-05-18 20:42:10,201:INFO:Declaring metric variables
2025-05-18 20:42:10,202:INFO:Importing untrained model
2025-05-18 20:42:10,203:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 20:42:10,205:INFO:Starting cross validation
2025-05-18 20:42:10,209:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:42:14,248:INFO:Calculating mean and std
2025-05-18 20:42:14,249:INFO:Creating metrics dataframe
2025-05-18 20:42:14,250:INFO:Uploading results into container
2025-05-18 20:42:14,250:INFO:Uploading model into container now
2025-05-18 20:42:14,250:INFO:_master_model_container: 8
2025-05-18 20:42:14,250:INFO:_display_container: 2
2025-05-18 20:42:14,250:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 20:42:14,250:INFO:create_model() successfully completed......................................
2025-05-18 20:42:14,401:INFO:SubProcess create_model() end ==================================
2025-05-18 20:42:14,401:INFO:Creating metrics dataframe
2025-05-18 20:42:14,405:INFO:Initializing Ada Boost Classifier
2025-05-18 20:42:14,405:INFO:Total runtime is 0.7664047519365946 minutes
2025-05-18 20:42:14,406:INFO:SubProcess create_model() called ==================================
2025-05-18 20:42:14,406:INFO:Initializing create_model()
2025-05-18 20:42:14,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:42:14,406:INFO:Checking exceptions
2025-05-18 20:42:14,406:INFO:Importing libraries
2025-05-18 20:42:14,406:INFO:Copying training dataset
2025-05-18 20:42:14,416:INFO:Defining folds
2025-05-18 20:42:14,416:INFO:Declaring metric variables
2025-05-18 20:42:14,417:INFO:Importing untrained model
2025-05-18 20:42:14,419:INFO:Ada Boost Classifier Imported successfully
2025-05-18 20:42:14,421:INFO:Starting cross validation
2025-05-18 20:42:14,424:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:42:18,015:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:42:18,067:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:42:18,098:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:42:18,100:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:42:18,109:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:42:20,391:INFO:Calculating mean and std
2025-05-18 20:42:20,393:INFO:Creating metrics dataframe
2025-05-18 20:42:20,397:INFO:Uploading results into container
2025-05-18 20:42:20,399:INFO:Uploading model into container now
2025-05-18 20:42:20,402:INFO:_master_model_container: 9
2025-05-18 20:42:20,402:INFO:_display_container: 2
2025-05-18 20:42:20,404:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-18 20:42:20,404:INFO:create_model() successfully completed......................................
2025-05-18 20:42:20,666:INFO:SubProcess create_model() end ==================================
2025-05-18 20:42:20,666:INFO:Creating metrics dataframe
2025-05-18 20:42:20,670:INFO:Initializing Gradient Boosting Classifier
2025-05-18 20:42:20,670:INFO:Total runtime is 0.870830217997233 minutes
2025-05-18 20:42:20,671:INFO:SubProcess create_model() called ==================================
2025-05-18 20:42:20,672:INFO:Initializing create_model()
2025-05-18 20:42:20,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:42:20,672:INFO:Checking exceptions
2025-05-18 20:42:20,672:INFO:Importing libraries
2025-05-18 20:42:20,672:INFO:Copying training dataset
2025-05-18 20:42:20,685:INFO:Defining folds
2025-05-18 20:42:20,685:INFO:Declaring metric variables
2025-05-18 20:42:20,686:INFO:Importing untrained model
2025-05-18 20:42:20,687:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 20:42:20,689:INFO:Starting cross validation
2025-05-18 20:42:20,694:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:42:35,286:INFO:Calculating mean and std
2025-05-18 20:42:35,288:INFO:Creating metrics dataframe
2025-05-18 20:42:35,290:INFO:Uploading results into container
2025-05-18 20:42:35,290:INFO:Uploading model into container now
2025-05-18 20:42:35,290:INFO:_master_model_container: 10
2025-05-18 20:42:35,290:INFO:_display_container: 2
2025-05-18 20:42:35,290:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 20:42:35,290:INFO:create_model() successfully completed......................................
2025-05-18 20:42:35,453:INFO:SubProcess create_model() end ==================================
2025-05-18 20:42:35,453:INFO:Creating metrics dataframe
2025-05-18 20:42:35,457:INFO:Initializing Linear Discriminant Analysis
2025-05-18 20:42:35,457:INFO:Total runtime is 1.1172819177309672 minutes
2025-05-18 20:42:35,458:INFO:SubProcess create_model() called ==================================
2025-05-18 20:42:35,459:INFO:Initializing create_model()
2025-05-18 20:42:35,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:42:35,459:INFO:Checking exceptions
2025-05-18 20:42:35,459:INFO:Importing libraries
2025-05-18 20:42:35,459:INFO:Copying training dataset
2025-05-18 20:42:35,469:INFO:Defining folds
2025-05-18 20:42:35,469:INFO:Declaring metric variables
2025-05-18 20:42:35,470:INFO:Importing untrained model
2025-05-18 20:42:35,471:INFO:Linear Discriminant Analysis Imported successfully
2025-05-18 20:42:35,473:INFO:Starting cross validation
2025-05-18 20:42:35,476:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:42:39,472:INFO:Calculating mean and std
2025-05-18 20:42:39,473:INFO:Creating metrics dataframe
2025-05-18 20:42:39,474:INFO:Uploading results into container
2025-05-18 20:42:39,474:INFO:Uploading model into container now
2025-05-18 20:42:39,475:INFO:_master_model_container: 11
2025-05-18 20:42:39,475:INFO:_display_container: 2
2025-05-18 20:42:39,475:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-18 20:42:39,475:INFO:create_model() successfully completed......................................
2025-05-18 20:42:39,721:INFO:SubProcess create_model() end ==================================
2025-05-18 20:42:39,721:INFO:Creating metrics dataframe
2025-05-18 20:42:39,726:INFO:Initializing Extra Trees Classifier
2025-05-18 20:42:39,726:INFO:Total runtime is 1.188424817721049 minutes
2025-05-18 20:42:39,727:INFO:SubProcess create_model() called ==================================
2025-05-18 20:42:39,727:INFO:Initializing create_model()
2025-05-18 20:42:39,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:42:39,727:INFO:Checking exceptions
2025-05-18 20:42:39,727:INFO:Importing libraries
2025-05-18 20:42:39,728:INFO:Copying training dataset
2025-05-18 20:42:39,743:INFO:Defining folds
2025-05-18 20:42:39,743:INFO:Declaring metric variables
2025-05-18 20:42:39,745:INFO:Importing untrained model
2025-05-18 20:42:39,746:INFO:Extra Trees Classifier Imported successfully
2025-05-18 20:42:39,749:INFO:Starting cross validation
2025-05-18 20:42:39,752:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:42:46,544:INFO:Calculating mean and std
2025-05-18 20:42:46,553:INFO:Creating metrics dataframe
2025-05-18 20:42:46,559:INFO:Uploading results into container
2025-05-18 20:42:46,560:INFO:Uploading model into container now
2025-05-18 20:42:46,560:INFO:_master_model_container: 12
2025-05-18 20:42:46,560:INFO:_display_container: 2
2025-05-18 20:42:46,561:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-18 20:42:46,561:INFO:create_model() successfully completed......................................
2025-05-18 20:42:46,839:INFO:SubProcess create_model() end ==================================
2025-05-18 20:42:46,839:INFO:Creating metrics dataframe
2025-05-18 20:42:46,844:INFO:Initializing Light Gradient Boosting Machine
2025-05-18 20:42:46,844:INFO:Total runtime is 1.307060166200002 minutes
2025-05-18 20:42:46,845:INFO:SubProcess create_model() called ==================================
2025-05-18 20:42:46,845:INFO:Initializing create_model()
2025-05-18 20:42:46,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:42:46,846:INFO:Checking exceptions
2025-05-18 20:42:46,846:INFO:Importing libraries
2025-05-18 20:42:46,846:INFO:Copying training dataset
2025-05-18 20:42:46,861:INFO:Defining folds
2025-05-18 20:42:46,861:INFO:Declaring metric variables
2025-05-18 20:42:46,862:INFO:Importing untrained model
2025-05-18 20:42:46,864:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 20:42:46,866:INFO:Starting cross validation
2025-05-18 20:42:46,870:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:42:53,267:INFO:Calculating mean and std
2025-05-18 20:42:53,268:INFO:Creating metrics dataframe
2025-05-18 20:42:53,269:INFO:Uploading results into container
2025-05-18 20:42:53,270:INFO:Uploading model into container now
2025-05-18 20:42:53,270:INFO:_master_model_container: 13
2025-05-18 20:42:53,270:INFO:_display_container: 2
2025-05-18 20:42:53,270:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 20:42:53,270:INFO:create_model() successfully completed......................................
2025-05-18 20:42:53,462:INFO:SubProcess create_model() end ==================================
2025-05-18 20:42:53,462:INFO:Creating metrics dataframe
2025-05-18 20:42:53,467:INFO:Initializing CatBoost Classifier
2025-05-18 20:42:53,467:INFO:Total runtime is 1.4174427668253582 minutes
2025-05-18 20:42:53,468:INFO:SubProcess create_model() called ==================================
2025-05-18 20:42:53,468:INFO:Initializing create_model()
2025-05-18 20:42:53,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:42:53,469:INFO:Checking exceptions
2025-05-18 20:42:53,469:INFO:Importing libraries
2025-05-18 20:42:53,469:INFO:Copying training dataset
2025-05-18 20:42:53,478:INFO:Defining folds
2025-05-18 20:42:53,478:INFO:Declaring metric variables
2025-05-18 20:42:53,479:INFO:Importing untrained model
2025-05-18 20:42:53,481:INFO:CatBoost Classifier Imported successfully
2025-05-18 20:42:53,483:INFO:Starting cross validation
2025-05-18 20:42:53,486:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:43:10,053:INFO:Calculating mean and std
2025-05-18 20:43:10,057:INFO:Creating metrics dataframe
2025-05-18 20:43:10,064:INFO:Uploading results into container
2025-05-18 20:43:10,066:INFO:Uploading model into container now
2025-05-18 20:43:10,068:INFO:_master_model_container: 14
2025-05-18 20:43:10,068:INFO:_display_container: 2
2025-05-18 20:43:10,068:INFO:<catboost.core.CatBoostClassifier object at 0x373e6d350>
2025-05-18 20:43:10,068:INFO:create_model() successfully completed......................................
2025-05-18 20:43:10,366:INFO:SubProcess create_model() end ==================================
2025-05-18 20:43:10,366:INFO:Creating metrics dataframe
2025-05-18 20:43:10,371:INFO:Initializing Dummy Classifier
2025-05-18 20:43:10,371:INFO:Total runtime is 1.6991735498110454 minutes
2025-05-18 20:43:10,372:INFO:SubProcess create_model() called ==================================
2025-05-18 20:43:10,372:INFO:Initializing create_model()
2025-05-18 20:43:10,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x364111350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:43:10,372:INFO:Checking exceptions
2025-05-18 20:43:10,373:INFO:Importing libraries
2025-05-18 20:43:10,373:INFO:Copying training dataset
2025-05-18 20:43:10,393:INFO:Defining folds
2025-05-18 20:43:10,393:INFO:Declaring metric variables
2025-05-18 20:43:10,394:INFO:Importing untrained model
2025-05-18 20:43:10,395:INFO:Dummy Classifier Imported successfully
2025-05-18 20:43:10,397:INFO:Starting cross validation
2025-05-18 20:43:10,402:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:43:14,540:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 20:43:14,576:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 20:43:14,725:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 20:43:15,024:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 20:43:15,026:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 20:43:15,035:INFO:Calculating mean and std
2025-05-18 20:43:15,037:INFO:Creating metrics dataframe
2025-05-18 20:43:15,041:INFO:Uploading results into container
2025-05-18 20:43:15,041:INFO:Uploading model into container now
2025-05-18 20:43:15,042:INFO:_master_model_container: 15
2025-05-18 20:43:15,042:INFO:_display_container: 2
2025-05-18 20:43:15,042:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-18 20:43:15,043:INFO:create_model() successfully completed......................................
2025-05-18 20:43:15,229:INFO:SubProcess create_model() end ==================================
2025-05-18 20:43:15,229:INFO:Creating metrics dataframe
2025-05-18 20:43:15,234:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-18 20:43:15,237:INFO:Initializing create_model()
2025-05-18 20:43:15,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:43:15,237:INFO:Checking exceptions
2025-05-18 20:43:15,238:INFO:Importing libraries
2025-05-18 20:43:15,238:INFO:Copying training dataset
2025-05-18 20:43:15,248:INFO:Defining folds
2025-05-18 20:43:15,248:INFO:Declaring metric variables
2025-05-18 20:43:15,248:INFO:Importing untrained model
2025-05-18 20:43:15,248:INFO:Declaring custom model
2025-05-18 20:43:15,249:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 20:43:15,252:INFO:Cross validation set to False
2025-05-18 20:43:15,252:INFO:Fitting Model
2025-05-18 20:43:16,632:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 20:43:16,643:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005129 seconds.
2025-05-18 20:43:16,643:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:43:16,643:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:43:16,643:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:43:16,644:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 20:43:16,644:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:43:17,737:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 20:43:17,737:INFO:create_model() successfully completed......................................
2025-05-18 20:43:17,950:INFO:Initializing create_model()
2025-05-18 20:43:17,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:43:17,950:INFO:Checking exceptions
2025-05-18 20:43:17,951:INFO:Importing libraries
2025-05-18 20:43:17,951:INFO:Copying training dataset
2025-05-18 20:43:17,962:INFO:Defining folds
2025-05-18 20:43:17,962:INFO:Declaring metric variables
2025-05-18 20:43:17,962:INFO:Importing untrained model
2025-05-18 20:43:17,962:INFO:Declaring custom model
2025-05-18 20:43:17,963:INFO:Logistic Regression Imported successfully
2025-05-18 20:43:17,965:INFO:Cross validation set to False
2025-05-18 20:43:17,965:INFO:Fitting Model
2025-05-18 20:43:18,988:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 20:43:18,998:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005312 seconds.
2025-05-18 20:43:18,998:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:43:18,998:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:43:18,998:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:43:18,999:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 20:43:18,999:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:43:20,675:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-18 20:43:20,675:INFO:create_model() successfully completed......................................
2025-05-18 20:43:20,863:INFO:Initializing create_model()
2025-05-18 20:43:20,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:43:20,864:INFO:Checking exceptions
2025-05-18 20:43:20,865:INFO:Importing libraries
2025-05-18 20:43:20,865:INFO:Copying training dataset
2025-05-18 20:43:20,875:INFO:Defining folds
2025-05-18 20:43:20,875:INFO:Declaring metric variables
2025-05-18 20:43:20,875:INFO:Importing untrained model
2025-05-18 20:43:20,875:INFO:Declaring custom model
2025-05-18 20:43:20,875:INFO:Ridge Classifier Imported successfully
2025-05-18 20:43:20,878:INFO:Cross validation set to False
2025-05-18 20:43:20,878:INFO:Fitting Model
2025-05-18 20:43:21,866:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 20:43:21,876:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004954 seconds.
2025-05-18 20:43:21,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:43:21,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:43:21,876:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:43:21,876:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 20:43:21,877:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:43:22,955:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-18 20:43:22,955:INFO:create_model() successfully completed......................................
2025-05-18 20:43:23,128:INFO:_master_model_container: 15
2025-05-18 20:43:23,128:INFO:_display_container: 2
2025-05-18 20:43:23,129:INFO:[QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)]
2025-05-18 20:43:23,129:INFO:compare_models() successfully completed......................................
2025-05-18 20:43:23,135:INFO:Initializing evaluate_model()
2025-05-18 20:43:23,135:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-18 20:43:23,143:INFO:Initializing plot_model()
2025-05-18 20:43:23,143:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-18 20:43:23,143:INFO:Checking exceptions
2025-05-18 20:43:23,147:INFO:Preloading libraries
2025-05-18 20:43:23,147:INFO:Copying training dataset
2025-05-18 20:43:23,147:INFO:Plot type: pipeline
2025-05-18 20:43:23,234:INFO:Visual Rendered Successfully
2025-05-18 20:43:23,408:INFO:plot_model() successfully completed......................................
2025-05-18 20:43:23,410:INFO:Initializing tune_model()
2025-05-18 20:43:23,410:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-18 20:43:23,410:INFO:Checking exceptions
2025-05-18 20:43:23,419:INFO:Copying training dataset
2025-05-18 20:43:23,426:INFO:Checking base model
2025-05-18 20:43:23,426:INFO:Base model : Quadratic Discriminant Analysis
2025-05-18 20:43:23,427:INFO:Declaring metric variables
2025-05-18 20:43:23,429:INFO:Defining Hyperparameters
2025-05-18 20:43:23,592:INFO:Tuning with n_jobs=-1
2025-05-18 20:43:23,592:INFO:Initializing RandomizedSearchCV
2025-05-18 20:43:58,949:INFO:best_params: {'actual_estimator__reg_param': 0.14}
2025-05-18 20:43:58,952:INFO:Hyperparameter search completed
2025-05-18 20:43:58,952:INFO:SubProcess create_model() called ==================================
2025-05-18 20:43:58,953:INFO:Initializing create_model()
2025-05-18 20:43:58,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x363f6f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_param': 0.14})
2025-05-18 20:43:58,953:INFO:Checking exceptions
2025-05-18 20:43:58,953:INFO:Importing libraries
2025-05-18 20:43:58,953:INFO:Copying training dataset
2025-05-18 20:43:58,968:INFO:Defining folds
2025-05-18 20:43:58,968:INFO:Declaring metric variables
2025-05-18 20:43:58,972:INFO:Importing untrained model
2025-05-18 20:43:58,972:INFO:Declaring custom model
2025-05-18 20:43:58,975:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 20:43:58,977:INFO:Starting cross validation
2025-05-18 20:43:58,983:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:44:03,145:INFO:Calculating mean and std
2025-05-18 20:44:03,146:INFO:Creating metrics dataframe
2025-05-18 20:44:03,148:INFO:Finalizing model
2025-05-18 20:44:04,148:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 20:44:04,159:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005029 seconds.
2025-05-18 20:44:04,159:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:44:04,159:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:44:04,159:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:44:04,159:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 20:44:04,159:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:44:05,264:INFO:Uploading results into container
2025-05-18 20:44:05,265:INFO:Uploading model into container now
2025-05-18 20:44:05,266:INFO:_master_model_container: 16
2025-05-18 20:44:05,266:INFO:_display_container: 3
2025-05-18 20:44:05,266:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.14,
                              store_covariance=False, tol=0.0001)
2025-05-18 20:44:05,266:INFO:create_model() successfully completed......................................
2025-05-18 20:44:05,486:INFO:SubProcess create_model() end ==================================
2025-05-18 20:44:05,486:INFO:choose_better activated
2025-05-18 20:44:05,487:INFO:SubProcess create_model() called ==================================
2025-05-18 20:44:05,488:INFO:Initializing create_model()
2025-05-18 20:44:05,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:44:05,488:INFO:Checking exceptions
2025-05-18 20:44:05,489:INFO:Importing libraries
2025-05-18 20:44:05,489:INFO:Copying training dataset
2025-05-18 20:44:05,499:INFO:Defining folds
2025-05-18 20:44:05,499:INFO:Declaring metric variables
2025-05-18 20:44:05,499:INFO:Importing untrained model
2025-05-18 20:44:05,499:INFO:Declaring custom model
2025-05-18 20:44:05,500:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 20:44:05,500:INFO:Starting cross validation
2025-05-18 20:44:05,502:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:44:09,438:INFO:Calculating mean and std
2025-05-18 20:44:09,439:INFO:Creating metrics dataframe
2025-05-18 20:44:09,440:INFO:Finalizing model
2025-05-18 20:44:10,450:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 20:44:10,461:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005223 seconds.
2025-05-18 20:44:10,461:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:44:10,461:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:44:10,461:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:44:10,461:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 20:44:10,462:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:44:11,543:INFO:Uploading results into container
2025-05-18 20:44:11,543:INFO:Uploading model into container now
2025-05-18 20:44:11,543:INFO:_master_model_container: 17
2025-05-18 20:44:11,543:INFO:_display_container: 4
2025-05-18 20:44:11,543:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 20:44:11,543:INFO:create_model() successfully completed......................................
2025-05-18 20:44:11,698:INFO:SubProcess create_model() end ==================================
2025-05-18 20:44:11,698:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) result for F1 is 0.2698
2025-05-18 20:44:11,698:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.14,
                              store_covariance=False, tol=0.0001) result for F1 is 0.2479
2025-05-18 20:44:11,699:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) is best model
2025-05-18 20:44:11,699:INFO:choose_better completed
2025-05-18 20:44:11,699:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-18 20:44:11,703:INFO:_master_model_container: 17
2025-05-18 20:44:11,703:INFO:_display_container: 3
2025-05-18 20:44:11,703:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 20:44:11,703:INFO:tune_model() successfully completed......................................
2025-05-18 20:44:11,859:INFO:Initializing evaluate_model()
2025-05-18 20:44:11,859:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-18 20:44:11,866:INFO:Initializing plot_model()
2025-05-18 20:44:11,866:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-18 20:44:11,866:INFO:Checking exceptions
2025-05-18 20:44:11,875:INFO:Preloading libraries
2025-05-18 20:44:11,875:INFO:Copying training dataset
2025-05-18 20:44:11,875:INFO:Plot type: pipeline
2025-05-18 20:44:11,941:INFO:Visual Rendered Successfully
2025-05-18 20:44:12,100:INFO:plot_model() successfully completed......................................
2025-05-18 20:44:12,102:INFO:Initializing interpret_model()
2025-05-18 20:44:12,102:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-18 20:44:12,102:INFO:Checking exceptions
2025-05-18 20:44:12,102:INFO:Soft dependency imported: shap: 0.47.2
2025-05-18 20:44:12,102:INFO:Initializing finalize_model()
2025-05-18 20:44:12,102:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-18 20:44:12,102:INFO:Finalizing QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 20:44:12,106:INFO:Initializing create_model()
2025-05-18 20:44:12,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:44:12,106:INFO:Checking exceptions
2025-05-18 20:44:12,106:INFO:Importing libraries
2025-05-18 20:44:12,107:INFO:Copying training dataset
2025-05-18 20:44:12,107:INFO:Defining folds
2025-05-18 20:44:12,107:INFO:Declaring metric variables
2025-05-18 20:44:12,107:INFO:Importing untrained model
2025-05-18 20:44:12,107:INFO:Declaring custom model
2025-05-18 20:44:12,107:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 20:44:12,109:INFO:Cross validation set to False
2025-05-18 20:44:12,109:INFO:Fitting Model
2025-05-18 20:44:13,509:INFO:[LightGBM] [Info] Number of positive: 61360, number of negative: 61360
2025-05-18 20:44:13,522:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006049 seconds.
2025-05-18 20:44:13,522:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:44:13,522:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:44:13,522:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:44:13,522:INFO:[LightGBM] [Info] Number of data points in the train set: 122720, number of used features: 28
2025-05-18 20:44:13,523:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:44:14,675:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=12,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False)
2025-05-18 20:44:14,676:INFO:create_model() successfully completed......................................
2025-05-18 20:44:14,825:INFO:_master_model_container: 17
2025-05-18 20:44:14,825:INFO:_display_container: 3
2025-05-18 20:44:14,849:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=12,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False)
2025-05-18 20:44:14,849:INFO:finalize_model() successfully completed......................................
2025-05-18 20:44:15,059:INFO:Initializing save_model()
2025-05-18 20:44:15,059:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=12,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=12,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-18 20:44:15,059:INFO:Adding model into prep_pipe
2025-05-18 20:44:15,059:WARNING:Only Model saved as it was a pipeline.
2025-05-18 20:44:15,066:INFO:final_cancer_model.pkl saved in current working directory
2025-05-18 20:44:15,089:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=12,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False)
2025-05-18 20:44:15,089:INFO:save_model() successfully completed......................................
2025-05-18 20:44:15,276:INFO:Initializing predict_model()
2025-05-18 20:44:15,276:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=12,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x32e771080>)
2025-05-18 20:44:15,276:INFO:Checking exceptions
2025-05-18 20:44:15,276:INFO:Preloading libraries
2025-05-18 20:44:15,277:INFO:Set up data.
2025-05-18 20:44:15,294:INFO:Set up index.
2025-05-18 20:44:15,604:INFO:Initializing blend_models()
2025-05-18 20:44:15,604:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator_list=[QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-18 20:44:15,604:INFO:Checking exceptions
2025-05-18 20:44:15,604:INFO:Estimator RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-05-18 20:44:15,612:INFO:Importing libraries
2025-05-18 20:44:15,612:INFO:Copying training dataset
2025-05-18 20:44:15,614:INFO:Getting model names
2025-05-18 20:44:15,615:INFO:SubProcess create_model() called ==================================
2025-05-18 20:44:15,616:INFO:Initializing create_model()
2025-05-18 20:44:15,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x32fafbb50>, estimator=VotingClassifier(estimators=[('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=None,
                                              copy_X=True, fit_intercept=True,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x356220f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:44:15,616:INFO:Checking exceptions
2025-05-18 20:44:15,616:INFO:Importing libraries
2025-05-18 20:44:15,616:INFO:Copying training dataset
2025-05-18 20:44:15,625:INFO:Defining folds
2025-05-18 20:44:15,625:INFO:Declaring metric variables
2025-05-18 20:44:15,626:INFO:Importing untrained model
2025-05-18 20:44:15,626:INFO:Declaring custom model
2025-05-18 20:44:15,628:INFO:Voting Classifier Imported successfully
2025-05-18 20:44:15,630:INFO:Starting cross validation
2025-05-18 20:44:15,633:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-18 20:44:19,829:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-05-18 20:44:19,922:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-05-18 20:44:20,152:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-05-18 20:44:20,158:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-05-18 20:44:20,250:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-05-18 20:44:20,268:INFO:Calculating mean and std
2025-05-18 20:44:20,269:INFO:Creating metrics dataframe
2025-05-18 20:44:20,272:INFO:Finalizing model
2025-05-18 20:44:21,297:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 20:44:21,307:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005031 seconds.
2025-05-18 20:44:21,307:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:44:21,307:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:44:21,307:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:44:21,307:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 20:44:21,308:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:49:37,608:INFO:PyCaret ClassificationExperiment
2025-05-18 20:49:37,608:INFO:Logging name: clf-default-name
2025-05-18 20:49:37,608:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-18 20:49:37,608:INFO:version 3.3.2
2025-05-18 20:49:37,608:INFO:Initializing setup()
2025-05-18 20:49:37,608:INFO:self.USI: 5a0e
2025-05-18 20:49:37,608:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-18 20:49:37,608:INFO:Checking environment
2025-05-18 20:49:37,608:INFO:python_version: 3.11.0
2025-05-18 20:49:37,608:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-18 20:49:37,609:INFO:machine: arm64
2025-05-18 20:49:37,609:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-18 20:49:37,609:INFO:Memory: svmem(total=17179869184, available=4280664064, percent=75.1, used=6957826048, free=61636608, active=4252385280, inactive=4209573888, wired=2705440768)
2025-05-18 20:49:37,609:INFO:Physical Core: 12
2025-05-18 20:49:37,609:INFO:Logical Core: 12
2025-05-18 20:49:37,609:INFO:Checking libraries
2025-05-18 20:49:37,609:INFO:System:
2025-05-18 20:49:37,609:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-18 20:49:37,609:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-18 20:49:37,609:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-18 20:49:37,609:INFO:PyCaret required dependencies:
2025-05-18 20:49:37,609:INFO:                 pip: 22.3
2025-05-18 20:49:37,609:INFO:          setuptools: 65.5.0
2025-05-18 20:49:37,609:INFO:             pycaret: 3.3.2
2025-05-18 20:49:37,609:INFO:             IPython: 9.2.0
2025-05-18 20:49:37,609:INFO:          ipywidgets: 8.1.7
2025-05-18 20:49:37,609:INFO:                tqdm: 4.67.1
2025-05-18 20:49:37,609:INFO:               numpy: 1.26.4
2025-05-18 20:49:37,609:INFO:              pandas: 2.1.4
2025-05-18 20:49:37,609:INFO:              jinja2: 3.1.6
2025-05-18 20:49:37,609:INFO:               scipy: 1.11.4
2025-05-18 20:49:37,609:INFO:              joblib: 1.3.2
2025-05-18 20:49:37,609:INFO:             sklearn: 1.4.2
2025-05-18 20:49:37,609:INFO:                pyod: 2.0.5
2025-05-18 20:49:37,609:INFO:            imblearn: 0.13.0
2025-05-18 20:49:37,609:INFO:   category_encoders: 2.7.0
2025-05-18 20:49:37,609:INFO:            lightgbm: 4.6.0
2025-05-18 20:49:37,609:INFO:               numba: 0.61.2
2025-05-18 20:49:37,609:INFO:            requests: 2.32.3
2025-05-18 20:49:37,609:INFO:          matplotlib: 3.7.5
2025-05-18 20:49:37,609:INFO:          scikitplot: 0.3.7
2025-05-18 20:49:37,609:INFO:         yellowbrick: 1.5
2025-05-18 20:49:37,609:INFO:              plotly: 5.24.1
2025-05-18 20:49:37,609:INFO:    plotly-resampler: Not installed
2025-05-18 20:49:37,609:INFO:             kaleido: 0.2.1
2025-05-18 20:49:37,609:INFO:           schemdraw: 0.15
2025-05-18 20:49:37,609:INFO:         statsmodels: 0.14.4
2025-05-18 20:49:37,609:INFO:              sktime: 0.26.0
2025-05-18 20:49:37,609:INFO:               tbats: 1.1.3
2025-05-18 20:49:37,609:INFO:            pmdarima: 2.0.4
2025-05-18 20:49:37,609:INFO:              psutil: 7.0.0
2025-05-18 20:49:37,609:INFO:          markupsafe: 3.0.2
2025-05-18 20:49:37,609:INFO:             pickle5: Not installed
2025-05-18 20:49:37,609:INFO:         cloudpickle: 3.1.1
2025-05-18 20:49:37,609:INFO:         deprecation: 2.1.0
2025-05-18 20:49:37,609:INFO:              xxhash: 3.5.0
2025-05-18 20:49:37,609:INFO:           wurlitzer: 3.1.1
2025-05-18 20:49:37,609:INFO:PyCaret optional dependencies:
2025-05-18 20:49:37,609:INFO:                shap: 0.47.2
2025-05-18 20:49:37,609:INFO:           interpret: Not installed
2025-05-18 20:49:37,609:INFO:                umap: Not installed
2025-05-18 20:49:37,609:INFO:     ydata_profiling: Not installed
2025-05-18 20:49:37,609:INFO:  explainerdashboard: Not installed
2025-05-18 20:49:37,609:INFO:             autoviz: Not installed
2025-05-18 20:49:37,609:INFO:           fairlearn: Not installed
2025-05-18 20:49:37,609:INFO:          deepchecks: Not installed
2025-05-18 20:49:37,609:INFO:             xgboost: Not installed
2025-05-18 20:49:37,609:INFO:            catboost: 1.2.8
2025-05-18 20:49:37,609:INFO:              kmodes: Not installed
2025-05-18 20:49:37,609:INFO:             mlxtend: Not installed
2025-05-18 20:49:37,609:INFO:       statsforecast: Not installed
2025-05-18 20:49:37,609:INFO:        tune_sklearn: Not installed
2025-05-18 20:49:37,609:INFO:                 ray: Not installed
2025-05-18 20:49:37,609:INFO:            hyperopt: Not installed
2025-05-18 20:49:37,609:INFO:              optuna: 4.3.0
2025-05-18 20:49:37,609:INFO:               skopt: Not installed
2025-05-18 20:49:37,609:INFO:              mlflow: Not installed
2025-05-18 20:49:37,609:INFO:              gradio: Not installed
2025-05-18 20:49:37,609:INFO:             fastapi: Not installed
2025-05-18 20:49:37,609:INFO:             uvicorn: Not installed
2025-05-18 20:49:37,609:INFO:              m2cgen: Not installed
2025-05-18 20:49:37,610:INFO:           evidently: Not installed
2025-05-18 20:49:37,610:INFO:               fugue: Not installed
2025-05-18 20:49:37,610:INFO:           streamlit: Not installed
2025-05-18 20:49:37,610:INFO:             prophet: Not installed
2025-05-18 20:49:37,610:INFO:None
2025-05-18 20:49:37,610:INFO:Set up data.
2025-05-18 20:49:37,642:INFO:Set up folding strategy.
2025-05-18 20:49:37,642:INFO:Set up train/test split.
2025-05-18 20:49:37,658:INFO:Set up index.
2025-05-18 20:49:37,659:INFO:Assigning column types.
2025-05-18 20:49:37,663:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-18 20:49:37,680:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 20:49:37,681:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 20:49:37,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:49:37,692:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:49:37,709:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 20:49:37,709:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 20:49:37,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:49:37,720:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:49:37,720:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-18 20:49:37,738:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 20:49:37,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:49:37,749:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:49:37,767:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 20:49:37,778:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:49:37,778:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:49:37,778:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-18 20:49:37,807:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:49:37,807:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:49:37,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:49:37,835:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:49:37,836:INFO:Preparing preprocessing pipeline...
2025-05-18 20:49:37,837:INFO:Set up simple imputation.
2025-05-18 20:49:37,843:INFO:Set up encoding of ordinal features.
2025-05-18 20:49:37,852:INFO:Set up encoding of categorical features.
2025-05-18 20:49:37,852:INFO:Set up imbalanced handling.
2025-05-18 20:49:37,852:INFO:Set up column transformation.
2025-05-18 20:49:37,852:INFO:Set up feature selection.
2025-05-18 20:49:37,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:49:37,880:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:49:39,306:INFO:Finished creating preprocessing pipeline.
2025-05-18 20:49:39,329:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=14,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-05-18 20:49:39,329:INFO:Creating final display dataframe.
2025-05-18 20:49:39,746:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 15)
5   Transformed train set shape       (85902, 15)
6    Transformed test set shape       (20919, 15)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19            Feature selection              True
20     Feature selection method           classic
21  Feature selection estimator          lightgbm
22  Number of features selected              0.95
23               Fold Generator   StratifiedKFold
24                  Fold Number                 5
25                     CPU Jobs                 1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              5a0e
2025-05-18 20:49:39,778:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:49:39,778:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:49:39,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:49:39,808:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:49:39,809:INFO:setup() successfully completed in 2.2s...............
2025-05-18 20:49:39,809:INFO:Initializing compare_models()
2025-05-18 20:49:39,810:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-18 20:49:39,810:INFO:Checking exceptions
2025-05-18 20:49:39,814:INFO:Preparing display monitor
2025-05-18 20:49:39,823:INFO:Initializing Logistic Regression
2025-05-18 20:49:39,823:INFO:Total runtime is 1.3470649719238282e-06 minutes
2025-05-18 20:49:39,824:INFO:SubProcess create_model() called ==================================
2025-05-18 20:49:39,824:INFO:Initializing create_model()
2025-05-18 20:49:39,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:49:39,824:INFO:Checking exceptions
2025-05-18 20:49:39,824:INFO:Importing libraries
2025-05-18 20:49:39,824:INFO:Copying training dataset
2025-05-18 20:49:39,835:INFO:Defining folds
2025-05-18 20:49:39,835:INFO:Declaring metric variables
2025-05-18 20:49:39,836:INFO:Importing untrained model
2025-05-18 20:49:39,838:INFO:Logistic Regression Imported successfully
2025-05-18 20:49:39,840:INFO:Starting cross validation
2025-05-18 20:49:39,843:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:49:40,631:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:49:40,640:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004193 seconds.
2025-05-18 20:49:40,640:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:49:40,640:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:49:40,640:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:49:40,640:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:49:40,640:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:49:43,056:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:49:43,065:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004385 seconds.
2025-05-18 20:49:43,065:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:49:43,065:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:49:43,066:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:49:43,066:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:49:43,066:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:49:45,427:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:49:45,436:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004707 seconds.
2025-05-18 20:49:45,436:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:49:45,436:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:49:45,436:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:49:45,437:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:49:45,437:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:49:47,719:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:49:47,728:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004333 seconds.
2025-05-18 20:49:47,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:49:47,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:49:47,728:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:49:47,728:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:49:47,728:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:49:50,064:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:49:50,073:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004374 seconds.
2025-05-18 20:49:50,073:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:49:50,073:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:49:50,073:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:49:50,073:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:49:50,073:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:49:52,027:INFO:Calculating mean and std
2025-05-18 20:49:52,028:INFO:Creating metrics dataframe
2025-05-18 20:49:52,029:INFO:Uploading results into container
2025-05-18 20:49:52,029:INFO:Uploading model into container now
2025-05-18 20:49:52,029:INFO:_master_model_container: 1
2025-05-18 20:49:52,029:INFO:_display_container: 2
2025-05-18 20:49:52,029:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-18 20:49:52,029:INFO:create_model() successfully completed......................................
2025-05-18 20:49:52,251:INFO:SubProcess create_model() end ==================================
2025-05-18 20:49:52,251:INFO:Creating metrics dataframe
2025-05-18 20:49:52,253:INFO:Initializing K Neighbors Classifier
2025-05-18 20:49:52,253:INFO:Total runtime is 0.20717713435490925 minutes
2025-05-18 20:49:52,255:INFO:SubProcess create_model() called ==================================
2025-05-18 20:49:52,255:INFO:Initializing create_model()
2025-05-18 20:49:52,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:49:52,255:INFO:Checking exceptions
2025-05-18 20:49:52,255:INFO:Importing libraries
2025-05-18 20:49:52,255:INFO:Copying training dataset
2025-05-18 20:49:52,264:INFO:Defining folds
2025-05-18 20:49:52,264:INFO:Declaring metric variables
2025-05-18 20:49:52,266:INFO:Importing untrained model
2025-05-18 20:49:52,267:INFO:K Neighbors Classifier Imported successfully
2025-05-18 20:49:52,269:INFO:Starting cross validation
2025-05-18 20:49:52,272:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:49:53,052:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:49:53,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005745 seconds.
2025-05-18 20:49:53,063:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:49:53,063:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:49:53,063:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:49:53,063:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:49:53,063:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:49:55,984:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:49:55,993:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004395 seconds.
2025-05-18 20:49:55,993:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:49:55,993:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:49:55,993:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:49:55,993:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:49:55,994:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:49:58,859:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:49:58,867:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004092 seconds.
2025-05-18 20:49:58,867:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:49:58,867:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:49:58,867:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:49:58,868:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:49:58,868:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:01,723:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:01,731:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004331 seconds.
2025-05-18 20:50:01,731:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:01,731:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:01,731:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:01,731:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:01,731:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:04,617:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:04,626:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004566 seconds.
2025-05-18 20:50:04,626:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:04,626:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:04,626:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:04,626:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:04,626:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:06,702:INFO:Calculating mean and std
2025-05-18 20:50:06,703:INFO:Creating metrics dataframe
2025-05-18 20:50:06,703:INFO:Uploading results into container
2025-05-18 20:50:06,704:INFO:Uploading model into container now
2025-05-18 20:50:06,704:INFO:_master_model_container: 2
2025-05-18 20:50:06,704:INFO:_display_container: 2
2025-05-18 20:50:06,704:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-18 20:50:06,704:INFO:create_model() successfully completed......................................
2025-05-18 20:50:06,855:INFO:SubProcess create_model() end ==================================
2025-05-18 20:50:06,856:INFO:Creating metrics dataframe
2025-05-18 20:50:06,858:INFO:Initializing Naive Bayes
2025-05-18 20:50:06,858:INFO:Total runtime is 0.4505923668543498 minutes
2025-05-18 20:50:06,859:INFO:SubProcess create_model() called ==================================
2025-05-18 20:50:06,860:INFO:Initializing create_model()
2025-05-18 20:50:06,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:50:06,860:INFO:Checking exceptions
2025-05-18 20:50:06,860:INFO:Importing libraries
2025-05-18 20:50:06,860:INFO:Copying training dataset
2025-05-18 20:50:06,868:INFO:Defining folds
2025-05-18 20:50:06,868:INFO:Declaring metric variables
2025-05-18 20:50:06,870:INFO:Importing untrained model
2025-05-18 20:50:06,871:INFO:Naive Bayes Imported successfully
2025-05-18 20:50:06,872:INFO:Starting cross validation
2025-05-18 20:50:06,875:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:50:07,677:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:50:07,687:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004440 seconds.
2025-05-18 20:50:07,687:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:07,687:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:07,687:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:07,687:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:50:07,687:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:09,600:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:09,609:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004622 seconds.
2025-05-18 20:50:09,609:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:09,609:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:09,609:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:09,609:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:09,610:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:11,549:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:11,557:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004180 seconds.
2025-05-18 20:50:11,557:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:11,557:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:11,557:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:11,557:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:11,558:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:13,429:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:13,438:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004384 seconds.
2025-05-18 20:50:13,438:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:13,438:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:13,438:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:13,438:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:13,438:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:15,357:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:15,366:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004421 seconds.
2025-05-18 20:50:15,366:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:15,366:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:15,366:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:15,366:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:15,367:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:16,465:INFO:Calculating mean and std
2025-05-18 20:50:16,466:INFO:Creating metrics dataframe
2025-05-18 20:50:16,467:INFO:Uploading results into container
2025-05-18 20:50:16,467:INFO:Uploading model into container now
2025-05-18 20:50:16,468:INFO:_master_model_container: 3
2025-05-18 20:50:16,468:INFO:_display_container: 2
2025-05-18 20:50:16,468:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-18 20:50:16,468:INFO:create_model() successfully completed......................................
2025-05-18 20:50:16,630:INFO:SubProcess create_model() end ==================================
2025-05-18 20:50:16,630:INFO:Creating metrics dataframe
2025-05-18 20:50:16,633:INFO:Initializing Decision Tree Classifier
2025-05-18 20:50:16,633:INFO:Total runtime is 0.6135057131449382 minutes
2025-05-18 20:50:16,634:INFO:SubProcess create_model() called ==================================
2025-05-18 20:50:16,634:INFO:Initializing create_model()
2025-05-18 20:50:16,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:50:16,635:INFO:Checking exceptions
2025-05-18 20:50:16,635:INFO:Importing libraries
2025-05-18 20:50:16,635:INFO:Copying training dataset
2025-05-18 20:50:16,643:INFO:Defining folds
2025-05-18 20:50:16,643:INFO:Declaring metric variables
2025-05-18 20:50:16,644:INFO:Importing untrained model
2025-05-18 20:50:16,646:INFO:Decision Tree Classifier Imported successfully
2025-05-18 20:50:16,648:INFO:Starting cross validation
2025-05-18 20:50:16,650:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:50:17,416:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:50:17,426:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004648 seconds.
2025-05-18 20:50:17,426:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:17,426:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:17,426:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:17,426:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:50:17,426:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:19,746:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:19,755:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004322 seconds.
2025-05-18 20:50:19,755:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:19,755:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:19,755:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:19,756:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:19,756:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:22,011:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:22,021:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005340 seconds.
2025-05-18 20:50:22,021:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:22,021:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:22,021:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:22,021:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:22,022:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:24,329:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:24,338:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004396 seconds.
2025-05-18 20:50:24,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:24,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:24,338:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:24,338:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:24,338:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:26,668:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:26,677:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004127 seconds.
2025-05-18 20:50:26,677:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:26,677:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:26,677:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:26,678:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:26,678:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:28,173:INFO:Calculating mean and std
2025-05-18 20:50:28,174:INFO:Creating metrics dataframe
2025-05-18 20:50:28,175:INFO:Uploading results into container
2025-05-18 20:50:28,175:INFO:Uploading model into container now
2025-05-18 20:50:28,175:INFO:_master_model_container: 4
2025-05-18 20:50:28,175:INFO:_display_container: 2
2025-05-18 20:50:28,175:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-18 20:50:28,175:INFO:create_model() successfully completed......................................
2025-05-18 20:50:28,341:INFO:SubProcess create_model() end ==================================
2025-05-18 20:50:28,341:INFO:Creating metrics dataframe
2025-05-18 20:50:28,344:INFO:Initializing SVM - Linear Kernel
2025-05-18 20:50:28,344:INFO:Total runtime is 0.8086899638175965 minutes
2025-05-18 20:50:28,345:INFO:SubProcess create_model() called ==================================
2025-05-18 20:50:28,346:INFO:Initializing create_model()
2025-05-18 20:50:28,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:50:28,346:INFO:Checking exceptions
2025-05-18 20:50:28,346:INFO:Importing libraries
2025-05-18 20:50:28,346:INFO:Copying training dataset
2025-05-18 20:50:28,356:INFO:Defining folds
2025-05-18 20:50:28,356:INFO:Declaring metric variables
2025-05-18 20:50:28,357:INFO:Importing untrained model
2025-05-18 20:50:28,359:INFO:SVM - Linear Kernel Imported successfully
2025-05-18 20:50:28,360:INFO:Starting cross validation
2025-05-18 20:50:28,363:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:50:29,197:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:50:29,206:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004099 seconds.
2025-05-18 20:50:29,206:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:29,206:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:29,206:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:29,206:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:50:29,206:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:31,662:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:31,671:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004529 seconds.
2025-05-18 20:50:31,671:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:31,671:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:31,671:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:31,671:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:31,671:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:34,356:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:34,364:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004270 seconds.
2025-05-18 20:50:34,364:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:34,364:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:34,365:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:34,365:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:34,365:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:36,898:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:36,907:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003856 seconds.
2025-05-18 20:50:36,907:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:36,907:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:36,907:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:36,907:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:36,907:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:39,650:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:39,659:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004572 seconds.
2025-05-18 20:50:39,659:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:39,659:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:39,659:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:39,659:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:39,659:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:41,269:INFO:Calculating mean and std
2025-05-18 20:50:41,269:INFO:Creating metrics dataframe
2025-05-18 20:50:41,270:INFO:Uploading results into container
2025-05-18 20:50:41,270:INFO:Uploading model into container now
2025-05-18 20:50:41,271:INFO:_master_model_container: 5
2025-05-18 20:50:41,271:INFO:_display_container: 2
2025-05-18 20:50:41,271:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-18 20:50:41,271:INFO:create_model() successfully completed......................................
2025-05-18 20:50:41,449:INFO:SubProcess create_model() end ==================================
2025-05-18 20:50:41,449:INFO:Creating metrics dataframe
2025-05-18 20:50:41,452:INFO:Initializing Ridge Classifier
2025-05-18 20:50:41,452:INFO:Total runtime is 1.0271569132804872 minutes
2025-05-18 20:50:41,453:INFO:SubProcess create_model() called ==================================
2025-05-18 20:50:41,454:INFO:Initializing create_model()
2025-05-18 20:50:41,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:50:41,454:INFO:Checking exceptions
2025-05-18 20:50:41,454:INFO:Importing libraries
2025-05-18 20:50:41,454:INFO:Copying training dataset
2025-05-18 20:50:41,463:INFO:Defining folds
2025-05-18 20:50:41,463:INFO:Declaring metric variables
2025-05-18 20:50:41,464:INFO:Importing untrained model
2025-05-18 20:50:41,466:INFO:Ridge Classifier Imported successfully
2025-05-18 20:50:41,468:INFO:Starting cross validation
2025-05-18 20:50:41,471:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:50:42,245:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:50:42,254:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004170 seconds.
2025-05-18 20:50:42,254:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:42,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:42,254:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:42,254:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:50:42,254:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:44,147:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:44,155:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004184 seconds.
2025-05-18 20:50:44,155:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:44,155:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:44,155:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:44,155:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:44,156:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:46,060:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:46,080:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015027 seconds.
2025-05-18 20:50:46,081:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:46,081:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:46,081:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:46,081:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:46,081:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:47,988:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:47,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004417 seconds.
2025-05-18 20:50:47,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:47,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:47,997:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:47,997:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:47,997:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:49,922:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:50:49,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004319 seconds.
2025-05-18 20:50:49,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:49,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:49,930:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:49,931:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:50:49,931:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:50:51,016:INFO:Calculating mean and std
2025-05-18 20:50:51,016:INFO:Creating metrics dataframe
2025-05-18 20:50:51,017:INFO:Uploading results into container
2025-05-18 20:50:51,017:INFO:Uploading model into container now
2025-05-18 20:50:51,018:INFO:_master_model_container: 6
2025-05-18 20:50:51,018:INFO:_display_container: 2
2025-05-18 20:50:51,018:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-18 20:50:51,018:INFO:create_model() successfully completed......................................
2025-05-18 20:50:51,172:INFO:SubProcess create_model() end ==================================
2025-05-18 20:50:51,172:INFO:Creating metrics dataframe
2025-05-18 20:50:51,175:INFO:Initializing Random Forest Classifier
2025-05-18 20:50:51,175:INFO:Total runtime is 1.1892092307408653 minutes
2025-05-18 20:50:51,176:INFO:SubProcess create_model() called ==================================
2025-05-18 20:50:51,177:INFO:Initializing create_model()
2025-05-18 20:50:51,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:50:51,177:INFO:Checking exceptions
2025-05-18 20:50:51,177:INFO:Importing libraries
2025-05-18 20:50:51,177:INFO:Copying training dataset
2025-05-18 20:50:51,185:INFO:Defining folds
2025-05-18 20:50:51,186:INFO:Declaring metric variables
2025-05-18 20:50:51,187:INFO:Importing untrained model
2025-05-18 20:50:51,188:INFO:Random Forest Classifier Imported successfully
2025-05-18 20:50:51,190:INFO:Starting cross validation
2025-05-18 20:50:51,192:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:50:51,974:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:50:51,982:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003922 seconds.
2025-05-18 20:50:51,982:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:50:51,982:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:50:51,982:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:50:51,982:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:50:51,983:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:51:01,337:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:51:01,347:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004630 seconds.
2025-05-18 20:51:01,347:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:51:01,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:51:01,347:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:51:01,347:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:51:01,348:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:51:10,598:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:51:10,607:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004402 seconds.
2025-05-18 20:51:10,607:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:51:10,607:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:51:10,607:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:51:10,607:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:51:10,607:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:51:20,077:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:51:20,087:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004108 seconds.
2025-05-18 20:51:20,087:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:51:20,087:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:51:20,087:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:51:20,087:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:51:20,087:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:51:29,633:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:51:29,642:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004748 seconds.
2025-05-18 20:51:29,642:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:51:29,642:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:51:29,642:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:51:29,642:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:51:29,643:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:51:38,136:INFO:Calculating mean and std
2025-05-18 20:51:38,138:INFO:Creating metrics dataframe
2025-05-18 20:51:38,139:INFO:Uploading results into container
2025-05-18 20:51:38,140:INFO:Uploading model into container now
2025-05-18 20:51:38,140:INFO:_master_model_container: 7
2025-05-18 20:51:38,140:INFO:_display_container: 2
2025-05-18 20:51:38,140:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-18 20:51:38,140:INFO:create_model() successfully completed......................................
2025-05-18 20:51:38,326:INFO:SubProcess create_model() end ==================================
2025-05-18 20:51:38,326:INFO:Creating metrics dataframe
2025-05-18 20:51:38,330:INFO:Initializing Quadratic Discriminant Analysis
2025-05-18 20:51:38,330:INFO:Total runtime is 1.9751204172770183 minutes
2025-05-18 20:51:38,331:INFO:SubProcess create_model() called ==================================
2025-05-18 20:51:38,331:INFO:Initializing create_model()
2025-05-18 20:51:38,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:51:38,332:INFO:Checking exceptions
2025-05-18 20:51:38,332:INFO:Importing libraries
2025-05-18 20:51:38,332:INFO:Copying training dataset
2025-05-18 20:51:38,341:INFO:Defining folds
2025-05-18 20:51:38,341:INFO:Declaring metric variables
2025-05-18 20:51:38,343:INFO:Importing untrained model
2025-05-18 20:51:38,344:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 20:51:38,346:INFO:Starting cross validation
2025-05-18 20:51:38,349:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:51:39,140:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:51:39,149:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004552 seconds.
2025-05-18 20:51:39,149:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:51:39,149:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:51:39,149:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:51:39,149:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:51:39,149:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:51:41,050:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:51:41,059:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004538 seconds.
2025-05-18 20:51:41,059:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:51:41,059:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:51:41,059:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:51:41,060:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:51:41,060:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:51:42,985:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:51:42,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004321 seconds.
2025-05-18 20:51:42,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:51:42,994:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:51:42,994:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:51:42,994:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:51:42,994:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:51:44,919:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:51:44,928:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003987 seconds.
2025-05-18 20:51:44,928:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:51:44,928:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:51:44,928:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:51:44,928:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:51:44,928:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:51:46,865:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:51:46,873:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004072 seconds.
2025-05-18 20:51:46,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:51:46,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:51:46,874:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:51:46,874:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:51:46,874:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:51:47,991:INFO:Calculating mean and std
2025-05-18 20:51:47,992:INFO:Creating metrics dataframe
2025-05-18 20:51:47,993:INFO:Uploading results into container
2025-05-18 20:51:47,993:INFO:Uploading model into container now
2025-05-18 20:51:47,993:INFO:_master_model_container: 8
2025-05-18 20:51:47,993:INFO:_display_container: 2
2025-05-18 20:51:47,993:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 20:51:47,993:INFO:create_model() successfully completed......................................
2025-05-18 20:51:48,162:INFO:SubProcess create_model() end ==================================
2025-05-18 20:51:48,162:INFO:Creating metrics dataframe
2025-05-18 20:51:48,165:INFO:Initializing Ada Boost Classifier
2025-05-18 20:51:48,165:INFO:Total runtime is 2.1390382846196494 minutes
2025-05-18 20:51:48,166:INFO:SubProcess create_model() called ==================================
2025-05-18 20:51:48,166:INFO:Initializing create_model()
2025-05-18 20:51:48,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:51:48,166:INFO:Checking exceptions
2025-05-18 20:51:48,166:INFO:Importing libraries
2025-05-18 20:51:48,166:INFO:Copying training dataset
2025-05-18 20:51:48,176:INFO:Defining folds
2025-05-18 20:51:48,176:INFO:Declaring metric variables
2025-05-18 20:51:48,177:INFO:Importing untrained model
2025-05-18 20:51:48,178:INFO:Ada Boost Classifier Imported successfully
2025-05-18 20:51:48,180:INFO:Starting cross validation
2025-05-18 20:51:48,183:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:51:48,959:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:51:48,968:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004627 seconds.
2025-05-18 20:51:48,968:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:51:48,968:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:51:48,968:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:51:48,968:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:51:48,968:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:51:50,016:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:51:52,973:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:51:52,982:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004591 seconds.
2025-05-18 20:51:52,982:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:51:52,982:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:51:52,982:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:51:52,982:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:51:52,982:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:51:54,040:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:51:57,044:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:51:57,053:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004652 seconds.
2025-05-18 20:51:57,053:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:51:57,053:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:51:57,053:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:51:57,053:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:51:57,054:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:51:58,101:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:52:01,089:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:52:01,097:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004310 seconds.
2025-05-18 20:52:01,097:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:52:01,097:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:52:01,097:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:52:01,098:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:52:01,098:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:52:02,152:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:52:05,165:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:52:05,175:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004397 seconds.
2025-05-18 20:52:05,175:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:52:05,175:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:52:05,175:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:52:05,175:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:52:05,175:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:52:06,226:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:52:08,408:INFO:Calculating mean and std
2025-05-18 20:52:08,409:INFO:Creating metrics dataframe
2025-05-18 20:52:08,410:INFO:Uploading results into container
2025-05-18 20:52:08,410:INFO:Uploading model into container now
2025-05-18 20:52:08,410:INFO:_master_model_container: 9
2025-05-18 20:52:08,410:INFO:_display_container: 2
2025-05-18 20:52:08,410:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-18 20:52:08,410:INFO:create_model() successfully completed......................................
2025-05-18 20:52:08,584:INFO:SubProcess create_model() end ==================================
2025-05-18 20:52:08,584:INFO:Creating metrics dataframe
2025-05-18 20:52:08,588:INFO:Initializing Gradient Boosting Classifier
2025-05-18 20:52:08,588:INFO:Total runtime is 2.4794212460517886 minutes
2025-05-18 20:52:08,589:INFO:SubProcess create_model() called ==================================
2025-05-18 20:52:08,590:INFO:Initializing create_model()
2025-05-18 20:52:08,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:52:08,590:INFO:Checking exceptions
2025-05-18 20:52:08,590:INFO:Importing libraries
2025-05-18 20:52:08,590:INFO:Copying training dataset
2025-05-18 20:52:08,599:INFO:Defining folds
2025-05-18 20:52:08,599:INFO:Declaring metric variables
2025-05-18 20:52:08,600:INFO:Importing untrained model
2025-05-18 20:52:08,601:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 20:52:08,603:INFO:Starting cross validation
2025-05-18 20:52:08,606:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:52:09,372:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:52:09,381:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004468 seconds.
2025-05-18 20:52:09,381:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:52:09,381:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:52:09,381:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:52:09,381:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:52:09,381:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:52:21,844:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:52:21,856:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006277 seconds.
2025-05-18 20:52:21,856:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:52:21,856:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:52:21,856:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:52:21,857:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:52:21,857:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:52:34,225:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:52:34,235:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004645 seconds.
2025-05-18 20:52:34,235:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:52:34,235:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:52:34,235:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:52:34,235:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:52:34,236:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:52:46,592:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:52:46,602:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004508 seconds.
2025-05-18 20:52:46,602:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:52:46,602:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:52:46,602:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:52:46,602:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:52:46,603:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:52:59,190:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:52:59,199:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004053 seconds.
2025-05-18 20:52:59,199:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:52:59,199:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:52:59,199:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:52:59,199:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:52:59,199:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:10,843:INFO:Calculating mean and std
2025-05-18 20:53:10,845:INFO:Creating metrics dataframe
2025-05-18 20:53:10,846:INFO:Uploading results into container
2025-05-18 20:53:10,847:INFO:Uploading model into container now
2025-05-18 20:53:10,847:INFO:_master_model_container: 10
2025-05-18 20:53:10,847:INFO:_display_container: 2
2025-05-18 20:53:10,847:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 20:53:10,847:INFO:create_model() successfully completed......................................
2025-05-18 20:53:11,069:INFO:SubProcess create_model() end ==================================
2025-05-18 20:53:11,069:INFO:Creating metrics dataframe
2025-05-18 20:53:11,073:INFO:Initializing Linear Discriminant Analysis
2025-05-18 20:53:11,073:INFO:Total runtime is 3.52083489894867 minutes
2025-05-18 20:53:11,074:INFO:SubProcess create_model() called ==================================
2025-05-18 20:53:11,075:INFO:Initializing create_model()
2025-05-18 20:53:11,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:53:11,075:INFO:Checking exceptions
2025-05-18 20:53:11,075:INFO:Importing libraries
2025-05-18 20:53:11,075:INFO:Copying training dataset
2025-05-18 20:53:11,085:INFO:Defining folds
2025-05-18 20:53:11,085:INFO:Declaring metric variables
2025-05-18 20:53:11,087:INFO:Importing untrained model
2025-05-18 20:53:11,088:INFO:Linear Discriminant Analysis Imported successfully
2025-05-18 20:53:11,090:INFO:Starting cross validation
2025-05-18 20:53:11,093:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:53:11,905:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:53:11,914:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004618 seconds.
2025-05-18 20:53:11,914:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:11,914:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:11,914:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:53:11,914:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:53:11,914:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:13,867:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:53:13,876:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004392 seconds.
2025-05-18 20:53:13,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:13,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:13,876:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:53:13,876:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:53:13,877:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:15,838:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:53:15,847:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004499 seconds.
2025-05-18 20:53:15,847:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:15,847:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:15,847:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:53:15,847:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:53:15,848:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:17,833:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:53:17,842:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004329 seconds.
2025-05-18 20:53:17,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:17,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:17,842:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:53:17,842:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:53:17,842:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:19,842:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:53:19,851:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004071 seconds.
2025-05-18 20:53:19,851:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:19,851:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:19,851:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:53:19,851:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:53:19,852:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:20,982:INFO:Calculating mean and std
2025-05-18 20:53:20,982:INFO:Creating metrics dataframe
2025-05-18 20:53:20,983:INFO:Uploading results into container
2025-05-18 20:53:20,983:INFO:Uploading model into container now
2025-05-18 20:53:20,984:INFO:_master_model_container: 11
2025-05-18 20:53:20,984:INFO:_display_container: 2
2025-05-18 20:53:20,984:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-18 20:53:20,984:INFO:create_model() successfully completed......................................
2025-05-18 20:53:21,152:INFO:SubProcess create_model() end ==================================
2025-05-18 20:53:21,152:INFO:Creating metrics dataframe
2025-05-18 20:53:21,156:INFO:Initializing Extra Trees Classifier
2025-05-18 20:53:21,156:INFO:Total runtime is 3.6888832966486618 minutes
2025-05-18 20:53:21,157:INFO:SubProcess create_model() called ==================================
2025-05-18 20:53:21,159:INFO:Initializing create_model()
2025-05-18 20:53:21,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:53:21,159:INFO:Checking exceptions
2025-05-18 20:53:21,159:INFO:Importing libraries
2025-05-18 20:53:21,160:INFO:Copying training dataset
2025-05-18 20:53:21,169:INFO:Defining folds
2025-05-18 20:53:21,169:INFO:Declaring metric variables
2025-05-18 20:53:21,170:INFO:Importing untrained model
2025-05-18 20:53:21,172:INFO:Extra Trees Classifier Imported successfully
2025-05-18 20:53:21,174:INFO:Starting cross validation
2025-05-18 20:53:21,177:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:53:21,967:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:53:21,975:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003981 seconds.
2025-05-18 20:53:21,975:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:21,975:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:21,975:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:53:21,975:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:53:21,976:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:27,917:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:53:27,926:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004199 seconds.
2025-05-18 20:53:27,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:27,927:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:27,927:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:53:27,927:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:53:27,927:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:33,837:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:53:33,846:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005351 seconds.
2025-05-18 20:53:33,846:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:33,846:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:33,846:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:53:33,847:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:53:33,847:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:39,796:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:53:39,804:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004313 seconds.
2025-05-18 20:53:39,804:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:39,804:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:39,804:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:53:39,804:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:53:39,804:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:45,752:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:53:45,761:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004409 seconds.
2025-05-18 20:53:45,761:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:45,761:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:45,761:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:53:45,761:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:53:45,762:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:50,868:INFO:Calculating mean and std
2025-05-18 20:53:50,869:INFO:Creating metrics dataframe
2025-05-18 20:53:50,870:INFO:Uploading results into container
2025-05-18 20:53:50,870:INFO:Uploading model into container now
2025-05-18 20:53:50,871:INFO:_master_model_container: 12
2025-05-18 20:53:50,871:INFO:_display_container: 2
2025-05-18 20:53:50,871:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-18 20:53:50,871:INFO:create_model() successfully completed......................................
2025-05-18 20:53:51,034:INFO:SubProcess create_model() end ==================================
2025-05-18 20:53:51,034:INFO:Creating metrics dataframe
2025-05-18 20:53:51,038:INFO:Initializing Light Gradient Boosting Machine
2025-05-18 20:53:51,038:INFO:Total runtime is 4.186927247047425 minutes
2025-05-18 20:53:51,040:INFO:SubProcess create_model() called ==================================
2025-05-18 20:53:51,040:INFO:Initializing create_model()
2025-05-18 20:53:51,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:53:51,040:INFO:Checking exceptions
2025-05-18 20:53:51,040:INFO:Importing libraries
2025-05-18 20:53:51,040:INFO:Copying training dataset
2025-05-18 20:53:51,049:INFO:Defining folds
2025-05-18 20:53:51,049:INFO:Declaring metric variables
2025-05-18 20:53:51,051:INFO:Importing untrained model
2025-05-18 20:53:51,052:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 20:53:51,054:INFO:Starting cross validation
2025-05-18 20:53:51,056:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:53:51,828:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:53:51,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004140 seconds.
2025-05-18 20:53:51,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:51,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:51,836:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:53:51,836:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:53:51,836:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:52,942:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:53:52,953:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004851 seconds.
2025-05-18 20:53:52,953:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:52,953:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:52,953:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 20:53:52,953:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 14
2025-05-18 20:53:52,953:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:54,257:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:53:54,266:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004153 seconds.
2025-05-18 20:53:54,266:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:54,266:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:54,266:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:53:54,266:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:53:54,266:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:55,375:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:53:55,386:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004815 seconds.
2025-05-18 20:53:55,386:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:55,386:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:55,386:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 20:53:55,386:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 14
2025-05-18 20:53:55,386:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:56,705:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:53:56,714:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004433 seconds.
2025-05-18 20:53:56,714:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:56,714:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:56,714:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:53:56,714:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:53:56,714:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:57,818:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:53:57,828:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004760 seconds.
2025-05-18 20:53:57,828:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:57,828:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:57,828:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 20:53:57,828:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 14
2025-05-18 20:53:57,828:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:53:59,186:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:53:59,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004552 seconds.
2025-05-18 20:53:59,195:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:53:59,195:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:53:59,195:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:53:59,195:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:53:59,195:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:54:00,312:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:54:00,322:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004998 seconds.
2025-05-18 20:54:00,322:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:54:00,322:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:54:00,322:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 20:54:00,322:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 14
2025-05-18 20:54:00,323:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:54:01,748:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:54:01,757:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004024 seconds.
2025-05-18 20:54:01,757:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:54:01,757:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:54:01,757:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:54:01,757:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:54:01,757:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:54:02,862:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:54:02,873:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005188 seconds.
2025-05-18 20:54:02,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:54:02,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:54:02,873:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 20:54:02,873:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 14
2025-05-18 20:54:02,873:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:54:03,424:INFO:Calculating mean and std
2025-05-18 20:54:03,425:INFO:Creating metrics dataframe
2025-05-18 20:54:03,426:INFO:Uploading results into container
2025-05-18 20:54:03,426:INFO:Uploading model into container now
2025-05-18 20:54:03,427:INFO:_master_model_container: 13
2025-05-18 20:54:03,427:INFO:_display_container: 2
2025-05-18 20:54:03,427:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 20:54:03,427:INFO:create_model() successfully completed......................................
2025-05-18 20:54:03,612:INFO:SubProcess create_model() end ==================================
2025-05-18 20:54:03,612:INFO:Creating metrics dataframe
2025-05-18 20:54:03,616:INFO:Initializing CatBoost Classifier
2025-05-18 20:54:03,616:INFO:Total runtime is 4.396561833222708 minutes
2025-05-18 20:54:03,618:INFO:SubProcess create_model() called ==================================
2025-05-18 20:54:03,618:INFO:Initializing create_model()
2025-05-18 20:54:03,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:54:03,618:INFO:Checking exceptions
2025-05-18 20:54:03,618:INFO:Importing libraries
2025-05-18 20:54:03,618:INFO:Copying training dataset
2025-05-18 20:54:03,627:INFO:Defining folds
2025-05-18 20:54:03,627:INFO:Declaring metric variables
2025-05-18 20:54:03,629:INFO:Importing untrained model
2025-05-18 20:54:03,630:INFO:CatBoost Classifier Imported successfully
2025-05-18 20:54:03,632:INFO:Starting cross validation
2025-05-18 20:54:03,637:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:54:04,429:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:54:04,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004751 seconds.
2025-05-18 20:54:04,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:54:04,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:54:04,439:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:54:04,439:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:54:04,439:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:54:20,324:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:54:20,333:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004074 seconds.
2025-05-18 20:54:20,333:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:54:20,333:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:54:20,333:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:54:20,333:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:54:20,333:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:54:36,176:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:54:36,186:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004355 seconds.
2025-05-18 20:54:36,186:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:54:36,186:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:54:36,186:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:54:36,186:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:54:36,186:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:54:51,956:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:54:51,966:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004434 seconds.
2025-05-18 20:54:51,966:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:54:51,966:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:54:51,966:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:54:51,966:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:54:51,967:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:55:07,794:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:55:07,803:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004656 seconds.
2025-05-18 20:55:07,803:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:55:07,803:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:55:07,803:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:55:07,803:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:55:07,804:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:55:22,911:INFO:Calculating mean and std
2025-05-18 20:55:22,914:INFO:Creating metrics dataframe
2025-05-18 20:55:22,916:INFO:Uploading results into container
2025-05-18 20:55:22,916:INFO:Uploading model into container now
2025-05-18 20:55:22,917:INFO:_master_model_container: 14
2025-05-18 20:55:22,917:INFO:_display_container: 2
2025-05-18 20:55:22,917:INFO:<catboost.core.CatBoostClassifier object at 0x35671e410>
2025-05-18 20:55:22,917:INFO:create_model() successfully completed......................................
2025-05-18 20:55:23,178:INFO:SubProcess create_model() end ==================================
2025-05-18 20:55:23,178:INFO:Creating metrics dataframe
2025-05-18 20:55:23,183:INFO:Initializing Dummy Classifier
2025-05-18 20:55:23,183:INFO:Total runtime is 5.722674079736075 minutes
2025-05-18 20:55:23,185:INFO:SubProcess create_model() called ==================================
2025-05-18 20:55:23,185:INFO:Initializing create_model()
2025-05-18 20:55:23,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x373e259d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:55:23,185:INFO:Checking exceptions
2025-05-18 20:55:23,185:INFO:Importing libraries
2025-05-18 20:55:23,185:INFO:Copying training dataset
2025-05-18 20:55:23,200:INFO:Defining folds
2025-05-18 20:55:23,200:INFO:Declaring metric variables
2025-05-18 20:55:23,202:INFO:Importing untrained model
2025-05-18 20:55:23,203:INFO:Dummy Classifier Imported successfully
2025-05-18 20:55:23,205:INFO:Starting cross validation
2025-05-18 20:55:23,209:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:55:24,039:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:55:24,048:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004632 seconds.
2025-05-18 20:55:24,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:55:24,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:55:24,048:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:55:24,048:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:55:24,048:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:55:25,157:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 20:55:25,970:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:55:25,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004456 seconds.
2025-05-18 20:55:25,979:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:55:25,979:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:55:25,979:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:55:25,979:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:55:25,980:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:55:27,095:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 20:55:27,895:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:55:27,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004361 seconds.
2025-05-18 20:55:27,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:55:27,904:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:55:27,904:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:55:27,904:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:55:27,905:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:55:28,990:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 20:55:29,791:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:55:29,799:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004401 seconds.
2025-05-18 20:55:29,799:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:55:29,799:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:55:29,799:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:55:29,800:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:55:29,800:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:55:30,910:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 20:55:31,736:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:55:31,745:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004205 seconds.
2025-05-18 20:55:31,745:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:55:31,745:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:55:31,745:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:55:31,745:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:55:31,745:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:55:32,826:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 20:55:32,830:INFO:Calculating mean and std
2025-05-18 20:55:32,831:INFO:Creating metrics dataframe
2025-05-18 20:55:32,832:INFO:Uploading results into container
2025-05-18 20:55:32,832:INFO:Uploading model into container now
2025-05-18 20:55:32,832:INFO:_master_model_container: 15
2025-05-18 20:55:32,832:INFO:_display_container: 2
2025-05-18 20:55:32,832:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-18 20:55:32,832:INFO:create_model() successfully completed......................................
2025-05-18 20:55:32,987:INFO:SubProcess create_model() end ==================================
2025-05-18 20:55:32,987:INFO:Creating metrics dataframe
2025-05-18 20:55:32,992:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-18 20:55:32,995:INFO:Initializing create_model()
2025-05-18 20:55:32,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:55:32,995:INFO:Checking exceptions
2025-05-18 20:55:32,995:INFO:Importing libraries
2025-05-18 20:55:32,995:INFO:Copying training dataset
2025-05-18 20:55:33,004:INFO:Defining folds
2025-05-18 20:55:33,004:INFO:Declaring metric variables
2025-05-18 20:55:33,004:INFO:Importing untrained model
2025-05-18 20:55:33,004:INFO:Declaring custom model
2025-05-18 20:55:33,004:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 20:55:33,007:INFO:Cross validation set to False
2025-05-18 20:55:33,007:INFO:Fitting Model
2025-05-18 20:55:33,992:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 20:55:34,003:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005323 seconds.
2025-05-18 20:55:34,003:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:55:34,003:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:55:34,003:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:55:34,003:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 20:55:34,003:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:55:48,094:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 20:55:48,094:INFO:create_model() successfully completed......................................
2025-05-18 20:55:48,247:INFO:Initializing create_model()
2025-05-18 20:55:48,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:55:48,247:INFO:Checking exceptions
2025-05-18 20:55:48,248:INFO:Importing libraries
2025-05-18 20:55:48,248:INFO:Copying training dataset
2025-05-18 20:55:48,256:INFO:Defining folds
2025-05-18 20:55:48,257:INFO:Declaring metric variables
2025-05-18 20:55:48,257:INFO:Importing untrained model
2025-05-18 20:55:48,257:INFO:Declaring custom model
2025-05-18 20:55:48,257:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 20:55:48,259:INFO:Cross validation set to False
2025-05-18 20:55:48,259:INFO:Fitting Model
2025-05-18 20:55:49,233:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 20:55:49,243:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004940 seconds.
2025-05-18 20:55:49,243:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:55:49,243:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:55:49,243:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:55:49,243:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 20:55:49,244:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:55:50,330:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 20:55:50,330:INFO:create_model() successfully completed......................................
2025-05-18 20:55:50,496:INFO:Initializing create_model()
2025-05-18 20:55:50,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:55:50,496:INFO:Checking exceptions
2025-05-18 20:55:50,497:INFO:Importing libraries
2025-05-18 20:55:50,497:INFO:Copying training dataset
2025-05-18 20:55:50,506:INFO:Defining folds
2025-05-18 20:55:50,506:INFO:Declaring metric variables
2025-05-18 20:55:50,506:INFO:Importing untrained model
2025-05-18 20:55:50,506:INFO:Declaring custom model
2025-05-18 20:55:50,506:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 20:55:50,509:INFO:Cross validation set to False
2025-05-18 20:55:50,509:INFO:Fitting Model
2025-05-18 20:55:51,485:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 20:55:51,495:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005066 seconds.
2025-05-18 20:55:51,495:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:55:51,495:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:55:51,495:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:55:51,496:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 20:55:51,496:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:55:52,624:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 20:55:52,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006009 seconds.
2025-05-18 20:55:52,637:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:55:52,637:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:55:52,637:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 20:55:52,637:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 14
2025-05-18 20:55:52,638:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:55:53,044:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 20:55:53,044:INFO:create_model() successfully completed......................................
2025-05-18 20:55:53,204:INFO:_master_model_container: 15
2025-05-18 20:55:53,204:INFO:_display_container: 2
2025-05-18 20:55:53,205:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2025-05-18 20:55:53,205:INFO:compare_models() successfully completed......................................
2025-05-18 20:55:53,206:INFO:Initializing evaluate_model()
2025-05-18 20:55:53,206:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-18 20:55:53,212:INFO:Initializing plot_model()
2025-05-18 20:55:53,212:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-18 20:55:53,212:INFO:Checking exceptions
2025-05-18 20:55:53,217:INFO:Preloading libraries
2025-05-18 20:55:53,221:INFO:Copying training dataset
2025-05-18 20:55:53,221:INFO:Plot type: pipeline
2025-05-18 20:55:53,295:INFO:Visual Rendered Successfully
2025-05-18 20:55:53,460:INFO:plot_model() successfully completed......................................
2025-05-18 20:55:53,461:INFO:Initializing tune_model()
2025-05-18 20:55:53,461:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x353784510>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-18 20:55:53,461:INFO:Checking exceptions
2025-05-18 20:55:53,470:INFO:Copying training dataset
2025-05-18 20:55:53,477:INFO:Checking base model
2025-05-18 20:55:53,477:INFO:Base model : Gradient Boosting Classifier
2025-05-18 20:55:53,479:INFO:Declaring metric variables
2025-05-18 20:55:53,480:INFO:Defining Hyperparameters
2025-05-18 20:55:53,648:INFO:Tuning with n_jobs=1
2025-05-18 20:55:53,648:INFO:Initializing RandomizedSearchCV
2025-05-18 20:56:24,768:INFO:PyCaret ClassificationExperiment
2025-05-18 20:56:24,768:INFO:Logging name: clf-default-name
2025-05-18 20:56:24,768:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-18 20:56:24,768:INFO:version 3.3.2
2025-05-18 20:56:24,768:INFO:Initializing setup()
2025-05-18 20:56:24,768:INFO:self.USI: 2cec
2025-05-18 20:56:24,768:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-18 20:56:24,768:INFO:Checking environment
2025-05-18 20:56:24,768:INFO:python_version: 3.11.0
2025-05-18 20:56:24,768:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-18 20:56:24,768:INFO:machine: arm64
2025-05-18 20:56:24,768:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-18 20:56:24,768:INFO:Memory: svmem(total=17179869184, available=3958489088, percent=77.0, used=6560219136, free=64454656, active=3911073792, inactive=3890921472, wired=2649145344)
2025-05-18 20:56:24,768:INFO:Physical Core: 12
2025-05-18 20:56:24,768:INFO:Logical Core: 12
2025-05-18 20:56:24,768:INFO:Checking libraries
2025-05-18 20:56:24,768:INFO:System:
2025-05-18 20:56:24,768:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-18 20:56:24,768:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-18 20:56:24,768:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-18 20:56:24,768:INFO:PyCaret required dependencies:
2025-05-18 20:56:24,768:INFO:                 pip: 22.3
2025-05-18 20:56:24,768:INFO:          setuptools: 65.5.0
2025-05-18 20:56:24,768:INFO:             pycaret: 3.3.2
2025-05-18 20:56:24,768:INFO:             IPython: 9.2.0
2025-05-18 20:56:24,768:INFO:          ipywidgets: 8.1.7
2025-05-18 20:56:24,768:INFO:                tqdm: 4.67.1
2025-05-18 20:56:24,768:INFO:               numpy: 1.26.4
2025-05-18 20:56:24,768:INFO:              pandas: 2.1.4
2025-05-18 20:56:24,768:INFO:              jinja2: 3.1.6
2025-05-18 20:56:24,768:INFO:               scipy: 1.11.4
2025-05-18 20:56:24,768:INFO:              joblib: 1.3.2
2025-05-18 20:56:24,768:INFO:             sklearn: 1.4.2
2025-05-18 20:56:24,768:INFO:                pyod: 2.0.5
2025-05-18 20:56:24,768:INFO:            imblearn: 0.13.0
2025-05-18 20:56:24,768:INFO:   category_encoders: 2.7.0
2025-05-18 20:56:24,768:INFO:            lightgbm: 4.6.0
2025-05-18 20:56:24,769:INFO:               numba: 0.61.2
2025-05-18 20:56:24,769:INFO:            requests: 2.32.3
2025-05-18 20:56:24,769:INFO:          matplotlib: 3.7.5
2025-05-18 20:56:24,769:INFO:          scikitplot: 0.3.7
2025-05-18 20:56:24,769:INFO:         yellowbrick: 1.5
2025-05-18 20:56:24,769:INFO:              plotly: 5.24.1
2025-05-18 20:56:24,769:INFO:    plotly-resampler: Not installed
2025-05-18 20:56:24,769:INFO:             kaleido: 0.2.1
2025-05-18 20:56:24,769:INFO:           schemdraw: 0.15
2025-05-18 20:56:24,769:INFO:         statsmodels: 0.14.4
2025-05-18 20:56:24,769:INFO:              sktime: 0.26.0
2025-05-18 20:56:24,769:INFO:               tbats: 1.1.3
2025-05-18 20:56:24,769:INFO:            pmdarima: 2.0.4
2025-05-18 20:56:24,769:INFO:              psutil: 7.0.0
2025-05-18 20:56:24,769:INFO:          markupsafe: 3.0.2
2025-05-18 20:56:24,769:INFO:             pickle5: Not installed
2025-05-18 20:56:24,769:INFO:         cloudpickle: 3.1.1
2025-05-18 20:56:24,769:INFO:         deprecation: 2.1.0
2025-05-18 20:56:24,769:INFO:              xxhash: 3.5.0
2025-05-18 20:56:24,769:INFO:           wurlitzer: 3.1.1
2025-05-18 20:56:24,769:INFO:PyCaret optional dependencies:
2025-05-18 20:56:24,769:INFO:                shap: 0.47.2
2025-05-18 20:56:24,769:INFO:           interpret: Not installed
2025-05-18 20:56:24,769:INFO:                umap: Not installed
2025-05-18 20:56:24,769:INFO:     ydata_profiling: Not installed
2025-05-18 20:56:24,769:INFO:  explainerdashboard: Not installed
2025-05-18 20:56:24,769:INFO:             autoviz: Not installed
2025-05-18 20:56:24,769:INFO:           fairlearn: Not installed
2025-05-18 20:56:24,769:INFO:          deepchecks: Not installed
2025-05-18 20:56:24,769:INFO:             xgboost: Not installed
2025-05-18 20:56:24,769:INFO:            catboost: 1.2.8
2025-05-18 20:56:24,769:INFO:              kmodes: Not installed
2025-05-18 20:56:24,769:INFO:             mlxtend: Not installed
2025-05-18 20:56:24,769:INFO:       statsforecast: Not installed
2025-05-18 20:56:24,769:INFO:        tune_sklearn: Not installed
2025-05-18 20:56:24,769:INFO:                 ray: Not installed
2025-05-18 20:56:24,769:INFO:            hyperopt: Not installed
2025-05-18 20:56:24,769:INFO:              optuna: 4.3.0
2025-05-18 20:56:24,769:INFO:               skopt: Not installed
2025-05-18 20:56:24,769:INFO:              mlflow: Not installed
2025-05-18 20:56:24,769:INFO:              gradio: Not installed
2025-05-18 20:56:24,769:INFO:             fastapi: Not installed
2025-05-18 20:56:24,769:INFO:             uvicorn: Not installed
2025-05-18 20:56:24,769:INFO:              m2cgen: Not installed
2025-05-18 20:56:24,769:INFO:           evidently: Not installed
2025-05-18 20:56:24,769:INFO:               fugue: Not installed
2025-05-18 20:56:24,769:INFO:           streamlit: Not installed
2025-05-18 20:56:24,769:INFO:             prophet: Not installed
2025-05-18 20:56:24,769:INFO:None
2025-05-18 20:56:24,769:INFO:Set up data.
2025-05-18 20:56:24,799:INFO:Set up folding strategy.
2025-05-18 20:56:24,799:INFO:Set up train/test split.
2025-05-18 20:56:24,813:INFO:Set up index.
2025-05-18 20:56:24,813:INFO:Assigning column types.
2025-05-18 20:56:24,817:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-18 20:56:24,835:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 20:56:24,835:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 20:56:24,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:56:24,847:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:56:24,865:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 20:56:24,865:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 20:56:24,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:56:24,876:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:56:24,876:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-18 20:56:24,894:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 20:56:24,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:56:24,905:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:56:24,923:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 20:56:24,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:56:24,934:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:56:24,934:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-18 20:56:24,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:56:24,963:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:56:24,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:56:24,993:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:56:24,993:INFO:Preparing preprocessing pipeline...
2025-05-18 20:56:24,994:INFO:Set up simple imputation.
2025-05-18 20:56:25,000:INFO:Set up encoding of ordinal features.
2025-05-18 20:56:25,009:INFO:Set up encoding of categorical features.
2025-05-18 20:56:25,009:INFO:Set up imbalanced handling.
2025-05-18 20:56:25,009:INFO:Set up column transformation.
2025-05-18 20:56:25,009:INFO:Set up feature selection.
2025-05-18 20:56:25,039:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:56:25,039:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:56:25,349:INFO:Finished creating preprocessing pipeline.
2025-05-18 20:56:25,372:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=14,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-05-18 20:56:25,372:INFO:Creating final display dataframe.
2025-05-18 20:56:25,601:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 15)
5   Transformed train set shape       (85902, 15)
6    Transformed test set shape       (20919, 15)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19            Feature selection              True
20     Feature selection method           classic
21  Feature selection estimator          lightgbm
22  Number of features selected              0.98
23               Fold Generator   StratifiedKFold
24                  Fold Number                 5
25                     CPU Jobs                 1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              2cec
2025-05-18 20:56:25,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:56:25,634:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:56:25,664:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 20:56:25,664:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 20:56:25,665:INFO:setup() successfully completed in 0.9s...............
2025-05-18 20:56:25,665:INFO:Initializing compare_models()
2025-05-18 20:56:25,665:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-18 20:56:25,665:INFO:Checking exceptions
2025-05-18 20:56:25,671:INFO:Preparing display monitor
2025-05-18 20:56:25,679:INFO:Initializing Logistic Regression
2025-05-18 20:56:25,679:INFO:Total runtime is 1.617272694905599e-06 minutes
2025-05-18 20:56:25,681:INFO:SubProcess create_model() called ==================================
2025-05-18 20:56:25,681:INFO:Initializing create_model()
2025-05-18 20:56:25,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:56:25,681:INFO:Checking exceptions
2025-05-18 20:56:25,681:INFO:Importing libraries
2025-05-18 20:56:25,681:INFO:Copying training dataset
2025-05-18 20:56:25,694:INFO:Defining folds
2025-05-18 20:56:25,694:INFO:Declaring metric variables
2025-05-18 20:56:25,695:INFO:Importing untrained model
2025-05-18 20:56:25,697:INFO:Logistic Regression Imported successfully
2025-05-18 20:56:25,699:INFO:Starting cross validation
2025-05-18 20:56:25,702:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:56:26,516:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:56:26,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004285 seconds.
2025-05-18 20:56:26,526:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:56:26,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:56:26,526:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:56:26,526:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:56:26,526:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:56:28,922:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:56:28,931:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004287 seconds.
2025-05-18 20:56:28,931:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:56:28,931:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:56:28,931:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:56:28,931:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:56:28,931:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:56:31,366:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:56:31,374:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004362 seconds.
2025-05-18 20:56:31,375:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:56:31,375:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:56:31,375:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:56:31,375:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:56:31,375:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:56:33,701:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:56:33,710:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004353 seconds.
2025-05-18 20:56:33,710:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:56:33,710:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:56:33,710:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:56:33,710:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:56:33,710:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:56:36,070:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:56:36,079:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004458 seconds.
2025-05-18 20:56:36,079:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:56:36,079:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:56:36,079:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:56:36,079:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:56:36,079:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:56:38,027:INFO:Calculating mean and std
2025-05-18 20:56:38,028:INFO:Creating metrics dataframe
2025-05-18 20:56:38,029:INFO:Uploading results into container
2025-05-18 20:56:38,029:INFO:Uploading model into container now
2025-05-18 20:56:38,029:INFO:_master_model_container: 1
2025-05-18 20:56:38,029:INFO:_display_container: 2
2025-05-18 20:56:38,029:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-18 20:56:38,029:INFO:create_model() successfully completed......................................
2025-05-18 20:56:38,276:INFO:SubProcess create_model() end ==================================
2025-05-18 20:56:38,276:INFO:Creating metrics dataframe
2025-05-18 20:56:38,278:INFO:Initializing K Neighbors Classifier
2025-05-18 20:56:38,278:INFO:Total runtime is 0.20998706817626953 minutes
2025-05-18 20:56:38,280:INFO:SubProcess create_model() called ==================================
2025-05-18 20:56:38,280:INFO:Initializing create_model()
2025-05-18 20:56:38,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:56:38,280:INFO:Checking exceptions
2025-05-18 20:56:38,280:INFO:Importing libraries
2025-05-18 20:56:38,280:INFO:Copying training dataset
2025-05-18 20:56:38,290:INFO:Defining folds
2025-05-18 20:56:38,291:INFO:Declaring metric variables
2025-05-18 20:56:38,292:INFO:Importing untrained model
2025-05-18 20:56:38,293:INFO:K Neighbors Classifier Imported successfully
2025-05-18 20:56:38,295:INFO:Starting cross validation
2025-05-18 20:56:38,298:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:56:39,098:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:56:39,107:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004553 seconds.
2025-05-18 20:56:39,107:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:56:39,107:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:56:39,107:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:56:39,107:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:56:39,107:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:56:42,236:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:56:42,246:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005038 seconds.
2025-05-18 20:56:42,246:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:56:42,246:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:56:42,246:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:56:42,246:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:56:42,247:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:56:45,540:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:56:45,549:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004549 seconds.
2025-05-18 20:56:45,549:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:56:45,549:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:56:45,549:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:56:45,549:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:56:45,549:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:56:48,808:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:56:48,818:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004687 seconds.
2025-05-18 20:56:48,818:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:56:48,818:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:56:48,818:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:56:48,818:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:56:48,819:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:56:51,773:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:56:51,782:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005228 seconds.
2025-05-18 20:56:51,782:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-18 20:56:51,782:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:56:51,782:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:56:51,782:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:56:54,161:INFO:Calculating mean and std
2025-05-18 20:56:54,162:INFO:Creating metrics dataframe
2025-05-18 20:56:54,164:INFO:Uploading results into container
2025-05-18 20:56:54,164:INFO:Uploading model into container now
2025-05-18 20:56:54,164:INFO:_master_model_container: 2
2025-05-18 20:56:54,164:INFO:_display_container: 2
2025-05-18 20:56:54,164:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-18 20:56:54,165:INFO:create_model() successfully completed......................................
2025-05-18 20:56:54,394:INFO:SubProcess create_model() end ==================================
2025-05-18 20:56:54,394:INFO:Creating metrics dataframe
2025-05-18 20:56:54,397:INFO:Initializing Naive Bayes
2025-05-18 20:56:54,397:INFO:Total runtime is 0.478627868493398 minutes
2025-05-18 20:56:54,398:INFO:SubProcess create_model() called ==================================
2025-05-18 20:56:54,398:INFO:Initializing create_model()
2025-05-18 20:56:54,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:56:54,398:INFO:Checking exceptions
2025-05-18 20:56:54,398:INFO:Importing libraries
2025-05-18 20:56:54,398:INFO:Copying training dataset
2025-05-18 20:56:54,409:INFO:Defining folds
2025-05-18 20:56:54,409:INFO:Declaring metric variables
2025-05-18 20:56:54,410:INFO:Importing untrained model
2025-05-18 20:56:54,411:INFO:Naive Bayes Imported successfully
2025-05-18 20:56:54,413:INFO:Starting cross validation
2025-05-18 20:56:54,416:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:56:55,201:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:56:55,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004424 seconds.
2025-05-18 20:56:55,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:56:55,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:56:55,210:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:56:55,210:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:56:55,211:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:56:57,124:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:56:57,133:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004415 seconds.
2025-05-18 20:56:57,133:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:56:57,133:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:56:57,133:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:56:57,133:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:56:57,134:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:56:59,054:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:56:59,062:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004526 seconds.
2025-05-18 20:56:59,063:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:56:59,063:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:56:59,063:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:56:59,063:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:56:59,063:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:00,955:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:00,963:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004147 seconds.
2025-05-18 20:57:00,963:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:00,963:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:00,963:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:00,963:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:00,963:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:02,916:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:02,925:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004330 seconds.
2025-05-18 20:57:02,925:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:02,925:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:02,925:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:02,925:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:02,925:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:04,021:INFO:Calculating mean and std
2025-05-18 20:57:04,022:INFO:Creating metrics dataframe
2025-05-18 20:57:04,023:INFO:Uploading results into container
2025-05-18 20:57:04,023:INFO:Uploading model into container now
2025-05-18 20:57:04,023:INFO:_master_model_container: 3
2025-05-18 20:57:04,023:INFO:_display_container: 2
2025-05-18 20:57:04,023:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-18 20:57:04,024:INFO:create_model() successfully completed......................................
2025-05-18 20:57:04,201:INFO:SubProcess create_model() end ==================================
2025-05-18 20:57:04,201:INFO:Creating metrics dataframe
2025-05-18 20:57:04,204:INFO:Initializing Decision Tree Classifier
2025-05-18 20:57:04,204:INFO:Total runtime is 0.6420870184898376 minutes
2025-05-18 20:57:04,206:INFO:SubProcess create_model() called ==================================
2025-05-18 20:57:04,206:INFO:Initializing create_model()
2025-05-18 20:57:04,206:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:57:04,206:INFO:Checking exceptions
2025-05-18 20:57:04,206:INFO:Importing libraries
2025-05-18 20:57:04,206:INFO:Copying training dataset
2025-05-18 20:57:04,216:INFO:Defining folds
2025-05-18 20:57:04,216:INFO:Declaring metric variables
2025-05-18 20:57:04,217:INFO:Importing untrained model
2025-05-18 20:57:04,218:INFO:Decision Tree Classifier Imported successfully
2025-05-18 20:57:04,221:INFO:Starting cross validation
2025-05-18 20:57:04,224:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:57:05,013:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:57:05,021:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004182 seconds.
2025-05-18 20:57:05,022:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:05,022:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:05,022:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:05,022:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:57:05,022:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:07,315:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:07,323:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004020 seconds.
2025-05-18 20:57:07,323:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:07,323:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:07,323:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:07,323:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:07,324:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:09,765:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:09,774:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004194 seconds.
2025-05-18 20:57:09,774:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:09,774:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:09,774:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:09,774:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:09,774:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:12,085:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:12,094:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004461 seconds.
2025-05-18 20:57:12,094:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:12,094:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:12,094:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:12,094:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:12,094:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:14,423:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:14,432:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004507 seconds.
2025-05-18 20:57:14,432:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:14,432:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:14,432:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:14,432:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:14,432:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:15,927:INFO:Calculating mean and std
2025-05-18 20:57:15,928:INFO:Creating metrics dataframe
2025-05-18 20:57:15,929:INFO:Uploading results into container
2025-05-18 20:57:15,929:INFO:Uploading model into container now
2025-05-18 20:57:15,929:INFO:_master_model_container: 4
2025-05-18 20:57:15,929:INFO:_display_container: 2
2025-05-18 20:57:15,929:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-18 20:57:15,929:INFO:create_model() successfully completed......................................
2025-05-18 20:57:16,100:INFO:SubProcess create_model() end ==================================
2025-05-18 20:57:16,100:INFO:Creating metrics dataframe
2025-05-18 20:57:16,103:INFO:Initializing SVM - Linear Kernel
2025-05-18 20:57:16,103:INFO:Total runtime is 0.8404005487759908 minutes
2025-05-18 20:57:16,104:INFO:SubProcess create_model() called ==================================
2025-05-18 20:57:16,105:INFO:Initializing create_model()
2025-05-18 20:57:16,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:57:16,105:INFO:Checking exceptions
2025-05-18 20:57:16,105:INFO:Importing libraries
2025-05-18 20:57:16,105:INFO:Copying training dataset
2025-05-18 20:57:16,114:INFO:Defining folds
2025-05-18 20:57:16,114:INFO:Declaring metric variables
2025-05-18 20:57:16,115:INFO:Importing untrained model
2025-05-18 20:57:16,116:INFO:SVM - Linear Kernel Imported successfully
2025-05-18 20:57:16,118:INFO:Starting cross validation
2025-05-18 20:57:16,121:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:57:16,898:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:57:16,907:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004171 seconds.
2025-05-18 20:57:16,907:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:16,907:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:16,907:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:16,907:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:57:16,908:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:19,295:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:19,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004287 seconds.
2025-05-18 20:57:19,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:19,304:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:19,304:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:19,304:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:19,304:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:22,476:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:22,486:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004629 seconds.
2025-05-18 20:57:22,486:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:22,486:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:22,486:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:22,487:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:22,487:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:24,993:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:25,001:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004159 seconds.
2025-05-18 20:57:25,001:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:25,001:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:25,001:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:25,001:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:25,002:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:27,676:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:27,685:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004322 seconds.
2025-05-18 20:57:27,685:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:27,685:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:27,685:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:27,685:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:27,686:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:29,276:INFO:Calculating mean and std
2025-05-18 20:57:29,278:INFO:Creating metrics dataframe
2025-05-18 20:57:29,279:INFO:Uploading results into container
2025-05-18 20:57:29,279:INFO:Uploading model into container now
2025-05-18 20:57:29,280:INFO:_master_model_container: 5
2025-05-18 20:57:29,280:INFO:_display_container: 2
2025-05-18 20:57:29,280:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-18 20:57:29,280:INFO:create_model() successfully completed......................................
2025-05-18 20:57:29,495:INFO:SubProcess create_model() end ==================================
2025-05-18 20:57:29,495:INFO:Creating metrics dataframe
2025-05-18 20:57:29,499:INFO:Initializing Ridge Classifier
2025-05-18 20:57:29,499:INFO:Total runtime is 1.0636664509773255 minutes
2025-05-18 20:57:29,500:INFO:SubProcess create_model() called ==================================
2025-05-18 20:57:29,501:INFO:Initializing create_model()
2025-05-18 20:57:29,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:57:29,501:INFO:Checking exceptions
2025-05-18 20:57:29,501:INFO:Importing libraries
2025-05-18 20:57:29,501:INFO:Copying training dataset
2025-05-18 20:57:29,511:INFO:Defining folds
2025-05-18 20:57:29,512:INFO:Declaring metric variables
2025-05-18 20:57:29,513:INFO:Importing untrained model
2025-05-18 20:57:29,515:INFO:Ridge Classifier Imported successfully
2025-05-18 20:57:29,517:INFO:Starting cross validation
2025-05-18 20:57:29,520:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:57:30,299:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:57:30,308:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004354 seconds.
2025-05-18 20:57:30,308:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:30,308:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:30,308:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:30,308:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:57:30,308:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:32,183:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:32,192:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004402 seconds.
2025-05-18 20:57:32,192:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:32,192:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:32,192:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:32,192:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:32,192:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:34,074:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:34,082:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004093 seconds.
2025-05-18 20:57:34,082:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:34,082:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:34,082:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:34,083:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:34,083:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:35,963:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:35,972:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004462 seconds.
2025-05-18 20:57:35,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:35,973:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:35,973:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:35,973:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:35,973:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:37,894:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:37,903:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004552 seconds.
2025-05-18 20:57:37,903:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:37,903:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:37,903:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:37,903:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:37,904:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:38,999:INFO:Calculating mean and std
2025-05-18 20:57:39,000:INFO:Creating metrics dataframe
2025-05-18 20:57:39,001:INFO:Uploading results into container
2025-05-18 20:57:39,001:INFO:Uploading model into container now
2025-05-18 20:57:39,001:INFO:_master_model_container: 6
2025-05-18 20:57:39,001:INFO:_display_container: 2
2025-05-18 20:57:39,001:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-18 20:57:39,001:INFO:create_model() successfully completed......................................
2025-05-18 20:57:39,166:INFO:SubProcess create_model() end ==================================
2025-05-18 20:57:39,166:INFO:Creating metrics dataframe
2025-05-18 20:57:39,169:INFO:Initializing Random Forest Classifier
2025-05-18 20:57:39,170:INFO:Total runtime is 1.2248399337132772 minutes
2025-05-18 20:57:39,171:INFO:SubProcess create_model() called ==================================
2025-05-18 20:57:39,171:INFO:Initializing create_model()
2025-05-18 20:57:39,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:57:39,171:INFO:Checking exceptions
2025-05-18 20:57:39,171:INFO:Importing libraries
2025-05-18 20:57:39,171:INFO:Copying training dataset
2025-05-18 20:57:39,180:INFO:Defining folds
2025-05-18 20:57:39,180:INFO:Declaring metric variables
2025-05-18 20:57:39,182:INFO:Importing untrained model
2025-05-18 20:57:39,183:INFO:Random Forest Classifier Imported successfully
2025-05-18 20:57:39,186:INFO:Starting cross validation
2025-05-18 20:57:39,188:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:57:39,976:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:57:39,985:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004465 seconds.
2025-05-18 20:57:39,985:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:39,985:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:39,985:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:39,985:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:57:39,985:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:49,288:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:49,297:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004325 seconds.
2025-05-18 20:57:49,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:49,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:49,297:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:49,297:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:49,297:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:57:58,743:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:57:58,752:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004378 seconds.
2025-05-18 20:57:58,752:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:57:58,752:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:57:58,752:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:57:58,752:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:57:58,753:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:58:08,182:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:58:08,190:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004029 seconds.
2025-05-18 20:58:08,190:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:58:08,190:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:58:08,191:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:58:08,191:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:58:08,191:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:58:17,681:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:58:17,691:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004437 seconds.
2025-05-18 20:58:17,691:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:58:17,691:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:58:17,691:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:58:17,691:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:58:17,691:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:58:26,296:INFO:Calculating mean and std
2025-05-18 20:58:26,298:INFO:Creating metrics dataframe
2025-05-18 20:58:26,300:INFO:Uploading results into container
2025-05-18 20:58:26,300:INFO:Uploading model into container now
2025-05-18 20:58:26,301:INFO:_master_model_container: 7
2025-05-18 20:58:26,301:INFO:_display_container: 2
2025-05-18 20:58:26,301:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-18 20:58:26,301:INFO:create_model() successfully completed......................................
2025-05-18 20:58:26,566:INFO:SubProcess create_model() end ==================================
2025-05-18 20:58:26,566:INFO:Creating metrics dataframe
2025-05-18 20:58:26,569:INFO:Initializing Quadratic Discriminant Analysis
2025-05-18 20:58:26,569:INFO:Total runtime is 2.0148382663726805 minutes
2025-05-18 20:58:26,571:INFO:SubProcess create_model() called ==================================
2025-05-18 20:58:26,571:INFO:Initializing create_model()
2025-05-18 20:58:26,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:58:26,571:INFO:Checking exceptions
2025-05-18 20:58:26,571:INFO:Importing libraries
2025-05-18 20:58:26,571:INFO:Copying training dataset
2025-05-18 20:58:26,581:INFO:Defining folds
2025-05-18 20:58:26,581:INFO:Declaring metric variables
2025-05-18 20:58:26,582:INFO:Importing untrained model
2025-05-18 20:58:26,583:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 20:58:26,585:INFO:Starting cross validation
2025-05-18 20:58:26,588:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:58:27,381:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:58:27,389:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004149 seconds.
2025-05-18 20:58:27,389:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:58:27,389:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:58:27,389:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:58:27,389:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:58:27,389:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:58:29,302:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:58:29,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004850 seconds.
2025-05-18 20:58:29,311:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:58:29,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:58:29,311:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:58:29,311:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:58:29,312:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:58:31,218:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:58:31,228:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004666 seconds.
2025-05-18 20:58:31,228:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:58:31,228:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:58:31,228:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:58:31,228:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:58:31,228:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:58:33,135:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:58:33,144:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003992 seconds.
2025-05-18 20:58:33,144:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:58:33,144:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:58:33,144:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:58:33,144:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:58:33,144:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:58:35,083:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:58:35,091:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003906 seconds.
2025-05-18 20:58:35,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:58:35,092:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:58:35,092:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:58:35,092:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:58:35,092:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:58:36,203:INFO:Calculating mean and std
2025-05-18 20:58:36,203:INFO:Creating metrics dataframe
2025-05-18 20:58:36,204:INFO:Uploading results into container
2025-05-18 20:58:36,204:INFO:Uploading model into container now
2025-05-18 20:58:36,205:INFO:_master_model_container: 8
2025-05-18 20:58:36,205:INFO:_display_container: 2
2025-05-18 20:58:36,205:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 20:58:36,205:INFO:create_model() successfully completed......................................
2025-05-18 20:58:36,365:INFO:SubProcess create_model() end ==================================
2025-05-18 20:58:36,365:INFO:Creating metrics dataframe
2025-05-18 20:58:36,368:INFO:Initializing Ada Boost Classifier
2025-05-18 20:58:36,368:INFO:Total runtime is 2.1781530539194742 minutes
2025-05-18 20:58:36,369:INFO:SubProcess create_model() called ==================================
2025-05-18 20:58:36,370:INFO:Initializing create_model()
2025-05-18 20:58:36,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:58:36,370:INFO:Checking exceptions
2025-05-18 20:58:36,370:INFO:Importing libraries
2025-05-18 20:58:36,370:INFO:Copying training dataset
2025-05-18 20:58:36,379:INFO:Defining folds
2025-05-18 20:58:36,379:INFO:Declaring metric variables
2025-05-18 20:58:36,380:INFO:Importing untrained model
2025-05-18 20:58:36,381:INFO:Ada Boost Classifier Imported successfully
2025-05-18 20:58:36,383:INFO:Starting cross validation
2025-05-18 20:58:36,386:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:58:37,160:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:58:37,169:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004331 seconds.
2025-05-18 20:58:37,169:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:58:37,169:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:58:37,169:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:58:37,169:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:58:37,170:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:58:38,223:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:58:41,192:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:58:41,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004458 seconds.
2025-05-18 20:58:41,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:58:41,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:58:41,201:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:58:41,201:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:58:41,201:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:58:42,254:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:58:45,196:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:58:45,204:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004475 seconds.
2025-05-18 20:58:45,205:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:58:45,205:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:58:45,205:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:58:45,205:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:58:45,205:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:58:46,247:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:58:49,202:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:58:49,211:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004229 seconds.
2025-05-18 20:58:49,211:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:58:49,211:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:58:49,212:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:58:49,212:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:58:49,212:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:58:50,252:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:58:53,265:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:58:53,274:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004293 seconds.
2025-05-18 20:58:53,274:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:58:53,274:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:58:53,274:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:58:53,274:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:58:53,274:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:58:54,318:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 20:58:56,486:INFO:Calculating mean and std
2025-05-18 20:58:56,487:INFO:Creating metrics dataframe
2025-05-18 20:58:56,488:INFO:Uploading results into container
2025-05-18 20:58:56,488:INFO:Uploading model into container now
2025-05-18 20:58:56,488:INFO:_master_model_container: 9
2025-05-18 20:58:56,488:INFO:_display_container: 2
2025-05-18 20:58:56,488:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-18 20:58:56,488:INFO:create_model() successfully completed......................................
2025-05-18 20:58:56,653:INFO:SubProcess create_model() end ==================================
2025-05-18 20:58:56,653:INFO:Creating metrics dataframe
2025-05-18 20:58:56,656:INFO:Initializing Gradient Boosting Classifier
2025-05-18 20:58:56,656:INFO:Total runtime is 2.5162869175275167 minutes
2025-05-18 20:58:56,658:INFO:SubProcess create_model() called ==================================
2025-05-18 20:58:56,658:INFO:Initializing create_model()
2025-05-18 20:58:56,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:58:56,658:INFO:Checking exceptions
2025-05-18 20:58:56,658:INFO:Importing libraries
2025-05-18 20:58:56,658:INFO:Copying training dataset
2025-05-18 20:58:56,667:INFO:Defining folds
2025-05-18 20:58:56,667:INFO:Declaring metric variables
2025-05-18 20:58:56,668:INFO:Importing untrained model
2025-05-18 20:58:56,669:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 20:58:56,671:INFO:Starting cross validation
2025-05-18 20:58:56,674:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:58:57,484:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:58:57,493:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004221 seconds.
2025-05-18 20:58:57,493:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:58:57,493:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:58:57,493:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:58:57,493:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:58:57,493:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:59:09,806:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:59:09,815:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004434 seconds.
2025-05-18 20:59:09,815:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:59:09,815:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:59:09,815:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:59:09,815:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:59:09,815:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:59:22,223:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:59:22,232:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004420 seconds.
2025-05-18 20:59:22,232:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:59:22,232:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:59:22,233:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:59:22,233:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:59:22,233:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:59:34,623:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:59:34,633:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004528 seconds.
2025-05-18 20:59:34,633:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:59:34,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:59:34,633:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:59:34,633:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:59:34,633:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:59:47,071:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 20:59:47,081:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004183 seconds.
2025-05-18 20:59:47,081:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:59:47,081:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:59:47,081:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:59:47,081:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 20:59:47,081:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 20:59:58,614:INFO:Calculating mean and std
2025-05-18 20:59:58,615:INFO:Creating metrics dataframe
2025-05-18 20:59:58,616:INFO:Uploading results into container
2025-05-18 20:59:58,616:INFO:Uploading model into container now
2025-05-18 20:59:58,616:INFO:_master_model_container: 10
2025-05-18 20:59:58,616:INFO:_display_container: 2
2025-05-18 20:59:58,616:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 20:59:58,616:INFO:create_model() successfully completed......................................
2025-05-18 20:59:58,785:INFO:SubProcess create_model() end ==================================
2025-05-18 20:59:58,785:INFO:Creating metrics dataframe
2025-05-18 20:59:58,789:INFO:Initializing Linear Discriminant Analysis
2025-05-18 20:59:58,789:INFO:Total runtime is 3.5518295844395955 minutes
2025-05-18 20:59:58,790:INFO:SubProcess create_model() called ==================================
2025-05-18 20:59:58,790:INFO:Initializing create_model()
2025-05-18 20:59:58,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 20:59:58,790:INFO:Checking exceptions
2025-05-18 20:59:58,790:INFO:Importing libraries
2025-05-18 20:59:58,790:INFO:Copying training dataset
2025-05-18 20:59:58,800:INFO:Defining folds
2025-05-18 20:59:58,800:INFO:Declaring metric variables
2025-05-18 20:59:58,801:INFO:Importing untrained model
2025-05-18 20:59:58,802:INFO:Linear Discriminant Analysis Imported successfully
2025-05-18 20:59:58,804:INFO:Starting cross validation
2025-05-18 20:59:58,807:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 20:59:59,596:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 20:59:59,605:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004438 seconds.
2025-05-18 20:59:59,605:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 20:59:59,605:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 20:59:59,605:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 20:59:59,605:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 20:59:59,605:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:01,515:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:01,527:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004449 seconds.
2025-05-18 21:00:01,527:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:01,527:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:01,527:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:01,527:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:00:01,527:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:03,469:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:03,478:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004493 seconds.
2025-05-18 21:00:03,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:03,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:03,478:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:03,478:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:00:03,478:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:05,382:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:05,390:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004157 seconds.
2025-05-18 21:00:05,390:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:05,390:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:05,390:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:05,390:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:00:05,390:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:07,323:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:07,332:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004413 seconds.
2025-05-18 21:00:07,332:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:07,332:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:07,332:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:07,332:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:00:07,332:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:08,448:INFO:Calculating mean and std
2025-05-18 21:00:08,448:INFO:Creating metrics dataframe
2025-05-18 21:00:08,449:INFO:Uploading results into container
2025-05-18 21:00:08,449:INFO:Uploading model into container now
2025-05-18 21:00:08,450:INFO:_master_model_container: 11
2025-05-18 21:00:08,450:INFO:_display_container: 2
2025-05-18 21:00:08,450:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-18 21:00:08,450:INFO:create_model() successfully completed......................................
2025-05-18 21:00:08,614:INFO:SubProcess create_model() end ==================================
2025-05-18 21:00:08,614:INFO:Creating metrics dataframe
2025-05-18 21:00:08,618:INFO:Initializing Extra Trees Classifier
2025-05-18 21:00:08,618:INFO:Total runtime is 3.7156421184539794 minutes
2025-05-18 21:00:08,619:INFO:SubProcess create_model() called ==================================
2025-05-18 21:00:08,619:INFO:Initializing create_model()
2025-05-18 21:00:08,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:00:08,619:INFO:Checking exceptions
2025-05-18 21:00:08,619:INFO:Importing libraries
2025-05-18 21:00:08,619:INFO:Copying training dataset
2025-05-18 21:00:08,628:INFO:Defining folds
2025-05-18 21:00:08,628:INFO:Declaring metric variables
2025-05-18 21:00:08,629:INFO:Importing untrained model
2025-05-18 21:00:08,630:INFO:Extra Trees Classifier Imported successfully
2025-05-18 21:00:08,632:INFO:Starting cross validation
2025-05-18 21:00:08,635:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:00:09,416:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:00:09,425:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004263 seconds.
2025-05-18 21:00:09,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:09,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:09,425:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:09,425:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:00:09,425:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:15,346:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:15,355:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004262 seconds.
2025-05-18 21:00:15,355:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:15,355:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:15,355:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:15,355:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:00:15,356:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:21,230:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:21,239:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004340 seconds.
2025-05-18 21:00:21,239:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:21,239:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:21,239:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:21,239:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:00:21,239:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:27,328:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:27,338:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004522 seconds.
2025-05-18 21:00:27,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:27,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:27,338:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:27,338:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:00:27,338:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:33,461:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:33,470:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004623 seconds.
2025-05-18 21:00:33,470:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:33,470:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:33,471:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:33,471:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:00:33,471:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:38,602:INFO:Calculating mean and std
2025-05-18 21:00:38,603:INFO:Creating metrics dataframe
2025-05-18 21:00:38,605:INFO:Uploading results into container
2025-05-18 21:00:38,605:INFO:Uploading model into container now
2025-05-18 21:00:38,605:INFO:_master_model_container: 12
2025-05-18 21:00:38,605:INFO:_display_container: 2
2025-05-18 21:00:38,605:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-18 21:00:38,605:INFO:create_model() successfully completed......................................
2025-05-18 21:00:38,865:INFO:SubProcess create_model() end ==================================
2025-05-18 21:00:38,865:INFO:Creating metrics dataframe
2025-05-18 21:00:38,869:INFO:Initializing Light Gradient Boosting Machine
2025-05-18 21:00:38,869:INFO:Total runtime is 4.219834514458974 minutes
2025-05-18 21:00:38,870:INFO:SubProcess create_model() called ==================================
2025-05-18 21:00:38,871:INFO:Initializing create_model()
2025-05-18 21:00:38,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:00:38,871:INFO:Checking exceptions
2025-05-18 21:00:38,871:INFO:Importing libraries
2025-05-18 21:00:38,871:INFO:Copying training dataset
2025-05-18 21:00:38,881:INFO:Defining folds
2025-05-18 21:00:38,881:INFO:Declaring metric variables
2025-05-18 21:00:38,882:INFO:Importing untrained model
2025-05-18 21:00:38,884:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 21:00:38,886:INFO:Starting cross validation
2025-05-18 21:00:38,889:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:00:39,669:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:00:39,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004098 seconds.
2025-05-18 21:00:39,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:39,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:39,678:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:39,678:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:00:39,678:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:40,783:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:00:40,794:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004872 seconds.
2025-05-18 21:00:40,794:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:40,794:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:40,794:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 21:00:40,794:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 14
2025-05-18 21:00:40,794:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:42,122:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:42,130:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004094 seconds.
2025-05-18 21:00:42,130:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:42,130:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:42,130:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:42,130:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:00:42,131:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:43,236:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:43,247:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004821 seconds.
2025-05-18 21:00:43,247:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:43,247:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:43,247:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 21:00:43,247:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 14
2025-05-18 21:00:43,247:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:44,564:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:44,572:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004306 seconds.
2025-05-18 21:00:44,572:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:44,572:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:44,572:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:44,573:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:00:44,573:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:45,683:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:45,694:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004787 seconds.
2025-05-18 21:00:45,694:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:45,694:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:45,694:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 21:00:45,694:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 14
2025-05-18 21:00:45,694:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:47,029:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:47,037:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004417 seconds.
2025-05-18 21:00:47,037:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:47,037:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:47,038:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:47,038:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:00:47,038:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:48,144:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:48,155:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004907 seconds.
2025-05-18 21:00:48,155:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:48,155:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:48,155:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 21:00:48,155:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 14
2025-05-18 21:00:48,155:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:49,515:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:49,524:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004593 seconds.
2025-05-18 21:00:49,525:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:49,525:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:49,525:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:49,525:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:00:49,525:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:50,619:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:00:50,630:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004903 seconds.
2025-05-18 21:00:50,630:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:50,630:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:50,630:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 21:00:50,630:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 14
2025-05-18 21:00:50,630:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:00:51,174:INFO:Calculating mean and std
2025-05-18 21:00:51,175:INFO:Creating metrics dataframe
2025-05-18 21:00:51,175:INFO:Uploading results into container
2025-05-18 21:00:51,176:INFO:Uploading model into container now
2025-05-18 21:00:51,176:INFO:_master_model_container: 13
2025-05-18 21:00:51,176:INFO:_display_container: 2
2025-05-18 21:00:51,176:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 21:00:51,176:INFO:create_model() successfully completed......................................
2025-05-18 21:00:51,335:INFO:SubProcess create_model() end ==================================
2025-05-18 21:00:51,335:INFO:Creating metrics dataframe
2025-05-18 21:00:51,339:INFO:Initializing CatBoost Classifier
2025-05-18 21:00:51,339:INFO:Total runtime is 4.4276648680369055 minutes
2025-05-18 21:00:51,340:INFO:SubProcess create_model() called ==================================
2025-05-18 21:00:51,340:INFO:Initializing create_model()
2025-05-18 21:00:51,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:00:51,340:INFO:Checking exceptions
2025-05-18 21:00:51,340:INFO:Importing libraries
2025-05-18 21:00:51,340:INFO:Copying training dataset
2025-05-18 21:00:51,349:INFO:Defining folds
2025-05-18 21:00:51,349:INFO:Declaring metric variables
2025-05-18 21:00:51,350:INFO:Importing untrained model
2025-05-18 21:00:51,352:INFO:CatBoost Classifier Imported successfully
2025-05-18 21:00:51,354:INFO:Starting cross validation
2025-05-18 21:00:51,360:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:00:52,137:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:00:52,146:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004286 seconds.
2025-05-18 21:00:52,146:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:00:52,146:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:00:52,146:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:00:52,146:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:00:52,146:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:01:07,841:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:01:07,849:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004150 seconds.
2025-05-18 21:01:07,849:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:01:07,849:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:01:07,849:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:01:07,849:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:01:07,849:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:01:23,462:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:01:23,472:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004501 seconds.
2025-05-18 21:01:23,472:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:01:23,472:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:01:23,472:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:01:23,472:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:01:23,472:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:01:39,127:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:01:39,136:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004516 seconds.
2025-05-18 21:01:39,136:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:01:39,137:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:01:39,137:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:01:39,137:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:01:39,137:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:01:54,744:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:01:54,753:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004417 seconds.
2025-05-18 21:01:54,753:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:01:54,753:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:01:54,753:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:01:54,753:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:01:54,753:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:02:09,480:INFO:Calculating mean and std
2025-05-18 21:02:09,481:INFO:Creating metrics dataframe
2025-05-18 21:02:09,482:INFO:Uploading results into container
2025-05-18 21:02:09,482:INFO:Uploading model into container now
2025-05-18 21:02:09,482:INFO:_master_model_container: 14
2025-05-18 21:02:09,482:INFO:_display_container: 2
2025-05-18 21:02:09,482:INFO:<catboost.core.CatBoostClassifier object at 0x35382e810>
2025-05-18 21:02:09,482:INFO:create_model() successfully completed......................................
2025-05-18 21:02:09,644:INFO:SubProcess create_model() end ==================================
2025-05-18 21:02:09,644:INFO:Creating metrics dataframe
2025-05-18 21:02:09,648:INFO:Initializing Dummy Classifier
2025-05-18 21:02:09,648:INFO:Total runtime is 5.73281310002009 minutes
2025-05-18 21:02:09,649:INFO:SubProcess create_model() called ==================================
2025-05-18 21:02:09,649:INFO:Initializing create_model()
2025-05-18 21:02:09,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f742f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:02:09,649:INFO:Checking exceptions
2025-05-18 21:02:09,649:INFO:Importing libraries
2025-05-18 21:02:09,649:INFO:Copying training dataset
2025-05-18 21:02:09,658:INFO:Defining folds
2025-05-18 21:02:09,658:INFO:Declaring metric variables
2025-05-18 21:02:09,659:INFO:Importing untrained model
2025-05-18 21:02:09,661:INFO:Dummy Classifier Imported successfully
2025-05-18 21:02:09,663:INFO:Starting cross validation
2025-05-18 21:02:09,666:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:02:10,433:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:02:10,441:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004411 seconds.
2025-05-18 21:02:10,441:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:02:10,441:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:02:10,442:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:02:10,442:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:02:10,442:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:02:11,527:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:02:12,298:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:02:12,306:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004257 seconds.
2025-05-18 21:02:12,307:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:02:12,307:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:02:12,307:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:02:12,307:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:02:12,307:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:02:13,380:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:02:14,160:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:02:14,169:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004316 seconds.
2025-05-18 21:02:14,169:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:02:14,169:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:02:14,169:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:02:14,169:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:02:14,170:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:02:15,250:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:02:16,038:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:02:16,047:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004080 seconds.
2025-05-18 21:02:16,047:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:02:16,047:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:02:16,047:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:02:16,047:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:02:16,047:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:02:17,132:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:02:17,937:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:02:17,946:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004174 seconds.
2025-05-18 21:02:17,946:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:02:17,946:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:02:17,946:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:02:17,946:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:02:17,946:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:02:19,017:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:02:19,022:INFO:Calculating mean and std
2025-05-18 21:02:19,022:INFO:Creating metrics dataframe
2025-05-18 21:02:19,023:INFO:Uploading results into container
2025-05-18 21:02:19,023:INFO:Uploading model into container now
2025-05-18 21:02:19,023:INFO:_master_model_container: 15
2025-05-18 21:02:19,023:INFO:_display_container: 2
2025-05-18 21:02:19,024:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-18 21:02:19,024:INFO:create_model() successfully completed......................................
2025-05-18 21:02:19,183:INFO:SubProcess create_model() end ==================================
2025-05-18 21:02:19,183:INFO:Creating metrics dataframe
2025-05-18 21:02:19,187:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-18 21:02:19,190:INFO:Initializing create_model()
2025-05-18 21:02:19,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:02:19,190:INFO:Checking exceptions
2025-05-18 21:02:19,191:INFO:Importing libraries
2025-05-18 21:02:19,191:INFO:Copying training dataset
2025-05-18 21:02:19,199:INFO:Defining folds
2025-05-18 21:02:19,200:INFO:Declaring metric variables
2025-05-18 21:02:19,200:INFO:Importing untrained model
2025-05-18 21:02:19,200:INFO:Declaring custom model
2025-05-18 21:02:19,200:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 21:02:19,202:INFO:Cross validation set to False
2025-05-18 21:02:19,202:INFO:Fitting Model
2025-05-18 21:02:20,179:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 21:02:20,189:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005160 seconds.
2025-05-18 21:02:20,189:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:02:20,189:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:02:20,189:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:02:20,189:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 21:02:20,190:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:02:34,158:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 21:02:34,158:INFO:create_model() successfully completed......................................
2025-05-18 21:02:34,316:INFO:Initializing create_model()
2025-05-18 21:02:34,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:02:34,316:INFO:Checking exceptions
2025-05-18 21:02:34,317:INFO:Importing libraries
2025-05-18 21:02:34,317:INFO:Copying training dataset
2025-05-18 21:02:34,325:INFO:Defining folds
2025-05-18 21:02:34,326:INFO:Declaring metric variables
2025-05-18 21:02:34,326:INFO:Importing untrained model
2025-05-18 21:02:34,326:INFO:Declaring custom model
2025-05-18 21:02:34,326:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 21:02:34,328:INFO:Cross validation set to False
2025-05-18 21:02:34,328:INFO:Fitting Model
2025-05-18 21:02:35,294:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 21:02:35,303:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004724 seconds.
2025-05-18 21:02:35,303:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:02:35,303:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:02:35,304:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:02:35,304:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 21:02:35,304:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:02:36,377:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 21:02:36,377:INFO:create_model() successfully completed......................................
2025-05-18 21:02:36,552:INFO:Initializing create_model()
2025-05-18 21:02:36,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:02:36,552:INFO:Checking exceptions
2025-05-18 21:02:36,553:INFO:Importing libraries
2025-05-18 21:02:36,553:INFO:Copying training dataset
2025-05-18 21:02:36,562:INFO:Defining folds
2025-05-18 21:02:36,562:INFO:Declaring metric variables
2025-05-18 21:02:36,562:INFO:Importing untrained model
2025-05-18 21:02:36,562:INFO:Declaring custom model
2025-05-18 21:02:36,562:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 21:02:36,565:INFO:Cross validation set to False
2025-05-18 21:02:36,565:INFO:Fitting Model
2025-05-18 21:02:37,555:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 21:02:37,565:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005064 seconds.
2025-05-18 21:02:37,565:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:02:37,565:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:02:37,565:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:02:37,565:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 21:02:37,566:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:02:38,740:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 21:02:38,754:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006474 seconds.
2025-05-18 21:02:38,755:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:02:38,755:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:02:38,755:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 21:02:38,755:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 14
2025-05-18 21:02:38,755:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:02:39,183:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 21:02:39,183:INFO:create_model() successfully completed......................................
2025-05-18 21:02:39,350:INFO:_master_model_container: 15
2025-05-18 21:02:39,350:INFO:_display_container: 2
2025-05-18 21:02:39,351:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2025-05-18 21:02:39,351:INFO:compare_models() successfully completed......................................
2025-05-18 21:02:39,352:INFO:Initializing evaluate_model()
2025-05-18 21:02:39,352:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-18 21:02:39,359:INFO:Initializing plot_model()
2025-05-18 21:02:39,359:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-18 21:02:39,359:INFO:Checking exceptions
2025-05-18 21:02:39,364:INFO:Preloading libraries
2025-05-18 21:02:39,367:INFO:Copying training dataset
2025-05-18 21:02:39,367:INFO:Plot type: pipeline
2025-05-18 21:02:39,434:INFO:Visual Rendered Successfully
2025-05-18 21:02:39,607:INFO:plot_model() successfully completed......................................
2025-05-18 21:02:39,609:INFO:Initializing tune_model()
2025-05-18 21:02:39,609:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559391d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-18 21:02:39,609:INFO:Checking exceptions
2025-05-18 21:02:39,619:INFO:Copying training dataset
2025-05-18 21:02:39,626:INFO:Checking base model
2025-05-18 21:02:39,626:INFO:Base model : Gradient Boosting Classifier
2025-05-18 21:02:39,628:INFO:Declaring metric variables
2025-05-18 21:02:39,629:INFO:Defining Hyperparameters
2025-05-18 21:02:39,806:INFO:Tuning with n_jobs=1
2025-05-18 21:02:39,807:INFO:Initializing RandomizedSearchCV
2025-05-18 21:03:40,132:INFO:PyCaret ClassificationExperiment
2025-05-18 21:03:40,133:INFO:Logging name: clf-default-name
2025-05-18 21:03:40,133:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-18 21:03:40,133:INFO:version 3.3.2
2025-05-18 21:03:40,133:INFO:Initializing setup()
2025-05-18 21:03:40,133:INFO:self.USI: b88d
2025-05-18 21:03:40,133:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-18 21:03:40,133:INFO:Checking environment
2025-05-18 21:03:40,133:INFO:python_version: 3.11.0
2025-05-18 21:03:40,133:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-18 21:03:40,133:INFO:machine: arm64
2025-05-18 21:03:40,133:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-18 21:03:40,133:INFO:Memory: svmem(total=17179869184, available=3744219136, percent=78.2, used=6370279424, free=60014592, active=3711123456, inactive=3673014272, wired=2659155968)
2025-05-18 21:03:40,133:INFO:Physical Core: 12
2025-05-18 21:03:40,133:INFO:Logical Core: 12
2025-05-18 21:03:40,133:INFO:Checking libraries
2025-05-18 21:03:40,133:INFO:System:
2025-05-18 21:03:40,133:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-18 21:03:40,133:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-18 21:03:40,133:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-18 21:03:40,133:INFO:PyCaret required dependencies:
2025-05-18 21:03:40,133:INFO:                 pip: 22.3
2025-05-18 21:03:40,133:INFO:          setuptools: 65.5.0
2025-05-18 21:03:40,133:INFO:             pycaret: 3.3.2
2025-05-18 21:03:40,133:INFO:             IPython: 9.2.0
2025-05-18 21:03:40,133:INFO:          ipywidgets: 8.1.7
2025-05-18 21:03:40,133:INFO:                tqdm: 4.67.1
2025-05-18 21:03:40,133:INFO:               numpy: 1.26.4
2025-05-18 21:03:40,133:INFO:              pandas: 2.1.4
2025-05-18 21:03:40,133:INFO:              jinja2: 3.1.6
2025-05-18 21:03:40,133:INFO:               scipy: 1.11.4
2025-05-18 21:03:40,133:INFO:              joblib: 1.3.2
2025-05-18 21:03:40,133:INFO:             sklearn: 1.4.2
2025-05-18 21:03:40,133:INFO:                pyod: 2.0.5
2025-05-18 21:03:40,133:INFO:            imblearn: 0.13.0
2025-05-18 21:03:40,133:INFO:   category_encoders: 2.7.0
2025-05-18 21:03:40,133:INFO:            lightgbm: 4.6.0
2025-05-18 21:03:40,133:INFO:               numba: 0.61.2
2025-05-18 21:03:40,133:INFO:            requests: 2.32.3
2025-05-18 21:03:40,133:INFO:          matplotlib: 3.7.5
2025-05-18 21:03:40,133:INFO:          scikitplot: 0.3.7
2025-05-18 21:03:40,133:INFO:         yellowbrick: 1.5
2025-05-18 21:03:40,133:INFO:              plotly: 5.24.1
2025-05-18 21:03:40,133:INFO:    plotly-resampler: Not installed
2025-05-18 21:03:40,133:INFO:             kaleido: 0.2.1
2025-05-18 21:03:40,133:INFO:           schemdraw: 0.15
2025-05-18 21:03:40,133:INFO:         statsmodels: 0.14.4
2025-05-18 21:03:40,133:INFO:              sktime: 0.26.0
2025-05-18 21:03:40,133:INFO:               tbats: 1.1.3
2025-05-18 21:03:40,133:INFO:            pmdarima: 2.0.4
2025-05-18 21:03:40,133:INFO:              psutil: 7.0.0
2025-05-18 21:03:40,133:INFO:          markupsafe: 3.0.2
2025-05-18 21:03:40,133:INFO:             pickle5: Not installed
2025-05-18 21:03:40,133:INFO:         cloudpickle: 3.1.1
2025-05-18 21:03:40,133:INFO:         deprecation: 2.1.0
2025-05-18 21:03:40,133:INFO:              xxhash: 3.5.0
2025-05-18 21:03:40,133:INFO:           wurlitzer: 3.1.1
2025-05-18 21:03:40,133:INFO:PyCaret optional dependencies:
2025-05-18 21:03:40,133:INFO:                shap: 0.47.2
2025-05-18 21:03:40,133:INFO:           interpret: Not installed
2025-05-18 21:03:40,133:INFO:                umap: Not installed
2025-05-18 21:03:40,133:INFO:     ydata_profiling: Not installed
2025-05-18 21:03:40,133:INFO:  explainerdashboard: Not installed
2025-05-18 21:03:40,133:INFO:             autoviz: Not installed
2025-05-18 21:03:40,133:INFO:           fairlearn: Not installed
2025-05-18 21:03:40,133:INFO:          deepchecks: Not installed
2025-05-18 21:03:40,134:INFO:             xgboost: Not installed
2025-05-18 21:03:40,134:INFO:            catboost: 1.2.8
2025-05-18 21:03:40,134:INFO:              kmodes: Not installed
2025-05-18 21:03:40,134:INFO:             mlxtend: Not installed
2025-05-18 21:03:40,134:INFO:       statsforecast: Not installed
2025-05-18 21:03:40,134:INFO:        tune_sklearn: Not installed
2025-05-18 21:03:40,134:INFO:                 ray: Not installed
2025-05-18 21:03:40,134:INFO:            hyperopt: Not installed
2025-05-18 21:03:40,134:INFO:              optuna: 4.3.0
2025-05-18 21:03:40,134:INFO:               skopt: Not installed
2025-05-18 21:03:40,134:INFO:              mlflow: Not installed
2025-05-18 21:03:40,134:INFO:              gradio: Not installed
2025-05-18 21:03:40,134:INFO:             fastapi: Not installed
2025-05-18 21:03:40,134:INFO:             uvicorn: Not installed
2025-05-18 21:03:40,134:INFO:              m2cgen: Not installed
2025-05-18 21:03:40,134:INFO:           evidently: Not installed
2025-05-18 21:03:40,134:INFO:               fugue: Not installed
2025-05-18 21:03:40,134:INFO:           streamlit: Not installed
2025-05-18 21:03:40,134:INFO:             prophet: Not installed
2025-05-18 21:03:40,134:INFO:None
2025-05-18 21:03:40,134:INFO:Set up data.
2025-05-18 21:03:40,169:INFO:Set up folding strategy.
2025-05-18 21:03:40,170:INFO:Set up train/test split.
2025-05-18 21:03:40,183:INFO:Set up index.
2025-05-18 21:03:40,186:INFO:Assigning column types.
2025-05-18 21:03:40,190:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-18 21:03:40,208:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 21:03:40,208:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 21:03:40,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:03:40,219:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:03:40,237:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 21:03:40,238:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 21:03:40,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:03:40,249:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:03:40,249:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-18 21:03:40,267:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 21:03:40,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:03:40,278:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:03:40,296:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 21:03:40,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:03:40,307:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:03:40,307:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-18 21:03:40,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:03:40,337:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:03:40,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:03:40,366:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:03:40,366:INFO:Preparing preprocessing pipeline...
2025-05-18 21:03:40,367:INFO:Set up simple imputation.
2025-05-18 21:03:40,374:INFO:Set up encoding of ordinal features.
2025-05-18 21:03:40,385:INFO:Set up encoding of categorical features.
2025-05-18 21:03:40,385:INFO:Set up imbalanced handling.
2025-05-18 21:03:40,385:INFO:Set up column transformation.
2025-05-18 21:03:40,669:INFO:Finished creating preprocessing pipeline.
2025-05-18 21:03:40,689:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-18 21:03:40,689:INFO:Creating final display dataframe.
2025-05-18 21:03:40,894:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                 1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              b88d
2025-05-18 21:03:40,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:03:40,926:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:03:40,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:03:40,957:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:03:40,958:INFO:setup() successfully completed in 0.83s...............
2025-05-18 21:03:40,959:INFO:Initializing compare_models()
2025-05-18 21:03:40,959:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-18 21:03:40,959:INFO:Checking exceptions
2025-05-18 21:03:40,964:INFO:Preparing display monitor
2025-05-18 21:03:40,973:INFO:Initializing Logistic Regression
2025-05-18 21:03:40,973:INFO:Total runtime is 2.968311309814453e-06 minutes
2025-05-18 21:03:40,974:INFO:SubProcess create_model() called ==================================
2025-05-18 21:03:40,975:INFO:Initializing create_model()
2025-05-18 21:03:40,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f206310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:03:40,975:INFO:Checking exceptions
2025-05-18 21:03:40,975:INFO:Importing libraries
2025-05-18 21:03:40,975:INFO:Copying training dataset
2025-05-18 21:03:40,985:INFO:Defining folds
2025-05-18 21:03:40,985:INFO:Declaring metric variables
2025-05-18 21:03:40,986:INFO:Importing untrained model
2025-05-18 21:03:40,987:INFO:Logistic Regression Imported successfully
2025-05-18 21:03:40,990:INFO:Starting cross validation
2025-05-18 21:03:40,991:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:03:44,214:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 21:03:47,321:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 21:03:50,393:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 21:03:53,475:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 21:03:56,447:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-18 21:03:56,489:INFO:Calculating mean and std
2025-05-18 21:03:56,490:INFO:Creating metrics dataframe
2025-05-18 21:03:56,491:INFO:Uploading results into container
2025-05-18 21:03:56,492:INFO:Uploading model into container now
2025-05-18 21:03:56,492:INFO:_master_model_container: 1
2025-05-18 21:03:56,492:INFO:_display_container: 2
2025-05-18 21:03:56,492:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-18 21:03:56,492:INFO:create_model() successfully completed......................................
2025-05-18 21:03:56,736:INFO:SubProcess create_model() end ==================================
2025-05-18 21:03:56,736:INFO:Creating metrics dataframe
2025-05-18 21:03:56,739:INFO:Initializing K Neighbors Classifier
2025-05-18 21:03:56,739:INFO:Total runtime is 0.26276874939600625 minutes
2025-05-18 21:03:56,740:INFO:SubProcess create_model() called ==================================
2025-05-18 21:03:56,740:INFO:Initializing create_model()
2025-05-18 21:03:56,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f206310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:03:56,741:INFO:Checking exceptions
2025-05-18 21:03:56,741:INFO:Importing libraries
2025-05-18 21:03:56,741:INFO:Copying training dataset
2025-05-18 21:03:56,750:INFO:Defining folds
2025-05-18 21:03:56,750:INFO:Declaring metric variables
2025-05-18 21:03:56,751:INFO:Importing untrained model
2025-05-18 21:03:56,752:INFO:K Neighbors Classifier Imported successfully
2025-05-18 21:03:56,754:INFO:Starting cross validation
2025-05-18 21:03:56,755:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:04:04,625:INFO:Calculating mean and std
2025-05-18 21:04:04,626:INFO:Creating metrics dataframe
2025-05-18 21:04:04,627:INFO:Uploading results into container
2025-05-18 21:04:04,627:INFO:Uploading model into container now
2025-05-18 21:04:04,627:INFO:_master_model_container: 2
2025-05-18 21:04:04,627:INFO:_display_container: 2
2025-05-18 21:04:04,627:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-18 21:04:04,628:INFO:create_model() successfully completed......................................
2025-05-18 21:04:04,807:INFO:SubProcess create_model() end ==================================
2025-05-18 21:04:04,807:INFO:Creating metrics dataframe
2025-05-18 21:04:04,810:INFO:Initializing Naive Bayes
2025-05-18 21:04:04,810:INFO:Total runtime is 0.3972839832305908 minutes
2025-05-18 21:04:04,811:INFO:SubProcess create_model() called ==================================
2025-05-18 21:04:04,811:INFO:Initializing create_model()
2025-05-18 21:04:04,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f206310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:04:04,812:INFO:Checking exceptions
2025-05-18 21:04:04,812:INFO:Importing libraries
2025-05-18 21:04:04,812:INFO:Copying training dataset
2025-05-18 21:04:04,821:INFO:Defining folds
2025-05-18 21:04:04,821:INFO:Declaring metric variables
2025-05-18 21:04:04,823:INFO:Importing untrained model
2025-05-18 21:04:04,824:INFO:Naive Bayes Imported successfully
2025-05-18 21:04:04,826:INFO:Starting cross validation
2025-05-18 21:04:04,827:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:04:08,961:INFO:Calculating mean and std
2025-05-18 21:04:08,961:INFO:Creating metrics dataframe
2025-05-18 21:04:08,962:INFO:Uploading results into container
2025-05-18 21:04:08,962:INFO:Uploading model into container now
2025-05-18 21:04:08,962:INFO:_master_model_container: 3
2025-05-18 21:04:08,962:INFO:_display_container: 2
2025-05-18 21:04:08,962:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-18 21:04:08,962:INFO:create_model() successfully completed......................................
2025-05-18 21:04:09,128:INFO:SubProcess create_model() end ==================================
2025-05-18 21:04:09,129:INFO:Creating metrics dataframe
2025-05-18 21:04:09,132:INFO:Initializing Decision Tree Classifier
2025-05-18 21:04:09,132:INFO:Total runtime is 0.4693114320437113 minutes
2025-05-18 21:04:09,133:INFO:SubProcess create_model() called ==================================
2025-05-18 21:04:09,133:INFO:Initializing create_model()
2025-05-18 21:04:09,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f206310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:04:09,133:INFO:Checking exceptions
2025-05-18 21:04:09,133:INFO:Importing libraries
2025-05-18 21:04:09,133:INFO:Copying training dataset
2025-05-18 21:04:09,142:INFO:Defining folds
2025-05-18 21:04:09,142:INFO:Declaring metric variables
2025-05-18 21:04:09,143:INFO:Importing untrained model
2025-05-18 21:04:09,144:INFO:Decision Tree Classifier Imported successfully
2025-05-18 21:04:09,146:INFO:Starting cross validation
2025-05-18 21:04:09,147:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:04:15,907:INFO:Calculating mean and std
2025-05-18 21:04:15,908:INFO:Creating metrics dataframe
2025-05-18 21:04:15,909:INFO:Uploading results into container
2025-05-18 21:04:15,909:INFO:Uploading model into container now
2025-05-18 21:04:15,909:INFO:_master_model_container: 4
2025-05-18 21:04:15,909:INFO:_display_container: 2
2025-05-18 21:04:15,910:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-18 21:04:15,910:INFO:create_model() successfully completed......................................
2025-05-18 21:04:16,072:INFO:SubProcess create_model() end ==================================
2025-05-18 21:04:16,072:INFO:Creating metrics dataframe
2025-05-18 21:04:16,075:INFO:Initializing SVM - Linear Kernel
2025-05-18 21:04:16,075:INFO:Total runtime is 0.5850284496943156 minutes
2025-05-18 21:04:16,076:INFO:SubProcess create_model() called ==================================
2025-05-18 21:04:16,076:INFO:Initializing create_model()
2025-05-18 21:04:16,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f206310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:04:16,076:INFO:Checking exceptions
2025-05-18 21:04:16,076:INFO:Importing libraries
2025-05-18 21:04:16,076:INFO:Copying training dataset
2025-05-18 21:04:16,085:INFO:Defining folds
2025-05-18 21:04:16,085:INFO:Declaring metric variables
2025-05-18 21:04:16,086:INFO:Importing untrained model
2025-05-18 21:04:16,087:INFO:SVM - Linear Kernel Imported successfully
2025-05-18 21:04:16,089:INFO:Starting cross validation
2025-05-18 21:04:16,090:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:04:25,880:INFO:Calculating mean and std
2025-05-18 21:04:25,881:INFO:Creating metrics dataframe
2025-05-18 21:04:25,882:INFO:Uploading results into container
2025-05-18 21:04:25,883:INFO:Uploading model into container now
2025-05-18 21:04:25,883:INFO:_master_model_container: 5
2025-05-18 21:04:25,883:INFO:_display_container: 2
2025-05-18 21:04:25,883:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-18 21:04:25,883:INFO:create_model() successfully completed......................................
2025-05-18 21:04:26,060:INFO:SubProcess create_model() end ==================================
2025-05-18 21:04:26,060:INFO:Creating metrics dataframe
2025-05-18 21:04:26,063:INFO:Initializing Ridge Classifier
2025-05-18 21:04:26,063:INFO:Total runtime is 0.7515013496081033 minutes
2025-05-18 21:04:26,064:INFO:SubProcess create_model() called ==================================
2025-05-18 21:04:26,064:INFO:Initializing create_model()
2025-05-18 21:04:26,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f206310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:04:26,065:INFO:Checking exceptions
2025-05-18 21:04:26,065:INFO:Importing libraries
2025-05-18 21:04:26,065:INFO:Copying training dataset
2025-05-18 21:04:26,074:INFO:Defining folds
2025-05-18 21:04:26,074:INFO:Declaring metric variables
2025-05-18 21:04:26,075:INFO:Importing untrained model
2025-05-18 21:04:26,076:INFO:Ridge Classifier Imported successfully
2025-05-18 21:04:26,078:INFO:Starting cross validation
2025-05-18 21:04:26,079:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:04:30,213:INFO:Calculating mean and std
2025-05-18 21:04:30,214:INFO:Creating metrics dataframe
2025-05-18 21:04:30,214:INFO:Uploading results into container
2025-05-18 21:04:30,214:INFO:Uploading model into container now
2025-05-18 21:04:30,215:INFO:_master_model_container: 6
2025-05-18 21:04:30,215:INFO:_display_container: 2
2025-05-18 21:04:30,215:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-18 21:04:30,215:INFO:create_model() successfully completed......................................
2025-05-18 21:04:30,380:INFO:SubProcess create_model() end ==================================
2025-05-18 21:04:30,380:INFO:Creating metrics dataframe
2025-05-18 21:04:30,384:INFO:Initializing Random Forest Classifier
2025-05-18 21:04:30,384:INFO:Total runtime is 0.8235138495763141 minutes
2025-05-18 21:04:30,385:INFO:SubProcess create_model() called ==================================
2025-05-18 21:04:30,385:INFO:Initializing create_model()
2025-05-18 21:04:30,385:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f206310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:04:30,385:INFO:Checking exceptions
2025-05-18 21:04:30,385:INFO:Importing libraries
2025-05-18 21:04:30,385:INFO:Copying training dataset
2025-05-18 21:04:30,394:INFO:Defining folds
2025-05-18 21:04:30,394:INFO:Declaring metric variables
2025-05-18 21:04:30,395:INFO:Importing untrained model
2025-05-18 21:04:30,397:INFO:Random Forest Classifier Imported successfully
2025-05-18 21:04:30,399:INFO:Starting cross validation
2025-05-18 21:04:30,400:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:05:12,754:INFO:Calculating mean and std
2025-05-18 21:05:12,757:INFO:Creating metrics dataframe
2025-05-18 21:05:12,758:INFO:Uploading results into container
2025-05-18 21:05:12,758:INFO:Uploading model into container now
2025-05-18 21:05:12,758:INFO:_master_model_container: 7
2025-05-18 21:05:12,759:INFO:_display_container: 2
2025-05-18 21:05:12,759:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-18 21:05:12,759:INFO:create_model() successfully completed......................................
2025-05-18 21:05:12,941:INFO:SubProcess create_model() end ==================================
2025-05-18 21:05:12,941:INFO:Creating metrics dataframe
2025-05-18 21:05:12,945:INFO:Initializing Quadratic Discriminant Analysis
2025-05-18 21:05:12,945:INFO:Total runtime is 1.5328633149464923 minutes
2025-05-18 21:05:12,946:INFO:SubProcess create_model() called ==================================
2025-05-18 21:05:12,946:INFO:Initializing create_model()
2025-05-18 21:05:12,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f206310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:05:12,946:INFO:Checking exceptions
2025-05-18 21:05:12,946:INFO:Importing libraries
2025-05-18 21:05:12,946:INFO:Copying training dataset
2025-05-18 21:05:12,956:INFO:Defining folds
2025-05-18 21:05:12,956:INFO:Declaring metric variables
2025-05-18 21:05:12,957:INFO:Importing untrained model
2025-05-18 21:05:12,958:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 21:05:12,960:INFO:Starting cross validation
2025-05-18 21:05:12,961:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:05:13,802:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 21:05:13,863:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:05:14,656:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 21:05:14,718:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:05:15,497:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 21:05:15,561:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:05:16,420:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 21:05:16,485:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:05:17,300:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-18 21:05:17,360:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:05:17,365:INFO:Calculating mean and std
2025-05-18 21:05:17,365:INFO:Creating metrics dataframe
2025-05-18 21:05:17,366:INFO:Uploading results into container
2025-05-18 21:05:17,366:INFO:Uploading model into container now
2025-05-18 21:05:17,367:INFO:_master_model_container: 8
2025-05-18 21:05:17,367:INFO:_display_container: 2
2025-05-18 21:05:17,367:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 21:05:17,367:INFO:create_model() successfully completed......................................
2025-05-18 21:05:17,550:INFO:SubProcess create_model() end ==================================
2025-05-18 21:05:17,550:INFO:Creating metrics dataframe
2025-05-18 21:05:17,553:INFO:Initializing Ada Boost Classifier
2025-05-18 21:05:17,553:INFO:Total runtime is 1.6096706668535867 minutes
2025-05-18 21:05:17,554:INFO:SubProcess create_model() called ==================================
2025-05-18 21:05:17,555:INFO:Initializing create_model()
2025-05-18 21:05:17,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f206310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:05:17,555:INFO:Checking exceptions
2025-05-18 21:05:17,555:INFO:Importing libraries
2025-05-18 21:05:17,555:INFO:Copying training dataset
2025-05-18 21:05:17,564:INFO:Defining folds
2025-05-18 21:05:17,564:INFO:Declaring metric variables
2025-05-18 21:05:17,565:INFO:Importing untrained model
2025-05-18 21:05:17,566:INFO:Ada Boost Classifier Imported successfully
2025-05-18 21:05:17,568:INFO:Starting cross validation
2025-05-18 21:05:17,569:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:05:18,403:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 21:05:21,694:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 21:05:25,060:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 21:05:28,388:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 21:05:31,673:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 21:05:34,399:INFO:Calculating mean and std
2025-05-18 21:05:34,400:INFO:Creating metrics dataframe
2025-05-18 21:05:34,401:INFO:Uploading results into container
2025-05-18 21:05:34,401:INFO:Uploading model into container now
2025-05-18 21:05:34,402:INFO:_master_model_container: 9
2025-05-18 21:05:34,402:INFO:_display_container: 2
2025-05-18 21:05:34,402:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-18 21:05:34,402:INFO:create_model() successfully completed......................................
2025-05-18 21:05:34,671:INFO:SubProcess create_model() end ==================================
2025-05-18 21:05:34,671:INFO:Creating metrics dataframe
2025-05-18 21:05:34,675:INFO:Initializing Gradient Boosting Classifier
2025-05-18 21:05:34,675:INFO:Total runtime is 1.8950371305147806 minutes
2025-05-18 21:05:34,676:INFO:SubProcess create_model() called ==================================
2025-05-18 21:05:34,677:INFO:Initializing create_model()
2025-05-18 21:05:34,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f206310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:05:34,677:INFO:Checking exceptions
2025-05-18 21:05:34,677:INFO:Importing libraries
2025-05-18 21:05:34,677:INFO:Copying training dataset
2025-05-18 21:05:34,686:INFO:Defining folds
2025-05-18 21:05:34,686:INFO:Declaring metric variables
2025-05-18 21:05:34,688:INFO:Importing untrained model
2025-05-18 21:05:34,689:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 21:05:34,691:INFO:Starting cross validation
2025-05-18 21:05:34,692:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:06:42,463:INFO:Calculating mean and std
2025-05-18 21:06:42,465:INFO:Creating metrics dataframe
2025-05-18 21:06:42,467:INFO:Uploading results into container
2025-05-18 21:06:42,467:INFO:Uploading model into container now
2025-05-18 21:06:42,467:INFO:_master_model_container: 10
2025-05-18 21:06:42,467:INFO:_display_container: 2
2025-05-18 21:06:42,468:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 21:06:42,468:INFO:create_model() successfully completed......................................
2025-05-18 21:06:42,685:INFO:SubProcess create_model() end ==================================
2025-05-18 21:06:42,685:INFO:Creating metrics dataframe
2025-05-18 21:06:42,689:INFO:Initializing Linear Discriminant Analysis
2025-05-18 21:06:42,689:INFO:Total runtime is 3.0286031007766723 minutes
2025-05-18 21:06:42,690:INFO:SubProcess create_model() called ==================================
2025-05-18 21:06:42,691:INFO:Initializing create_model()
2025-05-18 21:06:42,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f206310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:06:42,691:INFO:Checking exceptions
2025-05-18 21:06:42,691:INFO:Importing libraries
2025-05-18 21:06:42,691:INFO:Copying training dataset
2025-05-18 21:06:42,700:INFO:Defining folds
2025-05-18 21:06:42,700:INFO:Declaring metric variables
2025-05-18 21:06:42,701:INFO:Importing untrained model
2025-05-18 21:06:42,702:INFO:Linear Discriminant Analysis Imported successfully
2025-05-18 21:06:42,704:INFO:Starting cross validation
2025-05-18 21:06:42,705:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:06:47,296:INFO:Calculating mean and std
2025-05-18 21:06:47,297:INFO:Creating metrics dataframe
2025-05-18 21:06:47,297:INFO:Uploading results into container
2025-05-18 21:06:47,298:INFO:Uploading model into container now
2025-05-18 21:06:47,298:INFO:_master_model_container: 11
2025-05-18 21:06:47,298:INFO:_display_container: 2
2025-05-18 21:06:47,298:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-18 21:06:47,298:INFO:create_model() successfully completed......................................
2025-05-18 21:06:47,469:INFO:SubProcess create_model() end ==================================
2025-05-18 21:06:47,469:INFO:Creating metrics dataframe
2025-05-18 21:06:47,473:INFO:Initializing Extra Trees Classifier
2025-05-18 21:06:47,473:INFO:Total runtime is 3.1083353996276855 minutes
2025-05-18 21:06:47,474:INFO:SubProcess create_model() called ==================================
2025-05-18 21:06:47,475:INFO:Initializing create_model()
2025-05-18 21:06:47,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f206310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:06:47,475:INFO:Checking exceptions
2025-05-18 21:06:47,475:INFO:Importing libraries
2025-05-18 21:06:47,475:INFO:Copying training dataset
2025-05-18 21:06:47,484:INFO:Defining folds
2025-05-18 21:06:47,485:INFO:Declaring metric variables
2025-05-18 21:06:47,486:INFO:Importing untrained model
2025-05-18 21:06:47,487:INFO:Extra Trees Classifier Imported successfully
2025-05-18 21:06:47,489:INFO:Starting cross validation
2025-05-18 21:06:47,490:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:07:15,240:INFO:Calculating mean and std
2025-05-18 21:07:15,242:INFO:Creating metrics dataframe
2025-05-18 21:07:15,243:INFO:Uploading results into container
2025-05-18 21:07:15,244:INFO:Uploading model into container now
2025-05-18 21:07:15,244:INFO:_master_model_container: 12
2025-05-18 21:07:15,244:INFO:_display_container: 2
2025-05-18 21:07:15,245:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-18 21:07:15,245:INFO:create_model() successfully completed......................................
2025-05-18 21:07:15,499:INFO:SubProcess create_model() end ==================================
2025-05-18 21:07:15,499:INFO:Creating metrics dataframe
2025-05-18 21:07:15,504:INFO:Initializing Light Gradient Boosting Machine
2025-05-18 21:07:15,504:INFO:Total runtime is 3.5755120317141214 minutes
2025-05-18 21:07:15,505:INFO:SubProcess create_model() called ==================================
2025-05-18 21:07:15,505:INFO:Initializing create_model()
2025-05-18 21:07:15,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f206310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:07:15,505:INFO:Checking exceptions
2025-05-18 21:07:15,505:INFO:Importing libraries
2025-05-18 21:07:15,506:INFO:Copying training dataset
2025-05-18 21:07:15,518:INFO:Defining folds
2025-05-18 21:07:15,518:INFO:Declaring metric variables
2025-05-18 21:07:15,519:INFO:Importing untrained model
2025-05-18 21:07:15,521:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 21:07:15,523:INFO:Starting cross validation
2025-05-18 21:07:15,524:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:07:16,428:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:07:16,450:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010623 seconds.
2025-05-18 21:07:16,450:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:07:16,450:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:07:16,450:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:07:16,450:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:07:16,450:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:07:18,042:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:07:18,062:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009868 seconds.
2025-05-18 21:07:18,062:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:07:18,062:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:07:18,062:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:07:18,063:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:07:18,063:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:07:19,619:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:07:19,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010340 seconds.
2025-05-18 21:07:19,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:07:19,641:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:07:19,641:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:07:19,641:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:07:19,641:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:07:21,088:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:07:21,110:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010363 seconds.
2025-05-18 21:07:21,110:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:07:21,110:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:07:21,110:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:07:21,110:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:07:21,110:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:07:22,621:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:07:22,647:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010248 seconds.
2025-05-18 21:07:22,647:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:07:22,647:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:07:22,647:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:07:22,648:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:07:22,648:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:07:23,253:INFO:Calculating mean and std
2025-05-18 21:07:23,254:INFO:Creating metrics dataframe
2025-05-18 21:07:23,255:INFO:Uploading results into container
2025-05-18 21:07:23,255:INFO:Uploading model into container now
2025-05-18 21:07:23,255:INFO:_master_model_container: 13
2025-05-18 21:07:23,255:INFO:_display_container: 2
2025-05-18 21:07:23,256:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 21:07:23,256:INFO:create_model() successfully completed......................................
2025-05-18 21:07:23,438:INFO:SubProcess create_model() end ==================================
2025-05-18 21:07:23,438:INFO:Creating metrics dataframe
2025-05-18 21:07:23,443:INFO:Initializing CatBoost Classifier
2025-05-18 21:07:23,443:INFO:Total runtime is 3.707827850182851 minutes
2025-05-18 21:07:23,444:INFO:SubProcess create_model() called ==================================
2025-05-18 21:07:23,444:INFO:Initializing create_model()
2025-05-18 21:07:23,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x355938910>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f206310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:07:23,444:INFO:Checking exceptions
2025-05-18 21:07:23,444:INFO:Importing libraries
2025-05-18 21:07:23,444:INFO:Copying training dataset
2025-05-18 21:07:23,454:INFO:Defining folds
2025-05-18 21:07:23,454:INFO:Declaring metric variables
2025-05-18 21:07:23,456:INFO:Importing untrained model
2025-05-18 21:07:23,457:INFO:CatBoost Classifier Imported successfully
2025-05-18 21:07:23,460:INFO:Starting cross validation
2025-05-18 21:07:23,461:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:08:44,698:INFO:PyCaret ClassificationExperiment
2025-05-18 21:08:44,698:INFO:Logging name: clf-default-name
2025-05-18 21:08:44,699:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-18 21:08:44,699:INFO:version 3.3.2
2025-05-18 21:08:44,699:INFO:Initializing setup()
2025-05-18 21:08:44,699:INFO:self.USI: 642e
2025-05-18 21:08:44,699:INFO:self._variable_keys: {'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'memory', 'X', 'y_train', 'target_param', 'is_multiclass', 'fold_groups_param', 'gpu_param', 'idx', 'log_plots_param', 'fold_generator', 'pipeline', 'X_test', 'data', 'fold_shuffle_param', 'exp_id', 'USI', 'html_param', 'seed', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_test', 'exp_name_log', 'logging_param'}
2025-05-18 21:08:44,699:INFO:Checking environment
2025-05-18 21:08:44,699:INFO:python_version: 3.11.0
2025-05-18 21:08:44,699:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-18 21:08:44,699:INFO:machine: arm64
2025-05-18 21:08:44,699:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-18 21:08:44,699:INFO:Memory: svmem(total=17179869184, available=3359277056, percent=80.4, used=6089687040, free=65257472, active=3309355008, inactive=3291529216, wired=2780332032)
2025-05-18 21:08:44,699:INFO:Physical Core: 12
2025-05-18 21:08:44,699:INFO:Logical Core: 12
2025-05-18 21:08:44,699:INFO:Checking libraries
2025-05-18 21:08:44,699:INFO:System:
2025-05-18 21:08:44,699:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-18 21:08:44,699:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-18 21:08:44,699:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-18 21:08:44,699:INFO:PyCaret required dependencies:
2025-05-18 21:08:44,699:INFO:                 pip: 22.3
2025-05-18 21:08:44,699:INFO:          setuptools: 65.5.0
2025-05-18 21:08:44,699:INFO:             pycaret: 3.3.2
2025-05-18 21:08:44,699:INFO:             IPython: 9.2.0
2025-05-18 21:08:44,699:INFO:          ipywidgets: 8.1.7
2025-05-18 21:08:44,699:INFO:                tqdm: 4.67.1
2025-05-18 21:08:44,699:INFO:               numpy: 1.26.4
2025-05-18 21:08:44,699:INFO:              pandas: 2.1.4
2025-05-18 21:08:44,699:INFO:              jinja2: 3.1.6
2025-05-18 21:08:44,699:INFO:               scipy: 1.11.4
2025-05-18 21:08:44,699:INFO:              joblib: 1.3.2
2025-05-18 21:08:44,699:INFO:             sklearn: 1.4.2
2025-05-18 21:08:44,699:INFO:                pyod: 2.0.5
2025-05-18 21:08:44,699:INFO:            imblearn: 0.13.0
2025-05-18 21:08:44,699:INFO:   category_encoders: 2.7.0
2025-05-18 21:08:44,699:INFO:            lightgbm: 4.6.0
2025-05-18 21:08:44,699:INFO:               numba: 0.61.2
2025-05-18 21:08:44,699:INFO:            requests: 2.32.3
2025-05-18 21:08:44,699:INFO:          matplotlib: 3.7.5
2025-05-18 21:08:44,699:INFO:          scikitplot: 0.3.7
2025-05-18 21:08:44,699:INFO:         yellowbrick: 1.5
2025-05-18 21:08:44,699:INFO:              plotly: 5.24.1
2025-05-18 21:08:44,699:INFO:    plotly-resampler: Not installed
2025-05-18 21:08:44,699:INFO:             kaleido: 0.2.1
2025-05-18 21:08:44,699:INFO:           schemdraw: 0.15
2025-05-18 21:08:44,699:INFO:         statsmodels: 0.14.4
2025-05-18 21:08:44,699:INFO:              sktime: 0.26.0
2025-05-18 21:08:44,699:INFO:               tbats: 1.1.3
2025-05-18 21:08:44,699:INFO:            pmdarima: 2.0.4
2025-05-18 21:08:44,699:INFO:              psutil: 7.0.0
2025-05-18 21:08:44,699:INFO:          markupsafe: 3.0.2
2025-05-18 21:08:44,699:INFO:             pickle5: Not installed
2025-05-18 21:08:44,699:INFO:         cloudpickle: 3.1.1
2025-05-18 21:08:44,699:INFO:         deprecation: 2.1.0
2025-05-18 21:08:44,699:INFO:              xxhash: 3.5.0
2025-05-18 21:08:44,699:INFO:           wurlitzer: 3.1.1
2025-05-18 21:08:44,699:INFO:PyCaret optional dependencies:
2025-05-18 21:08:44,699:INFO:                shap: 0.47.2
2025-05-18 21:08:44,699:INFO:           interpret: Not installed
2025-05-18 21:08:44,699:INFO:                umap: Not installed
2025-05-18 21:08:44,699:INFO:     ydata_profiling: Not installed
2025-05-18 21:08:44,699:INFO:  explainerdashboard: Not installed
2025-05-18 21:08:44,699:INFO:             autoviz: Not installed
2025-05-18 21:08:44,699:INFO:           fairlearn: Not installed
2025-05-18 21:08:44,699:INFO:          deepchecks: Not installed
2025-05-18 21:08:44,700:INFO:             xgboost: Not installed
2025-05-18 21:08:44,700:INFO:            catboost: 1.2.8
2025-05-18 21:08:44,700:INFO:              kmodes: Not installed
2025-05-18 21:08:44,700:INFO:             mlxtend: Not installed
2025-05-18 21:08:44,700:INFO:       statsforecast: Not installed
2025-05-18 21:08:44,700:INFO:        tune_sklearn: Not installed
2025-05-18 21:08:44,700:INFO:                 ray: Not installed
2025-05-18 21:08:44,700:INFO:            hyperopt: Not installed
2025-05-18 21:08:44,700:INFO:              optuna: 4.3.0
2025-05-18 21:08:44,700:INFO:               skopt: Not installed
2025-05-18 21:08:44,700:INFO:              mlflow: Not installed
2025-05-18 21:08:44,700:INFO:              gradio: Not installed
2025-05-18 21:08:44,700:INFO:             fastapi: Not installed
2025-05-18 21:08:44,700:INFO:             uvicorn: Not installed
2025-05-18 21:08:44,700:INFO:              m2cgen: Not installed
2025-05-18 21:08:44,700:INFO:           evidently: Not installed
2025-05-18 21:08:44,700:INFO:               fugue: Not installed
2025-05-18 21:08:44,700:INFO:           streamlit: Not installed
2025-05-18 21:08:44,700:INFO:             prophet: Not installed
2025-05-18 21:08:44,700:INFO:None
2025-05-18 21:08:44,700:INFO:Set up data.
2025-05-18 21:08:44,736:INFO:Set up folding strategy.
2025-05-18 21:08:44,736:INFO:Set up train/test split.
2025-05-18 21:08:44,752:INFO:Set up index.
2025-05-18 21:08:44,752:INFO:Assigning column types.
2025-05-18 21:08:44,756:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-18 21:08:44,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 21:08:44,775:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 21:08:44,786:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:08:44,787:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:08:44,804:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-18 21:08:44,805:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 21:08:44,815:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:08:44,815:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:08:44,816:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-18 21:08:44,833:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 21:08:44,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:08:44,845:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:08:44,864:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-18 21:08:44,875:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:08:44,875:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:08:44,875:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-18 21:08:44,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:08:44,904:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:08:44,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:08:44,934:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:08:44,934:INFO:Preparing preprocessing pipeline...
2025-05-18 21:08:44,935:INFO:Set up simple imputation.
2025-05-18 21:08:44,942:INFO:Set up encoding of ordinal features.
2025-05-18 21:08:44,952:INFO:Set up encoding of categorical features.
2025-05-18 21:08:44,952:INFO:Set up imbalanced handling.
2025-05-18 21:08:44,952:INFO:Set up column transformation.
2025-05-18 21:08:44,952:INFO:Set up feature selection.
2025-05-18 21:08:44,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:08:44,980:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:08:45,281:INFO:Finished creating preprocessing pipeline.
2025-05-18 21:08:45,305:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=14,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-05-18 21:08:45,305:INFO:Creating final display dataframe.
2025-05-18 21:08:45,533:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 15)
5   Transformed train set shape       (85902, 15)
6    Transformed test set shape       (20919, 15)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19            Feature selection              True
20     Feature selection method           classic
21  Feature selection estimator          lightgbm
22  Number of features selected              0.99
23               Fold Generator   StratifiedKFold
24                  Fold Number                 5
25                     CPU Jobs                 1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              642e
2025-05-18 21:08:45,566:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:08:45,566:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:08:45,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-18 21:08:45,595:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-18 21:08:45,596:INFO:setup() successfully completed in 0.9s...............
2025-05-18 21:08:45,596:INFO:Initializing compare_models()
2025-05-18 21:08:45,596:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-18 21:08:45,596:INFO:Checking exceptions
2025-05-18 21:08:45,603:INFO:Preparing display monitor
2025-05-18 21:08:45,611:INFO:Initializing Logistic Regression
2025-05-18 21:08:45,611:INFO:Total runtime is 1.7523765563964843e-06 minutes
2025-05-18 21:08:45,612:INFO:SubProcess create_model() called ==================================
2025-05-18 21:08:45,613:INFO:Initializing create_model()
2025-05-18 21:08:45,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:08:45,613:INFO:Checking exceptions
2025-05-18 21:08:45,613:INFO:Importing libraries
2025-05-18 21:08:45,613:INFO:Copying training dataset
2025-05-18 21:08:45,625:INFO:Defining folds
2025-05-18 21:08:45,625:INFO:Declaring metric variables
2025-05-18 21:08:45,627:INFO:Importing untrained model
2025-05-18 21:08:45,628:INFO:Logistic Regression Imported successfully
2025-05-18 21:08:45,631:INFO:Starting cross validation
2025-05-18 21:08:45,637:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:08:46,475:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:08:46,485:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004679 seconds.
2025-05-18 21:08:46,485:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:08:46,485:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:08:46,485:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:08:46,485:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:08:46,486:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:08:49,010:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:08:49,018:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004110 seconds.
2025-05-18 21:08:49,018:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:08:49,018:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:08:49,018:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:08:49,018:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:08:49,019:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:08:51,648:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:08:51,657:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004360 seconds.
2025-05-18 21:08:51,657:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:08:51,657:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:08:51,657:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:08:51,657:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:08:51,657:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:08:53,940:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:08:53,949:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004349 seconds.
2025-05-18 21:08:53,949:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:08:53,949:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:08:53,949:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:08:53,949:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:08:53,950:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:08:56,275:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:08:56,284:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004434 seconds.
2025-05-18 21:08:56,284:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:08:56,284:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:08:56,284:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:08:56,285:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:08:56,285:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:08:58,258:INFO:Calculating mean and std
2025-05-18 21:08:58,258:INFO:Creating metrics dataframe
2025-05-18 21:08:58,259:INFO:Uploading results into container
2025-05-18 21:08:58,260:INFO:Uploading model into container now
2025-05-18 21:08:58,260:INFO:_master_model_container: 1
2025-05-18 21:08:58,260:INFO:_display_container: 2
2025-05-18 21:08:58,260:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-18 21:08:58,260:INFO:create_model() successfully completed......................................
2025-05-18 21:08:58,516:INFO:SubProcess create_model() end ==================================
2025-05-18 21:08:58,516:INFO:Creating metrics dataframe
2025-05-18 21:08:58,519:INFO:Initializing K Neighbors Classifier
2025-05-18 21:08:58,519:INFO:Total runtime is 0.21513285239537555 minutes
2025-05-18 21:08:58,520:INFO:SubProcess create_model() called ==================================
2025-05-18 21:08:58,520:INFO:Initializing create_model()
2025-05-18 21:08:58,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:08:58,521:INFO:Checking exceptions
2025-05-18 21:08:58,521:INFO:Importing libraries
2025-05-18 21:08:58,521:INFO:Copying training dataset
2025-05-18 21:08:58,533:INFO:Defining folds
2025-05-18 21:08:58,533:INFO:Declaring metric variables
2025-05-18 21:08:58,535:INFO:Importing untrained model
2025-05-18 21:08:58,536:INFO:K Neighbors Classifier Imported successfully
2025-05-18 21:08:58,538:INFO:Starting cross validation
2025-05-18 21:08:58,541:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:08:59,418:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:08:59,428:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004525 seconds.
2025-05-18 21:08:59,428:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:08:59,429:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:08:59,429:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:08:59,429:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:08:59,429:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:02,522:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:02,531:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004407 seconds.
2025-05-18 21:09:02,531:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:02,531:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:02,531:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:02,531:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:02,532:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:05,751:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:05,759:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004300 seconds.
2025-05-18 21:09:05,760:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:05,760:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:05,760:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:05,760:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:05,760:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:09,012:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:09,021:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004696 seconds.
2025-05-18 21:09:09,021:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:09,021:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:09,021:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:09,021:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:09,022:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:11,992:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:12,001:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004524 seconds.
2025-05-18 21:09:12,001:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:12,001:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:12,001:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:12,001:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:12,002:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:14,400:INFO:Calculating mean and std
2025-05-18 21:09:14,401:INFO:Creating metrics dataframe
2025-05-18 21:09:14,403:INFO:Uploading results into container
2025-05-18 21:09:14,403:INFO:Uploading model into container now
2025-05-18 21:09:14,403:INFO:_master_model_container: 2
2025-05-18 21:09:14,403:INFO:_display_container: 2
2025-05-18 21:09:14,404:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-18 21:09:14,404:INFO:create_model() successfully completed......................................
2025-05-18 21:09:14,657:INFO:SubProcess create_model() end ==================================
2025-05-18 21:09:14,658:INFO:Creating metrics dataframe
2025-05-18 21:09:14,661:INFO:Initializing Naive Bayes
2025-05-18 21:09:14,661:INFO:Total runtime is 0.48417088588078816 minutes
2025-05-18 21:09:14,663:INFO:SubProcess create_model() called ==================================
2025-05-18 21:09:14,663:INFO:Initializing create_model()
2025-05-18 21:09:14,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:09:14,663:INFO:Checking exceptions
2025-05-18 21:09:14,663:INFO:Importing libraries
2025-05-18 21:09:14,663:INFO:Copying training dataset
2025-05-18 21:09:14,674:INFO:Defining folds
2025-05-18 21:09:14,674:INFO:Declaring metric variables
2025-05-18 21:09:14,675:INFO:Importing untrained model
2025-05-18 21:09:14,676:INFO:Naive Bayes Imported successfully
2025-05-18 21:09:14,679:INFO:Starting cross validation
2025-05-18 21:09:14,682:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:09:15,491:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:09:15,501:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004539 seconds.
2025-05-18 21:09:15,501:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:15,501:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:15,501:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:15,501:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:09:15,502:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:17,615:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:17,624:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004288 seconds.
2025-05-18 21:09:17,624:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:17,624:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:17,624:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:17,625:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:17,626:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:19,576:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:19,585:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004375 seconds.
2025-05-18 21:09:19,585:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:19,585:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:19,585:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:19,585:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:19,585:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:21,552:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:21,561:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004140 seconds.
2025-05-18 21:09:21,561:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:21,561:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:21,561:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:21,561:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:21,561:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:23,505:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:23,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004316 seconds.
2025-05-18 21:09:23,513:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:23,513:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:23,514:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:23,514:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:23,514:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:24,623:INFO:Calculating mean and std
2025-05-18 21:09:24,624:INFO:Creating metrics dataframe
2025-05-18 21:09:24,625:INFO:Uploading results into container
2025-05-18 21:09:24,625:INFO:Uploading model into container now
2025-05-18 21:09:24,625:INFO:_master_model_container: 3
2025-05-18 21:09:24,625:INFO:_display_container: 2
2025-05-18 21:09:24,625:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-18 21:09:24,625:INFO:create_model() successfully completed......................................
2025-05-18 21:09:24,812:INFO:SubProcess create_model() end ==================================
2025-05-18 21:09:24,812:INFO:Creating metrics dataframe
2025-05-18 21:09:24,815:INFO:Initializing Decision Tree Classifier
2025-05-18 21:09:24,815:INFO:Total runtime is 0.6534066994984944 minutes
2025-05-18 21:09:24,817:INFO:SubProcess create_model() called ==================================
2025-05-18 21:09:24,817:INFO:Initializing create_model()
2025-05-18 21:09:24,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:09:24,817:INFO:Checking exceptions
2025-05-18 21:09:24,817:INFO:Importing libraries
2025-05-18 21:09:24,817:INFO:Copying training dataset
2025-05-18 21:09:24,826:INFO:Defining folds
2025-05-18 21:09:24,826:INFO:Declaring metric variables
2025-05-18 21:09:24,827:INFO:Importing untrained model
2025-05-18 21:09:24,828:INFO:Decision Tree Classifier Imported successfully
2025-05-18 21:09:24,830:INFO:Starting cross validation
2025-05-18 21:09:24,833:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:09:25,604:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:09:25,613:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004446 seconds.
2025-05-18 21:09:25,613:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:25,613:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:25,613:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:25,613:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:09:25,613:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:27,953:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:27,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004008 seconds.
2025-05-18 21:09:27,962:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:27,962:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:27,962:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:27,962:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:27,963:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:30,264:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:30,272:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004379 seconds.
2025-05-18 21:09:30,272:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:30,272:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:30,273:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:30,273:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:30,273:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:32,634:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:32,642:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004326 seconds.
2025-05-18 21:09:32,643:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:32,643:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:32,643:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:32,643:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:32,643:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:34,988:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:34,996:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004111 seconds.
2025-05-18 21:09:34,996:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:34,996:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:34,996:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:34,996:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:34,997:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:36,522:INFO:Calculating mean and std
2025-05-18 21:09:36,522:INFO:Creating metrics dataframe
2025-05-18 21:09:36,523:INFO:Uploading results into container
2025-05-18 21:09:36,524:INFO:Uploading model into container now
2025-05-18 21:09:36,524:INFO:_master_model_container: 4
2025-05-18 21:09:36,524:INFO:_display_container: 2
2025-05-18 21:09:36,524:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-18 21:09:36,524:INFO:create_model() successfully completed......................................
2025-05-18 21:09:36,702:INFO:SubProcess create_model() end ==================================
2025-05-18 21:09:36,702:INFO:Creating metrics dataframe
2025-05-18 21:09:36,705:INFO:Initializing SVM - Linear Kernel
2025-05-18 21:09:36,705:INFO:Total runtime is 0.8515681346257526 minutes
2025-05-18 21:09:36,706:INFO:SubProcess create_model() called ==================================
2025-05-18 21:09:36,707:INFO:Initializing create_model()
2025-05-18 21:09:36,707:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:09:36,707:INFO:Checking exceptions
2025-05-18 21:09:36,707:INFO:Importing libraries
2025-05-18 21:09:36,707:INFO:Copying training dataset
2025-05-18 21:09:36,715:INFO:Defining folds
2025-05-18 21:09:36,716:INFO:Declaring metric variables
2025-05-18 21:09:36,717:INFO:Importing untrained model
2025-05-18 21:09:36,718:INFO:SVM - Linear Kernel Imported successfully
2025-05-18 21:09:36,720:INFO:Starting cross validation
2025-05-18 21:09:36,722:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:09:37,496:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:09:37,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004428 seconds.
2025-05-18 21:09:37,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:37,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:37,505:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:37,505:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:09:37,506:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:40,084:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:40,094:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004539 seconds.
2025-05-18 21:09:40,094:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:40,094:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:40,094:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:40,094:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:40,094:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:42,946:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:42,956:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004651 seconds.
2025-05-18 21:09:42,956:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:42,956:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:42,956:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:42,956:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:42,956:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:45,708:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:45,717:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004560 seconds.
2025-05-18 21:09:45,717:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:45,717:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:45,717:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:45,717:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:45,718:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:48,422:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:48,431:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004463 seconds.
2025-05-18 21:09:48,431:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:48,431:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:48,431:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:48,432:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:48,432:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:50,049:INFO:Calculating mean and std
2025-05-18 21:09:50,050:INFO:Creating metrics dataframe
2025-05-18 21:09:50,050:INFO:Uploading results into container
2025-05-18 21:09:50,051:INFO:Uploading model into container now
2025-05-18 21:09:50,051:INFO:_master_model_container: 5
2025-05-18 21:09:50,051:INFO:_display_container: 2
2025-05-18 21:09:50,051:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-18 21:09:50,051:INFO:create_model() successfully completed......................................
2025-05-18 21:09:50,227:INFO:SubProcess create_model() end ==================================
2025-05-18 21:09:50,227:INFO:Creating metrics dataframe
2025-05-18 21:09:50,230:INFO:Initializing Ridge Classifier
2025-05-18 21:09:50,230:INFO:Total runtime is 1.076978798707326 minutes
2025-05-18 21:09:50,231:INFO:SubProcess create_model() called ==================================
2025-05-18 21:09:50,231:INFO:Initializing create_model()
2025-05-18 21:09:50,231:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:09:50,231:INFO:Checking exceptions
2025-05-18 21:09:50,231:INFO:Importing libraries
2025-05-18 21:09:50,231:INFO:Copying training dataset
2025-05-18 21:09:50,240:INFO:Defining folds
2025-05-18 21:09:50,240:INFO:Declaring metric variables
2025-05-18 21:09:50,241:INFO:Importing untrained model
2025-05-18 21:09:50,242:INFO:Ridge Classifier Imported successfully
2025-05-18 21:09:50,245:INFO:Starting cross validation
2025-05-18 21:09:50,247:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:09:51,036:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:09:51,045:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004562 seconds.
2025-05-18 21:09:51,045:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:51,045:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:51,045:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:51,045:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:09:51,046:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:52,972:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:52,981:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004365 seconds.
2025-05-18 21:09:52,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:52,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:52,981:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:52,981:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:52,981:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:54,875:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:54,884:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004386 seconds.
2025-05-18 21:09:54,884:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:54,884:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:54,884:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:54,884:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:54,884:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:56,862:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:56,872:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004413 seconds.
2025-05-18 21:09:56,872:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:56,872:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:56,872:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:56,872:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:56,872:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:58,787:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:09:58,797:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004423 seconds.
2025-05-18 21:09:58,797:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:09:58,797:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:09:58,797:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:09:58,797:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:09:58,797:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:09:59,956:INFO:Calculating mean and std
2025-05-18 21:09:59,956:INFO:Creating metrics dataframe
2025-05-18 21:09:59,957:INFO:Uploading results into container
2025-05-18 21:09:59,957:INFO:Uploading model into container now
2025-05-18 21:09:59,957:INFO:_master_model_container: 6
2025-05-18 21:09:59,957:INFO:_display_container: 2
2025-05-18 21:09:59,958:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-18 21:09:59,958:INFO:create_model() successfully completed......................................
2025-05-18 21:10:00,127:INFO:SubProcess create_model() end ==================================
2025-05-18 21:10:00,127:INFO:Creating metrics dataframe
2025-05-18 21:10:00,131:INFO:Initializing Random Forest Classifier
2025-05-18 21:10:00,131:INFO:Total runtime is 1.2419937690099079 minutes
2025-05-18 21:10:00,132:INFO:SubProcess create_model() called ==================================
2025-05-18 21:10:00,132:INFO:Initializing create_model()
2025-05-18 21:10:00,132:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:10:00,132:INFO:Checking exceptions
2025-05-18 21:10:00,132:INFO:Importing libraries
2025-05-18 21:10:00,132:INFO:Copying training dataset
2025-05-18 21:10:00,141:INFO:Defining folds
2025-05-18 21:10:00,141:INFO:Declaring metric variables
2025-05-18 21:10:00,142:INFO:Importing untrained model
2025-05-18 21:10:00,143:INFO:Random Forest Classifier Imported successfully
2025-05-18 21:10:00,145:INFO:Starting cross validation
2025-05-18 21:10:00,148:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:10:00,938:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:10:00,947:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004410 seconds.
2025-05-18 21:10:00,947:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:10:00,947:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:10:00,947:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:10:00,947:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:10:00,947:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:10:10,397:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:10:10,407:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004477 seconds.
2025-05-18 21:10:10,407:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:10:10,407:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:10:10,407:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:10:10,407:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:10:10,408:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:10:19,841:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:10:19,850:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004588 seconds.
2025-05-18 21:10:19,850:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:10:19,850:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:10:19,850:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:10:19,850:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:10:19,850:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:10:29,408:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:10:29,424:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005215 seconds.
2025-05-18 21:10:29,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:10:29,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:10:29,425:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:10:29,425:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:10:29,425:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:10:39,348:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:10:39,357:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004582 seconds.
2025-05-18 21:10:39,357:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:10:39,357:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:10:39,357:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:10:39,357:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:10:39,357:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:10:47,920:INFO:Calculating mean and std
2025-05-18 21:10:47,920:INFO:Creating metrics dataframe
2025-05-18 21:10:47,921:INFO:Uploading results into container
2025-05-18 21:10:47,921:INFO:Uploading model into container now
2025-05-18 21:10:47,922:INFO:_master_model_container: 7
2025-05-18 21:10:47,922:INFO:_display_container: 2
2025-05-18 21:10:47,922:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-18 21:10:47,922:INFO:create_model() successfully completed......................................
2025-05-18 21:10:48,148:INFO:SubProcess create_model() end ==================================
2025-05-18 21:10:48,148:INFO:Creating metrics dataframe
2025-05-18 21:10:48,151:INFO:Initializing Quadratic Discriminant Analysis
2025-05-18 21:10:48,151:INFO:Total runtime is 2.0423364520072935 minutes
2025-05-18 21:10:48,152:INFO:SubProcess create_model() called ==================================
2025-05-18 21:10:48,153:INFO:Initializing create_model()
2025-05-18 21:10:48,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:10:48,153:INFO:Checking exceptions
2025-05-18 21:10:48,153:INFO:Importing libraries
2025-05-18 21:10:48,153:INFO:Copying training dataset
2025-05-18 21:10:48,162:INFO:Defining folds
2025-05-18 21:10:48,162:INFO:Declaring metric variables
2025-05-18 21:10:48,163:INFO:Importing untrained model
2025-05-18 21:10:48,164:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-18 21:10:48,166:INFO:Starting cross validation
2025-05-18 21:10:48,168:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:10:48,932:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:10:48,941:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004446 seconds.
2025-05-18 21:10:48,941:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:10:48,941:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:10:48,941:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:10:48,942:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:10:48,942:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:10:50,853:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:10:50,862:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004235 seconds.
2025-05-18 21:10:50,862:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:10:50,862:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:10:50,863:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:10:50,863:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:10:50,863:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:10:52,771:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:10:52,780:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004332 seconds.
2025-05-18 21:10:52,780:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:10:52,780:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:10:52,781:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:10:52,781:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:10:52,781:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:10:54,692:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:10:54,701:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004491 seconds.
2025-05-18 21:10:54,701:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:10:54,701:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:10:54,701:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:10:54,701:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:10:54,702:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:10:56,817:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:10:56,827:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004400 seconds.
2025-05-18 21:10:56,827:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:10:56,827:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:10:56,827:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:10:56,827:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:10:56,827:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:10:57,988:INFO:Calculating mean and std
2025-05-18 21:10:57,989:INFO:Creating metrics dataframe
2025-05-18 21:10:57,990:INFO:Uploading results into container
2025-05-18 21:10:57,990:INFO:Uploading model into container now
2025-05-18 21:10:57,990:INFO:_master_model_container: 8
2025-05-18 21:10:57,990:INFO:_display_container: 2
2025-05-18 21:10:57,990:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-18 21:10:57,990:INFO:create_model() successfully completed......................................
2025-05-18 21:10:58,188:INFO:SubProcess create_model() end ==================================
2025-05-18 21:10:58,188:INFO:Creating metrics dataframe
2025-05-18 21:10:58,192:INFO:Initializing Ada Boost Classifier
2025-05-18 21:10:58,192:INFO:Total runtime is 2.2096821347872413 minutes
2025-05-18 21:10:58,193:INFO:SubProcess create_model() called ==================================
2025-05-18 21:10:58,193:INFO:Initializing create_model()
2025-05-18 21:10:58,193:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:10:58,194:INFO:Checking exceptions
2025-05-18 21:10:58,194:INFO:Importing libraries
2025-05-18 21:10:58,194:INFO:Copying training dataset
2025-05-18 21:10:58,203:INFO:Defining folds
2025-05-18 21:10:58,204:INFO:Declaring metric variables
2025-05-18 21:10:58,205:INFO:Importing untrained model
2025-05-18 21:10:58,206:INFO:Ada Boost Classifier Imported successfully
2025-05-18 21:10:58,208:INFO:Starting cross validation
2025-05-18 21:10:58,211:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:10:59,032:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:10:59,042:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004657 seconds.
2025-05-18 21:10:59,042:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:10:59,042:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:10:59,043:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:10:59,043:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:10:59,043:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:11:00,288:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 21:11:03,544:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:11:03,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004540 seconds.
2025-05-18 21:11:03,553:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:11:03,553:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:11:03,553:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:11:03,554:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:11:03,554:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:11:04,664:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 21:11:07,818:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:11:07,827:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004263 seconds.
2025-05-18 21:11:07,827:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:11:07,827:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:11:07,827:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:11:07,828:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:11:07,828:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:11:08,891:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 21:11:12,115:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:11:12,125:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004588 seconds.
2025-05-18 21:11:12,126:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:11:12,126:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:11:12,126:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:11:12,126:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:11:12,126:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:11:13,246:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 21:11:16,340:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:11:16,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004614 seconds.
2025-05-18 21:11:16,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:11:16,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:11:16,350:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:11:16,350:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:11:16,350:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:11:17,401:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-18 21:11:19,650:INFO:Calculating mean and std
2025-05-18 21:11:19,651:INFO:Creating metrics dataframe
2025-05-18 21:11:19,653:INFO:Uploading results into container
2025-05-18 21:11:19,653:INFO:Uploading model into container now
2025-05-18 21:11:19,654:INFO:_master_model_container: 9
2025-05-18 21:11:19,654:INFO:_display_container: 2
2025-05-18 21:11:19,654:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-18 21:11:19,654:INFO:create_model() successfully completed......................................
2025-05-18 21:11:19,933:INFO:SubProcess create_model() end ==================================
2025-05-18 21:11:19,933:INFO:Creating metrics dataframe
2025-05-18 21:11:19,937:INFO:Initializing Gradient Boosting Classifier
2025-05-18 21:11:19,937:INFO:Total runtime is 2.572097837924957 minutes
2025-05-18 21:11:19,938:INFO:SubProcess create_model() called ==================================
2025-05-18 21:11:19,939:INFO:Initializing create_model()
2025-05-18 21:11:19,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:11:19,939:INFO:Checking exceptions
2025-05-18 21:11:19,939:INFO:Importing libraries
2025-05-18 21:11:19,939:INFO:Copying training dataset
2025-05-18 21:11:19,953:INFO:Defining folds
2025-05-18 21:11:19,953:INFO:Declaring metric variables
2025-05-18 21:11:19,955:INFO:Importing untrained model
2025-05-18 21:11:19,956:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 21:11:19,959:INFO:Starting cross validation
2025-05-18 21:11:19,962:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:11:20,786:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:11:20,795:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004718 seconds.
2025-05-18 21:11:20,795:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:11:20,795:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:11:20,796:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:11:20,796:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:11:20,796:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:11:33,190:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:11:33,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004384 seconds.
2025-05-18 21:11:33,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:11:33,200:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:11:33,200:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:11:33,200:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:11:33,201:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:11:45,627:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:11:45,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004273 seconds.
2025-05-18 21:11:45,637:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:11:45,637:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:11:45,637:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:11:45,637:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:11:45,637:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:11:57,906:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:11:57,916:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004591 seconds.
2025-05-18 21:11:57,916:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:11:57,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:11:57,916:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:11:57,916:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:11:57,916:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:12:10,429:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:12:10,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004721 seconds.
2025-05-18 21:12:10,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:12:10,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:12:10,439:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:12:10,439:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:12:10,440:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:12:22,534:INFO:Calculating mean and std
2025-05-18 21:12:22,536:INFO:Creating metrics dataframe
2025-05-18 21:12:22,537:INFO:Uploading results into container
2025-05-18 21:12:22,538:INFO:Uploading model into container now
2025-05-18 21:12:22,538:INFO:_master_model_container: 10
2025-05-18 21:12:22,538:INFO:_display_container: 2
2025-05-18 21:12:22,538:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-18 21:12:22,538:INFO:create_model() successfully completed......................................
2025-05-18 21:12:22,806:INFO:SubProcess create_model() end ==================================
2025-05-18 21:12:22,806:INFO:Creating metrics dataframe
2025-05-18 21:12:22,810:INFO:Initializing Linear Discriminant Analysis
2025-05-18 21:12:22,810:INFO:Total runtime is 3.6199831167856846 minutes
2025-05-18 21:12:22,811:INFO:SubProcess create_model() called ==================================
2025-05-18 21:12:22,812:INFO:Initializing create_model()
2025-05-18 21:12:22,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:12:22,812:INFO:Checking exceptions
2025-05-18 21:12:22,812:INFO:Importing libraries
2025-05-18 21:12:22,812:INFO:Copying training dataset
2025-05-18 21:12:22,822:INFO:Defining folds
2025-05-18 21:12:22,822:INFO:Declaring metric variables
2025-05-18 21:12:22,823:INFO:Importing untrained model
2025-05-18 21:12:22,825:INFO:Linear Discriminant Analysis Imported successfully
2025-05-18 21:12:22,827:INFO:Starting cross validation
2025-05-18 21:12:22,830:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:12:23,684:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:12:23,693:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004362 seconds.
2025-05-18 21:12:23,693:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:12:23,693:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:12:23,693:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:12:23,693:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:12:23,694:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:12:25,616:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:12:25,625:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004582 seconds.
2025-05-18 21:12:25,625:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:12:25,625:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:12:25,625:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:12:25,625:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:12:25,625:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:12:27,556:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:12:27,564:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004559 seconds.
2025-05-18 21:12:27,564:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:12:27,564:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:12:27,565:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:12:27,565:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:12:27,565:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:12:29,578:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:12:29,587:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004280 seconds.
2025-05-18 21:12:29,587:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:12:29,587:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:12:29,587:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:12:29,588:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:12:29,588:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:12:31,915:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:12:31,925:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004756 seconds.
2025-05-18 21:12:31,925:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:12:31,925:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:12:31,925:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:12:31,925:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:12:31,925:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:12:33,144:INFO:Calculating mean and std
2025-05-18 21:12:33,145:INFO:Creating metrics dataframe
2025-05-18 21:12:33,146:INFO:Uploading results into container
2025-05-18 21:12:33,147:INFO:Uploading model into container now
2025-05-18 21:12:33,147:INFO:_master_model_container: 11
2025-05-18 21:12:33,147:INFO:_display_container: 2
2025-05-18 21:12:33,147:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-18 21:12:33,147:INFO:create_model() successfully completed......................................
2025-05-18 21:12:33,358:INFO:SubProcess create_model() end ==================================
2025-05-18 21:12:33,358:INFO:Creating metrics dataframe
2025-05-18 21:12:33,362:INFO:Initializing Extra Trees Classifier
2025-05-18 21:12:33,362:INFO:Total runtime is 3.795846199989318 minutes
2025-05-18 21:12:33,363:INFO:SubProcess create_model() called ==================================
2025-05-18 21:12:33,363:INFO:Initializing create_model()
2025-05-18 21:12:33,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:12:33,364:INFO:Checking exceptions
2025-05-18 21:12:33,364:INFO:Importing libraries
2025-05-18 21:12:33,364:INFO:Copying training dataset
2025-05-18 21:12:33,373:INFO:Defining folds
2025-05-18 21:12:33,373:INFO:Declaring metric variables
2025-05-18 21:12:33,374:INFO:Importing untrained model
2025-05-18 21:12:33,376:INFO:Extra Trees Classifier Imported successfully
2025-05-18 21:12:33,378:INFO:Starting cross validation
2025-05-18 21:12:33,381:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:12:34,275:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:12:34,284:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004380 seconds.
2025-05-18 21:12:34,284:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:12:34,284:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:12:34,284:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:12:34,285:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:12:34,285:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:12:40,415:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:12:40,425:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004861 seconds.
2025-05-18 21:12:40,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:12:40,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:12:40,425:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:12:40,425:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:12:40,426:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:12:46,305:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:12:46,314:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004077 seconds.
2025-05-18 21:12:46,314:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:12:46,314:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:12:46,314:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:12:46,314:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:12:46,314:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:12:52,176:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:12:52,186:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004403 seconds.
2025-05-18 21:12:52,186:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:12:52,186:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:12:52,186:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:12:52,186:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:12:52,186:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:12:58,153:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:12:58,161:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004497 seconds.
2025-05-18 21:12:58,162:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:12:58,162:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:12:58,162:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:12:58,162:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:12:58,162:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:13:03,213:INFO:Calculating mean and std
2025-05-18 21:13:03,214:INFO:Creating metrics dataframe
2025-05-18 21:13:03,215:INFO:Uploading results into container
2025-05-18 21:13:03,216:INFO:Uploading model into container now
2025-05-18 21:13:03,216:INFO:_master_model_container: 12
2025-05-18 21:13:03,216:INFO:_display_container: 2
2025-05-18 21:13:03,216:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-18 21:13:03,216:INFO:create_model() successfully completed......................................
2025-05-18 21:13:03,488:INFO:SubProcess create_model() end ==================================
2025-05-18 21:13:03,489:INFO:Creating metrics dataframe
2025-05-18 21:13:03,493:INFO:Initializing Light Gradient Boosting Machine
2025-05-18 21:13:03,493:INFO:Total runtime is 4.298033050696055 minutes
2025-05-18 21:13:03,494:INFO:SubProcess create_model() called ==================================
2025-05-18 21:13:03,495:INFO:Initializing create_model()
2025-05-18 21:13:03,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:13:03,495:INFO:Checking exceptions
2025-05-18 21:13:03,495:INFO:Importing libraries
2025-05-18 21:13:03,495:INFO:Copying training dataset
2025-05-18 21:13:03,506:INFO:Defining folds
2025-05-18 21:13:03,506:INFO:Declaring metric variables
2025-05-18 21:13:03,507:INFO:Importing untrained model
2025-05-18 21:13:03,509:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-18 21:13:03,511:INFO:Starting cross validation
2025-05-18 21:13:03,513:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:13:04,320:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:13:04,320:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360

2025-05-18 21:13:04,330:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004357 seconds.
2025-05-18 21:13:04,330:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:13:04,330:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:13:04,330:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:13:04,330:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:13:04,330:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:13:05,446:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:13:05,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005040 seconds.
2025-05-18 21:13:05,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:13:05,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:13:05,457:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 21:13:05,457:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 14
2025-05-18 21:13:05,457:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:13:06,757:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:13:06,766:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004170 seconds.
2025-05-18 21:13:06,766:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:13:06,766:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:13:06,766:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:13:06,766:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:13:06,766:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:13:07,925:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:13:07,935:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004720 seconds.
2025-05-18 21:13:07,935:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:13:07,935:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:13:07,935:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 21:13:07,935:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 14
2025-05-18 21:13:07,935:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:13:09,252:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:13:09,261:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004470 seconds.
2025-05-18 21:13:09,261:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:13:09,261:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:13:09,261:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:13:09,261:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:13:09,262:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:13:10,368:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:13:10,378:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004743 seconds.
2025-05-18 21:13:10,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:13:10,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:13:10,378:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 21:13:10,378:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 14
2025-05-18 21:13:10,378:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:13:11,720:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:13:11,729:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004357 seconds.
2025-05-18 21:13:11,729:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:13:11,729:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:13:11,729:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:13:11,729:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:13:11,729:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:13:12,823:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:13:12,834:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005004 seconds.
2025-05-18 21:13:12,834:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:13:12,834:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:13:12,834:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 21:13:12,834:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 14
2025-05-18 21:13:12,834:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:13:14,192:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:13:14,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004335 seconds.
2025-05-18 21:13:14,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:13:14,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:13:14,201:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:13:14,201:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:13:14,201:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:13:15,311:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:13:15,322:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004778 seconds.
2025-05-18 21:13:15,322:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:13:15,322:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:13:15,322:INFO:[LightGBM] [Info] Total Bins 3570
2025-05-18 21:13:15,322:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 14
2025-05-18 21:13:15,322:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:13:15,868:INFO:Calculating mean and std
2025-05-18 21:13:15,869:INFO:Creating metrics dataframe
2025-05-18 21:13:15,869:INFO:Uploading results into container
2025-05-18 21:13:15,870:INFO:Uploading model into container now
2025-05-18 21:13:15,870:INFO:_master_model_container: 13
2025-05-18 21:13:15,870:INFO:_display_container: 2
2025-05-18 21:13:15,870:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-18 21:13:15,870:INFO:create_model() successfully completed......................................
2025-05-18 21:13:16,043:INFO:SubProcess create_model() end ==================================
2025-05-18 21:13:16,043:INFO:Creating metrics dataframe
2025-05-18 21:13:16,047:INFO:Initializing CatBoost Classifier
2025-05-18 21:13:16,047:INFO:Total runtime is 4.5072658856709795 minutes
2025-05-18 21:13:16,048:INFO:SubProcess create_model() called ==================================
2025-05-18 21:13:16,048:INFO:Initializing create_model()
2025-05-18 21:13:16,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:13:16,048:INFO:Checking exceptions
2025-05-18 21:13:16,048:INFO:Importing libraries
2025-05-18 21:13:16,048:INFO:Copying training dataset
2025-05-18 21:13:16,057:INFO:Defining folds
2025-05-18 21:13:16,057:INFO:Declaring metric variables
2025-05-18 21:13:16,058:INFO:Importing untrained model
2025-05-18 21:13:16,059:INFO:CatBoost Classifier Imported successfully
2025-05-18 21:13:16,061:INFO:Starting cross validation
2025-05-18 21:13:16,067:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:13:16,836:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:13:16,845:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004144 seconds.
2025-05-18 21:13:16,845:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:13:16,845:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:13:16,845:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:13:16,845:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:13:16,845:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:13:32,702:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:13:32,712:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004554 seconds.
2025-05-18 21:13:32,712:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:13:32,712:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:13:32,712:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:13:32,713:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:13:32,713:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:13:49,079:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:13:49,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004534 seconds.
2025-05-18 21:13:49,089:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:13:49,089:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:13:49,089:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:13:49,089:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:13:49,089:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:14:05,608:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:14:05,617:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003921 seconds.
2025-05-18 21:14:05,617:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:14:05,617:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:14:05,617:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:14:05,617:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:14:05,617:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:14:21,523:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:14:21,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004237 seconds.
2025-05-18 21:14:21,533:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:14:21,533:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:14:21,533:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:14:21,533:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:14:21,534:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:14:36,249:INFO:Calculating mean and std
2025-05-18 21:14:36,251:INFO:Creating metrics dataframe
2025-05-18 21:14:36,252:INFO:Uploading results into container
2025-05-18 21:14:36,253:INFO:Uploading model into container now
2025-05-18 21:14:36,253:INFO:_master_model_container: 14
2025-05-18 21:14:36,253:INFO:_display_container: 2
2025-05-18 21:14:36,253:INFO:<catboost.core.CatBoostClassifier object at 0x3565bc090>
2025-05-18 21:14:36,253:INFO:create_model() successfully completed......................................
2025-05-18 21:14:36,530:INFO:SubProcess create_model() end ==================================
2025-05-18 21:14:36,530:INFO:Creating metrics dataframe
2025-05-18 21:14:36,534:INFO:Initializing Dummy Classifier
2025-05-18 21:14:36,534:INFO:Total runtime is 5.848721182346344 minutes
2025-05-18 21:14:36,535:INFO:SubProcess create_model() called ==================================
2025-05-18 21:14:36,536:INFO:Initializing create_model()
2025-05-18 21:14:36,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x36f3d1bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:14:36,536:INFO:Checking exceptions
2025-05-18 21:14:36,536:INFO:Importing libraries
2025-05-18 21:14:36,536:INFO:Copying training dataset
2025-05-18 21:14:36,546:INFO:Defining folds
2025-05-18 21:14:36,546:INFO:Declaring metric variables
2025-05-18 21:14:36,547:INFO:Importing untrained model
2025-05-18 21:14:36,548:INFO:Dummy Classifier Imported successfully
2025-05-18 21:14:36,550:INFO:Starting cross validation
2025-05-18 21:14:36,552:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-18 21:14:37,362:INFO:[LightGBM] [Info] Number of positive: 34360, number of negative: 34360
2025-05-18 21:14:37,371:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004631 seconds.
2025-05-18 21:14:37,371:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:14:37,371:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:14:37,371:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:14:37,371:INFO:[LightGBM] [Info] Number of data points in the train set: 68720, number of used features: 28
2025-05-18 21:14:37,371:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:14:38,480:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:14:39,254:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:14:39,263:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004378 seconds.
2025-05-18 21:14:39,263:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:14:39,263:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:14:39,263:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:14:39,263:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:14:39,263:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:14:40,351:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:14:41,134:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:14:41,142:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004351 seconds.
2025-05-18 21:14:41,142:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:14:41,142:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:14:41,142:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:14:41,142:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:14:41,143:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:14:42,219:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:14:43,020:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:14:43,029:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004389 seconds.
2025-05-18 21:14:43,029:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:14:43,029:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:14:43,029:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:14:43,029:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:14:43,029:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:14:44,147:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:14:45,059:INFO:[LightGBM] [Info] Number of positive: 34361, number of negative: 34361
2025-05-18 21:14:45,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004272 seconds.
2025-05-18 21:14:45,068:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:14:45,068:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:14:45,068:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:14:45,068:INFO:[LightGBM] [Info] Number of data points in the train set: 68722, number of used features: 28
2025-05-18 21:14:45,068:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:14:46,256:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-18 21:14:46,262:INFO:Calculating mean and std
2025-05-18 21:14:46,263:INFO:Creating metrics dataframe
2025-05-18 21:14:46,264:INFO:Uploading results into container
2025-05-18 21:14:46,265:INFO:Uploading model into container now
2025-05-18 21:14:46,265:INFO:_master_model_container: 15
2025-05-18 21:14:46,265:INFO:_display_container: 2
2025-05-18 21:14:46,265:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-18 21:14:46,265:INFO:create_model() successfully completed......................................
2025-05-18 21:14:46,487:INFO:SubProcess create_model() end ==================================
2025-05-18 21:14:46,487:INFO:Creating metrics dataframe
2025-05-18 21:14:46,492:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-18 21:14:46,496:INFO:Initializing create_model()
2025-05-18 21:14:46,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3559b2610>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-18 21:14:46,496:INFO:Checking exceptions
2025-05-18 21:14:46,497:INFO:Importing libraries
2025-05-18 21:14:46,497:INFO:Copying training dataset
2025-05-18 21:14:46,507:INFO:Defining folds
2025-05-18 21:14:46,507:INFO:Declaring metric variables
2025-05-18 21:14:46,507:INFO:Importing untrained model
2025-05-18 21:14:46,507:INFO:Declaring custom model
2025-05-18 21:14:46,507:INFO:Gradient Boosting Classifier Imported successfully
2025-05-18 21:14:46,510:INFO:Cross validation set to False
2025-05-18 21:14:46,510:INFO:Fitting Model
2025-05-18 21:14:47,569:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-18 21:14:47,579:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005095 seconds.
2025-05-18 21:14:47,579:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-18 21:14:47,579:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-18 21:14:47,579:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-18 21:14:47,579:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-18 21:14:47,579:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-18 21:20:42,924:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2925465276.py:114: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded['Cancer'] = train_df['Cancer']

2025-05-18 21:20:42,925:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2925465276.py:131: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded['Iodine_Country_Risk'] = (train_df_encoded[iodine_def_col[0]] == 1) & (train_df_encoded[country_ind_col[0]] == 1).astype(int)

2025-05-18 21:20:42,926:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2925465276.py:132: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded['Iodine_Country_Risk'] = (test_df_encoded[iodine_def_col[0]] == 1) & (test_df_encoded[country_ind_col[0]] == 1).astype(int)

2025-05-18 21:20:42,928:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2925465276.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:20:42,931:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2925465276.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:20:42,934:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2925465276.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:20:42,934:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2925465276.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:20:42,939:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2925465276.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:20:42,939:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2925465276.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:20:42,942:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2925465276.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:20:42,943:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2925465276.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:20:42,946:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2925465276.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:20:42,946:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2925465276.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:23:39,016:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:114: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded['Cancer'] = train_df['Cancer']

2025-05-18 21:23:39,018:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:131: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded['Iodine_Country_Risk'] = (train_df_encoded[iodine_def_col[0]] == 1) & (train_df_encoded[country_ind_col[0]] == 1).astype(int)

2025-05-18 21:23:39,019:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:132: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded['Iodine_Country_Risk'] = (test_df_encoded[iodine_def_col[0]] == 1) & (test_df_encoded[country_ind_col[0]] == 1).astype(int)

2025-05-18 21:23:39,021:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:23:39,022:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:23:39,024:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:23:39,025:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:23:39,027:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:23:39,028:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:23:39,031:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:23:39,031:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:23:39,034:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:23:39,034:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:23:57,159:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:114: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded['Cancer'] = train_df['Cancer']

2025-05-18 21:23:57,161:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:131: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded['Iodine_Country_Risk'] = (train_df_encoded[iodine_def_col[0]] == 1) & (train_df_encoded[country_ind_col[0]] == 1).astype(int)

2025-05-18 21:23:57,161:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:132: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded['Iodine_Country_Risk'] = (test_df_encoded[iodine_def_col[0]] == 1) & (test_df_encoded[country_ind_col[0]] == 1).astype(int)

2025-05-18 21:23:57,164:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:23:57,164:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:23:57,167:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:23:57,167:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:23:57,170:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:23:57,170:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:23:57,173:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:23:57,174:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:23:57,176:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:150: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:23:57,177:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/1610800056.py:152: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:25:23,274:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:114: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded['Cancer'] = train_df['Cancer']

2025-05-18 21:25:23,276:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:131: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded['Iodine_Country_Risk'] = (train_df_encoded[iodine_def_col[0]] == 1) & (train_df_encoded[country_ind_col[0]] == 1).astype(int)

2025-05-18 21:25:23,276:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:132: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded['Iodine_Country_Risk'] = (test_df_encoded[iodine_def_col[0]] == 1) & (test_df_encoded[country_ind_col[0]] == 1).astype(int)

2025-05-18 21:25:23,277:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:147: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].astype(float)

2025-05-18 21:25:23,277:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:149: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].astype(float)

2025-05-18 21:25:23,277:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:147: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].astype(float)

2025-05-18 21:25:23,277:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:149: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].astype(float)

2025-05-18 21:25:23,277:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:147: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].astype(float)

2025-05-18 21:25:23,278:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:149: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].astype(float)

2025-05-18 21:25:23,278:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:147: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].astype(float)

2025-05-18 21:25:23,278:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:149: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].astype(float)

2025-05-18 21:25:23,278:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:147: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].astype(float)

2025-05-18 21:25:23,278:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:149: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].astype(float)

2025-05-18 21:25:23,279:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:147: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].astype(float)

2025-05-18 21:25:23,279:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:149: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].astype(float)

2025-05-18 21:25:23,282:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:25:23,282:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:158: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:25:23,285:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:25:23,286:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:158: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:25:23,288:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:25:23,289:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:158: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:25:23,291:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:25:23,292:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:158: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:25:23,295:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:25:23,295:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:158: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:25:23,297:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[col] = train_df_encoded[col].clip(q1, q3)

2025-05-18 21:25:23,297:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:158: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[col] = test_df_encoded[col].clip(q1, q3) #    

2025-05-18 21:25:23,303:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:163: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train_df_encoded[numerical_cols] = scaler.fit_transform(train_df_encoded[numerical_cols])

2025-05-18 21:25:23,304:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_21344/2000252994.py:167: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test_df_encoded[numerical_cols_in_test] = scaler.transform(test_df_encoded[numerical_cols_in_test])

