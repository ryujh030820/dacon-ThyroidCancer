2025-05-13 15:12:46,822:INFO:PyCaret ClassificationExperiment
2025-05-13 15:12:46,822:INFO:Logging name: clf-default-name
2025-05-13 15:12:46,822:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-13 15:12:46,822:INFO:version 3.3.2
2025-05-13 15:12:46,822:INFO:Initializing setup()
2025-05-13 15:12:46,822:INFO:self.USI: 77f9
2025-05-13 15:12:46,822:INFO:self._variable_keys: {'data', 'memory', 'gpu_param', '_available_plots', 'idx', 'html_param', 'gpu_n_jobs_param', 'fold_generator', 'fold_groups_param', 'logging_param', 'y', 'exp_id', 'X_train', 'is_multiclass', '_ml_usecase', 'X_test', 'y_test', 'y_train', 'exp_name_log', 'X', 'USI', 'fix_imbalance', 'fold_shuffle_param', 'log_plots_param', 'target_param', 'seed', 'pipeline', 'n_jobs_param'}
2025-05-13 15:12:46,822:INFO:Checking environment
2025-05-13 15:12:46,822:INFO:python_version: 3.11.0
2025-05-13 15:12:46,822:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-13 15:12:46,822:INFO:machine: arm64
2025-05-13 15:12:46,822:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:12:46,822:INFO:Memory: svmem(total=17179869184, available=4077387776, percent=76.3, used=6680018944, free=60080128, active=4042293248, inactive=4012113920, wired=2637725696)
2025-05-13 15:12:46,822:INFO:Physical Core: 12
2025-05-13 15:12:46,822:INFO:Logical Core: 12
2025-05-13 15:12:46,822:INFO:Checking libraries
2025-05-13 15:12:46,822:INFO:System:
2025-05-13 15:12:46,822:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-13 15:12:46,822:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-13 15:12:46,822:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:12:46,822:INFO:PyCaret required dependencies:
2025-05-13 15:12:46,823:INFO:                 pip: 22.3
2025-05-13 15:12:46,823:INFO:          setuptools: 65.5.0
2025-05-13 15:12:46,823:INFO:             pycaret: 3.3.2
2025-05-13 15:12:46,823:INFO:             IPython: 9.2.0
2025-05-13 15:12:46,823:INFO:          ipywidgets: 8.1.7
2025-05-13 15:12:46,823:INFO:                tqdm: 4.67.1
2025-05-13 15:12:46,823:INFO:               numpy: 1.26.4
2025-05-13 15:12:46,823:INFO:              pandas: 2.1.4
2025-05-13 15:12:46,823:INFO:              jinja2: 3.1.6
2025-05-13 15:12:46,823:INFO:               scipy: 1.11.4
2025-05-13 15:12:46,823:INFO:              joblib: 1.3.2
2025-05-13 15:12:46,823:INFO:             sklearn: 1.4.2
2025-05-13 15:12:46,823:INFO:                pyod: 2.0.5
2025-05-13 15:12:46,823:INFO:            imblearn: 0.13.0
2025-05-13 15:12:46,823:INFO:   category_encoders: 2.7.0
2025-05-13 15:12:46,823:INFO:            lightgbm: 4.6.0
2025-05-13 15:12:46,823:INFO:               numba: 0.61.2
2025-05-13 15:12:46,823:INFO:            requests: 2.32.3
2025-05-13 15:12:46,823:INFO:          matplotlib: 3.7.5
2025-05-13 15:12:46,823:INFO:          scikitplot: 0.3.7
2025-05-13 15:12:46,823:INFO:         yellowbrick: 1.5
2025-05-13 15:12:46,823:INFO:              plotly: 5.24.1
2025-05-13 15:12:46,823:INFO:    plotly-resampler: Not installed
2025-05-13 15:12:46,823:INFO:             kaleido: 0.2.1
2025-05-13 15:12:46,823:INFO:           schemdraw: 0.15
2025-05-13 15:12:46,823:INFO:         statsmodels: 0.14.4
2025-05-13 15:12:46,823:INFO:              sktime: 0.26.0
2025-05-13 15:12:46,823:INFO:               tbats: 1.1.3
2025-05-13 15:12:46,823:INFO:            pmdarima: 2.0.4
2025-05-13 15:12:46,823:INFO:              psutil: 7.0.0
2025-05-13 15:12:46,823:INFO:          markupsafe: 3.0.2
2025-05-13 15:12:46,823:INFO:             pickle5: Not installed
2025-05-13 15:12:46,823:INFO:         cloudpickle: 3.1.1
2025-05-13 15:12:46,823:INFO:         deprecation: 2.1.0
2025-05-13 15:12:46,823:INFO:              xxhash: 3.5.0
2025-05-13 15:12:46,823:INFO:           wurlitzer: 3.1.1
2025-05-13 15:12:46,823:INFO:PyCaret optional dependencies:
2025-05-13 15:12:46,823:INFO:                shap: 0.47.2
2025-05-13 15:12:46,823:INFO:           interpret: Not installed
2025-05-13 15:12:46,823:INFO:                umap: Not installed
2025-05-13 15:12:46,823:INFO:     ydata_profiling: Not installed
2025-05-13 15:12:46,823:INFO:  explainerdashboard: Not installed
2025-05-13 15:12:46,823:INFO:             autoviz: Not installed
2025-05-13 15:12:46,823:INFO:           fairlearn: Not installed
2025-05-13 15:12:46,823:INFO:          deepchecks: Not installed
2025-05-13 15:12:46,823:INFO:             xgboost: Not installed
2025-05-13 15:12:46,823:INFO:            catboost: Not installed
2025-05-13 15:12:46,823:INFO:              kmodes: Not installed
2025-05-13 15:12:46,823:INFO:             mlxtend: Not installed
2025-05-13 15:12:46,823:INFO:       statsforecast: Not installed
2025-05-13 15:12:46,823:INFO:        tune_sklearn: Not installed
2025-05-13 15:12:46,823:INFO:                 ray: Not installed
2025-05-13 15:12:46,823:INFO:            hyperopt: Not installed
2025-05-13 15:12:46,823:INFO:              optuna: 4.3.0
2025-05-13 15:12:46,823:INFO:               skopt: Not installed
2025-05-13 15:12:46,823:INFO:              mlflow: Not installed
2025-05-13 15:12:46,823:INFO:              gradio: Not installed
2025-05-13 15:12:46,823:INFO:             fastapi: Not installed
2025-05-13 15:12:46,823:INFO:             uvicorn: Not installed
2025-05-13 15:12:46,823:INFO:              m2cgen: Not installed
2025-05-13 15:12:46,823:INFO:           evidently: Not installed
2025-05-13 15:12:46,823:INFO:               fugue: Not installed
2025-05-13 15:12:46,823:INFO:           streamlit: Not installed
2025-05-13 15:12:46,823:INFO:             prophet: Not installed
2025-05-13 15:12:46,823:INFO:None
2025-05-13 15:12:46,823:INFO:Set up data.
2025-05-13 15:12:46,851:INFO:Set up folding strategy.
2025-05-13 15:12:46,851:INFO:Set up train/test split.
2025-05-13 15:12:46,864:INFO:Set up index.
2025-05-13 15:12:46,865:INFO:Assigning column types.
2025-05-13 15:12:46,868:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-13 15:12:46,887:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,887:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,899:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,919:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,931:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-13 15:12:46,951:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,983:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,995:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,995:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-13 15:12:47,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:47,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:47,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:47,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:47,058:INFO:Preparing preprocessing pipeline...
2025-05-13 15:12:47,060:INFO:Set up simple imputation.
2025-05-13 15:12:47,066:INFO:Set up encoding of ordinal features.
2025-05-13 15:12:47,074:INFO:Set up encoding of categorical features.
2025-05-13 15:12:47,074:INFO:Set up imbalanced handling.
2025-05-13 15:12:47,074:INFO:Set up column transformation.
2025-05-13 15:12:48,359:INFO:Finished creating preprocessing pipeline.
2025-05-13 15:12:48,376:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-13 15:12:48,376:INFO:Creating final display dataframe.
2025-05-13 15:12:48,836:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 15)
4        Transformed data shape      (106821, 28)
5   Transformed train set shape       (85902, 28)
6    Transformed test set shape       (20919, 28)
7              Numeric features                 6
8          Categorical features                 8
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              77f9
2025-05-13 15:12:48,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:48,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:48,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:48,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:48,905:INFO:setup() successfully completed in 2.09s...............
2025-05-13 15:12:48,905:INFO:Initializing compare_models()
2025-05-13 15:12:48,906:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-13 15:12:48,906:INFO:Checking exceptions
2025-05-13 15:12:48,913:INFO:Preparing display monitor
2025-05-13 15:12:48,923:INFO:Initializing Logistic Regression
2025-05-13 15:12:48,923:INFO:Total runtime is 2.3523966471354168e-06 minutes
2025-05-13 15:12:48,924:INFO:SubProcess create_model() called ==================================
2025-05-13 15:12:48,925:INFO:Initializing create_model()
2025-05-13 15:12:48,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:12:48,925:INFO:Checking exceptions
2025-05-13 15:12:48,925:INFO:Importing libraries
2025-05-13 15:12:48,925:INFO:Copying training dataset
2025-05-13 15:12:48,937:INFO:Defining folds
2025-05-13 15:12:48,937:INFO:Declaring metric variables
2025-05-13 15:12:48,938:INFO:Importing untrained model
2025-05-13 15:12:48,940:INFO:Logistic Regression Imported successfully
2025-05-13 15:12:48,942:INFO:Starting cross validation
2025-05-13 15:12:48,944:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:12:54,690:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,738:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,739:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,787:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,793:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,842:INFO:Calculating mean and std
2025-05-13 15:12:54,844:INFO:Creating metrics dataframe
2025-05-13 15:12:54,846:INFO:Uploading results into container
2025-05-13 15:12:54,847:INFO:Uploading model into container now
2025-05-13 15:12:54,847:INFO:_master_model_container: 1
2025-05-13 15:12:54,847:INFO:_display_container: 2
2025-05-13 15:12:54,847:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-13 15:12:54,847:INFO:create_model() successfully completed......................................
2025-05-13 15:12:54,986:INFO:SubProcess create_model() end ==================================
2025-05-13 15:12:54,987:INFO:Creating metrics dataframe
2025-05-13 15:12:54,989:INFO:Initializing K Neighbors Classifier
2025-05-13 15:12:54,989:INFO:Total runtime is 0.10111306905746459 minutes
2025-05-13 15:12:54,991:INFO:SubProcess create_model() called ==================================
2025-05-13 15:12:54,991:INFO:Initializing create_model()
2025-05-13 15:12:54,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:12:54,991:INFO:Checking exceptions
2025-05-13 15:12:54,991:INFO:Importing libraries
2025-05-13 15:12:54,991:INFO:Copying training dataset
2025-05-13 15:12:55,002:INFO:Defining folds
2025-05-13 15:12:55,002:INFO:Declaring metric variables
2025-05-13 15:12:55,003:INFO:Importing untrained model
2025-05-13 15:12:55,005:INFO:K Neighbors Classifier Imported successfully
2025-05-13 15:12:55,007:INFO:Starting cross validation
2025-05-13 15:12:55,008:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:00,778:INFO:Calculating mean and std
2025-05-13 15:13:00,779:INFO:Creating metrics dataframe
2025-05-13 15:13:00,781:INFO:Uploading results into container
2025-05-13 15:13:00,781:INFO:Uploading model into container now
2025-05-13 15:13:00,782:INFO:_master_model_container: 2
2025-05-13 15:13:00,782:INFO:_display_container: 2
2025-05-13 15:13:00,782:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-13 15:13:00,782:INFO:create_model() successfully completed......................................
2025-05-13 15:13:00,869:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:00,869:INFO:Creating metrics dataframe
2025-05-13 15:13:00,872:INFO:Initializing Naive Bayes
2025-05-13 15:13:00,872:INFO:Total runtime is 0.19915663401285805 minutes
2025-05-13 15:13:00,873:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:00,873:INFO:Initializing create_model()
2025-05-13 15:13:00,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:00,874:INFO:Checking exceptions
2025-05-13 15:13:00,874:INFO:Importing libraries
2025-05-13 15:13:00,874:INFO:Copying training dataset
2025-05-13 15:13:00,883:INFO:Defining folds
2025-05-13 15:13:00,884:INFO:Declaring metric variables
2025-05-13 15:13:00,885:INFO:Importing untrained model
2025-05-13 15:13:00,887:INFO:Naive Bayes Imported successfully
2025-05-13 15:13:00,889:INFO:Starting cross validation
2025-05-13 15:13:00,890:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:03,066:INFO:Calculating mean and std
2025-05-13 15:13:03,067:INFO:Creating metrics dataframe
2025-05-13 15:13:03,068:INFO:Uploading results into container
2025-05-13 15:13:03,068:INFO:Uploading model into container now
2025-05-13 15:13:03,068:INFO:_master_model_container: 3
2025-05-13 15:13:03,068:INFO:_display_container: 2
2025-05-13 15:13:03,068:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-13 15:13:03,068:INFO:create_model() successfully completed......................................
2025-05-13 15:13:03,147:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:03,147:INFO:Creating metrics dataframe
2025-05-13 15:13:03,150:INFO:Initializing Decision Tree Classifier
2025-05-13 15:13:03,150:INFO:Total runtime is 0.23711818854014077 minutes
2025-05-13 15:13:03,151:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:03,151:INFO:Initializing create_model()
2025-05-13 15:13:03,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:03,151:INFO:Checking exceptions
2025-05-13 15:13:03,151:INFO:Importing libraries
2025-05-13 15:13:03,151:INFO:Copying training dataset
2025-05-13 15:13:03,161:INFO:Defining folds
2025-05-13 15:13:03,161:INFO:Declaring metric variables
2025-05-13 15:13:03,162:INFO:Importing untrained model
2025-05-13 15:13:03,163:INFO:Decision Tree Classifier Imported successfully
2025-05-13 15:13:03,165:INFO:Starting cross validation
2025-05-13 15:13:03,167:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:04,774:INFO:Calculating mean and std
2025-05-13 15:13:04,775:INFO:Creating metrics dataframe
2025-05-13 15:13:04,776:INFO:Uploading results into container
2025-05-13 15:13:04,776:INFO:Uploading model into container now
2025-05-13 15:13:04,776:INFO:_master_model_container: 4
2025-05-13 15:13:04,776:INFO:_display_container: 2
2025-05-13 15:13:04,776:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-13 15:13:04,776:INFO:create_model() successfully completed......................................
2025-05-13 15:13:04,854:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:04,854:INFO:Creating metrics dataframe
2025-05-13 15:13:04,857:INFO:Initializing SVM - Linear Kernel
2025-05-13 15:13:04,857:INFO:Total runtime is 0.26557176907857255 minutes
2025-05-13 15:13:04,858:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:04,858:INFO:Initializing create_model()
2025-05-13 15:13:04,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:04,858:INFO:Checking exceptions
2025-05-13 15:13:04,859:INFO:Importing libraries
2025-05-13 15:13:04,859:INFO:Copying training dataset
2025-05-13 15:13:04,867:INFO:Defining folds
2025-05-13 15:13:04,867:INFO:Declaring metric variables
2025-05-13 15:13:04,868:INFO:Importing untrained model
2025-05-13 15:13:04,869:INFO:SVM - Linear Kernel Imported successfully
2025-05-13 15:13:04,871:INFO:Starting cross validation
2025-05-13 15:13:04,873:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:07,992:INFO:Calculating mean and std
2025-05-13 15:13:07,993:INFO:Creating metrics dataframe
2025-05-13 15:13:07,994:INFO:Uploading results into container
2025-05-13 15:13:07,994:INFO:Uploading model into container now
2025-05-13 15:13:07,994:INFO:_master_model_container: 5
2025-05-13 15:13:07,994:INFO:_display_container: 2
2025-05-13 15:13:07,994:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-13 15:13:07,994:INFO:create_model() successfully completed......................................
2025-05-13 15:13:08,087:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:08,088:INFO:Creating metrics dataframe
2025-05-13 15:13:08,091:INFO:Initializing Ridge Classifier
2025-05-13 15:13:08,091:INFO:Total runtime is 0.31947088638941445 minutes
2025-05-13 15:13:08,092:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:08,092:INFO:Initializing create_model()
2025-05-13 15:13:08,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:08,092:INFO:Checking exceptions
2025-05-13 15:13:08,092:INFO:Importing libraries
2025-05-13 15:13:08,092:INFO:Copying training dataset
2025-05-13 15:13:08,103:INFO:Defining folds
2025-05-13 15:13:08,103:INFO:Declaring metric variables
2025-05-13 15:13:08,104:INFO:Importing untrained model
2025-05-13 15:13:08,105:INFO:Ridge Classifier Imported successfully
2025-05-13 15:13:08,107:INFO:Starting cross validation
2025-05-13 15:13:08,109:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:10,225:INFO:Calculating mean and std
2025-05-13 15:13:10,225:INFO:Creating metrics dataframe
2025-05-13 15:13:10,226:INFO:Uploading results into container
2025-05-13 15:13:10,227:INFO:Uploading model into container now
2025-05-13 15:13:10,227:INFO:_master_model_container: 6
2025-05-13 15:13:10,227:INFO:_display_container: 2
2025-05-13 15:13:10,227:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-13 15:13:10,227:INFO:create_model() successfully completed......................................
2025-05-13 15:13:10,302:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:10,302:INFO:Creating metrics dataframe
2025-05-13 15:13:10,305:INFO:Initializing Random Forest Classifier
2025-05-13 15:13:10,305:INFO:Total runtime is 0.3563728173573812 minutes
2025-05-13 15:13:10,306:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:10,306:INFO:Initializing create_model()
2025-05-13 15:13:10,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:10,306:INFO:Checking exceptions
2025-05-13 15:13:10,307:INFO:Importing libraries
2025-05-13 15:13:10,307:INFO:Copying training dataset
2025-05-13 15:13:10,316:INFO:Defining folds
2025-05-13 15:13:10,316:INFO:Declaring metric variables
2025-05-13 15:13:10,317:INFO:Importing untrained model
2025-05-13 15:13:10,318:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:13:10,320:INFO:Starting cross validation
2025-05-13 15:13:10,321:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:16,029:INFO:Calculating mean and std
2025-05-13 15:13:16,031:INFO:Creating metrics dataframe
2025-05-13 15:13:16,034:INFO:Uploading results into container
2025-05-13 15:13:16,034:INFO:Uploading model into container now
2025-05-13 15:13:16,035:INFO:_master_model_container: 7
2025-05-13 15:13:16,035:INFO:_display_container: 2
2025-05-13 15:13:16,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:13:16,035:INFO:create_model() successfully completed......................................
2025-05-13 15:13:16,135:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:16,135:INFO:Creating metrics dataframe
2025-05-13 15:13:16,138:INFO:Initializing Quadratic Discriminant Analysis
2025-05-13 15:13:16,138:INFO:Total runtime is 0.4535940527915955 minutes
2025-05-13 15:13:16,140:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:16,140:INFO:Initializing create_model()
2025-05-13 15:13:16,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:16,140:INFO:Checking exceptions
2025-05-13 15:13:16,140:INFO:Importing libraries
2025-05-13 15:13:16,140:INFO:Copying training dataset
2025-05-13 15:13:16,153:INFO:Defining folds
2025-05-13 15:13:16,153:INFO:Declaring metric variables
2025-05-13 15:13:16,155:INFO:Importing untrained model
2025-05-13 15:13:16,156:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-13 15:13:16,158:INFO:Starting cross validation
2025-05-13 15:13:16,160:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:17,138:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:17,152:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:17,156:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:17,162:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:17,212:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:17,226:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:17,229:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:17,238:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:18,305:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:18,368:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:18,383:INFO:Calculating mean and std
2025-05-13 15:13:18,384:INFO:Creating metrics dataframe
2025-05-13 15:13:18,385:INFO:Uploading results into container
2025-05-13 15:13:18,385:INFO:Uploading model into container now
2025-05-13 15:13:18,385:INFO:_master_model_container: 8
2025-05-13 15:13:18,385:INFO:_display_container: 2
2025-05-13 15:13:18,385:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-13 15:13:18,385:INFO:create_model() successfully completed......................................
2025-05-13 15:13:18,475:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:18,475:INFO:Creating metrics dataframe
2025-05-13 15:13:18,478:INFO:Initializing Ada Boost Classifier
2025-05-13 15:13:18,478:INFO:Total runtime is 0.4925962845484416 minutes
2025-05-13 15:13:18,480:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:18,480:INFO:Initializing create_model()
2025-05-13 15:13:18,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:18,480:INFO:Checking exceptions
2025-05-13 15:13:18,480:INFO:Importing libraries
2025-05-13 15:13:18,480:INFO:Copying training dataset
2025-05-13 15:13:18,491:INFO:Defining folds
2025-05-13 15:13:18,491:INFO:Declaring metric variables
2025-05-13 15:13:18,492:INFO:Importing untrained model
2025-05-13 15:13:18,493:INFO:Ada Boost Classifier Imported successfully
2025-05-13 15:13:18,496:INFO:Starting cross validation
2025-05-13 15:13:18,497:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:19,402:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:19,467:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:19,479:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:19,484:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:19,507:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:22,144:INFO:Calculating mean and std
2025-05-13 15:13:22,145:INFO:Creating metrics dataframe
2025-05-13 15:13:22,146:INFO:Uploading results into container
2025-05-13 15:13:22,146:INFO:Uploading model into container now
2025-05-13 15:13:22,146:INFO:_master_model_container: 9
2025-05-13 15:13:22,146:INFO:_display_container: 2
2025-05-13 15:13:22,146:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-13 15:13:22,146:INFO:create_model() successfully completed......................................
2025-05-13 15:13:22,220:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:22,220:INFO:Creating metrics dataframe
2025-05-13 15:13:22,224:INFO:Initializing Gradient Boosting Classifier
2025-05-13 15:13:22,224:INFO:Total runtime is 0.5550253868103028 minutes
2025-05-13 15:13:22,225:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:22,225:INFO:Initializing create_model()
2025-05-13 15:13:22,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:22,226:INFO:Checking exceptions
2025-05-13 15:13:22,226:INFO:Importing libraries
2025-05-13 15:13:22,226:INFO:Copying training dataset
2025-05-13 15:13:22,236:INFO:Defining folds
2025-05-13 15:13:22,236:INFO:Declaring metric variables
2025-05-13 15:13:22,238:INFO:Importing untrained model
2025-05-13 15:13:22,239:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:13:22,241:INFO:Starting cross validation
2025-05-13 15:13:22,242:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:35,548:INFO:Calculating mean and std
2025-05-13 15:13:35,550:INFO:Creating metrics dataframe
2025-05-13 15:13:35,551:INFO:Uploading results into container
2025-05-13 15:13:35,552:INFO:Uploading model into container now
2025-05-13 15:13:35,552:INFO:_master_model_container: 10
2025-05-13 15:13:35,552:INFO:_display_container: 2
2025-05-13 15:13:35,552:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:13:35,552:INFO:create_model() successfully completed......................................
2025-05-13 15:13:35,632:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:35,632:INFO:Creating metrics dataframe
2025-05-13 15:13:35,635:INFO:Initializing Linear Discriminant Analysis
2025-05-13 15:13:35,636:INFO:Total runtime is 0.7785467346509298 minutes
2025-05-13 15:13:35,637:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:35,637:INFO:Initializing create_model()
2025-05-13 15:13:35,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:35,637:INFO:Checking exceptions
2025-05-13 15:13:35,637:INFO:Importing libraries
2025-05-13 15:13:35,637:INFO:Copying training dataset
2025-05-13 15:13:35,648:INFO:Defining folds
2025-05-13 15:13:35,648:INFO:Declaring metric variables
2025-05-13 15:13:35,649:INFO:Importing untrained model
2025-05-13 15:13:35,650:INFO:Linear Discriminant Analysis Imported successfully
2025-05-13 15:13:35,653:INFO:Starting cross validation
2025-05-13 15:13:35,654:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:36,781:INFO:Calculating mean and std
2025-05-13 15:13:36,781:INFO:Creating metrics dataframe
2025-05-13 15:13:36,783:INFO:Uploading results into container
2025-05-13 15:13:36,783:INFO:Uploading model into container now
2025-05-13 15:13:36,783:INFO:_master_model_container: 11
2025-05-13 15:13:36,783:INFO:_display_container: 2
2025-05-13 15:13:36,784:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-13 15:13:36,784:INFO:create_model() successfully completed......................................
2025-05-13 15:13:36,862:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:36,862:INFO:Creating metrics dataframe
2025-05-13 15:13:36,866:INFO:Initializing Extra Trees Classifier
2025-05-13 15:13:36,866:INFO:Total runtime is 0.7990583856900534 minutes
2025-05-13 15:13:36,867:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:36,868:INFO:Initializing create_model()
2025-05-13 15:13:36,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:36,868:INFO:Checking exceptions
2025-05-13 15:13:36,868:INFO:Importing libraries
2025-05-13 15:13:36,868:INFO:Copying training dataset
2025-05-13 15:13:36,878:INFO:Defining folds
2025-05-13 15:13:36,878:INFO:Declaring metric variables
2025-05-13 15:13:36,879:INFO:Importing untrained model
2025-05-13 15:13:36,881:INFO:Extra Trees Classifier Imported successfully
2025-05-13 15:13:36,883:INFO:Starting cross validation
2025-05-13 15:13:36,884:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:41,817:INFO:Calculating mean and std
2025-05-13 15:13:41,820:INFO:Creating metrics dataframe
2025-05-13 15:13:41,826:INFO:Uploading results into container
2025-05-13 15:13:41,826:INFO:Uploading model into container now
2025-05-13 15:13:41,827:INFO:_master_model_container: 12
2025-05-13 15:13:41,827:INFO:_display_container: 2
2025-05-13 15:13:41,828:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-13 15:13:41,828:INFO:create_model() successfully completed......................................
2025-05-13 15:13:41,972:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:41,972:INFO:Creating metrics dataframe
2025-05-13 15:13:41,976:INFO:Initializing Light Gradient Boosting Machine
2025-05-13 15:13:41,976:INFO:Total runtime is 0.8842240532239279 minutes
2025-05-13 15:13:41,977:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:41,978:INFO:Initializing create_model()
2025-05-13 15:13:41,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:41,978:INFO:Checking exceptions
2025-05-13 15:13:41,978:INFO:Importing libraries
2025-05-13 15:13:41,978:INFO:Copying training dataset
2025-05-13 15:13:41,990:INFO:Defining folds
2025-05-13 15:13:41,991:INFO:Declaring metric variables
2025-05-13 15:13:41,992:INFO:Importing untrained model
2025-05-13 15:13:41,994:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:13:41,996:INFO:Starting cross validation
2025-05-13 15:13:41,998:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:45,903:INFO:Calculating mean and std
2025-05-13 15:13:45,904:INFO:Creating metrics dataframe
2025-05-13 15:13:45,905:INFO:Uploading results into container
2025-05-13 15:13:45,906:INFO:Uploading model into container now
2025-05-13 15:13:45,906:INFO:_master_model_container: 13
2025-05-13 15:13:45,906:INFO:_display_container: 2
2025-05-13 15:13:45,907:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:13:45,907:INFO:create_model() successfully completed......................................
2025-05-13 15:13:45,990:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:45,990:INFO:Creating metrics dataframe
2025-05-13 15:13:45,994:INFO:Initializing Dummy Classifier
2025-05-13 15:13:45,994:INFO:Total runtime is 0.9511892199516297 minutes
2025-05-13 15:13:45,995:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:45,995:INFO:Initializing create_model()
2025-05-13 15:13:45,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:45,995:INFO:Checking exceptions
2025-05-13 15:13:45,996:INFO:Importing libraries
2025-05-13 15:13:45,996:INFO:Copying training dataset
2025-05-13 15:13:46,006:INFO:Defining folds
2025-05-13 15:13:46,006:INFO:Declaring metric variables
2025-05-13 15:13:46,007:INFO:Importing untrained model
2025-05-13 15:13:46,009:INFO:Dummy Classifier Imported successfully
2025-05-13 15:13:46,011:INFO:Starting cross validation
2025-05-13 15:13:46,012:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:46,982:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,046:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,053:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,094:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,145:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,157:INFO:Calculating mean and std
2025-05-13 15:13:47,158:INFO:Creating metrics dataframe
2025-05-13 15:13:47,159:INFO:Uploading results into container
2025-05-13 15:13:47,159:INFO:Uploading model into container now
2025-05-13 15:13:47,159:INFO:_master_model_container: 14
2025-05-13 15:13:47,159:INFO:_display_container: 2
2025-05-13 15:13:47,159:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-13 15:13:47,159:INFO:create_model() successfully completed......................................
2025-05-13 15:13:47,234:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:47,234:INFO:Creating metrics dataframe
2025-05-13 15:13:47,238:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-13 15:13:47,241:INFO:Initializing create_model()
2025-05-13 15:13:47,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:47,241:INFO:Checking exceptions
2025-05-13 15:13:47,242:INFO:Importing libraries
2025-05-13 15:13:47,242:INFO:Copying training dataset
2025-05-13 15:13:47,252:INFO:Defining folds
2025-05-13 15:13:47,252:INFO:Declaring metric variables
2025-05-13 15:13:47,252:INFO:Importing untrained model
2025-05-13 15:13:47,252:INFO:Declaring custom model
2025-05-13 15:13:47,252:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:13:47,253:INFO:Cross validation set to False
2025-05-13 15:13:47,253:INFO:Fitting Model
2025-05-13 15:14:03,158:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:14:03,159:INFO:create_model() successfully completed......................................
2025-05-13 15:14:03,245:INFO:Initializing create_model()
2025-05-13 15:14:03,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:14:03,246:INFO:Checking exceptions
2025-05-13 15:14:03,246:INFO:Importing libraries
2025-05-13 15:14:03,246:INFO:Copying training dataset
2025-05-13 15:14:03,258:INFO:Defining folds
2025-05-13 15:14:03,258:INFO:Declaring metric variables
2025-05-13 15:14:03,258:INFO:Importing untrained model
2025-05-13 15:14:03,258:INFO:Declaring custom model
2025-05-13 15:14:03,259:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:14:03,260:INFO:Cross validation set to False
2025-05-13 15:14:03,260:INFO:Fitting Model
2025-05-13 15:14:04,294:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-13 15:14:04,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004644 seconds.
2025-05-13 15:14:04,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-13 15:14:04,305:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-13 15:14:04,305:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-13 15:14:04,305:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 27
2025-05-13 15:14:04,305:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-13 15:14:05,066:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:14:05,066:INFO:create_model() successfully completed......................................
2025-05-13 15:14:05,141:INFO:Initializing create_model()
2025-05-13 15:14:05,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:14:05,141:INFO:Checking exceptions
2025-05-13 15:14:05,142:INFO:Importing libraries
2025-05-13 15:14:05,142:INFO:Copying training dataset
2025-05-13 15:14:05,151:INFO:Defining folds
2025-05-13 15:14:05,151:INFO:Declaring metric variables
2025-05-13 15:14:05,151:INFO:Importing untrained model
2025-05-13 15:14:05,151:INFO:Declaring custom model
2025-05-13 15:14:05,151:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:14:05,152:INFO:Cross validation set to False
2025-05-13 15:14:05,152:INFO:Fitting Model
2025-05-13 15:14:07,395:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:14:07,395:INFO:create_model() successfully completed......................................
2025-05-13 15:14:07,478:INFO:_master_model_container: 14
2025-05-13 15:14:07,478:INFO:_display_container: 2
2025-05-13 15:14:07,478:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-13 15:14:07,478:INFO:compare_models() successfully completed......................................
2025-05-13 15:14:07,479:INFO:Initializing evaluate_model()
2025-05-13 15:14:07,479:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:14:07,486:INFO:Initializing plot_model()
2025-05-13 15:14:07,486:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:14:07,486:INFO:Checking exceptions
2025-05-13 15:14:07,490:INFO:Preloading libraries
2025-05-13 15:14:07,494:INFO:Copying training dataset
2025-05-13 15:14:07,494:INFO:Plot type: pipeline
2025-05-13 15:14:07,556:INFO:Visual Rendered Successfully
2025-05-13 15:14:07,633:INFO:plot_model() successfully completed......................................
2025-05-13 15:14:07,635:INFO:Initializing tune_model()
2025-05-13 15:14:07,635:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-13 15:14:07,635:INFO:Checking exceptions
2025-05-13 15:14:07,644:INFO:Copying training dataset
2025-05-13 15:14:07,653:INFO:Checking base model
2025-05-13 15:14:07,653:INFO:Base model : Gradient Boosting Classifier
2025-05-13 15:14:07,654:INFO:Declaring metric variables
2025-05-13 15:14:07,656:INFO:Defining Hyperparameters
2025-05-13 15:14:07,736:INFO:Tuning with n_jobs=-1
2025-05-13 15:14:07,736:INFO:Initializing RandomizedSearchCV
2025-05-13 15:14:45,989:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-13 15:14:45,992:INFO:Hyperparameter search completed
2025-05-13 15:14:45,992:INFO:SubProcess create_model() called ==================================
2025-05-13 15:14:45,993:INFO:Initializing create_model()
2025-05-13 15:14:45,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331be6f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-13 15:14:45,993:INFO:Checking exceptions
2025-05-13 15:14:45,993:INFO:Importing libraries
2025-05-13 15:14:45,993:INFO:Copying training dataset
2025-05-13 15:14:46,009:INFO:Defining folds
2025-05-13 15:14:46,009:INFO:Declaring metric variables
2025-05-13 15:14:46,018:INFO:Importing untrained model
2025-05-13 15:14:46,018:INFO:Declaring custom model
2025-05-13 15:14:46,020:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:14:46,023:INFO:Starting cross validation
2025-05-13 15:14:46,026:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:14:56,051:INFO:Calculating mean and std
2025-05-13 15:14:56,052:INFO:Creating metrics dataframe
2025-05-13 15:14:56,055:INFO:Finalizing model
2025-05-13 15:15:07,296:INFO:Uploading results into container
2025-05-13 15:15:07,297:INFO:Uploading model into container now
2025-05-13 15:15:07,297:INFO:_master_model_container: 15
2025-05-13 15:15:07,297:INFO:_display_container: 3
2025-05-13 15:15:07,298:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:15:07,298:INFO:create_model() successfully completed......................................
2025-05-13 15:15:07,430:INFO:SubProcess create_model() end ==================================
2025-05-13 15:15:07,430:INFO:choose_better activated
2025-05-13 15:15:07,431:INFO:SubProcess create_model() called ==================================
2025-05-13 15:15:07,432:INFO:Initializing create_model()
2025-05-13 15:15:07,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:15:07,432:INFO:Checking exceptions
2025-05-13 15:15:07,433:INFO:Importing libraries
2025-05-13 15:15:07,433:INFO:Copying training dataset
2025-05-13 15:15:07,443:INFO:Defining folds
2025-05-13 15:15:07,443:INFO:Declaring metric variables
2025-05-13 15:15:07,443:INFO:Importing untrained model
2025-05-13 15:15:07,443:INFO:Declaring custom model
2025-05-13 15:15:07,443:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:15:07,443:INFO:Starting cross validation
2025-05-13 15:15:07,444:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:15:20,739:INFO:Calculating mean and std
2025-05-13 15:15:20,741:INFO:Creating metrics dataframe
2025-05-13 15:15:20,745:INFO:Finalizing model
2025-05-13 15:15:36,998:INFO:Uploading results into container
2025-05-13 15:15:36,999:INFO:Uploading model into container now
2025-05-13 15:15:36,999:INFO:_master_model_container: 16
2025-05-13 15:15:36,999:INFO:_display_container: 4
2025-05-13 15:15:37,000:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:15:37,000:INFO:create_model() successfully completed......................................
2025-05-13 15:15:37,130:INFO:SubProcess create_model() end ==================================
2025-05-13 15:15:37,130:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4745
2025-05-13 15:15:37,131:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4906
2025-05-13 15:15:37,131:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-13 15:15:37,131:INFO:choose_better completed
2025-05-13 15:15:37,135:INFO:_master_model_container: 16
2025-05-13 15:15:37,135:INFO:_display_container: 3
2025-05-13 15:15:37,135:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:15:37,135:INFO:tune_model() successfully completed......................................
2025-05-13 15:15:37,226:INFO:Initializing evaluate_model()
2025-05-13 15:15:37,226:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:15:37,235:INFO:Initializing plot_model()
2025-05-13 15:15:37,235:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:15:37,235:INFO:Checking exceptions
2025-05-13 15:15:37,241:INFO:Preloading libraries
2025-05-13 15:15:37,251:INFO:Copying training dataset
2025-05-13 15:15:37,251:INFO:Plot type: pipeline
2025-05-13 15:15:37,309:INFO:Visual Rendered Successfully
2025-05-13 15:15:37,396:INFO:plot_model() successfully completed......................................
2025-05-13 15:15:37,398:INFO:Initializing interpret_model()
2025-05-13 15:15:37,398:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-13 15:15:37,398:INFO:Checking exceptions
2025-05-13 15:15:37,398:INFO:Soft dependency imported: shap: 0.47.2
2025-05-13 15:15:37,568:INFO:Initializing finalize_model()
2025-05-13 15:15:37,568:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-13 15:15:37,569:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:15:37,573:INFO:Initializing create_model()
2025-05-13 15:15:37,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:15:37,573:INFO:Checking exceptions
2025-05-13 15:15:37,573:INFO:Importing libraries
2025-05-13 15:15:37,573:INFO:Copying training dataset
2025-05-13 15:15:37,574:INFO:Defining folds
2025-05-13 15:15:37,574:INFO:Declaring metric variables
2025-05-13 15:15:37,574:INFO:Importing untrained model
2025-05-13 15:15:37,574:INFO:Declaring custom model
2025-05-13 15:15:37,574:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:15:37,575:INFO:Cross validation set to False
2025-05-13 15:15:37,575:INFO:Fitting Model
2025-05-13 15:15:54,143:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:15:54,143:INFO:create_model() successfully completed......................................
2025-05-13 15:15:54,245:INFO:_master_model_container: 16
2025-05-13 15:15:54,245:INFO:_display_container: 3
2025-05-13 15:15:54,269:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:15:54,269:INFO:finalize_model() successfully completed......................................
2025-05-13 15:15:54,396:INFO:Initializing save_model()
2025-05-13 15:15:54,396:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-13 15:15:54,396:INFO:Adding model into prep_pipe
2025-05-13 15:15:54,396:WARNING:Only Model saved as it was a pipeline.
2025-05-13 15:15:54,422:INFO:final_cancer_model.pkl saved in current working directory
2025-05-13 15:15:54,440:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:15:54,440:INFO:save_model() successfully completed......................................
2025-05-13 15:15:54,541:INFO:Initializing predict_model()
2025-05-13 15:15:54,541:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x33692b9c0>)
2025-05-13 15:15:54,541:INFO:Checking exceptions
2025-05-13 15:15:54,541:INFO:Preloading libraries
2025-05-13 15:15:54,542:INFO:Set up data.
2025-05-13 15:15:54,559:INFO:Set up index.
2025-05-13 15:15:55,442:INFO:Initializing blend_models()
2025-05-13 15:15:55,442:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-13 15:15:55,442:INFO:Checking exceptions
2025-05-13 15:15:55,451:INFO:Importing libraries
2025-05-13 15:15:55,451:INFO:Copying training dataset
2025-05-13 15:15:55,452:INFO:Getting model names
2025-05-13 15:15:55,453:INFO:SubProcess create_model() called ==================================
2025-05-13 15:15:55,455:INFO:Initializing create_model()
2025-05-13 15:15:55,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337385d50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:15:55,455:INFO:Checking exceptions
2025-05-13 15:15:55,455:INFO:Importing libraries
2025-05-13 15:15:55,456:INFO:Copying training dataset
2025-05-13 15:15:55,466:INFO:Defining folds
2025-05-13 15:15:55,466:INFO:Declaring metric variables
2025-05-13 15:15:55,467:INFO:Importing untrained model
2025-05-13 15:15:55,467:INFO:Declaring custom model
2025-05-13 15:15:55,469:INFO:Voting Classifier Imported successfully
2025-05-13 15:15:55,471:INFO:Starting cross validation
2025-05-13 15:15:55,472:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:16:11,942:INFO:Calculating mean and std
2025-05-13 15:16:11,945:INFO:Creating metrics dataframe
2025-05-13 15:16:11,954:INFO:Finalizing model
2025-05-13 15:16:28,349:INFO:Uploading results into container
2025-05-13 15:16:28,350:INFO:Uploading model into container now
2025-05-13 15:16:28,350:INFO:_master_model_container: 17
2025-05-13 15:16:28,351:INFO:_display_container: 4
2025-05-13 15:16:28,355:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-13 15:16:28,355:INFO:create_model() successfully completed......................................
2025-05-13 15:16:28,546:INFO:SubProcess create_model() end ==================================
2025-05-13 15:16:28,550:INFO:_master_model_container: 17
2025-05-13 15:16:28,550:INFO:_display_container: 4
2025-05-13 15:16:28,552:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-13 15:16:28,552:INFO:blend_models() successfully completed......................................
2025-05-13 15:16:28,642:INFO:Initializing evaluate_model()
2025-05-13 15:16:28,643:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:16:28,652:INFO:Initializing plot_model()
2025-05-13 15:16:28,653:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:16:28,653:INFO:Checking exceptions
2025-05-13 15:16:28,657:INFO:Preloading libraries
2025-05-13 15:16:28,782:INFO:Copying training dataset
2025-05-13 15:16:28,782:INFO:Plot type: pipeline
2025-05-13 15:16:28,843:INFO:Visual Rendered Successfully
2025-05-13 15:16:28,935:INFO:plot_model() successfully completed......................................
2025-05-13 15:16:28,943:INFO:Initializing predict_model()
2025-05-13 15:16:28,944:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x33f8c8fe0>)
2025-05-13 15:16:28,944:INFO:Checking exceptions
2025-05-13 15:16:28,944:INFO:Preloading libraries
2025-05-13 15:16:28,945:INFO:Set up data.
2025-05-13 15:16:28,967:INFO:Set up index.
2025-05-13 15:16:29,618:INFO:Initializing plot_model()
2025-05-13 15:16:29,618:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:16:29,618:INFO:Checking exceptions
2025-05-13 15:16:29,622:INFO:Preloading libraries
2025-05-13 15:16:29,626:INFO:Copying training dataset
2025-05-13 15:16:29,626:INFO:Plot type: confusion_matrix
2025-05-13 15:16:29,840:INFO:Fitting Model
2025-05-13 15:16:29,841:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:16:29,842:INFO:Scoring test/hold-out set
2025-05-13 15:16:29,921:INFO:Visual Rendered Successfully
2025-05-13 15:16:30,010:INFO:plot_model() successfully completed......................................
2025-05-13 15:16:30,011:INFO:Initializing plot_model()
2025-05-13 15:16:30,011:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:16:30,011:INFO:Checking exceptions
2025-05-13 15:16:30,015:INFO:Preloading libraries
2025-05-13 15:16:30,019:INFO:Copying training dataset
2025-05-13 15:16:30,019:INFO:Plot type: auc
2025-05-13 15:16:30,217:INFO:Fitting Model
2025-05-13 15:16:30,218:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:16:30,219:INFO:Scoring test/hold-out set
2025-05-13 15:16:30,338:INFO:Visual Rendered Successfully
2025-05-13 15:16:30,427:INFO:plot_model() successfully completed......................................
2025-05-13 15:16:30,428:INFO:Initializing plot_model()
2025-05-13 15:16:30,428:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:16:30,428:INFO:Checking exceptions
2025-05-13 15:16:30,432:INFO:Preloading libraries
2025-05-13 15:16:30,436:INFO:Copying training dataset
2025-05-13 15:16:30,436:INFO:Plot type: feature
2025-05-13 15:16:30,436:WARNING:No coef_ found. Trying feature_importances_
2025-05-13 15:16:30,509:INFO:Visual Rendered Successfully
2025-05-13 15:16:30,591:INFO:plot_model() successfully completed......................................
2025-05-13 15:38:44,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 15:38:44,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 15:38:44,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 15:38:44,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 15:38:45,012:INFO:PyCaret ClassificationExperiment
2025-05-13 15:38:45,012:INFO:Logging name: clf-default-name
2025-05-13 15:38:45,012:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-13 15:38:45,012:INFO:version 3.3.2
2025-05-13 15:38:45,012:INFO:Initializing setup()
2025-05-13 15:38:45,012:INFO:self.USI: 4919
2025-05-13 15:38:45,012:INFO:self._variable_keys: {'fold_groups_param', 'html_param', 'USI', 'fix_imbalance', 'log_plots_param', 'idx', 'fold_generator', 'exp_name_log', 'exp_id', 'y', 'is_multiclass', 'memory', 'gpu_param', 'y_test', 'pipeline', 'seed', '_ml_usecase', 'X_train', 'gpu_n_jobs_param', 'y_train', 'fold_shuffle_param', 'X', 'data', '_available_plots', 'X_test', 'target_param', 'n_jobs_param', 'logging_param'}
2025-05-13 15:38:45,012:INFO:Checking environment
2025-05-13 15:38:45,012:INFO:python_version: 3.11.0
2025-05-13 15:38:45,012:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-13 15:38:45,012:INFO:machine: arm64
2025-05-13 15:38:45,012:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:38:45,012:INFO:Memory: svmem(total=17179869184, available=3887300608, percent=77.4, used=6402818048, free=76447744, active=3830382592, inactive=3719823360, wired=2572435456)
2025-05-13 15:38:45,012:INFO:Physical Core: 12
2025-05-13 15:38:45,012:INFO:Logical Core: 12
2025-05-13 15:38:45,012:INFO:Checking libraries
2025-05-13 15:38:45,012:INFO:System:
2025-05-13 15:38:45,012:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-13 15:38:45,012:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-13 15:38:45,012:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:38:45,012:INFO:PyCaret required dependencies:
2025-05-13 15:38:45,037:INFO:                 pip: 22.3
2025-05-13 15:38:45,037:INFO:          setuptools: 65.5.0
2025-05-13 15:38:45,037:INFO:             pycaret: 3.3.2
2025-05-13 15:38:45,037:INFO:             IPython: 9.2.0
2025-05-13 15:38:45,037:INFO:          ipywidgets: 8.1.7
2025-05-13 15:38:45,037:INFO:                tqdm: 4.67.1
2025-05-13 15:38:45,037:INFO:               numpy: 1.26.4
2025-05-13 15:38:45,037:INFO:              pandas: 2.1.4
2025-05-13 15:38:45,037:INFO:              jinja2: 3.1.6
2025-05-13 15:38:45,037:INFO:               scipy: 1.11.4
2025-05-13 15:38:45,037:INFO:              joblib: 1.3.2
2025-05-13 15:38:45,037:INFO:             sklearn: 1.4.2
2025-05-13 15:38:45,037:INFO:                pyod: 2.0.5
2025-05-13 15:38:45,037:INFO:            imblearn: 0.13.0
2025-05-13 15:38:45,037:INFO:   category_encoders: 2.7.0
2025-05-13 15:38:45,037:INFO:            lightgbm: 4.6.0
2025-05-13 15:38:45,037:INFO:               numba: 0.61.2
2025-05-13 15:38:45,037:INFO:            requests: 2.32.3
2025-05-13 15:38:45,037:INFO:          matplotlib: 3.7.5
2025-05-13 15:38:45,038:INFO:          scikitplot: 0.3.7
2025-05-13 15:38:45,038:INFO:         yellowbrick: 1.5
2025-05-13 15:38:45,038:INFO:              plotly: 5.24.1
2025-05-13 15:38:45,038:INFO:    plotly-resampler: Not installed
2025-05-13 15:38:45,038:INFO:             kaleido: 0.2.1
2025-05-13 15:38:45,038:INFO:           schemdraw: 0.15
2025-05-13 15:38:45,038:INFO:         statsmodels: 0.14.4
2025-05-13 15:38:45,038:INFO:              sktime: 0.26.0
2025-05-13 15:38:45,038:INFO:               tbats: 1.1.3
2025-05-13 15:38:45,038:INFO:            pmdarima: 2.0.4
2025-05-13 15:38:45,038:INFO:              psutil: 7.0.0
2025-05-13 15:38:45,038:INFO:          markupsafe: 3.0.2
2025-05-13 15:38:45,038:INFO:             pickle5: Not installed
2025-05-13 15:38:45,038:INFO:         cloudpickle: 3.1.1
2025-05-13 15:38:45,038:INFO:         deprecation: 2.1.0
2025-05-13 15:38:45,038:INFO:              xxhash: 3.5.0
2025-05-13 15:38:45,038:INFO:           wurlitzer: 3.1.1
2025-05-13 15:38:45,038:INFO:PyCaret optional dependencies:
2025-05-13 15:38:45,043:INFO:                shap: 0.47.2
2025-05-13 15:38:45,043:INFO:           interpret: Not installed
2025-05-13 15:38:45,043:INFO:                umap: Not installed
2025-05-13 15:38:45,043:INFO:     ydata_profiling: Not installed
2025-05-13 15:38:45,043:INFO:  explainerdashboard: Not installed
2025-05-13 15:38:45,043:INFO:             autoviz: Not installed
2025-05-13 15:38:45,043:INFO:           fairlearn: Not installed
2025-05-13 15:38:45,043:INFO:          deepchecks: Not installed
2025-05-13 15:38:45,043:INFO:             xgboost: Not installed
2025-05-13 15:38:45,043:INFO:            catboost: Not installed
2025-05-13 15:38:45,043:INFO:              kmodes: Not installed
2025-05-13 15:38:45,043:INFO:             mlxtend: Not installed
2025-05-13 15:38:45,043:INFO:       statsforecast: Not installed
2025-05-13 15:38:45,043:INFO:        tune_sklearn: Not installed
2025-05-13 15:38:45,043:INFO:                 ray: Not installed
2025-05-13 15:38:45,043:INFO:            hyperopt: Not installed
2025-05-13 15:38:45,043:INFO:              optuna: 4.3.0
2025-05-13 15:38:45,043:INFO:               skopt: Not installed
2025-05-13 15:38:45,043:INFO:              mlflow: Not installed
2025-05-13 15:38:45,043:INFO:              gradio: Not installed
2025-05-13 15:38:45,043:INFO:             fastapi: Not installed
2025-05-13 15:38:45,043:INFO:             uvicorn: Not installed
2025-05-13 15:38:45,043:INFO:              m2cgen: Not installed
2025-05-13 15:38:45,043:INFO:           evidently: Not installed
2025-05-13 15:38:45,043:INFO:               fugue: Not installed
2025-05-13 15:38:45,043:INFO:           streamlit: Not installed
2025-05-13 15:38:45,043:INFO:             prophet: Not installed
2025-05-13 15:38:45,043:INFO:None
2025-05-13 15:38:45,043:INFO:Set up data.
2025-05-13 15:38:45,071:INFO:Set up folding strategy.
2025-05-13 15:38:45,071:INFO:Set up train/test split.
2025-05-13 15:38:45,091:INFO:Set up index.
2025-05-13 15:38:45,092:INFO:Assigning column types.
2025-05-13 15:38:45,095:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-13 15:38:45,113:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,115:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,146:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,157:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-13 15:38:45,175:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,204:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,215:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-13 15:38:45,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,276:INFO:Preparing preprocessing pipeline...
2025-05-13 15:38:45,277:INFO:Set up simple imputation.
2025-05-13 15:38:45,282:INFO:Set up encoding of ordinal features.
2025-05-13 15:38:45,290:INFO:Set up encoding of categorical features.
2025-05-13 15:38:45,290:INFO:Set up imbalanced handling.
2025-05-13 15:38:45,290:INFO:Set up column transformation.
2025-05-13 15:38:46,546:INFO:Finished creating preprocessing pipeline.
2025-05-13 15:38:46,561:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-13 15:38:46,561:INFO:Creating final display dataframe.
2025-05-13 15:38:47,001:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 14)
4        Transformed data shape      (106821, 27)
5   Transformed train set shape       (85902, 27)
6    Transformed test set shape       (20919, 27)
7              Numeric features                 6
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              4919
2025-05-13 15:38:47,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:47,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:47,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:47,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:47,068:INFO:setup() successfully completed in 2.06s...............
2025-05-13 15:38:47,068:INFO:Initializing compare_models()
2025-05-13 15:38:47,068:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-13 15:38:47,068:INFO:Checking exceptions
2025-05-13 15:38:47,076:INFO:Preparing display monitor
2025-05-13 15:38:47,108:INFO:Initializing Logistic Regression
2025-05-13 15:38:47,108:INFO:Total runtime is 2.9365221659342447e-06 minutes
2025-05-13 15:38:47,110:INFO:SubProcess create_model() called ==================================
2025-05-13 15:38:47,110:INFO:Initializing create_model()
2025-05-13 15:38:47,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:38:47,110:INFO:Checking exceptions
2025-05-13 15:38:47,110:INFO:Importing libraries
2025-05-13 15:38:47,110:INFO:Copying training dataset
2025-05-13 15:38:47,123:INFO:Defining folds
2025-05-13 15:38:47,123:INFO:Declaring metric variables
2025-05-13 15:38:47,124:INFO:Importing untrained model
2025-05-13 15:38:47,125:INFO:Logistic Regression Imported successfully
2025-05-13 15:38:47,128:INFO:Starting cross validation
2025-05-13 15:38:47,129:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:38:52,369:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,423:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,438:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,454:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,493:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,549:INFO:Calculating mean and std
2025-05-13 15:38:52,551:INFO:Creating metrics dataframe
2025-05-13 15:38:52,552:INFO:Uploading results into container
2025-05-13 15:38:52,553:INFO:Uploading model into container now
2025-05-13 15:38:52,553:INFO:_master_model_container: 1
2025-05-13 15:38:52,553:INFO:_display_container: 2
2025-05-13 15:38:52,554:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-13 15:38:52,554:INFO:create_model() successfully completed......................................
2025-05-13 15:38:52,612:INFO:SubProcess create_model() end ==================================
2025-05-13 15:38:52,613:INFO:Creating metrics dataframe
2025-05-13 15:38:52,615:INFO:Initializing K Neighbors Classifier
2025-05-13 15:38:52,615:INFO:Total runtime is 0.09178495407104492 minutes
2025-05-13 15:38:52,617:INFO:SubProcess create_model() called ==================================
2025-05-13 15:38:52,617:INFO:Initializing create_model()
2025-05-13 15:38:52,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:38:52,617:INFO:Checking exceptions
2025-05-13 15:38:52,617:INFO:Importing libraries
2025-05-13 15:38:52,617:INFO:Copying training dataset
2025-05-13 15:38:52,626:INFO:Defining folds
2025-05-13 15:38:52,626:INFO:Declaring metric variables
2025-05-13 15:38:52,627:INFO:Importing untrained model
2025-05-13 15:38:52,629:INFO:K Neighbors Classifier Imported successfully
2025-05-13 15:38:52,631:INFO:Starting cross validation
2025-05-13 15:38:52,632:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:38:58,431:INFO:Calculating mean and std
2025-05-13 15:38:58,433:INFO:Creating metrics dataframe
2025-05-13 15:38:58,438:INFO:Uploading results into container
2025-05-13 15:38:58,438:INFO:Uploading model into container now
2025-05-13 15:38:58,439:INFO:_master_model_container: 2
2025-05-13 15:38:58,439:INFO:_display_container: 2
2025-05-13 15:38:58,440:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-13 15:38:58,440:INFO:create_model() successfully completed......................................
2025-05-13 15:38:58,526:INFO:SubProcess create_model() end ==================================
2025-05-13 15:38:58,526:INFO:Creating metrics dataframe
2025-05-13 15:38:58,530:INFO:Initializing Naive Bayes
2025-05-13 15:38:58,530:INFO:Total runtime is 0.1903595010439555 minutes
2025-05-13 15:38:58,531:INFO:SubProcess create_model() called ==================================
2025-05-13 15:38:58,531:INFO:Initializing create_model()
2025-05-13 15:38:58,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:38:58,531:INFO:Checking exceptions
2025-05-13 15:38:58,532:INFO:Importing libraries
2025-05-13 15:38:58,532:INFO:Copying training dataset
2025-05-13 15:38:58,542:INFO:Defining folds
2025-05-13 15:38:58,542:INFO:Declaring metric variables
2025-05-13 15:38:58,543:INFO:Importing untrained model
2025-05-13 15:38:58,544:INFO:Naive Bayes Imported successfully
2025-05-13 15:38:58,547:INFO:Starting cross validation
2025-05-13 15:38:58,548:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:00,749:INFO:Calculating mean and std
2025-05-13 15:39:00,749:INFO:Creating metrics dataframe
2025-05-13 15:39:00,750:INFO:Uploading results into container
2025-05-13 15:39:00,751:INFO:Uploading model into container now
2025-05-13 15:39:00,751:INFO:_master_model_container: 3
2025-05-13 15:39:00,751:INFO:_display_container: 2
2025-05-13 15:39:00,751:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-13 15:39:00,751:INFO:create_model() successfully completed......................................
2025-05-13 15:39:00,821:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:00,821:INFO:Creating metrics dataframe
2025-05-13 15:39:00,825:INFO:Initializing Decision Tree Classifier
2025-05-13 15:39:00,825:INFO:Total runtime is 0.2286062002182007 minutes
2025-05-13 15:39:00,826:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:00,826:INFO:Initializing create_model()
2025-05-13 15:39:00,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:00,826:INFO:Checking exceptions
2025-05-13 15:39:00,826:INFO:Importing libraries
2025-05-13 15:39:00,826:INFO:Copying training dataset
2025-05-13 15:39:00,835:INFO:Defining folds
2025-05-13 15:39:00,835:INFO:Declaring metric variables
2025-05-13 15:39:00,836:INFO:Importing untrained model
2025-05-13 15:39:00,837:INFO:Decision Tree Classifier Imported successfully
2025-05-13 15:39:00,839:INFO:Starting cross validation
2025-05-13 15:39:00,841:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:02,424:INFO:Calculating mean and std
2025-05-13 15:39:02,425:INFO:Creating metrics dataframe
2025-05-13 15:39:02,426:INFO:Uploading results into container
2025-05-13 15:39:02,426:INFO:Uploading model into container now
2025-05-13 15:39:02,426:INFO:_master_model_container: 4
2025-05-13 15:39:02,427:INFO:_display_container: 2
2025-05-13 15:39:02,427:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-13 15:39:02,427:INFO:create_model() successfully completed......................................
2025-05-13 15:39:02,470:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:02,471:INFO:Creating metrics dataframe
2025-05-13 15:39:02,474:INFO:Initializing SVM - Linear Kernel
2025-05-13 15:39:02,474:INFO:Total runtime is 0.2560910701751709 minutes
2025-05-13 15:39:02,475:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:02,475:INFO:Initializing create_model()
2025-05-13 15:39:02,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:02,475:INFO:Checking exceptions
2025-05-13 15:39:02,475:INFO:Importing libraries
2025-05-13 15:39:02,475:INFO:Copying training dataset
2025-05-13 15:39:02,484:INFO:Defining folds
2025-05-13 15:39:02,484:INFO:Declaring metric variables
2025-05-13 15:39:02,485:INFO:Importing untrained model
2025-05-13 15:39:02,487:INFO:SVM - Linear Kernel Imported successfully
2025-05-13 15:39:02,489:INFO:Starting cross validation
2025-05-13 15:39:02,490:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:06,111:INFO:Calculating mean and std
2025-05-13 15:39:06,114:INFO:Creating metrics dataframe
2025-05-13 15:39:06,118:INFO:Uploading results into container
2025-05-13 15:39:06,119:INFO:Uploading model into container now
2025-05-13 15:39:06,119:INFO:_master_model_container: 5
2025-05-13 15:39:06,119:INFO:_display_container: 2
2025-05-13 15:39:06,120:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-13 15:39:06,120:INFO:create_model() successfully completed......................................
2025-05-13 15:39:06,209:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:06,209:INFO:Creating metrics dataframe
2025-05-13 15:39:06,213:INFO:Initializing Ridge Classifier
2025-05-13 15:39:06,213:INFO:Total runtime is 0.3184064189592997 minutes
2025-05-13 15:39:06,214:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:06,214:INFO:Initializing create_model()
2025-05-13 15:39:06,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:06,214:INFO:Checking exceptions
2025-05-13 15:39:06,214:INFO:Importing libraries
2025-05-13 15:39:06,215:INFO:Copying training dataset
2025-05-13 15:39:06,226:INFO:Defining folds
2025-05-13 15:39:06,226:INFO:Declaring metric variables
2025-05-13 15:39:06,227:INFO:Importing untrained model
2025-05-13 15:39:06,228:INFO:Ridge Classifier Imported successfully
2025-05-13 15:39:06,230:INFO:Starting cross validation
2025-05-13 15:39:06,231:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:07,261:INFO:Calculating mean and std
2025-05-13 15:39:07,261:INFO:Creating metrics dataframe
2025-05-13 15:39:07,263:INFO:Uploading results into container
2025-05-13 15:39:07,263:INFO:Uploading model into container now
2025-05-13 15:39:07,263:INFO:_master_model_container: 6
2025-05-13 15:39:07,263:INFO:_display_container: 2
2025-05-13 15:39:07,263:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-13 15:39:07,263:INFO:create_model() successfully completed......................................
2025-05-13 15:39:07,310:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:07,310:INFO:Creating metrics dataframe
2025-05-13 15:39:07,313:INFO:Initializing Random Forest Classifier
2025-05-13 15:39:07,313:INFO:Total runtime is 0.3367486516634623 minutes
2025-05-13 15:39:07,314:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:07,314:INFO:Initializing create_model()
2025-05-13 15:39:07,315:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:07,315:INFO:Checking exceptions
2025-05-13 15:39:07,315:INFO:Importing libraries
2025-05-13 15:39:07,315:INFO:Copying training dataset
2025-05-13 15:39:07,325:INFO:Defining folds
2025-05-13 15:39:07,325:INFO:Declaring metric variables
2025-05-13 15:39:07,326:INFO:Importing untrained model
2025-05-13 15:39:07,327:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:39:07,329:INFO:Starting cross validation
2025-05-13 15:39:07,330:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:13,517:INFO:Calculating mean and std
2025-05-13 15:39:13,524:INFO:Creating metrics dataframe
2025-05-13 15:39:13,529:INFO:Uploading results into container
2025-05-13 15:39:13,529:INFO:Uploading model into container now
2025-05-13 15:39:13,530:INFO:_master_model_container: 7
2025-05-13 15:39:13,530:INFO:_display_container: 2
2025-05-13 15:39:13,531:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:39:13,531:INFO:create_model() successfully completed......................................
2025-05-13 15:39:13,613:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:13,613:INFO:Creating metrics dataframe
2025-05-13 15:39:13,617:INFO:Initializing Quadratic Discriminant Analysis
2025-05-13 15:39:13,617:INFO:Total runtime is 0.4418077707290649 minutes
2025-05-13 15:39:13,618:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:13,618:INFO:Initializing create_model()
2025-05-13 15:39:13,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:13,618:INFO:Checking exceptions
2025-05-13 15:39:13,618:INFO:Importing libraries
2025-05-13 15:39:13,619:INFO:Copying training dataset
2025-05-13 15:39:13,635:INFO:Defining folds
2025-05-13 15:39:13,635:INFO:Declaring metric variables
2025-05-13 15:39:13,637:INFO:Importing untrained model
2025-05-13 15:39:13,639:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-13 15:39:13,641:INFO:Starting cross validation
2025-05-13 15:39:13,642:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:14,572:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:14,604:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:14,626:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:14,637:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:14,643:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:14,694:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:14,703:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:15,990:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:16,051:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:16,062:INFO:Calculating mean and std
2025-05-13 15:39:16,063:INFO:Creating metrics dataframe
2025-05-13 15:39:16,064:INFO:Uploading results into container
2025-05-13 15:39:16,064:INFO:Uploading model into container now
2025-05-13 15:39:16,064:INFO:_master_model_container: 8
2025-05-13 15:39:16,064:INFO:_display_container: 2
2025-05-13 15:39:16,064:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-13 15:39:16,064:INFO:create_model() successfully completed......................................
2025-05-13 15:39:16,109:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:16,109:INFO:Creating metrics dataframe
2025-05-13 15:39:16,112:INFO:Initializing Ada Boost Classifier
2025-05-13 15:39:16,112:INFO:Total runtime is 0.48340231974919634 minutes
2025-05-13 15:39:16,114:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:16,114:INFO:Initializing create_model()
2025-05-13 15:39:16,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:16,114:INFO:Checking exceptions
2025-05-13 15:39:16,114:INFO:Importing libraries
2025-05-13 15:39:16,114:INFO:Copying training dataset
2025-05-13 15:39:16,129:INFO:Defining folds
2025-05-13 15:39:16,129:INFO:Declaring metric variables
2025-05-13 15:39:16,130:INFO:Importing untrained model
2025-05-13 15:39:16,132:INFO:Ada Boost Classifier Imported successfully
2025-05-13 15:39:16,134:INFO:Starting cross validation
2025-05-13 15:39:16,135:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:17,048:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:17,069:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:17,089:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:17,096:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:17,097:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:19,884:INFO:Calculating mean and std
2025-05-13 15:39:19,888:INFO:Creating metrics dataframe
2025-05-13 15:39:19,894:INFO:Uploading results into container
2025-05-13 15:39:19,895:INFO:Uploading model into container now
2025-05-13 15:39:19,895:INFO:_master_model_container: 9
2025-05-13 15:39:19,896:INFO:_display_container: 2
2025-05-13 15:39:19,896:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-13 15:39:19,896:INFO:create_model() successfully completed......................................
2025-05-13 15:39:19,990:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:19,991:INFO:Creating metrics dataframe
2025-05-13 15:39:19,995:INFO:Initializing Gradient Boosting Classifier
2025-05-13 15:39:19,995:INFO:Total runtime is 0.5481151382128397 minutes
2025-05-13 15:39:19,997:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:19,997:INFO:Initializing create_model()
2025-05-13 15:39:19,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:19,997:INFO:Checking exceptions
2025-05-13 15:39:19,997:INFO:Importing libraries
2025-05-13 15:39:19,997:INFO:Copying training dataset
2025-05-13 15:39:20,012:INFO:Defining folds
2025-05-13 15:39:20,012:INFO:Declaring metric variables
2025-05-13 15:39:20,014:INFO:Importing untrained model
2025-05-13 15:39:20,016:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:39:20,018:INFO:Starting cross validation
2025-05-13 15:39:20,020:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:32,940:INFO:Calculating mean and std
2025-05-13 15:39:32,941:INFO:Creating metrics dataframe
2025-05-13 15:39:32,942:INFO:Uploading results into container
2025-05-13 15:39:32,942:INFO:Uploading model into container now
2025-05-13 15:39:32,943:INFO:_master_model_container: 10
2025-05-13 15:39:32,943:INFO:_display_container: 2
2025-05-13 15:39:32,943:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:39:32,943:INFO:create_model() successfully completed......................................
2025-05-13 15:39:32,990:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:32,990:INFO:Creating metrics dataframe
2025-05-13 15:39:32,994:INFO:Initializing Linear Discriminant Analysis
2025-05-13 15:39:32,994:INFO:Total runtime is 0.7647580186525981 minutes
2025-05-13 15:39:32,995:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:32,995:INFO:Initializing create_model()
2025-05-13 15:39:32,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:32,995:INFO:Checking exceptions
2025-05-13 15:39:32,995:INFO:Importing libraries
2025-05-13 15:39:32,995:INFO:Copying training dataset
2025-05-13 15:39:33,005:INFO:Defining folds
2025-05-13 15:39:33,005:INFO:Declaring metric variables
2025-05-13 15:39:33,007:INFO:Importing untrained model
2025-05-13 15:39:33,008:INFO:Linear Discriminant Analysis Imported successfully
2025-05-13 15:39:33,010:INFO:Starting cross validation
2025-05-13 15:39:33,011:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:34,122:INFO:Calculating mean and std
2025-05-13 15:39:34,123:INFO:Creating metrics dataframe
2025-05-13 15:39:34,124:INFO:Uploading results into container
2025-05-13 15:39:34,124:INFO:Uploading model into container now
2025-05-13 15:39:34,124:INFO:_master_model_container: 11
2025-05-13 15:39:34,124:INFO:_display_container: 2
2025-05-13 15:39:34,125:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-13 15:39:34,125:INFO:create_model() successfully completed......................................
2025-05-13 15:39:34,166:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:34,166:INFO:Creating metrics dataframe
2025-05-13 15:39:34,171:INFO:Initializing Extra Trees Classifier
2025-05-13 15:39:34,171:INFO:Total runtime is 0.7843758344650269 minutes
2025-05-13 15:39:34,172:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:34,172:INFO:Initializing create_model()
2025-05-13 15:39:34,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:34,172:INFO:Checking exceptions
2025-05-13 15:39:34,172:INFO:Importing libraries
2025-05-13 15:39:34,172:INFO:Copying training dataset
2025-05-13 15:39:34,182:INFO:Defining folds
2025-05-13 15:39:34,182:INFO:Declaring metric variables
2025-05-13 15:39:34,184:INFO:Importing untrained model
2025-05-13 15:39:34,185:INFO:Extra Trees Classifier Imported successfully
2025-05-13 15:39:34,187:INFO:Starting cross validation
2025-05-13 15:39:34,188:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:38,694:INFO:Calculating mean and std
2025-05-13 15:39:38,698:INFO:Creating metrics dataframe
2025-05-13 15:39:38,704:INFO:Uploading results into container
2025-05-13 15:39:38,705:INFO:Uploading model into container now
2025-05-13 15:39:38,706:INFO:_master_model_container: 12
2025-05-13 15:39:38,706:INFO:_display_container: 2
2025-05-13 15:39:38,707:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-13 15:39:38,708:INFO:create_model() successfully completed......................................
2025-05-13 15:39:38,816:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:38,816:INFO:Creating metrics dataframe
2025-05-13 15:39:38,820:INFO:Initializing Light Gradient Boosting Machine
2025-05-13 15:39:38,820:INFO:Total runtime is 0.8618667523066204 minutes
2025-05-13 15:39:38,822:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:38,822:INFO:Initializing create_model()
2025-05-13 15:39:38,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:38,822:INFO:Checking exceptions
2025-05-13 15:39:38,822:INFO:Importing libraries
2025-05-13 15:39:38,822:INFO:Copying training dataset
2025-05-13 15:39:38,838:INFO:Defining folds
2025-05-13 15:39:38,838:INFO:Declaring metric variables
2025-05-13 15:39:38,840:INFO:Importing untrained model
2025-05-13 15:39:38,841:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:39:38,844:INFO:Starting cross validation
2025-05-13 15:39:38,845:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:43,198:INFO:Calculating mean and std
2025-05-13 15:39:43,199:INFO:Creating metrics dataframe
2025-05-13 15:39:43,200:INFO:Uploading results into container
2025-05-13 15:39:43,201:INFO:Uploading model into container now
2025-05-13 15:39:43,201:INFO:_master_model_container: 13
2025-05-13 15:39:43,201:INFO:_display_container: 2
2025-05-13 15:39:43,202:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:39:43,202:INFO:create_model() successfully completed......................................
2025-05-13 15:39:43,256:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:43,256:INFO:Creating metrics dataframe
2025-05-13 15:39:43,260:INFO:Initializing Dummy Classifier
2025-05-13 15:39:43,260:INFO:Total runtime is 0.9358652194341024 minutes
2025-05-13 15:39:43,261:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:43,262:INFO:Initializing create_model()
2025-05-13 15:39:43,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:43,262:INFO:Checking exceptions
2025-05-13 15:39:43,262:INFO:Importing libraries
2025-05-13 15:39:43,262:INFO:Copying training dataset
2025-05-13 15:39:43,271:INFO:Defining folds
2025-05-13 15:39:43,271:INFO:Declaring metric variables
2025-05-13 15:39:43,273:INFO:Importing untrained model
2025-05-13 15:39:43,274:INFO:Dummy Classifier Imported successfully
2025-05-13 15:39:43,276:INFO:Starting cross validation
2025-05-13 15:39:43,277:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:44,246:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,246:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,257:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,268:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,343:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,362:INFO:Calculating mean and std
2025-05-13 15:39:44,363:INFO:Creating metrics dataframe
2025-05-13 15:39:44,365:INFO:Uploading results into container
2025-05-13 15:39:44,365:INFO:Uploading model into container now
2025-05-13 15:39:44,365:INFO:_master_model_container: 14
2025-05-13 15:39:44,365:INFO:_display_container: 2
2025-05-13 15:39:44,365:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-13 15:39:44,366:INFO:create_model() successfully completed......................................
2025-05-13 15:39:44,413:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:44,413:INFO:Creating metrics dataframe
2025-05-13 15:39:44,419:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-13 15:39:44,422:INFO:Initializing create_model()
2025-05-13 15:39:44,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:44,422:INFO:Checking exceptions
2025-05-13 15:39:44,423:INFO:Importing libraries
2025-05-13 15:39:44,423:INFO:Copying training dataset
2025-05-13 15:39:44,432:INFO:Defining folds
2025-05-13 15:39:44,432:INFO:Declaring metric variables
2025-05-13 15:39:44,432:INFO:Importing untrained model
2025-05-13 15:39:44,432:INFO:Declaring custom model
2025-05-13 15:39:44,432:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:39:44,433:INFO:Cross validation set to False
2025-05-13 15:39:44,433:INFO:Fitting Model
2025-05-13 15:40:00,069:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:40:00,070:INFO:create_model() successfully completed......................................
2025-05-13 15:40:00,121:INFO:Initializing create_model()
2025-05-13 15:40:00,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:40:00,121:INFO:Checking exceptions
2025-05-13 15:40:00,122:INFO:Importing libraries
2025-05-13 15:40:00,122:INFO:Copying training dataset
2025-05-13 15:40:00,131:INFO:Defining folds
2025-05-13 15:40:00,131:INFO:Declaring metric variables
2025-05-13 15:40:00,131:INFO:Importing untrained model
2025-05-13 15:40:00,131:INFO:Declaring custom model
2025-05-13 15:40:00,132:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:40:00,132:INFO:Cross validation set to False
2025-05-13 15:40:00,132:INFO:Fitting Model
2025-05-13 15:40:01,091:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-13 15:40:01,104:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008033 seconds.
2025-05-13 15:40:01,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-13 15:40:01,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-13 15:40:01,104:INFO:[LightGBM] [Info] Total Bins 6630
2025-05-13 15:40:01,104:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 26
2025-05-13 15:40:01,104:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-13 15:40:01,859:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:40:01,859:INFO:create_model() successfully completed......................................
2025-05-13 15:40:01,908:INFO:Initializing create_model()
2025-05-13 15:40:01,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:40:01,908:INFO:Checking exceptions
2025-05-13 15:40:01,909:INFO:Importing libraries
2025-05-13 15:40:01,909:INFO:Copying training dataset
2025-05-13 15:40:01,919:INFO:Defining folds
2025-05-13 15:40:01,919:INFO:Declaring metric variables
2025-05-13 15:40:01,919:INFO:Importing untrained model
2025-05-13 15:40:01,919:INFO:Declaring custom model
2025-05-13 15:40:01,919:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:40:01,920:INFO:Cross validation set to False
2025-05-13 15:40:01,920:INFO:Fitting Model
2025-05-13 15:40:04,311:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:40:04,311:INFO:create_model() successfully completed......................................
2025-05-13 15:40:04,360:INFO:_master_model_container: 14
2025-05-13 15:40:04,360:INFO:_display_container: 2
2025-05-13 15:40:04,360:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-13 15:40:04,361:INFO:compare_models() successfully completed......................................
2025-05-13 15:40:04,361:INFO:Initializing evaluate_model()
2025-05-13 15:40:04,361:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:40:04,367:INFO:Initializing plot_model()
2025-05-13 15:40:04,367:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:40:04,367:INFO:Checking exceptions
2025-05-13 15:40:04,371:INFO:Preloading libraries
2025-05-13 15:40:04,374:INFO:Copying training dataset
2025-05-13 15:40:04,374:INFO:Plot type: pipeline
2025-05-13 15:40:04,461:INFO:Visual Rendered Successfully
2025-05-13 15:40:04,506:INFO:plot_model() successfully completed......................................
2025-05-13 15:40:04,508:INFO:Initializing tune_model()
2025-05-13 15:40:04,508:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-13 15:40:04,508:INFO:Checking exceptions
2025-05-13 15:40:04,516:INFO:Copying training dataset
2025-05-13 15:40:04,523:INFO:Checking base model
2025-05-13 15:40:04,523:INFO:Base model : Gradient Boosting Classifier
2025-05-13 15:40:04,524:INFO:Declaring metric variables
2025-05-13 15:40:04,525:INFO:Defining Hyperparameters
2025-05-13 15:40:04,569:INFO:Tuning with n_jobs=-1
2025-05-13 15:40:04,569:INFO:Initializing RandomizedSearchCV
2025-05-13 15:40:45,144:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-13 15:40:45,149:INFO:Hyperparameter search completed
2025-05-13 15:40:45,149:INFO:SubProcess create_model() called ==================================
2025-05-13 15:40:45,150:INFO:Initializing create_model()
2025-05-13 15:40:45,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325fb0410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-13 15:40:45,150:INFO:Checking exceptions
2025-05-13 15:40:45,150:INFO:Importing libraries
2025-05-13 15:40:45,150:INFO:Copying training dataset
2025-05-13 15:40:45,163:INFO:Defining folds
2025-05-13 15:40:45,163:INFO:Declaring metric variables
2025-05-13 15:40:45,166:INFO:Importing untrained model
2025-05-13 15:40:45,166:INFO:Declaring custom model
2025-05-13 15:40:45,169:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:40:45,171:INFO:Starting cross validation
2025-05-13 15:40:45,174:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:40:54,838:INFO:Calculating mean and std
2025-05-13 15:40:54,839:INFO:Creating metrics dataframe
2025-05-13 15:40:54,842:INFO:Finalizing model
2025-05-13 15:41:05,382:INFO:Uploading results into container
2025-05-13 15:41:05,383:INFO:Uploading model into container now
2025-05-13 15:41:05,384:INFO:_master_model_container: 15
2025-05-13 15:41:05,384:INFO:_display_container: 3
2025-05-13 15:41:05,384:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:41:05,384:INFO:create_model() successfully completed......................................
2025-05-13 15:41:05,481:INFO:SubProcess create_model() end ==================================
2025-05-13 15:41:05,481:INFO:choose_better activated
2025-05-13 15:41:05,483:INFO:SubProcess create_model() called ==================================
2025-05-13 15:41:05,483:INFO:Initializing create_model()
2025-05-13 15:41:05,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:41:05,485:INFO:Checking exceptions
2025-05-13 15:41:05,486:INFO:Importing libraries
2025-05-13 15:41:05,486:INFO:Copying training dataset
2025-05-13 15:41:05,496:INFO:Defining folds
2025-05-13 15:41:05,496:INFO:Declaring metric variables
2025-05-13 15:41:05,496:INFO:Importing untrained model
2025-05-13 15:41:05,496:INFO:Declaring custom model
2025-05-13 15:41:05,496:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:41:05,496:INFO:Starting cross validation
2025-05-13 15:41:05,497:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:41:18,521:INFO:Calculating mean and std
2025-05-13 15:41:18,522:INFO:Creating metrics dataframe
2025-05-13 15:41:18,525:INFO:Finalizing model
2025-05-13 15:41:34,251:INFO:Uploading results into container
2025-05-13 15:41:34,251:INFO:Uploading model into container now
2025-05-13 15:41:34,252:INFO:_master_model_container: 16
2025-05-13 15:41:34,252:INFO:_display_container: 4
2025-05-13 15:41:34,252:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:41:34,252:INFO:create_model() successfully completed......................................
2025-05-13 15:41:34,332:INFO:SubProcess create_model() end ==================================
2025-05-13 15:41:34,333:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4809
2025-05-13 15:41:34,333:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4906
2025-05-13 15:41:34,333:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-13 15:41:34,333:INFO:choose_better completed
2025-05-13 15:41:34,337:INFO:_master_model_container: 16
2025-05-13 15:41:34,337:INFO:_display_container: 3
2025-05-13 15:41:34,337:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:41:34,337:INFO:tune_model() successfully completed......................................
2025-05-13 15:41:34,387:INFO:Initializing evaluate_model()
2025-05-13 15:41:34,387:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:41:34,395:INFO:Initializing plot_model()
2025-05-13 15:41:34,395:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:41:34,395:INFO:Checking exceptions
2025-05-13 15:41:34,401:INFO:Preloading libraries
2025-05-13 15:41:34,410:INFO:Copying training dataset
2025-05-13 15:41:34,410:INFO:Plot type: pipeline
2025-05-13 15:41:34,473:INFO:Visual Rendered Successfully
2025-05-13 15:41:34,517:INFO:plot_model() successfully completed......................................
2025-05-13 15:41:34,519:INFO:Initializing interpret_model()
2025-05-13 15:41:34,519:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-13 15:41:34,519:INFO:Checking exceptions
2025-05-13 15:41:34,519:INFO:Soft dependency imported: shap: 0.47.2
2025-05-13 15:41:34,802:INFO:Initializing finalize_model()
2025-05-13 15:41:34,802:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-13 15:41:34,802:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:41:34,806:INFO:Initializing create_model()
2025-05-13 15:41:34,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:41:34,806:INFO:Checking exceptions
2025-05-13 15:41:34,807:INFO:Importing libraries
2025-05-13 15:41:34,807:INFO:Copying training dataset
2025-05-13 15:41:34,807:INFO:Defining folds
2025-05-13 15:41:34,807:INFO:Declaring metric variables
2025-05-13 15:41:34,807:INFO:Importing untrained model
2025-05-13 15:41:34,807:INFO:Declaring custom model
2025-05-13 15:41:34,807:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:41:34,809:INFO:Cross validation set to False
2025-05-13 15:41:34,809:INFO:Fitting Model
2025-05-13 15:41:50,493:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:41:50,494:INFO:create_model() successfully completed......................................
2025-05-13 15:41:50,544:INFO:_master_model_container: 16
2025-05-13 15:41:50,544:INFO:_display_container: 3
2025-05-13 15:41:50,560:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:41:50,560:INFO:finalize_model() successfully completed......................................
2025-05-13 15:41:50,638:INFO:Initializing save_model()
2025-05-13 15:41:50,638:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-13 15:41:50,638:INFO:Adding model into prep_pipe
2025-05-13 15:41:50,638:WARNING:Only Model saved as it was a pipeline.
2025-05-13 15:41:50,661:INFO:final_cancer_model.pkl saved in current working directory
2025-05-13 15:41:50,677:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:41:50,677:INFO:save_model() successfully completed......................................
2025-05-13 15:41:50,739:INFO:Initializing predict_model()
2025-05-13 15:41:50,739:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x325f053a0>)
2025-05-13 15:41:50,739:INFO:Checking exceptions
2025-05-13 15:41:50,739:INFO:Preloading libraries
2025-05-13 15:41:50,740:INFO:Set up data.
2025-05-13 15:41:50,754:INFO:Set up index.
2025-05-13 15:41:51,535:INFO:Initializing blend_models()
2025-05-13 15:41:51,535:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-13 15:41:51,535:INFO:Checking exceptions
2025-05-13 15:41:51,544:INFO:Importing libraries
2025-05-13 15:41:51,544:INFO:Copying training dataset
2025-05-13 15:41:51,545:INFO:Getting model names
2025-05-13 15:41:51,546:INFO:SubProcess create_model() called ==================================
2025-05-13 15:41:51,548:INFO:Initializing create_model()
2025-05-13 15:41:51,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325feed50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:41:51,548:INFO:Checking exceptions
2025-05-13 15:41:51,548:INFO:Importing libraries
2025-05-13 15:41:51,548:INFO:Copying training dataset
2025-05-13 15:41:51,557:INFO:Defining folds
2025-05-13 15:41:51,557:INFO:Declaring metric variables
2025-05-13 15:41:51,558:INFO:Importing untrained model
2025-05-13 15:41:51,558:INFO:Declaring custom model
2025-05-13 15:41:51,560:INFO:Voting Classifier Imported successfully
2025-05-13 15:41:51,562:INFO:Starting cross validation
2025-05-13 15:41:51,563:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:42:08,254:INFO:Calculating mean and std
2025-05-13 15:42:08,257:INFO:Creating metrics dataframe
2025-05-13 15:42:08,271:INFO:Finalizing model
2025-05-13 15:42:24,806:INFO:Uploading results into container
2025-05-13 15:42:24,810:INFO:Uploading model into container now
2025-05-13 15:42:24,810:INFO:_master_model_container: 17
2025-05-13 15:42:24,810:INFO:_display_container: 4
2025-05-13 15:42:24,814:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-13 15:42:24,814:INFO:create_model() successfully completed......................................
2025-05-13 15:42:24,927:INFO:SubProcess create_model() end ==================================
2025-05-13 15:42:24,931:INFO:_master_model_container: 17
2025-05-13 15:42:24,931:INFO:_display_container: 4
2025-05-13 15:42:24,933:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-13 15:42:24,933:INFO:blend_models() successfully completed......................................
2025-05-13 15:42:24,988:INFO:Initializing evaluate_model()
2025-05-13 15:42:24,988:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:42:25,000:INFO:Initializing plot_model()
2025-05-13 15:42:25,000:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:42:25,000:INFO:Checking exceptions
2025-05-13 15:42:25,005:INFO:Preloading libraries
2025-05-13 15:42:25,135:INFO:Copying training dataset
2025-05-13 15:42:25,135:INFO:Plot type: pipeline
2025-05-13 15:42:25,195:INFO:Visual Rendered Successfully
2025-05-13 15:42:25,244:INFO:plot_model() successfully completed......................................
2025-05-13 15:42:25,253:INFO:Initializing predict_model()
2025-05-13 15:42:25,253:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x32fb43600>)
2025-05-13 15:42:25,253:INFO:Checking exceptions
2025-05-13 15:42:25,253:INFO:Preloading libraries
2025-05-13 15:42:25,254:INFO:Set up data.
2025-05-13 15:42:25,269:INFO:Set up index.
2025-05-13 15:42:25,839:INFO:Initializing plot_model()
2025-05-13 15:42:25,839:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:42:25,839:INFO:Checking exceptions
2025-05-13 15:42:25,844:INFO:Preloading libraries
2025-05-13 15:42:25,847:INFO:Copying training dataset
2025-05-13 15:42:25,847:INFO:Plot type: confusion_matrix
2025-05-13 15:42:26,040:INFO:Fitting Model
2025-05-13 15:42:26,042:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:42:26,043:INFO:Scoring test/hold-out set
2025-05-13 15:42:26,117:INFO:Visual Rendered Successfully
2025-05-13 15:42:26,166:INFO:plot_model() successfully completed......................................
2025-05-13 15:42:26,167:INFO:Initializing plot_model()
2025-05-13 15:42:26,167:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:42:26,167:INFO:Checking exceptions
2025-05-13 15:42:26,171:INFO:Preloading libraries
2025-05-13 15:42:26,174:INFO:Copying training dataset
2025-05-13 15:42:26,175:INFO:Plot type: auc
2025-05-13 15:42:26,361:INFO:Fitting Model
2025-05-13 15:42:26,362:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:42:26,363:INFO:Scoring test/hold-out set
2025-05-13 15:42:26,474:INFO:Visual Rendered Successfully
2025-05-13 15:42:26,521:INFO:plot_model() successfully completed......................................
2025-05-13 15:42:26,521:INFO:Initializing plot_model()
2025-05-13 15:42:26,521:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:42:26,521:INFO:Checking exceptions
2025-05-13 15:42:26,527:INFO:Preloading libraries
2025-05-13 15:42:26,530:INFO:Copying training dataset
2025-05-13 15:42:26,530:INFO:Plot type: feature
2025-05-13 15:42:26,531:WARNING:No coef_ found. Trying feature_importances_
2025-05-13 15:42:26,599:INFO:Visual Rendered Successfully
2025-05-13 15:42:26,648:INFO:plot_model() successfully completed......................................
2025-05-13 15:46:43,301:INFO:PyCaret ClassificationExperiment
2025-05-13 15:46:43,301:INFO:Logging name: clf-default-name
2025-05-13 15:46:43,301:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-13 15:46:43,301:INFO:version 3.3.2
2025-05-13 15:46:43,301:INFO:Initializing setup()
2025-05-13 15:46:43,301:INFO:self.USI: 6f06
2025-05-13 15:46:43,301:INFO:self._variable_keys: {'fold_groups_param', 'html_param', 'USI', 'fix_imbalance', 'log_plots_param', 'idx', 'fold_generator', 'exp_name_log', 'exp_id', 'y', 'is_multiclass', 'memory', 'gpu_param', 'y_test', 'pipeline', 'seed', '_ml_usecase', 'X_train', 'gpu_n_jobs_param', 'y_train', 'fold_shuffle_param', 'X', 'data', '_available_plots', 'X_test', 'target_param', 'n_jobs_param', 'logging_param'}
2025-05-13 15:46:43,301:INFO:Checking environment
2025-05-13 15:46:43,301:INFO:python_version: 3.11.0
2025-05-13 15:46:43,301:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-13 15:46:43,301:INFO:machine: arm64
2025-05-13 15:46:43,301:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:46:43,302:INFO:Memory: svmem(total=17179869184, available=3750920192, percent=78.2, used=6131138560, free=61603840, active=3702865920, inactive=3663511552, wired=2428272640)
2025-05-13 15:46:43,302:INFO:Physical Core: 12
2025-05-13 15:46:43,302:INFO:Logical Core: 12
2025-05-13 15:46:43,302:INFO:Checking libraries
2025-05-13 15:46:43,302:INFO:System:
2025-05-13 15:46:43,302:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-13 15:46:43,302:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-13 15:46:43,302:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:46:43,302:INFO:PyCaret required dependencies:
2025-05-13 15:46:43,302:INFO:                 pip: 22.3
2025-05-13 15:46:43,302:INFO:          setuptools: 65.5.0
2025-05-13 15:46:43,302:INFO:             pycaret: 3.3.2
2025-05-13 15:46:43,302:INFO:             IPython: 9.2.0
2025-05-13 15:46:43,302:INFO:          ipywidgets: 8.1.7
2025-05-13 15:46:43,302:INFO:                tqdm: 4.67.1
2025-05-13 15:46:43,302:INFO:               numpy: 1.26.4
2025-05-13 15:46:43,302:INFO:              pandas: 2.1.4
2025-05-13 15:46:43,302:INFO:              jinja2: 3.1.6
2025-05-13 15:46:43,302:INFO:               scipy: 1.11.4
2025-05-13 15:46:43,302:INFO:              joblib: 1.3.2
2025-05-13 15:46:43,302:INFO:             sklearn: 1.4.2
2025-05-13 15:46:43,302:INFO:                pyod: 2.0.5
2025-05-13 15:46:43,302:INFO:            imblearn: 0.13.0
2025-05-13 15:46:43,302:INFO:   category_encoders: 2.7.0
2025-05-13 15:46:43,302:INFO:            lightgbm: 4.6.0
2025-05-13 15:46:43,302:INFO:               numba: 0.61.2
2025-05-13 15:46:43,302:INFO:            requests: 2.32.3
2025-05-13 15:46:43,302:INFO:          matplotlib: 3.7.5
2025-05-13 15:46:43,302:INFO:          scikitplot: 0.3.7
2025-05-13 15:46:43,302:INFO:         yellowbrick: 1.5
2025-05-13 15:46:43,302:INFO:              plotly: 5.24.1
2025-05-13 15:46:43,302:INFO:    plotly-resampler: Not installed
2025-05-13 15:46:43,302:INFO:             kaleido: 0.2.1
2025-05-13 15:46:43,302:INFO:           schemdraw: 0.15
2025-05-13 15:46:43,302:INFO:         statsmodels: 0.14.4
2025-05-13 15:46:43,302:INFO:              sktime: 0.26.0
2025-05-13 15:46:43,302:INFO:               tbats: 1.1.3
2025-05-13 15:46:43,302:INFO:            pmdarima: 2.0.4
2025-05-13 15:46:43,302:INFO:              psutil: 7.0.0
2025-05-13 15:46:43,302:INFO:          markupsafe: 3.0.2
2025-05-13 15:46:43,302:INFO:             pickle5: Not installed
2025-05-13 15:46:43,302:INFO:         cloudpickle: 3.1.1
2025-05-13 15:46:43,302:INFO:         deprecation: 2.1.0
2025-05-13 15:46:43,302:INFO:              xxhash: 3.5.0
2025-05-13 15:46:43,302:INFO:           wurlitzer: 3.1.1
2025-05-13 15:46:43,302:INFO:PyCaret optional dependencies:
2025-05-13 15:46:43,302:INFO:                shap: 0.47.2
2025-05-13 15:46:43,302:INFO:           interpret: Not installed
2025-05-13 15:46:43,302:INFO:                umap: Not installed
2025-05-13 15:46:43,302:INFO:     ydata_profiling: Not installed
2025-05-13 15:46:43,302:INFO:  explainerdashboard: Not installed
2025-05-13 15:46:43,302:INFO:             autoviz: Not installed
2025-05-13 15:46:43,302:INFO:           fairlearn: Not installed
2025-05-13 15:46:43,302:INFO:          deepchecks: Not installed
2025-05-13 15:46:43,302:INFO:             xgboost: Not installed
2025-05-13 15:46:43,302:INFO:            catboost: Not installed
2025-05-13 15:46:43,302:INFO:              kmodes: Not installed
2025-05-13 15:46:43,302:INFO:             mlxtend: Not installed
2025-05-13 15:46:43,302:INFO:       statsforecast: Not installed
2025-05-13 15:46:43,302:INFO:        tune_sklearn: Not installed
2025-05-13 15:46:43,302:INFO:                 ray: Not installed
2025-05-13 15:46:43,302:INFO:            hyperopt: Not installed
2025-05-13 15:46:43,302:INFO:              optuna: 4.3.0
2025-05-13 15:46:43,302:INFO:               skopt: Not installed
2025-05-13 15:46:43,302:INFO:              mlflow: Not installed
2025-05-13 15:46:43,302:INFO:              gradio: Not installed
2025-05-13 15:46:43,302:INFO:             fastapi: Not installed
2025-05-13 15:46:43,302:INFO:             uvicorn: Not installed
2025-05-13 15:46:43,302:INFO:              m2cgen: Not installed
2025-05-13 15:46:43,302:INFO:           evidently: Not installed
2025-05-13 15:46:43,302:INFO:               fugue: Not installed
2025-05-13 15:46:43,302:INFO:           streamlit: Not installed
2025-05-13 15:46:43,302:INFO:             prophet: Not installed
2025-05-13 15:46:43,302:INFO:None
2025-05-13 15:46:43,303:INFO:Set up data.
2025-05-13 15:46:43,335:INFO:Set up folding strategy.
2025-05-13 15:46:43,335:INFO:Set up train/test split.
2025-05-13 15:46:43,348:INFO:Set up index.
2025-05-13 15:46:43,349:INFO:Assigning column types.
2025-05-13 15:46:43,352:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-13 15:46:43,370:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,371:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,403:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,404:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,415:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,415:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-13 15:46:43,433:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,462:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,473:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-13 15:46:43,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,504:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,534:INFO:Preparing preprocessing pipeline...
2025-05-13 15:46:43,536:INFO:Set up simple imputation.
2025-05-13 15:46:43,542:INFO:Set up encoding of ordinal features.
2025-05-13 15:46:43,553:INFO:Set up encoding of categorical features.
2025-05-13 15:46:43,553:INFO:Set up imbalanced handling.
2025-05-13 15:46:43,553:INFO:Set up column transformation.
2025-05-13 15:46:44,751:INFO:Finished creating preprocessing pipeline.
2025-05-13 15:46:44,770:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-13 15:46:44,770:INFO:Creating final display dataframe.
2025-05-13 15:46:45,311:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 17)
4        Transformed data shape      (106821, 35)
5   Transformed train set shape       (85902, 35)
6    Transformed test set shape       (20919, 35)
7              Numeric features                 6
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              6f06
2025-05-13 15:46:45,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:45,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:45,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:45,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:45,374:INFO:setup() successfully completed in 2.08s...............
2025-05-13 15:46:45,375:INFO:Initializing compare_models()
2025-05-13 15:46:45,375:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-13 15:46:45,375:INFO:Checking exceptions
2025-05-13 15:46:45,379:INFO:Preparing display monitor
2025-05-13 15:46:45,388:INFO:Initializing Logistic Regression
2025-05-13 15:46:45,388:INFO:Total runtime is 1.3192494710286458e-06 minutes
2025-05-13 15:46:45,389:INFO:SubProcess create_model() called ==================================
2025-05-13 15:46:45,389:INFO:Initializing create_model()
2025-05-13 15:46:45,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:46:45,389:INFO:Checking exceptions
2025-05-13 15:46:45,389:INFO:Importing libraries
2025-05-13 15:46:45,389:INFO:Copying training dataset
2025-05-13 15:46:45,400:INFO:Defining folds
2025-05-13 15:46:45,400:INFO:Declaring metric variables
2025-05-13 15:46:45,402:INFO:Importing untrained model
2025-05-13 15:46:45,403:INFO:Logistic Regression Imported successfully
2025-05-13 15:46:45,405:INFO:Starting cross validation
2025-05-13 15:46:45,406:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:46:49,918:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:50,095:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:50,115:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:50,134:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:51,151:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:51,219:INFO:Calculating mean and std
2025-05-13 15:46:51,220:INFO:Creating metrics dataframe
2025-05-13 15:46:51,222:INFO:Uploading results into container
2025-05-13 15:46:51,222:INFO:Uploading model into container now
2025-05-13 15:46:51,222:INFO:_master_model_container: 1
2025-05-13 15:46:51,222:INFO:_display_container: 2
2025-05-13 15:46:51,223:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-13 15:46:51,223:INFO:create_model() successfully completed......................................
2025-05-13 15:46:51,317:INFO:SubProcess create_model() end ==================================
2025-05-13 15:46:51,317:INFO:Creating metrics dataframe
2025-05-13 15:46:51,320:INFO:Initializing K Neighbors Classifier
2025-05-13 15:46:51,320:INFO:Total runtime is 0.0988743503888448 minutes
2025-05-13 15:46:51,322:INFO:SubProcess create_model() called ==================================
2025-05-13 15:46:51,322:INFO:Initializing create_model()
2025-05-13 15:46:51,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:46:51,322:INFO:Checking exceptions
2025-05-13 15:46:51,322:INFO:Importing libraries
2025-05-13 15:46:51,322:INFO:Copying training dataset
2025-05-13 15:46:51,333:INFO:Defining folds
2025-05-13 15:46:51,333:INFO:Declaring metric variables
2025-05-13 15:46:51,335:INFO:Importing untrained model
2025-05-13 15:46:51,336:INFO:K Neighbors Classifier Imported successfully
2025-05-13 15:46:51,338:INFO:Starting cross validation
2025-05-13 15:46:51,339:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:46:58,123:INFO:Calculating mean and std
2025-05-13 15:46:58,126:INFO:Creating metrics dataframe
2025-05-13 15:46:58,130:INFO:Uploading results into container
2025-05-13 15:46:58,131:INFO:Uploading model into container now
2025-05-13 15:46:58,131:INFO:_master_model_container: 2
2025-05-13 15:46:58,131:INFO:_display_container: 2
2025-05-13 15:46:58,132:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-13 15:46:58,132:INFO:create_model() successfully completed......................................
2025-05-13 15:46:58,193:INFO:SubProcess create_model() end ==================================
2025-05-13 15:46:58,193:INFO:Creating metrics dataframe
2025-05-13 15:46:58,196:INFO:Initializing Naive Bayes
2025-05-13 15:46:58,196:INFO:Total runtime is 0.21347267230351766 minutes
2025-05-13 15:46:58,197:INFO:SubProcess create_model() called ==================================
2025-05-13 15:46:58,197:INFO:Initializing create_model()
2025-05-13 15:46:58,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:46:58,197:INFO:Checking exceptions
2025-05-13 15:46:58,197:INFO:Importing libraries
2025-05-13 15:46:58,198:INFO:Copying training dataset
2025-05-13 15:46:58,209:INFO:Defining folds
2025-05-13 15:46:58,209:INFO:Declaring metric variables
2025-05-13 15:46:58,210:INFO:Importing untrained model
2025-05-13 15:46:58,212:INFO:Naive Bayes Imported successfully
2025-05-13 15:46:58,214:INFO:Starting cross validation
2025-05-13 15:46:58,216:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:00,598:INFO:Calculating mean and std
2025-05-13 15:47:00,599:INFO:Creating metrics dataframe
2025-05-13 15:47:00,601:INFO:Uploading results into container
2025-05-13 15:47:00,601:INFO:Uploading model into container now
2025-05-13 15:47:00,601:INFO:_master_model_container: 3
2025-05-13 15:47:00,601:INFO:_display_container: 2
2025-05-13 15:47:00,601:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-13 15:47:00,602:INFO:create_model() successfully completed......................................
2025-05-13 15:47:00,655:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:00,655:INFO:Creating metrics dataframe
2025-05-13 15:47:00,658:INFO:Initializing Decision Tree Classifier
2025-05-13 15:47:00,658:INFO:Total runtime is 0.2545124689737956 minutes
2025-05-13 15:47:00,660:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:00,660:INFO:Initializing create_model()
2025-05-13 15:47:00,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:00,660:INFO:Checking exceptions
2025-05-13 15:47:00,660:INFO:Importing libraries
2025-05-13 15:47:00,660:INFO:Copying training dataset
2025-05-13 15:47:00,670:INFO:Defining folds
2025-05-13 15:47:00,670:INFO:Declaring metric variables
2025-05-13 15:47:00,671:INFO:Importing untrained model
2025-05-13 15:47:00,673:INFO:Decision Tree Classifier Imported successfully
2025-05-13 15:47:00,675:INFO:Starting cross validation
2025-05-13 15:47:00,677:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:03,679:INFO:Calculating mean and std
2025-05-13 15:47:03,680:INFO:Creating metrics dataframe
2025-05-13 15:47:03,681:INFO:Uploading results into container
2025-05-13 15:47:03,681:INFO:Uploading model into container now
2025-05-13 15:47:03,682:INFO:_master_model_container: 4
2025-05-13 15:47:03,682:INFO:_display_container: 2
2025-05-13 15:47:03,682:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-13 15:47:03,682:INFO:create_model() successfully completed......................................
2025-05-13 15:47:03,771:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:03,771:INFO:Creating metrics dataframe
2025-05-13 15:47:03,774:INFO:Initializing SVM - Linear Kernel
2025-05-13 15:47:03,775:INFO:Total runtime is 0.3064471522967021 minutes
2025-05-13 15:47:03,776:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:03,776:INFO:Initializing create_model()
2025-05-13 15:47:03,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:03,776:INFO:Checking exceptions
2025-05-13 15:47:03,777:INFO:Importing libraries
2025-05-13 15:47:03,777:INFO:Copying training dataset
2025-05-13 15:47:03,786:INFO:Defining folds
2025-05-13 15:47:03,786:INFO:Declaring metric variables
2025-05-13 15:47:03,788:INFO:Importing untrained model
2025-05-13 15:47:03,789:INFO:SVM - Linear Kernel Imported successfully
2025-05-13 15:47:03,791:INFO:Starting cross validation
2025-05-13 15:47:03,793:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:08,285:INFO:Calculating mean and std
2025-05-13 15:47:08,286:INFO:Creating metrics dataframe
2025-05-13 15:47:08,288:INFO:Uploading results into container
2025-05-13 15:47:08,288:INFO:Uploading model into container now
2025-05-13 15:47:08,288:INFO:_master_model_container: 5
2025-05-13 15:47:08,288:INFO:_display_container: 2
2025-05-13 15:47:08,289:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-13 15:47:08,289:INFO:create_model() successfully completed......................................
2025-05-13 15:47:08,350:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:08,350:INFO:Creating metrics dataframe
2025-05-13 15:47:08,354:INFO:Initializing Ridge Classifier
2025-05-13 15:47:08,354:INFO:Total runtime is 0.3827689170837403 minutes
2025-05-13 15:47:08,355:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:08,356:INFO:Initializing create_model()
2025-05-13 15:47:08,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:08,356:INFO:Checking exceptions
2025-05-13 15:47:08,356:INFO:Importing libraries
2025-05-13 15:47:08,356:INFO:Copying training dataset
2025-05-13 15:47:08,365:INFO:Defining folds
2025-05-13 15:47:08,365:INFO:Declaring metric variables
2025-05-13 15:47:08,367:INFO:Importing untrained model
2025-05-13 15:47:08,368:INFO:Ridge Classifier Imported successfully
2025-05-13 15:47:08,371:INFO:Starting cross validation
2025-05-13 15:47:08,372:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:11,116:INFO:Calculating mean and std
2025-05-13 15:47:11,117:INFO:Creating metrics dataframe
2025-05-13 15:47:11,121:INFO:Uploading results into container
2025-05-13 15:47:11,121:INFO:Uploading model into container now
2025-05-13 15:47:11,122:INFO:_master_model_container: 6
2025-05-13 15:47:11,122:INFO:_display_container: 2
2025-05-13 15:47:11,122:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-13 15:47:11,122:INFO:create_model() successfully completed......................................
2025-05-13 15:47:11,217:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:11,217:INFO:Creating metrics dataframe
2025-05-13 15:47:11,220:INFO:Initializing Random Forest Classifier
2025-05-13 15:47:11,220:INFO:Total runtime is 0.4305449684460958 minutes
2025-05-13 15:47:11,222:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:11,222:INFO:Initializing create_model()
2025-05-13 15:47:11,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:11,222:INFO:Checking exceptions
2025-05-13 15:47:11,222:INFO:Importing libraries
2025-05-13 15:47:11,222:INFO:Copying training dataset
2025-05-13 15:47:11,235:INFO:Defining folds
2025-05-13 15:47:11,235:INFO:Declaring metric variables
2025-05-13 15:47:11,236:INFO:Importing untrained model
2025-05-13 15:47:11,238:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:47:11,240:INFO:Starting cross validation
2025-05-13 15:47:11,242:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:17,420:INFO:Calculating mean and std
2025-05-13 15:47:17,423:INFO:Creating metrics dataframe
2025-05-13 15:47:17,426:INFO:Uploading results into container
2025-05-13 15:47:17,427:INFO:Uploading model into container now
2025-05-13 15:47:17,427:INFO:_master_model_container: 7
2025-05-13 15:47:17,427:INFO:_display_container: 2
2025-05-13 15:47:17,428:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:47:17,428:INFO:create_model() successfully completed......................................
2025-05-13 15:47:17,541:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:17,541:INFO:Creating metrics dataframe
2025-05-13 15:47:17,545:INFO:Initializing Quadratic Discriminant Analysis
2025-05-13 15:47:17,545:INFO:Total runtime is 0.5359603842099507 minutes
2025-05-13 15:47:17,547:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:17,547:INFO:Initializing create_model()
2025-05-13 15:47:17,547:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:17,547:INFO:Checking exceptions
2025-05-13 15:47:17,547:INFO:Importing libraries
2025-05-13 15:47:17,547:INFO:Copying training dataset
2025-05-13 15:47:17,563:INFO:Defining folds
2025-05-13 15:47:17,563:INFO:Declaring metric variables
2025-05-13 15:47:17,565:INFO:Importing untrained model
2025-05-13 15:47:17,566:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-13 15:47:17,568:INFO:Starting cross validation
2025-05-13 15:47:17,570:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:18,910:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:18,918:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:18,944:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:18,969:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:18,984:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:19,055:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:19,093:INFO:Calculating mean and std
2025-05-13 15:47:19,094:INFO:Creating metrics dataframe
2025-05-13 15:47:19,095:INFO:Uploading results into container
2025-05-13 15:47:19,096:INFO:Uploading model into container now
2025-05-13 15:47:19,096:INFO:_master_model_container: 8
2025-05-13 15:47:19,096:INFO:_display_container: 2
2025-05-13 15:47:19,096:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-13 15:47:19,096:INFO:create_model() successfully completed......................................
2025-05-13 15:47:19,150:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:19,150:INFO:Creating metrics dataframe
2025-05-13 15:47:19,154:INFO:Initializing Ada Boost Classifier
2025-05-13 15:47:19,154:INFO:Total runtime is 0.5627730687459309 minutes
2025-05-13 15:47:19,155:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:19,156:INFO:Initializing create_model()
2025-05-13 15:47:19,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:19,156:INFO:Checking exceptions
2025-05-13 15:47:19,156:INFO:Importing libraries
2025-05-13 15:47:19,156:INFO:Copying training dataset
2025-05-13 15:47:19,167:INFO:Defining folds
2025-05-13 15:47:19,167:INFO:Declaring metric variables
2025-05-13 15:47:19,168:INFO:Importing untrained model
2025-05-13 15:47:19,170:INFO:Ada Boost Classifier Imported successfully
2025-05-13 15:47:19,172:INFO:Starting cross validation
2025-05-13 15:47:19,174:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:20,347:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:20,385:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:20,410:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:20,430:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:20,438:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:23,295:INFO:Calculating mean and std
2025-05-13 15:47:23,295:INFO:Creating metrics dataframe
2025-05-13 15:47:23,296:INFO:Uploading results into container
2025-05-13 15:47:23,296:INFO:Uploading model into container now
2025-05-13 15:47:23,296:INFO:_master_model_container: 9
2025-05-13 15:47:23,296:INFO:_display_container: 2
2025-05-13 15:47:23,297:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-13 15:47:23,297:INFO:create_model() successfully completed......................................
2025-05-13 15:47:23,344:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:23,345:INFO:Creating metrics dataframe
2025-05-13 15:47:23,348:INFO:Initializing Gradient Boosting Classifier
2025-05-13 15:47:23,348:INFO:Total runtime is 0.6326791882514953 minutes
2025-05-13 15:47:23,350:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:23,350:INFO:Initializing create_model()
2025-05-13 15:47:23,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:23,350:INFO:Checking exceptions
2025-05-13 15:47:23,350:INFO:Importing libraries
2025-05-13 15:47:23,350:INFO:Copying training dataset
2025-05-13 15:47:23,360:INFO:Defining folds
2025-05-13 15:47:23,360:INFO:Declaring metric variables
2025-05-13 15:47:23,361:INFO:Importing untrained model
2025-05-13 15:47:23,362:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:47:23,365:INFO:Starting cross validation
2025-05-13 15:47:23,366:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:38,117:INFO:Calculating mean and std
2025-05-13 15:47:38,119:INFO:Creating metrics dataframe
2025-05-13 15:47:38,123:INFO:Uploading results into container
2025-05-13 15:47:38,123:INFO:Uploading model into container now
2025-05-13 15:47:38,124:INFO:_master_model_container: 10
2025-05-13 15:47:38,124:INFO:_display_container: 2
2025-05-13 15:47:38,124:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:47:38,125:INFO:create_model() successfully completed......................................
2025-05-13 15:47:38,239:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:38,239:INFO:Creating metrics dataframe
2025-05-13 15:47:38,244:INFO:Initializing Linear Discriminant Analysis
2025-05-13 15:47:38,244:INFO:Total runtime is 0.8809373378753661 minutes
2025-05-13 15:47:38,245:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:38,245:INFO:Initializing create_model()
2025-05-13 15:47:38,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:38,245:INFO:Checking exceptions
2025-05-13 15:47:38,246:INFO:Importing libraries
2025-05-13 15:47:38,246:INFO:Copying training dataset
2025-05-13 15:47:38,263:INFO:Defining folds
2025-05-13 15:47:38,263:INFO:Declaring metric variables
2025-05-13 15:47:38,265:INFO:Importing untrained model
2025-05-13 15:47:38,266:INFO:Linear Discriminant Analysis Imported successfully
2025-05-13 15:47:38,268:INFO:Starting cross validation
2025-05-13 15:47:38,270:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:39,735:INFO:Calculating mean and std
2025-05-13 15:47:39,736:INFO:Creating metrics dataframe
2025-05-13 15:47:39,737:INFO:Uploading results into container
2025-05-13 15:47:39,737:INFO:Uploading model into container now
2025-05-13 15:47:39,738:INFO:_master_model_container: 11
2025-05-13 15:47:39,738:INFO:_display_container: 2
2025-05-13 15:47:39,738:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-13 15:47:39,738:INFO:create_model() successfully completed......................................
2025-05-13 15:47:39,787:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:39,787:INFO:Creating metrics dataframe
2025-05-13 15:47:39,791:INFO:Initializing Extra Trees Classifier
2025-05-13 15:47:39,791:INFO:Total runtime is 0.9067201852798461 minutes
2025-05-13 15:47:39,792:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:39,792:INFO:Initializing create_model()
2025-05-13 15:47:39,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:39,792:INFO:Checking exceptions
2025-05-13 15:47:39,792:INFO:Importing libraries
2025-05-13 15:47:39,792:INFO:Copying training dataset
2025-05-13 15:47:39,802:INFO:Defining folds
2025-05-13 15:47:39,802:INFO:Declaring metric variables
2025-05-13 15:47:39,803:INFO:Importing untrained model
2025-05-13 15:47:39,805:INFO:Extra Trees Classifier Imported successfully
2025-05-13 15:47:39,807:INFO:Starting cross validation
2025-05-13 15:47:39,808:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:44,921:INFO:Calculating mean and std
2025-05-13 15:47:44,925:INFO:Creating metrics dataframe
2025-05-13 15:47:44,931:INFO:Uploading results into container
2025-05-13 15:47:44,932:INFO:Uploading model into container now
2025-05-13 15:47:44,932:INFO:_master_model_container: 12
2025-05-13 15:47:44,933:INFO:_display_container: 2
2025-05-13 15:47:44,933:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-13 15:47:44,933:INFO:create_model() successfully completed......................................
2025-05-13 15:47:45,080:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:45,080:INFO:Creating metrics dataframe
2025-05-13 15:47:45,084:INFO:Initializing Light Gradient Boosting Machine
2025-05-13 15:47:45,084:INFO:Total runtime is 0.9949469526608784 minutes
2025-05-13 15:47:45,086:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:45,086:INFO:Initializing create_model()
2025-05-13 15:47:45,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:45,086:INFO:Checking exceptions
2025-05-13 15:47:45,086:INFO:Importing libraries
2025-05-13 15:47:45,086:INFO:Copying training dataset
2025-05-13 15:47:45,107:INFO:Defining folds
2025-05-13 15:47:45,108:INFO:Declaring metric variables
2025-05-13 15:47:45,109:INFO:Importing untrained model
2025-05-13 15:47:45,111:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:47:45,113:INFO:Starting cross validation
2025-05-13 15:47:45,115:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:49,600:INFO:Calculating mean and std
2025-05-13 15:47:49,601:INFO:Creating metrics dataframe
2025-05-13 15:47:49,602:INFO:Uploading results into container
2025-05-13 15:47:49,602:INFO:Uploading model into container now
2025-05-13 15:47:49,602:INFO:_master_model_container: 13
2025-05-13 15:47:49,602:INFO:_display_container: 2
2025-05-13 15:47:49,603:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:47:49,603:INFO:create_model() successfully completed......................................
2025-05-13 15:47:49,655:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:49,655:INFO:Creating metrics dataframe
2025-05-13 15:47:49,659:INFO:Initializing Dummy Classifier
2025-05-13 15:47:49,659:INFO:Total runtime is 1.0711941679318744 minutes
2025-05-13 15:47:49,661:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:49,661:INFO:Initializing create_model()
2025-05-13 15:47:49,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:49,661:INFO:Checking exceptions
2025-05-13 15:47:49,661:INFO:Importing libraries
2025-05-13 15:47:49,661:INFO:Copying training dataset
2025-05-13 15:47:49,671:INFO:Defining folds
2025-05-13 15:47:49,671:INFO:Declaring metric variables
2025-05-13 15:47:49,672:INFO:Importing untrained model
2025-05-13 15:47:49,673:INFO:Dummy Classifier Imported successfully
2025-05-13 15:47:49,675:INFO:Starting cross validation
2025-05-13 15:47:49,677:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:50,855:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:50,899:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:50,966:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:50,998:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:51,046:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:51,061:INFO:Calculating mean and std
2025-05-13 15:47:51,062:INFO:Creating metrics dataframe
2025-05-13 15:47:51,063:INFO:Uploading results into container
2025-05-13 15:47:51,063:INFO:Uploading model into container now
2025-05-13 15:47:51,064:INFO:_master_model_container: 14
2025-05-13 15:47:51,064:INFO:_display_container: 2
2025-05-13 15:47:51,064:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-13 15:47:51,064:INFO:create_model() successfully completed......................................
2025-05-13 15:47:51,112:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:51,112:INFO:Creating metrics dataframe
2025-05-13 15:47:51,116:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-13 15:47:51,119:INFO:Initializing create_model()
2025-05-13 15:47:51,119:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:51,119:INFO:Checking exceptions
2025-05-13 15:47:51,119:INFO:Importing libraries
2025-05-13 15:47:51,120:INFO:Copying training dataset
2025-05-13 15:47:51,130:INFO:Defining folds
2025-05-13 15:47:51,130:INFO:Declaring metric variables
2025-05-13 15:47:51,130:INFO:Importing untrained model
2025-05-13 15:47:51,130:INFO:Declaring custom model
2025-05-13 15:47:51,130:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:47:51,131:INFO:Cross validation set to False
2025-05-13 15:47:51,131:INFO:Fitting Model
2025-05-13 15:48:08,726:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:48:08,727:INFO:create_model() successfully completed......................................
2025-05-13 15:48:08,794:INFO:Initializing create_model()
2025-05-13 15:48:08,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:48:08,794:INFO:Checking exceptions
2025-05-13 15:48:08,795:INFO:Importing libraries
2025-05-13 15:48:08,795:INFO:Copying training dataset
2025-05-13 15:48:08,805:INFO:Defining folds
2025-05-13 15:48:08,805:INFO:Declaring metric variables
2025-05-13 15:48:08,805:INFO:Importing untrained model
2025-05-13 15:48:08,805:INFO:Declaring custom model
2025-05-13 15:48:08,805:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:48:08,806:INFO:Cross validation set to False
2025-05-13 15:48:08,806:INFO:Fitting Model
2025-05-13 15:48:10,058:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-05-13 15:48:10,059:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-13 15:48:10,069:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005456 seconds.
2025-05-13 15:48:10,069:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-13 15:48:10,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-13 15:48:10,069:INFO:[LightGBM] [Info] Total Bins 8670
2025-05-13 15:48:10,070:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 34
2025-05-13 15:48:10,070:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-13 15:48:10,853:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:48:10,853:INFO:create_model() successfully completed......................................
2025-05-13 15:48:10,907:INFO:Initializing create_model()
2025-05-13 15:48:10,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:48:10,908:INFO:Checking exceptions
2025-05-13 15:48:10,908:INFO:Importing libraries
2025-05-13 15:48:10,909:INFO:Copying training dataset
2025-05-13 15:48:10,919:INFO:Defining folds
2025-05-13 15:48:10,919:INFO:Declaring metric variables
2025-05-13 15:48:10,919:INFO:Importing untrained model
2025-05-13 15:48:10,919:INFO:Declaring custom model
2025-05-13 15:48:10,919:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:48:10,920:INFO:Cross validation set to False
2025-05-13 15:48:10,920:INFO:Fitting Model
2025-05-13 15:48:13,166:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:48:13,166:INFO:create_model() successfully completed......................................
2025-05-13 15:48:13,225:INFO:_master_model_container: 14
2025-05-13 15:48:13,225:INFO:_display_container: 2
2025-05-13 15:48:13,226:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-13 15:48:13,226:INFO:compare_models() successfully completed......................................
2025-05-13 15:48:13,237:INFO:Initializing evaluate_model()
2025-05-13 15:48:13,237:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:48:13,245:INFO:Initializing plot_model()
2025-05-13 15:48:13,245:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:48:13,245:INFO:Checking exceptions
2025-05-13 15:48:13,249:INFO:Preloading libraries
2025-05-13 15:48:13,252:INFO:Copying training dataset
2025-05-13 15:48:13,252:INFO:Plot type: pipeline
2025-05-13 15:48:13,312:INFO:Visual Rendered Successfully
2025-05-13 15:48:13,361:INFO:plot_model() successfully completed......................................
2025-05-13 15:48:13,363:INFO:Initializing tune_model()
2025-05-13 15:48:13,363:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-13 15:48:13,363:INFO:Checking exceptions
2025-05-13 15:48:13,372:INFO:Copying training dataset
2025-05-13 15:48:13,385:INFO:Checking base model
2025-05-13 15:48:13,385:INFO:Base model : Gradient Boosting Classifier
2025-05-13 15:48:13,386:INFO:Declaring metric variables
2025-05-13 15:48:13,388:INFO:Defining Hyperparameters
2025-05-13 15:48:13,444:INFO:Tuning with n_jobs=-1
2025-05-13 15:48:13,444:INFO:Initializing RandomizedSearchCV
2025-05-13 15:48:52,601:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-13 15:48:52,603:INFO:Hyperparameter search completed
2025-05-13 15:48:52,604:INFO:SubProcess create_model() called ==================================
2025-05-13 15:48:52,605:INFO:Initializing create_model()
2025-05-13 15:48:52,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f04c490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-13 15:48:52,605:INFO:Checking exceptions
2025-05-13 15:48:52,605:INFO:Importing libraries
2025-05-13 15:48:52,605:INFO:Copying training dataset
2025-05-13 15:48:52,620:INFO:Defining folds
2025-05-13 15:48:52,620:INFO:Declaring metric variables
2025-05-13 15:48:52,623:INFO:Importing untrained model
2025-05-13 15:48:52,623:INFO:Declaring custom model
2025-05-13 15:48:52,625:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:48:52,628:INFO:Starting cross validation
2025-05-13 15:48:52,631:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:49:02,360:INFO:Calculating mean and std
2025-05-13 15:49:02,361:INFO:Creating metrics dataframe
2025-05-13 15:49:02,363:INFO:Finalizing model
2025-05-13 15:49:13,199:INFO:Uploading results into container
2025-05-13 15:49:13,200:INFO:Uploading model into container now
2025-05-13 15:49:13,201:INFO:_master_model_container: 15
2025-05-13 15:49:13,201:INFO:_display_container: 3
2025-05-13 15:49:13,201:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:49:13,202:INFO:create_model() successfully completed......................................
2025-05-13 15:49:13,289:INFO:SubProcess create_model() end ==================================
2025-05-13 15:49:13,289:INFO:choose_better activated
2025-05-13 15:49:13,292:INFO:SubProcess create_model() called ==================================
2025-05-13 15:49:13,292:INFO:Initializing create_model()
2025-05-13 15:49:13,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:49:13,292:INFO:Checking exceptions
2025-05-13 15:49:13,293:INFO:Importing libraries
2025-05-13 15:49:13,293:INFO:Copying training dataset
2025-05-13 15:49:13,304:INFO:Defining folds
2025-05-13 15:49:13,304:INFO:Declaring metric variables
2025-05-13 15:49:13,304:INFO:Importing untrained model
2025-05-13 15:49:13,304:INFO:Declaring custom model
2025-05-13 15:49:13,304:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:49:13,304:INFO:Starting cross validation
2025-05-13 15:49:13,306:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:49:28,290:INFO:Calculating mean and std
2025-05-13 15:49:28,292:INFO:Creating metrics dataframe
2025-05-13 15:49:28,293:INFO:Finalizing model
2025-05-13 15:49:45,538:INFO:Uploading results into container
2025-05-13 15:49:45,539:INFO:Uploading model into container now
2025-05-13 15:49:45,539:INFO:_master_model_container: 16
2025-05-13 15:49:45,539:INFO:_display_container: 4
2025-05-13 15:49:45,539:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:49:45,539:INFO:create_model() successfully completed......................................
2025-05-13 15:49:45,633:INFO:SubProcess create_model() end ==================================
2025-05-13 15:49:45,633:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4645
2025-05-13 15:49:45,634:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.489
2025-05-13 15:49:45,634:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-13 15:49:45,634:INFO:choose_better completed
2025-05-13 15:49:45,637:INFO:_master_model_container: 16
2025-05-13 15:49:45,637:INFO:_display_container: 3
2025-05-13 15:49:45,638:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:49:45,638:INFO:tune_model() successfully completed......................................
2025-05-13 15:49:45,693:INFO:Initializing evaluate_model()
2025-05-13 15:49:45,693:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:49:45,701:INFO:Initializing plot_model()
2025-05-13 15:49:45,701:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:49:45,701:INFO:Checking exceptions
2025-05-13 15:49:45,709:INFO:Preloading libraries
2025-05-13 15:49:45,717:INFO:Copying training dataset
2025-05-13 15:49:45,717:INFO:Plot type: pipeline
2025-05-13 15:49:45,776:INFO:Visual Rendered Successfully
2025-05-13 15:49:45,831:INFO:plot_model() successfully completed......................................
2025-05-13 15:49:45,833:INFO:Initializing interpret_model()
2025-05-13 15:49:45,833:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-13 15:49:45,833:INFO:Checking exceptions
2025-05-13 15:49:45,833:INFO:Soft dependency imported: shap: 0.47.2
2025-05-13 15:49:45,834:INFO:Initializing finalize_model()
2025-05-13 15:49:45,834:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-13 15:49:45,834:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:49:45,838:INFO:Initializing create_model()
2025-05-13 15:49:45,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:49:45,838:INFO:Checking exceptions
2025-05-13 15:49:45,838:INFO:Importing libraries
2025-05-13 15:49:45,838:INFO:Copying training dataset
2025-05-13 15:49:45,839:INFO:Defining folds
2025-05-13 15:49:45,839:INFO:Declaring metric variables
2025-05-13 15:49:45,839:INFO:Importing untrained model
2025-05-13 15:49:45,839:INFO:Declaring custom model
2025-05-13 15:49:45,840:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:49:45,841:INFO:Cross validation set to False
2025-05-13 15:49:45,841:INFO:Fitting Model
2025-05-13 15:50:00,667:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:50:00,668:INFO:create_model() successfully completed......................................
2025-05-13 15:50:00,713:INFO:_master_model_container: 16
2025-05-13 15:50:00,713:INFO:_display_container: 3
2025-05-13 15:50:00,733:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:50:00,733:INFO:finalize_model() successfully completed......................................
2025-05-13 15:50:00,813:INFO:Initializing save_model()
2025-05-13 15:50:00,813:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-13 15:50:00,813:INFO:Adding model into prep_pipe
2025-05-13 15:50:00,813:WARNING:Only Model saved as it was a pipeline.
2025-05-13 15:50:00,838:INFO:final_cancer_model.pkl saved in current working directory
2025-05-13 15:50:00,858:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:50:00,858:INFO:save_model() successfully completed......................................
2025-05-13 15:50:00,929:INFO:Initializing predict_model()
2025-05-13 15:50:00,929:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x32627cb80>)
2025-05-13 15:50:00,930:INFO:Checking exceptions
2025-05-13 15:50:00,930:INFO:Preloading libraries
2025-05-13 15:50:00,931:INFO:Set up data.
2025-05-13 15:50:00,955:INFO:Set up index.
2025-05-13 15:50:01,788:INFO:Initializing plot_model()
2025-05-13 15:50:01,788:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:50:01,788:INFO:Checking exceptions
2025-05-13 15:50:01,792:INFO:Preloading libraries
2025-05-13 15:50:01,796:INFO:Copying training dataset
2025-05-13 15:50:01,796:INFO:Plot type: confusion_matrix
2025-05-13 15:50:02,029:INFO:Fitting Model
2025-05-13 15:50:02,029:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:50:02,030:INFO:Scoring test/hold-out set
2025-05-13 15:50:02,102:INFO:Visual Rendered Successfully
2025-05-13 15:50:02,152:INFO:plot_model() successfully completed......................................
2025-05-13 15:50:02,152:INFO:Initializing plot_model()
2025-05-13 15:50:02,152:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:50:02,152:INFO:Checking exceptions
2025-05-13 15:50:02,156:INFO:Preloading libraries
2025-05-13 15:50:02,160:INFO:Copying training dataset
2025-05-13 15:50:02,160:INFO:Plot type: auc
2025-05-13 15:50:02,391:INFO:Fitting Model
2025-05-13 15:50:02,392:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:50:02,393:INFO:Scoring test/hold-out set
2025-05-13 15:50:02,507:INFO:Visual Rendered Successfully
2025-05-13 15:50:02,558:INFO:plot_model() successfully completed......................................
2025-05-13 15:50:02,558:INFO:Initializing plot_model()
2025-05-13 15:50:02,558:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:50:02,558:INFO:Checking exceptions
2025-05-13 15:50:02,563:INFO:Preloading libraries
2025-05-13 15:50:02,566:INFO:Copying training dataset
2025-05-13 15:50:02,566:INFO:Plot type: feature
2025-05-13 15:50:02,567:WARNING:No coef_ found. Trying feature_importances_
2025-05-13 15:50:02,641:INFO:Visual Rendered Successfully
2025-05-13 15:50:02,691:INFO:plot_model() successfully completed......................................
2025-05-13 15:50:02,691:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:189: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  age_cancer_ratio = train_df_processed.groupby('Age_Group')['Cancer'].mean() * 100

2025-05-13 15:50:02,713:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 45824 (\N{HANGUL SYLLABLE DAE}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,714:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 51060 (\N{HANGUL SYLLABLE I}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,714:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 49345 (\N{HANGUL SYLLABLE SANG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,714:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 50672 (\N{HANGUL SYLLABLE YEON}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,714:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 47161 (\N{HANGUL SYLLABLE RYEONG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 50516 (\N{HANGUL SYLLABLE AM}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 48156 (\N{HANGUL SYLLABLE BAL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 49373 (\N{HANGUL SYLLABLE SAENG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 48708 (\N{HANGUL SYLLABLE BI}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 50984 (\N{HANGUL SYLLABLE YUL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,718:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50516 (\N{HANGUL SYLLABLE AM}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48156 (\N{HANGUL SYLLABLE BAL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49373 (\N{HANGUL SYLLABLE SAENG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48708 (\N{HANGUL SYLLABLE BI}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50984 (\N{HANGUL SYLLABLE YUL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50672 (\N{HANGUL SYLLABLE YEON}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47161 (\N{HANGUL SYLLABLE RYEONG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 45824 (\N{HANGUL SYLLABLE DAE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,741:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51060 (\N{HANGUL SYLLABLE I}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,741:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49345 (\N{HANGUL SYLLABLE SANG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:51:31,254:INFO:PyCaret ClassificationExperiment
2025-05-13 15:51:31,254:INFO:Logging name: clf-default-name
2025-05-13 15:51:31,254:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-13 15:51:31,254:INFO:version 3.3.2
2025-05-13 15:51:31,255:INFO:Initializing setup()
2025-05-13 15:51:31,255:INFO:self.USI: eba9
2025-05-13 15:51:31,255:INFO:self._variable_keys: {'fold_groups_param', 'html_param', 'USI', 'fix_imbalance', 'log_plots_param', 'idx', 'fold_generator', 'exp_name_log', 'exp_id', 'y', 'is_multiclass', 'memory', 'gpu_param', 'y_test', 'pipeline', 'seed', '_ml_usecase', 'X_train', 'gpu_n_jobs_param', 'y_train', 'fold_shuffle_param', 'X', 'data', '_available_plots', 'X_test', 'target_param', 'n_jobs_param', 'logging_param'}
2025-05-13 15:51:31,255:INFO:Checking environment
2025-05-13 15:51:31,255:INFO:python_version: 3.11.0
2025-05-13 15:51:31,255:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-13 15:51:31,255:INFO:machine: arm64
2025-05-13 15:51:31,255:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:51:31,255:INFO:Memory: svmem(total=17179869184, available=3357442048, percent=80.5, used=5936070656, free=72073216, active=3300605952, inactive=3279241216, wired=2635464704)
2025-05-13 15:51:31,255:INFO:Physical Core: 12
2025-05-13 15:51:31,255:INFO:Logical Core: 12
2025-05-13 15:51:31,255:INFO:Checking libraries
2025-05-13 15:51:31,255:INFO:System:
2025-05-13 15:51:31,255:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-13 15:51:31,255:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-13 15:51:31,255:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:51:31,255:INFO:PyCaret required dependencies:
2025-05-13 15:51:31,255:INFO:                 pip: 22.3
2025-05-13 15:51:31,255:INFO:          setuptools: 65.5.0
2025-05-13 15:51:31,255:INFO:             pycaret: 3.3.2
2025-05-13 15:51:31,255:INFO:             IPython: 9.2.0
2025-05-13 15:51:31,255:INFO:          ipywidgets: 8.1.7
2025-05-13 15:51:31,255:INFO:                tqdm: 4.67.1
2025-05-13 15:51:31,255:INFO:               numpy: 1.26.4
2025-05-13 15:51:31,255:INFO:              pandas: 2.1.4
2025-05-13 15:51:31,255:INFO:              jinja2: 3.1.6
2025-05-13 15:51:31,255:INFO:               scipy: 1.11.4
2025-05-13 15:51:31,255:INFO:              joblib: 1.3.2
2025-05-13 15:51:31,255:INFO:             sklearn: 1.4.2
2025-05-13 15:51:31,255:INFO:                pyod: 2.0.5
2025-05-13 15:51:31,255:INFO:            imblearn: 0.13.0
2025-05-13 15:51:31,255:INFO:   category_encoders: 2.7.0
2025-05-13 15:51:31,255:INFO:            lightgbm: 4.6.0
2025-05-13 15:51:31,255:INFO:               numba: 0.61.2
2025-05-13 15:51:31,255:INFO:            requests: 2.32.3
2025-05-13 15:51:31,255:INFO:          matplotlib: 3.7.5
2025-05-13 15:51:31,255:INFO:          scikitplot: 0.3.7
2025-05-13 15:51:31,255:INFO:         yellowbrick: 1.5
2025-05-13 15:51:31,255:INFO:              plotly: 5.24.1
2025-05-13 15:51:31,255:INFO:    plotly-resampler: Not installed
2025-05-13 15:51:31,255:INFO:             kaleido: 0.2.1
2025-05-13 15:51:31,255:INFO:           schemdraw: 0.15
2025-05-13 15:51:31,255:INFO:         statsmodels: 0.14.4
2025-05-13 15:51:31,255:INFO:              sktime: 0.26.0
2025-05-13 15:51:31,255:INFO:               tbats: 1.1.3
2025-05-13 15:51:31,255:INFO:            pmdarima: 2.0.4
2025-05-13 15:51:31,255:INFO:              psutil: 7.0.0
2025-05-13 15:51:31,255:INFO:          markupsafe: 3.0.2
2025-05-13 15:51:31,255:INFO:             pickle5: Not installed
2025-05-13 15:51:31,255:INFO:         cloudpickle: 3.1.1
2025-05-13 15:51:31,255:INFO:         deprecation: 2.1.0
2025-05-13 15:51:31,255:INFO:              xxhash: 3.5.0
2025-05-13 15:51:31,255:INFO:           wurlitzer: 3.1.1
2025-05-13 15:51:31,255:INFO:PyCaret optional dependencies:
2025-05-13 15:51:31,255:INFO:                shap: 0.47.2
2025-05-13 15:51:31,255:INFO:           interpret: Not installed
2025-05-13 15:51:31,255:INFO:                umap: Not installed
2025-05-13 15:51:31,255:INFO:     ydata_profiling: Not installed
2025-05-13 15:51:31,255:INFO:  explainerdashboard: Not installed
2025-05-13 15:51:31,255:INFO:             autoviz: Not installed
2025-05-13 15:51:31,256:INFO:           fairlearn: Not installed
2025-05-13 15:51:31,256:INFO:          deepchecks: Not installed
2025-05-13 15:51:31,256:INFO:             xgboost: Not installed
2025-05-13 15:51:31,256:INFO:            catboost: Not installed
2025-05-13 15:51:31,256:INFO:              kmodes: Not installed
2025-05-13 15:51:31,256:INFO:             mlxtend: Not installed
2025-05-13 15:51:31,256:INFO:       statsforecast: Not installed
2025-05-13 15:51:31,256:INFO:        tune_sklearn: Not installed
2025-05-13 15:51:31,256:INFO:                 ray: Not installed
2025-05-13 15:51:31,256:INFO:            hyperopt: Not installed
2025-05-13 15:51:31,256:INFO:              optuna: 4.3.0
2025-05-13 15:51:31,256:INFO:               skopt: Not installed
2025-05-13 15:51:31,256:INFO:              mlflow: Not installed
2025-05-13 15:51:31,256:INFO:              gradio: Not installed
2025-05-13 15:51:31,256:INFO:             fastapi: Not installed
2025-05-13 15:51:31,256:INFO:             uvicorn: Not installed
2025-05-13 15:51:31,256:INFO:              m2cgen: Not installed
2025-05-13 15:51:31,256:INFO:           evidently: Not installed
2025-05-13 15:51:31,256:INFO:               fugue: Not installed
2025-05-13 15:51:31,256:INFO:           streamlit: Not installed
2025-05-13 15:51:31,256:INFO:             prophet: Not installed
2025-05-13 15:51:31,256:INFO:None
2025-05-13 15:51:31,256:INFO:Set up data.
2025-05-13 15:51:31,287:INFO:Set up folding strategy.
2025-05-13 15:51:31,287:INFO:Set up train/test split.
2025-05-13 15:51:31,301:INFO:Set up index.
2025-05-13 15:51:31,301:INFO:Assigning column types.
2025-05-13 15:51:31,305:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-13 15:51:31,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,324:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,354:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,366:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-13 15:51:31,385:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,397:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,415:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,426:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-13 15:51:31,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,490:INFO:Preparing preprocessing pipeline...
2025-05-13 15:51:31,491:INFO:Set up simple imputation.
2025-05-13 15:51:31,498:INFO:Set up encoding of ordinal features.
2025-05-13 15:51:31,507:INFO:Set up encoding of categorical features.
2025-05-13 15:51:31,508:INFO:Set up imbalanced handling.
2025-05-13 15:51:31,508:INFO:Set up column transformation.
2025-05-13 15:51:32,709:INFO:Finished creating preprocessing pipeline.
2025-05-13 15:51:32,728:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-13 15:51:32,728:INFO:Creating final display dataframe.
2025-05-13 15:51:33,263:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 17)
4        Transformed data shape      (106821, 37)
5   Transformed train set shape       (85902, 37)
6    Transformed test set shape       (20919, 37)
7              Numeric features                 6
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              eba9
2025-05-13 15:51:33,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:33,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:33,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:33,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:33,329:INFO:setup() successfully completed in 2.08s...............
2025-05-13 15:51:33,330:INFO:Initializing compare_models()
2025-05-13 15:51:33,330:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-13 15:51:33,330:INFO:Checking exceptions
2025-05-13 15:51:33,336:INFO:Preparing display monitor
2025-05-13 15:51:33,344:INFO:Initializing Logistic Regression
2025-05-13 15:51:33,345:INFO:Total runtime is 1.7682711283365886e-06 minutes
2025-05-13 15:51:33,346:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:33,346:INFO:Initializing create_model()
2025-05-13 15:51:33,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:33,346:INFO:Checking exceptions
2025-05-13 15:51:33,346:INFO:Importing libraries
2025-05-13 15:51:33,346:INFO:Copying training dataset
2025-05-13 15:51:33,358:INFO:Defining folds
2025-05-13 15:51:33,358:INFO:Declaring metric variables
2025-05-13 15:51:33,359:INFO:Importing untrained model
2025-05-13 15:51:33,361:INFO:Logistic Regression Imported successfully
2025-05-13 15:51:33,363:INFO:Starting cross validation
2025-05-13 15:51:33,364:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:37,456:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:37,607:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:38,921:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:39,010:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:42,459:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:42,526:INFO:Calculating mean and std
2025-05-13 15:51:42,528:INFO:Creating metrics dataframe
2025-05-13 15:51:42,531:INFO:Uploading results into container
2025-05-13 15:51:42,531:INFO:Uploading model into container now
2025-05-13 15:51:42,532:INFO:_master_model_container: 1
2025-05-13 15:51:42,532:INFO:_display_container: 2
2025-05-13 15:51:42,532:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-13 15:51:42,532:INFO:create_model() successfully completed......................................
2025-05-13 15:51:42,610:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:42,610:INFO:Creating metrics dataframe
2025-05-13 15:51:42,613:INFO:Initializing K Neighbors Classifier
2025-05-13 15:51:42,613:INFO:Total runtime is 0.15447012186050413 minutes
2025-05-13 15:51:42,614:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:42,614:INFO:Initializing create_model()
2025-05-13 15:51:42,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:42,614:INFO:Checking exceptions
2025-05-13 15:51:42,614:INFO:Importing libraries
2025-05-13 15:51:42,614:INFO:Copying training dataset
2025-05-13 15:51:42,626:INFO:Defining folds
2025-05-13 15:51:42,626:INFO:Declaring metric variables
2025-05-13 15:51:42,627:INFO:Importing untrained model
2025-05-13 15:51:42,628:INFO:K Neighbors Classifier Imported successfully
2025-05-13 15:51:42,631:INFO:Starting cross validation
2025-05-13 15:51:42,633:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:48,117:INFO:Calculating mean and std
2025-05-13 15:51:48,118:INFO:Creating metrics dataframe
2025-05-13 15:51:48,119:INFO:Uploading results into container
2025-05-13 15:51:48,119:INFO:Uploading model into container now
2025-05-13 15:51:48,120:INFO:_master_model_container: 2
2025-05-13 15:51:48,120:INFO:_display_container: 2
2025-05-13 15:51:48,120:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-13 15:51:48,120:INFO:create_model() successfully completed......................................
2025-05-13 15:51:48,178:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:48,178:INFO:Creating metrics dataframe
2025-05-13 15:51:48,182:INFO:Initializing Naive Bayes
2025-05-13 15:51:48,182:INFO:Total runtime is 0.24729955196380612 minutes
2025-05-13 15:51:48,184:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:48,184:INFO:Initializing create_model()
2025-05-13 15:51:48,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:48,184:INFO:Checking exceptions
2025-05-13 15:51:48,184:INFO:Importing libraries
2025-05-13 15:51:48,184:INFO:Copying training dataset
2025-05-13 15:51:48,202:INFO:Defining folds
2025-05-13 15:51:48,203:INFO:Declaring metric variables
2025-05-13 15:51:48,204:INFO:Importing untrained model
2025-05-13 15:51:48,205:INFO:Naive Bayes Imported successfully
2025-05-13 15:51:48,208:INFO:Starting cross validation
2025-05-13 15:51:48,209:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:49,622:INFO:Calculating mean and std
2025-05-13 15:51:49,624:INFO:Creating metrics dataframe
2025-05-13 15:51:49,628:INFO:Uploading results into container
2025-05-13 15:51:49,629:INFO:Uploading model into container now
2025-05-13 15:51:49,629:INFO:_master_model_container: 3
2025-05-13 15:51:49,629:INFO:_display_container: 2
2025-05-13 15:51:49,630:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-13 15:51:49,630:INFO:create_model() successfully completed......................................
2025-05-13 15:51:49,734:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:49,735:INFO:Creating metrics dataframe
2025-05-13 15:51:49,738:INFO:Initializing Decision Tree Classifier
2025-05-13 15:51:49,738:INFO:Total runtime is 0.27322769959767657 minutes
2025-05-13 15:51:49,739:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:49,740:INFO:Initializing create_model()
2025-05-13 15:51:49,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:49,740:INFO:Checking exceptions
2025-05-13 15:51:49,740:INFO:Importing libraries
2025-05-13 15:51:49,740:INFO:Copying training dataset
2025-05-13 15:51:49,760:INFO:Defining folds
2025-05-13 15:51:49,760:INFO:Declaring metric variables
2025-05-13 15:51:49,761:INFO:Importing untrained model
2025-05-13 15:51:49,763:INFO:Decision Tree Classifier Imported successfully
2025-05-13 15:51:49,766:INFO:Starting cross validation
2025-05-13 15:51:49,768:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:51,706:INFO:Calculating mean and std
2025-05-13 15:51:51,707:INFO:Creating metrics dataframe
2025-05-13 15:51:51,708:INFO:Uploading results into container
2025-05-13 15:51:51,708:INFO:Uploading model into container now
2025-05-13 15:51:51,709:INFO:_master_model_container: 4
2025-05-13 15:51:51,709:INFO:_display_container: 2
2025-05-13 15:51:51,709:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-13 15:51:51,709:INFO:create_model() successfully completed......................................
2025-05-13 15:51:51,805:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:51,805:INFO:Creating metrics dataframe
2025-05-13 15:51:51,809:INFO:Initializing SVM - Linear Kernel
2025-05-13 15:51:51,809:INFO:Total runtime is 0.30773888429005936 minutes
2025-05-13 15:51:51,811:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:51,811:INFO:Initializing create_model()
2025-05-13 15:51:51,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:51,811:INFO:Checking exceptions
2025-05-13 15:51:51,811:INFO:Importing libraries
2025-05-13 15:51:51,811:INFO:Copying training dataset
2025-05-13 15:51:51,830:INFO:Defining folds
2025-05-13 15:51:51,831:INFO:Declaring metric variables
2025-05-13 15:51:51,834:INFO:Importing untrained model
2025-05-13 15:51:51,838:INFO:SVM - Linear Kernel Imported successfully
2025-05-13 15:51:51,842:INFO:Starting cross validation
2025-05-13 15:51:51,853:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:56,188:INFO:Calculating mean and std
2025-05-13 15:51:56,190:INFO:Creating metrics dataframe
2025-05-13 15:51:56,192:INFO:Uploading results into container
2025-05-13 15:51:56,192:INFO:Uploading model into container now
2025-05-13 15:51:56,192:INFO:_master_model_container: 5
2025-05-13 15:51:56,192:INFO:_display_container: 2
2025-05-13 15:51:56,193:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-13 15:51:56,193:INFO:create_model() successfully completed......................................
2025-05-13 15:51:56,255:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:56,255:INFO:Creating metrics dataframe
2025-05-13 15:51:56,258:INFO:Initializing Ridge Classifier
2025-05-13 15:51:56,258:INFO:Total runtime is 0.3818989992141723 minutes
2025-05-13 15:51:56,260:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:56,260:INFO:Initializing create_model()
2025-05-13 15:51:56,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:56,260:INFO:Checking exceptions
2025-05-13 15:51:56,260:INFO:Importing libraries
2025-05-13 15:51:56,260:INFO:Copying training dataset
2025-05-13 15:51:56,270:INFO:Defining folds
2025-05-13 15:51:56,270:INFO:Declaring metric variables
2025-05-13 15:51:56,271:INFO:Importing untrained model
2025-05-13 15:51:56,272:INFO:Ridge Classifier Imported successfully
2025-05-13 15:51:56,275:INFO:Starting cross validation
2025-05-13 15:51:56,276:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:57,793:INFO:Calculating mean and std
2025-05-13 15:51:57,794:INFO:Creating metrics dataframe
2025-05-13 15:51:57,795:INFO:Uploading results into container
2025-05-13 15:51:57,795:INFO:Uploading model into container now
2025-05-13 15:51:57,795:INFO:_master_model_container: 6
2025-05-13 15:51:57,795:INFO:_display_container: 2
2025-05-13 15:51:57,796:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-13 15:51:57,796:INFO:create_model() successfully completed......................................
2025-05-13 15:51:57,852:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:57,852:INFO:Creating metrics dataframe
2025-05-13 15:51:57,856:INFO:Initializing Random Forest Classifier
2025-05-13 15:51:57,856:INFO:Total runtime is 0.4085217038790384 minutes
2025-05-13 15:51:57,857:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:57,857:INFO:Initializing create_model()
2025-05-13 15:51:57,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:57,857:INFO:Checking exceptions
2025-05-13 15:51:57,857:INFO:Importing libraries
2025-05-13 15:51:57,857:INFO:Copying training dataset
2025-05-13 15:51:57,868:INFO:Defining folds
2025-05-13 15:51:57,868:INFO:Declaring metric variables
2025-05-13 15:51:57,869:INFO:Importing untrained model
2025-05-13 15:51:57,870:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:51:57,873:INFO:Starting cross validation
2025-05-13 15:51:57,874:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:04,077:INFO:Calculating mean and std
2025-05-13 15:52:04,081:INFO:Creating metrics dataframe
2025-05-13 15:52:04,089:INFO:Uploading results into container
2025-05-13 15:52:04,089:INFO:Uploading model into container now
2025-05-13 15:52:04,090:INFO:_master_model_container: 7
2025-05-13 15:52:04,090:INFO:_display_container: 2
2025-05-13 15:52:04,091:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:52:04,092:INFO:create_model() successfully completed......................................
2025-05-13 15:52:04,203:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:04,203:INFO:Creating metrics dataframe
2025-05-13 15:52:04,207:INFO:Initializing Quadratic Discriminant Analysis
2025-05-13 15:52:04,208:INFO:Total runtime is 0.5143866697947184 minutes
2025-05-13 15:52:04,209:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:04,209:INFO:Initializing create_model()
2025-05-13 15:52:04,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:04,210:INFO:Checking exceptions
2025-05-13 15:52:04,210:INFO:Importing libraries
2025-05-13 15:52:04,210:INFO:Copying training dataset
2025-05-13 15:52:04,222:INFO:Defining folds
2025-05-13 15:52:04,222:INFO:Declaring metric variables
2025-05-13 15:52:04,224:INFO:Importing untrained model
2025-05-13 15:52:04,226:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-13 15:52:04,228:INFO:Starting cross validation
2025-05-13 15:52:04,232:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:05,555:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,573:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,586:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,639:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,680:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,689:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:05,733:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:05,770:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:05,782:INFO:Calculating mean and std
2025-05-13 15:52:05,783:INFO:Creating metrics dataframe
2025-05-13 15:52:05,784:INFO:Uploading results into container
2025-05-13 15:52:05,784:INFO:Uploading model into container now
2025-05-13 15:52:05,784:INFO:_master_model_container: 8
2025-05-13 15:52:05,784:INFO:_display_container: 2
2025-05-13 15:52:05,785:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-13 15:52:05,785:INFO:create_model() successfully completed......................................
2025-05-13 15:52:05,838:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:05,838:INFO:Creating metrics dataframe
2025-05-13 15:52:05,842:INFO:Initializing Ada Boost Classifier
2025-05-13 15:52:05,842:INFO:Total runtime is 0.5416210691134135 minutes
2025-05-13 15:52:05,843:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:05,843:INFO:Initializing create_model()
2025-05-13 15:52:05,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:05,843:INFO:Checking exceptions
2025-05-13 15:52:05,843:INFO:Importing libraries
2025-05-13 15:52:05,843:INFO:Copying training dataset
2025-05-13 15:52:05,852:INFO:Defining folds
2025-05-13 15:52:05,852:INFO:Declaring metric variables
2025-05-13 15:52:05,854:INFO:Importing untrained model
2025-05-13 15:52:05,855:INFO:Ada Boost Classifier Imported successfully
2025-05-13 15:52:05,857:INFO:Starting cross validation
2025-05-13 15:52:05,861:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:07,058:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:07,086:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:07,100:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:07,111:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:07,116:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:10,046:INFO:Calculating mean and std
2025-05-13 15:52:10,046:INFO:Creating metrics dataframe
2025-05-13 15:52:10,047:INFO:Uploading results into container
2025-05-13 15:52:10,047:INFO:Uploading model into container now
2025-05-13 15:52:10,048:INFO:_master_model_container: 9
2025-05-13 15:52:10,048:INFO:_display_container: 2
2025-05-13 15:52:10,048:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-13 15:52:10,048:INFO:create_model() successfully completed......................................
2025-05-13 15:52:10,100:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:10,100:INFO:Creating metrics dataframe
2025-05-13 15:52:10,104:INFO:Initializing Gradient Boosting Classifier
2025-05-13 15:52:10,104:INFO:Total runtime is 0.6126559217770894 minutes
2025-05-13 15:52:10,105:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:10,105:INFO:Initializing create_model()
2025-05-13 15:52:10,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:10,105:INFO:Checking exceptions
2025-05-13 15:52:10,105:INFO:Importing libraries
2025-05-13 15:52:10,106:INFO:Copying training dataset
2025-05-13 15:52:10,115:INFO:Defining folds
2025-05-13 15:52:10,116:INFO:Declaring metric variables
2025-05-13 15:52:10,117:INFO:Importing untrained model
2025-05-13 15:52:10,118:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:52:10,120:INFO:Starting cross validation
2025-05-13 15:52:10,122:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:25,448:INFO:Calculating mean and std
2025-05-13 15:52:25,451:INFO:Creating metrics dataframe
2025-05-13 15:52:25,454:INFO:Uploading results into container
2025-05-13 15:52:25,454:INFO:Uploading model into container now
2025-05-13 15:52:25,455:INFO:_master_model_container: 10
2025-05-13 15:52:25,455:INFO:_display_container: 2
2025-05-13 15:52:25,457:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:52:25,457:INFO:create_model() successfully completed......................................
2025-05-13 15:52:25,556:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:25,556:INFO:Creating metrics dataframe
2025-05-13 15:52:25,560:INFO:Initializing Linear Discriminant Analysis
2025-05-13 15:52:25,560:INFO:Total runtime is 0.8702641169230143 minutes
2025-05-13 15:52:25,562:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:25,562:INFO:Initializing create_model()
2025-05-13 15:52:25,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:25,562:INFO:Checking exceptions
2025-05-13 15:52:25,562:INFO:Importing libraries
2025-05-13 15:52:25,562:INFO:Copying training dataset
2025-05-13 15:52:25,580:INFO:Defining folds
2025-05-13 15:52:25,580:INFO:Declaring metric variables
2025-05-13 15:52:25,581:INFO:Importing untrained model
2025-05-13 15:52:25,583:INFO:Linear Discriminant Analysis Imported successfully
2025-05-13 15:52:25,585:INFO:Starting cross validation
2025-05-13 15:52:25,587:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:27,094:INFO:Calculating mean and std
2025-05-13 15:52:27,095:INFO:Creating metrics dataframe
2025-05-13 15:52:27,096:INFO:Uploading results into container
2025-05-13 15:52:27,096:INFO:Uploading model into container now
2025-05-13 15:52:27,096:INFO:_master_model_container: 11
2025-05-13 15:52:27,096:INFO:_display_container: 2
2025-05-13 15:52:27,096:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-13 15:52:27,096:INFO:create_model() successfully completed......................................
2025-05-13 15:52:27,143:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:27,144:INFO:Creating metrics dataframe
2025-05-13 15:52:27,148:INFO:Initializing Extra Trees Classifier
2025-05-13 15:52:27,148:INFO:Total runtime is 0.8967252651850383 minutes
2025-05-13 15:52:27,149:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:27,149:INFO:Initializing create_model()
2025-05-13 15:52:27,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:27,149:INFO:Checking exceptions
2025-05-13 15:52:27,149:INFO:Importing libraries
2025-05-13 15:52:27,149:INFO:Copying training dataset
2025-05-13 15:52:27,158:INFO:Defining folds
2025-05-13 15:52:27,158:INFO:Declaring metric variables
2025-05-13 15:52:27,159:INFO:Importing untrained model
2025-05-13 15:52:27,161:INFO:Extra Trees Classifier Imported successfully
2025-05-13 15:52:27,162:INFO:Starting cross validation
2025-05-13 15:52:27,164:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:32,596:INFO:Calculating mean and std
2025-05-13 15:52:32,600:INFO:Creating metrics dataframe
2025-05-13 15:52:32,604:INFO:Uploading results into container
2025-05-13 15:52:32,605:INFO:Uploading model into container now
2025-05-13 15:52:32,608:INFO:_master_model_container: 12
2025-05-13 15:52:32,608:INFO:_display_container: 2
2025-05-13 15:52:32,611:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-13 15:52:32,611:INFO:create_model() successfully completed......................................
2025-05-13 15:52:32,732:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:32,732:INFO:Creating metrics dataframe
2025-05-13 15:52:32,736:INFO:Initializing Light Gradient Boosting Machine
2025-05-13 15:52:32,737:INFO:Total runtime is 0.9898682355880737 minutes
2025-05-13 15:52:32,738:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:32,738:INFO:Initializing create_model()
2025-05-13 15:52:32,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:32,738:INFO:Checking exceptions
2025-05-13 15:52:32,738:INFO:Importing libraries
2025-05-13 15:52:32,738:INFO:Copying training dataset
2025-05-13 15:52:32,754:INFO:Defining folds
2025-05-13 15:52:32,754:INFO:Declaring metric variables
2025-05-13 15:52:32,756:INFO:Importing untrained model
2025-05-13 15:52:32,758:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:52:32,761:INFO:Starting cross validation
2025-05-13 15:52:32,763:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:37,434:INFO:Calculating mean and std
2025-05-13 15:52:37,435:INFO:Creating metrics dataframe
2025-05-13 15:52:37,435:INFO:Uploading results into container
2025-05-13 15:52:37,436:INFO:Uploading model into container now
2025-05-13 15:52:37,436:INFO:_master_model_container: 13
2025-05-13 15:52:37,436:INFO:_display_container: 2
2025-05-13 15:52:37,436:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:52:37,436:INFO:create_model() successfully completed......................................
2025-05-13 15:52:37,487:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:37,487:INFO:Creating metrics dataframe
2025-05-13 15:52:37,491:INFO:Initializing Dummy Classifier
2025-05-13 15:52:37,491:INFO:Total runtime is 1.0691153526306152 minutes
2025-05-13 15:52:37,493:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:37,493:INFO:Initializing create_model()
2025-05-13 15:52:37,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:37,493:INFO:Checking exceptions
2025-05-13 15:52:37,493:INFO:Importing libraries
2025-05-13 15:52:37,493:INFO:Copying training dataset
2025-05-13 15:52:37,503:INFO:Defining folds
2025-05-13 15:52:37,503:INFO:Declaring metric variables
2025-05-13 15:52:37,504:INFO:Importing untrained model
2025-05-13 15:52:37,505:INFO:Dummy Classifier Imported successfully
2025-05-13 15:52:37,508:INFO:Starting cross validation
2025-05-13 15:52:37,509:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:38,748:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,813:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,824:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,851:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,854:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,870:INFO:Calculating mean and std
2025-05-13 15:52:38,871:INFO:Creating metrics dataframe
2025-05-13 15:52:38,873:INFO:Uploading results into container
2025-05-13 15:52:38,873:INFO:Uploading model into container now
2025-05-13 15:52:38,873:INFO:_master_model_container: 14
2025-05-13 15:52:38,873:INFO:_display_container: 2
2025-05-13 15:52:38,874:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-13 15:52:38,874:INFO:create_model() successfully completed......................................
2025-05-13 15:52:38,938:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:38,938:INFO:Creating metrics dataframe
2025-05-13 15:52:38,943:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-13 15:52:38,947:INFO:Initializing create_model()
2025-05-13 15:52:38,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:38,947:INFO:Checking exceptions
2025-05-13 15:52:38,948:INFO:Importing libraries
2025-05-13 15:52:38,948:INFO:Copying training dataset
2025-05-13 15:52:38,958:INFO:Defining folds
2025-05-13 15:52:38,958:INFO:Declaring metric variables
2025-05-13 15:52:38,958:INFO:Importing untrained model
2025-05-13 15:52:38,958:INFO:Declaring custom model
2025-05-13 15:52:38,958:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:52:38,960:INFO:Cross validation set to False
2025-05-13 15:52:38,960:INFO:Fitting Model
2025-05-13 15:52:56,429:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:52:56,430:INFO:create_model() successfully completed......................................
2025-05-13 15:52:56,502:INFO:Initializing create_model()
2025-05-13 15:52:56,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:56,502:INFO:Checking exceptions
2025-05-13 15:52:56,503:INFO:Importing libraries
2025-05-13 15:52:56,503:INFO:Copying training dataset
2025-05-13 15:52:56,513:INFO:Defining folds
2025-05-13 15:52:56,513:INFO:Declaring metric variables
2025-05-13 15:52:56,513:INFO:Importing untrained model
2025-05-13 15:52:56,514:INFO:Declaring custom model
2025-05-13 15:52:56,514:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:52:56,516:INFO:Cross validation set to False
2025-05-13 15:52:56,516:INFO:Fitting Model
2025-05-13 15:52:57,743:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-05-13 15:52:57,743:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-13 15:52:57,754:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005956 seconds.
2025-05-13 15:52:57,754:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-13 15:52:57,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-13 15:52:57,755:INFO:[LightGBM] [Info] Total Bins 9180
2025-05-13 15:52:57,755:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 36
2025-05-13 15:52:57,755:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-13 15:52:58,537:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:52:58,537:INFO:create_model() successfully completed......................................
2025-05-13 15:52:58,597:INFO:Initializing create_model()
2025-05-13 15:52:58,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:58,597:INFO:Checking exceptions
2025-05-13 15:52:58,598:INFO:Importing libraries
2025-05-13 15:52:58,598:INFO:Copying training dataset
2025-05-13 15:52:58,607:INFO:Defining folds
2025-05-13 15:52:58,607:INFO:Declaring metric variables
2025-05-13 15:52:58,607:INFO:Importing untrained model
2025-05-13 15:52:58,607:INFO:Declaring custom model
2025-05-13 15:52:58,608:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:52:58,609:INFO:Cross validation set to False
2025-05-13 15:52:58,609:INFO:Fitting Model
2025-05-13 15:53:01,182:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:53:01,182:INFO:create_model() successfully completed......................................
2025-05-13 15:53:01,254:INFO:_master_model_container: 14
2025-05-13 15:53:01,254:INFO:_display_container: 2
2025-05-13 15:53:01,255:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-13 15:53:01,255:INFO:compare_models() successfully completed......................................
2025-05-13 15:53:01,274:INFO:Initializing evaluate_model()
2025-05-13 15:53:01,274:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:53:01,283:INFO:Initializing plot_model()
2025-05-13 15:53:01,283:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:53:01,283:INFO:Checking exceptions
2025-05-13 15:53:01,288:INFO:Preloading libraries
2025-05-13 15:53:01,291:INFO:Copying training dataset
2025-05-13 15:53:01,291:INFO:Plot type: pipeline
2025-05-13 15:53:01,362:INFO:Visual Rendered Successfully
2025-05-13 15:53:01,418:INFO:plot_model() successfully completed......................................
2025-05-13 15:53:01,419:INFO:Initializing tune_model()
2025-05-13 15:53:01,419:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-13 15:53:01,420:INFO:Checking exceptions
2025-05-13 15:53:01,429:INFO:Copying training dataset
2025-05-13 15:53:01,436:INFO:Checking base model
2025-05-13 15:53:01,436:INFO:Base model : Gradient Boosting Classifier
2025-05-13 15:53:01,438:INFO:Declaring metric variables
2025-05-13 15:53:01,439:INFO:Defining Hyperparameters
2025-05-13 15:53:01,494:INFO:Tuning with n_jobs=-1
2025-05-13 15:53:01,494:INFO:Initializing RandomizedSearchCV
2025-05-13 15:53:45,641:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-13 15:53:45,644:INFO:Hyperparameter search completed
2025-05-13 15:53:45,646:INFO:SubProcess create_model() called ==================================
2025-05-13 15:53:45,647:INFO:Initializing create_model()
2025-05-13 15:53:45,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32feeeed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-13 15:53:45,647:INFO:Checking exceptions
2025-05-13 15:53:45,647:INFO:Importing libraries
2025-05-13 15:53:45,648:INFO:Copying training dataset
2025-05-13 15:53:45,665:INFO:Defining folds
2025-05-13 15:53:45,665:INFO:Declaring metric variables
2025-05-13 15:53:45,671:INFO:Importing untrained model
2025-05-13 15:53:45,671:INFO:Declaring custom model
2025-05-13 15:53:45,674:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:53:45,677:INFO:Starting cross validation
2025-05-13 15:53:45,682:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:53:56,758:INFO:Calculating mean and std
2025-05-13 15:53:56,759:INFO:Creating metrics dataframe
2025-05-13 15:53:56,762:INFO:Finalizing model
2025-05-13 15:54:08,504:INFO:Uploading results into container
2025-05-13 15:54:08,506:INFO:Uploading model into container now
2025-05-13 15:54:08,507:INFO:_master_model_container: 15
2025-05-13 15:54:08,507:INFO:_display_container: 3
2025-05-13 15:54:08,508:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:54:08,508:INFO:create_model() successfully completed......................................
2025-05-13 15:54:08,596:INFO:SubProcess create_model() end ==================================
2025-05-13 15:54:08,596:INFO:choose_better activated
2025-05-13 15:54:08,598:INFO:SubProcess create_model() called ==================================
2025-05-13 15:54:08,598:INFO:Initializing create_model()
2025-05-13 15:54:08,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:54:08,598:INFO:Checking exceptions
2025-05-13 15:54:08,599:INFO:Importing libraries
2025-05-13 15:54:08,599:INFO:Copying training dataset
2025-05-13 15:54:08,608:INFO:Defining folds
2025-05-13 15:54:08,608:INFO:Declaring metric variables
2025-05-13 15:54:08,608:INFO:Importing untrained model
2025-05-13 15:54:08,609:INFO:Declaring custom model
2025-05-13 15:54:08,609:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:54:08,609:INFO:Starting cross validation
2025-05-13 15:54:08,610:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:54:24,304:INFO:Calculating mean and std
2025-05-13 15:54:24,305:INFO:Creating metrics dataframe
2025-05-13 15:54:24,309:INFO:Finalizing model
2025-05-13 15:54:42,775:INFO:Uploading results into container
2025-05-13 15:54:42,776:INFO:Uploading model into container now
2025-05-13 15:54:42,776:INFO:_master_model_container: 16
2025-05-13 15:54:42,776:INFO:_display_container: 4
2025-05-13 15:54:42,777:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:54:42,777:INFO:create_model() successfully completed......................................
2025-05-13 15:54:42,888:INFO:SubProcess create_model() end ==================================
2025-05-13 15:54:42,889:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4636
2025-05-13 15:54:42,889:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4897
2025-05-13 15:54:42,889:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-13 15:54:42,889:INFO:choose_better completed
2025-05-13 15:54:42,894:INFO:_master_model_container: 16
2025-05-13 15:54:42,894:INFO:_display_container: 3
2025-05-13 15:54:42,894:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:54:42,894:INFO:tune_model() successfully completed......................................
2025-05-13 15:54:42,951:INFO:Initializing evaluate_model()
2025-05-13 15:54:42,951:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:54:42,964:INFO:Initializing plot_model()
2025-05-13 15:54:42,965:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:54:42,965:INFO:Checking exceptions
2025-05-13 15:54:42,971:INFO:Preloading libraries
2025-05-13 15:54:42,984:INFO:Copying training dataset
2025-05-13 15:54:42,984:INFO:Plot type: pipeline
2025-05-13 15:54:43,044:INFO:Visual Rendered Successfully
2025-05-13 15:54:43,096:INFO:plot_model() successfully completed......................................
2025-05-13 15:54:43,098:INFO:Initializing interpret_model()
2025-05-13 15:54:43,098:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-13 15:54:43,098:INFO:Checking exceptions
2025-05-13 15:54:43,099:INFO:Soft dependency imported: shap: 0.47.2
2025-05-13 15:54:43,099:INFO:Initializing finalize_model()
2025-05-13 15:54:43,099:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-13 15:54:43,099:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:54:43,103:INFO:Initializing create_model()
2025-05-13 15:54:43,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:54:43,103:INFO:Checking exceptions
2025-05-13 15:54:43,104:INFO:Importing libraries
2025-05-13 15:54:43,104:INFO:Copying training dataset
2025-05-13 15:54:43,104:INFO:Defining folds
2025-05-13 15:54:43,104:INFO:Declaring metric variables
2025-05-13 15:54:43,104:INFO:Importing untrained model
2025-05-13 15:54:43,104:INFO:Declaring custom model
2025-05-13 15:54:43,105:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:54:43,106:INFO:Cross validation set to False
2025-05-13 15:54:43,106:INFO:Fitting Model
2025-05-13 15:54:59,325:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:54:59,326:INFO:create_model() successfully completed......................................
2025-05-13 15:54:59,373:INFO:_master_model_container: 16
2025-05-13 15:54:59,373:INFO:_display_container: 3
2025-05-13 15:54:59,392:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:54:59,392:INFO:finalize_model() successfully completed......................................
2025-05-13 15:54:59,473:INFO:Initializing save_model()
2025-05-13 15:54:59,473:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-13 15:54:59,473:INFO:Adding model into prep_pipe
2025-05-13 15:54:59,473:WARNING:Only Model saved as it was a pipeline.
2025-05-13 15:54:59,497:INFO:final_cancer_model.pkl saved in current working directory
2025-05-13 15:54:59,516:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:54:59,516:INFO:save_model() successfully completed......................................
2025-05-13 15:54:59,584:INFO:Initializing predict_model()
2025-05-13 15:54:59,584:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x32627cb80>)
2025-05-13 15:54:59,584:INFO:Checking exceptions
2025-05-13 15:54:59,584:INFO:Preloading libraries
2025-05-13 15:54:59,585:INFO:Set up data.
2025-05-13 15:54:59,602:INFO:Set up index.
2025-05-13 15:55:00,476:INFO:Initializing plot_model()
2025-05-13 15:55:00,476:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:55:00,476:INFO:Checking exceptions
2025-05-13 15:55:00,481:INFO:Preloading libraries
2025-05-13 15:55:00,485:INFO:Copying training dataset
2025-05-13 15:55:00,485:INFO:Plot type: confusion_matrix
2025-05-13 15:55:00,717:INFO:Fitting Model
2025-05-13 15:55:00,717:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:55:00,718:INFO:Scoring test/hold-out set
2025-05-13 15:55:00,791:INFO:Visual Rendered Successfully
2025-05-13 15:55:00,840:INFO:plot_model() successfully completed......................................
2025-05-13 15:55:00,840:INFO:Initializing plot_model()
2025-05-13 15:55:00,840:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:55:00,840:INFO:Checking exceptions
2025-05-13 15:55:00,844:INFO:Preloading libraries
2025-05-13 15:55:00,848:INFO:Copying training dataset
2025-05-13 15:55:00,848:INFO:Plot type: auc
2025-05-13 15:55:01,085:INFO:Fitting Model
2025-05-13 15:55:01,086:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:55:01,087:INFO:Scoring test/hold-out set
2025-05-13 15:55:01,202:INFO:Visual Rendered Successfully
2025-05-13 15:55:01,252:INFO:plot_model() successfully completed......................................
2025-05-13 15:55:01,252:INFO:Initializing plot_model()
2025-05-13 15:55:01,252:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:55:01,252:INFO:Checking exceptions
2025-05-13 15:55:01,257:INFO:Preloading libraries
2025-05-13 15:55:01,260:INFO:Copying training dataset
2025-05-13 15:55:01,260:INFO:Plot type: feature
2025-05-13 15:55:01,261:WARNING:No coef_ found. Trying feature_importances_
2025-05-13 15:55:01,335:INFO:Visual Rendered Successfully
2025-05-13 15:55:01,394:INFO:plot_model() successfully completed......................................
2025-05-13 15:55:01,394:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:189: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  age_cancer_ratio = train_df_processed.groupby('Age_Group')['Cancer'].mean() * 100

2025-05-13 15:55:01,413:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 45824 (\N{HANGUL SYLLABLE DAE}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,414:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 51060 (\N{HANGUL SYLLABLE I}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,414:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 49345 (\N{HANGUL SYLLABLE SANG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,415:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 50672 (\N{HANGUL SYLLABLE YEON}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,415:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 47161 (\N{HANGUL SYLLABLE RYEONG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 50516 (\N{HANGUL SYLLABLE AM}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 48156 (\N{HANGUL SYLLABLE BAL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 49373 (\N{HANGUL SYLLABLE SAENG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 48708 (\N{HANGUL SYLLABLE BI}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 50984 (\N{HANGUL SYLLABLE YUL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,419:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50516 (\N{HANGUL SYLLABLE AM}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48156 (\N{HANGUL SYLLABLE BAL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49373 (\N{HANGUL SYLLABLE SAENG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48708 (\N{HANGUL SYLLABLE BI}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50984 (\N{HANGUL SYLLABLE YUL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50672 (\N{HANGUL SYLLABLE YEON}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47161 (\N{HANGUL SYLLABLE RYEONG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 45824 (\N{HANGUL SYLLABLE DAE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,443:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51060 (\N{HANGUL SYLLABLE I}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,443:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49345 (\N{HANGUL SYLLABLE SANG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

