2025-05-13 15:12:46,822:INFO:PyCaret ClassificationExperiment
2025-05-13 15:12:46,822:INFO:Logging name: clf-default-name
2025-05-13 15:12:46,822:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-13 15:12:46,822:INFO:version 3.3.2
2025-05-13 15:12:46,822:INFO:Initializing setup()
2025-05-13 15:12:46,822:INFO:self.USI: 77f9
2025-05-13 15:12:46,822:INFO:self._variable_keys: {'data', 'memory', 'gpu_param', '_available_plots', 'idx', 'html_param', 'gpu_n_jobs_param', 'fold_generator', 'fold_groups_param', 'logging_param', 'y', 'exp_id', 'X_train', 'is_multiclass', '_ml_usecase', 'X_test', 'y_test', 'y_train', 'exp_name_log', 'X', 'USI', 'fix_imbalance', 'fold_shuffle_param', 'log_plots_param', 'target_param', 'seed', 'pipeline', 'n_jobs_param'}
2025-05-13 15:12:46,822:INFO:Checking environment
2025-05-13 15:12:46,822:INFO:python_version: 3.11.0
2025-05-13 15:12:46,822:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-13 15:12:46,822:INFO:machine: arm64
2025-05-13 15:12:46,822:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:12:46,822:INFO:Memory: svmem(total=17179869184, available=4077387776, percent=76.3, used=6680018944, free=60080128, active=4042293248, inactive=4012113920, wired=2637725696)
2025-05-13 15:12:46,822:INFO:Physical Core: 12
2025-05-13 15:12:46,822:INFO:Logical Core: 12
2025-05-13 15:12:46,822:INFO:Checking libraries
2025-05-13 15:12:46,822:INFO:System:
2025-05-13 15:12:46,822:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-13 15:12:46,822:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-13 15:12:46,822:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:12:46,822:INFO:PyCaret required dependencies:
2025-05-13 15:12:46,823:INFO:                 pip: 22.3
2025-05-13 15:12:46,823:INFO:          setuptools: 65.5.0
2025-05-13 15:12:46,823:INFO:             pycaret: 3.3.2
2025-05-13 15:12:46,823:INFO:             IPython: 9.2.0
2025-05-13 15:12:46,823:INFO:          ipywidgets: 8.1.7
2025-05-13 15:12:46,823:INFO:                tqdm: 4.67.1
2025-05-13 15:12:46,823:INFO:               numpy: 1.26.4
2025-05-13 15:12:46,823:INFO:              pandas: 2.1.4
2025-05-13 15:12:46,823:INFO:              jinja2: 3.1.6
2025-05-13 15:12:46,823:INFO:               scipy: 1.11.4
2025-05-13 15:12:46,823:INFO:              joblib: 1.3.2
2025-05-13 15:12:46,823:INFO:             sklearn: 1.4.2
2025-05-13 15:12:46,823:INFO:                pyod: 2.0.5
2025-05-13 15:12:46,823:INFO:            imblearn: 0.13.0
2025-05-13 15:12:46,823:INFO:   category_encoders: 2.7.0
2025-05-13 15:12:46,823:INFO:            lightgbm: 4.6.0
2025-05-13 15:12:46,823:INFO:               numba: 0.61.2
2025-05-13 15:12:46,823:INFO:            requests: 2.32.3
2025-05-13 15:12:46,823:INFO:          matplotlib: 3.7.5
2025-05-13 15:12:46,823:INFO:          scikitplot: 0.3.7
2025-05-13 15:12:46,823:INFO:         yellowbrick: 1.5
2025-05-13 15:12:46,823:INFO:              plotly: 5.24.1
2025-05-13 15:12:46,823:INFO:    plotly-resampler: Not installed
2025-05-13 15:12:46,823:INFO:             kaleido: 0.2.1
2025-05-13 15:12:46,823:INFO:           schemdraw: 0.15
2025-05-13 15:12:46,823:INFO:         statsmodels: 0.14.4
2025-05-13 15:12:46,823:INFO:              sktime: 0.26.0
2025-05-13 15:12:46,823:INFO:               tbats: 1.1.3
2025-05-13 15:12:46,823:INFO:            pmdarima: 2.0.4
2025-05-13 15:12:46,823:INFO:              psutil: 7.0.0
2025-05-13 15:12:46,823:INFO:          markupsafe: 3.0.2
2025-05-13 15:12:46,823:INFO:             pickle5: Not installed
2025-05-13 15:12:46,823:INFO:         cloudpickle: 3.1.1
2025-05-13 15:12:46,823:INFO:         deprecation: 2.1.0
2025-05-13 15:12:46,823:INFO:              xxhash: 3.5.0
2025-05-13 15:12:46,823:INFO:           wurlitzer: 3.1.1
2025-05-13 15:12:46,823:INFO:PyCaret optional dependencies:
2025-05-13 15:12:46,823:INFO:                shap: 0.47.2
2025-05-13 15:12:46,823:INFO:           interpret: Not installed
2025-05-13 15:12:46,823:INFO:                umap: Not installed
2025-05-13 15:12:46,823:INFO:     ydata_profiling: Not installed
2025-05-13 15:12:46,823:INFO:  explainerdashboard: Not installed
2025-05-13 15:12:46,823:INFO:             autoviz: Not installed
2025-05-13 15:12:46,823:INFO:           fairlearn: Not installed
2025-05-13 15:12:46,823:INFO:          deepchecks: Not installed
2025-05-13 15:12:46,823:INFO:             xgboost: Not installed
2025-05-13 15:12:46,823:INFO:            catboost: Not installed
2025-05-13 15:12:46,823:INFO:              kmodes: Not installed
2025-05-13 15:12:46,823:INFO:             mlxtend: Not installed
2025-05-13 15:12:46,823:INFO:       statsforecast: Not installed
2025-05-13 15:12:46,823:INFO:        tune_sklearn: Not installed
2025-05-13 15:12:46,823:INFO:                 ray: Not installed
2025-05-13 15:12:46,823:INFO:            hyperopt: Not installed
2025-05-13 15:12:46,823:INFO:              optuna: 4.3.0
2025-05-13 15:12:46,823:INFO:               skopt: Not installed
2025-05-13 15:12:46,823:INFO:              mlflow: Not installed
2025-05-13 15:12:46,823:INFO:              gradio: Not installed
2025-05-13 15:12:46,823:INFO:             fastapi: Not installed
2025-05-13 15:12:46,823:INFO:             uvicorn: Not installed
2025-05-13 15:12:46,823:INFO:              m2cgen: Not installed
2025-05-13 15:12:46,823:INFO:           evidently: Not installed
2025-05-13 15:12:46,823:INFO:               fugue: Not installed
2025-05-13 15:12:46,823:INFO:           streamlit: Not installed
2025-05-13 15:12:46,823:INFO:             prophet: Not installed
2025-05-13 15:12:46,823:INFO:None
2025-05-13 15:12:46,823:INFO:Set up data.
2025-05-13 15:12:46,851:INFO:Set up folding strategy.
2025-05-13 15:12:46,851:INFO:Set up train/test split.
2025-05-13 15:12:46,864:INFO:Set up index.
2025-05-13 15:12:46,865:INFO:Assigning column types.
2025-05-13 15:12:46,868:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-13 15:12:46,887:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,887:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,899:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,919:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,931:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-13 15:12:46,951:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,983:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:12:46,995:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:46,995:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-13 15:12:47,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:47,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:47,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:47,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:47,058:INFO:Preparing preprocessing pipeline...
2025-05-13 15:12:47,060:INFO:Set up simple imputation.
2025-05-13 15:12:47,066:INFO:Set up encoding of ordinal features.
2025-05-13 15:12:47,074:INFO:Set up encoding of categorical features.
2025-05-13 15:12:47,074:INFO:Set up imbalanced handling.
2025-05-13 15:12:47,074:INFO:Set up column transformation.
2025-05-13 15:12:48,359:INFO:Finished creating preprocessing pipeline.
2025-05-13 15:12:48,376:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-13 15:12:48,376:INFO:Creating final display dataframe.
2025-05-13 15:12:48,836:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 15)
4        Transformed data shape      (106821, 28)
5   Transformed train set shape       (85902, 28)
6    Transformed test set shape       (20919, 28)
7              Numeric features                 6
8          Categorical features                 8
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              77f9
2025-05-13 15:12:48,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:48,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:48,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:48,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:12:48,905:INFO:setup() successfully completed in 2.09s...............
2025-05-13 15:12:48,905:INFO:Initializing compare_models()
2025-05-13 15:12:48,906:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-13 15:12:48,906:INFO:Checking exceptions
2025-05-13 15:12:48,913:INFO:Preparing display monitor
2025-05-13 15:12:48,923:INFO:Initializing Logistic Regression
2025-05-13 15:12:48,923:INFO:Total runtime is 2.3523966471354168e-06 minutes
2025-05-13 15:12:48,924:INFO:SubProcess create_model() called ==================================
2025-05-13 15:12:48,925:INFO:Initializing create_model()
2025-05-13 15:12:48,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:12:48,925:INFO:Checking exceptions
2025-05-13 15:12:48,925:INFO:Importing libraries
2025-05-13 15:12:48,925:INFO:Copying training dataset
2025-05-13 15:12:48,937:INFO:Defining folds
2025-05-13 15:12:48,937:INFO:Declaring metric variables
2025-05-13 15:12:48,938:INFO:Importing untrained model
2025-05-13 15:12:48,940:INFO:Logistic Regression Imported successfully
2025-05-13 15:12:48,942:INFO:Starting cross validation
2025-05-13 15:12:48,944:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:12:54,690:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,738:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,739:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,787:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,793:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:12:54,842:INFO:Calculating mean and std
2025-05-13 15:12:54,844:INFO:Creating metrics dataframe
2025-05-13 15:12:54,846:INFO:Uploading results into container
2025-05-13 15:12:54,847:INFO:Uploading model into container now
2025-05-13 15:12:54,847:INFO:_master_model_container: 1
2025-05-13 15:12:54,847:INFO:_display_container: 2
2025-05-13 15:12:54,847:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-13 15:12:54,847:INFO:create_model() successfully completed......................................
2025-05-13 15:12:54,986:INFO:SubProcess create_model() end ==================================
2025-05-13 15:12:54,987:INFO:Creating metrics dataframe
2025-05-13 15:12:54,989:INFO:Initializing K Neighbors Classifier
2025-05-13 15:12:54,989:INFO:Total runtime is 0.10111306905746459 minutes
2025-05-13 15:12:54,991:INFO:SubProcess create_model() called ==================================
2025-05-13 15:12:54,991:INFO:Initializing create_model()
2025-05-13 15:12:54,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:12:54,991:INFO:Checking exceptions
2025-05-13 15:12:54,991:INFO:Importing libraries
2025-05-13 15:12:54,991:INFO:Copying training dataset
2025-05-13 15:12:55,002:INFO:Defining folds
2025-05-13 15:12:55,002:INFO:Declaring metric variables
2025-05-13 15:12:55,003:INFO:Importing untrained model
2025-05-13 15:12:55,005:INFO:K Neighbors Classifier Imported successfully
2025-05-13 15:12:55,007:INFO:Starting cross validation
2025-05-13 15:12:55,008:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:00,778:INFO:Calculating mean and std
2025-05-13 15:13:00,779:INFO:Creating metrics dataframe
2025-05-13 15:13:00,781:INFO:Uploading results into container
2025-05-13 15:13:00,781:INFO:Uploading model into container now
2025-05-13 15:13:00,782:INFO:_master_model_container: 2
2025-05-13 15:13:00,782:INFO:_display_container: 2
2025-05-13 15:13:00,782:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-13 15:13:00,782:INFO:create_model() successfully completed......................................
2025-05-13 15:13:00,869:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:00,869:INFO:Creating metrics dataframe
2025-05-13 15:13:00,872:INFO:Initializing Naive Bayes
2025-05-13 15:13:00,872:INFO:Total runtime is 0.19915663401285805 minutes
2025-05-13 15:13:00,873:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:00,873:INFO:Initializing create_model()
2025-05-13 15:13:00,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:00,874:INFO:Checking exceptions
2025-05-13 15:13:00,874:INFO:Importing libraries
2025-05-13 15:13:00,874:INFO:Copying training dataset
2025-05-13 15:13:00,883:INFO:Defining folds
2025-05-13 15:13:00,884:INFO:Declaring metric variables
2025-05-13 15:13:00,885:INFO:Importing untrained model
2025-05-13 15:13:00,887:INFO:Naive Bayes Imported successfully
2025-05-13 15:13:00,889:INFO:Starting cross validation
2025-05-13 15:13:00,890:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:03,066:INFO:Calculating mean and std
2025-05-13 15:13:03,067:INFO:Creating metrics dataframe
2025-05-13 15:13:03,068:INFO:Uploading results into container
2025-05-13 15:13:03,068:INFO:Uploading model into container now
2025-05-13 15:13:03,068:INFO:_master_model_container: 3
2025-05-13 15:13:03,068:INFO:_display_container: 2
2025-05-13 15:13:03,068:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-13 15:13:03,068:INFO:create_model() successfully completed......................................
2025-05-13 15:13:03,147:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:03,147:INFO:Creating metrics dataframe
2025-05-13 15:13:03,150:INFO:Initializing Decision Tree Classifier
2025-05-13 15:13:03,150:INFO:Total runtime is 0.23711818854014077 minutes
2025-05-13 15:13:03,151:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:03,151:INFO:Initializing create_model()
2025-05-13 15:13:03,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:03,151:INFO:Checking exceptions
2025-05-13 15:13:03,151:INFO:Importing libraries
2025-05-13 15:13:03,151:INFO:Copying training dataset
2025-05-13 15:13:03,161:INFO:Defining folds
2025-05-13 15:13:03,161:INFO:Declaring metric variables
2025-05-13 15:13:03,162:INFO:Importing untrained model
2025-05-13 15:13:03,163:INFO:Decision Tree Classifier Imported successfully
2025-05-13 15:13:03,165:INFO:Starting cross validation
2025-05-13 15:13:03,167:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:04,774:INFO:Calculating mean and std
2025-05-13 15:13:04,775:INFO:Creating metrics dataframe
2025-05-13 15:13:04,776:INFO:Uploading results into container
2025-05-13 15:13:04,776:INFO:Uploading model into container now
2025-05-13 15:13:04,776:INFO:_master_model_container: 4
2025-05-13 15:13:04,776:INFO:_display_container: 2
2025-05-13 15:13:04,776:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-13 15:13:04,776:INFO:create_model() successfully completed......................................
2025-05-13 15:13:04,854:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:04,854:INFO:Creating metrics dataframe
2025-05-13 15:13:04,857:INFO:Initializing SVM - Linear Kernel
2025-05-13 15:13:04,857:INFO:Total runtime is 0.26557176907857255 minutes
2025-05-13 15:13:04,858:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:04,858:INFO:Initializing create_model()
2025-05-13 15:13:04,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:04,858:INFO:Checking exceptions
2025-05-13 15:13:04,859:INFO:Importing libraries
2025-05-13 15:13:04,859:INFO:Copying training dataset
2025-05-13 15:13:04,867:INFO:Defining folds
2025-05-13 15:13:04,867:INFO:Declaring metric variables
2025-05-13 15:13:04,868:INFO:Importing untrained model
2025-05-13 15:13:04,869:INFO:SVM - Linear Kernel Imported successfully
2025-05-13 15:13:04,871:INFO:Starting cross validation
2025-05-13 15:13:04,873:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:07,992:INFO:Calculating mean and std
2025-05-13 15:13:07,993:INFO:Creating metrics dataframe
2025-05-13 15:13:07,994:INFO:Uploading results into container
2025-05-13 15:13:07,994:INFO:Uploading model into container now
2025-05-13 15:13:07,994:INFO:_master_model_container: 5
2025-05-13 15:13:07,994:INFO:_display_container: 2
2025-05-13 15:13:07,994:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-13 15:13:07,994:INFO:create_model() successfully completed......................................
2025-05-13 15:13:08,087:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:08,088:INFO:Creating metrics dataframe
2025-05-13 15:13:08,091:INFO:Initializing Ridge Classifier
2025-05-13 15:13:08,091:INFO:Total runtime is 0.31947088638941445 minutes
2025-05-13 15:13:08,092:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:08,092:INFO:Initializing create_model()
2025-05-13 15:13:08,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:08,092:INFO:Checking exceptions
2025-05-13 15:13:08,092:INFO:Importing libraries
2025-05-13 15:13:08,092:INFO:Copying training dataset
2025-05-13 15:13:08,103:INFO:Defining folds
2025-05-13 15:13:08,103:INFO:Declaring metric variables
2025-05-13 15:13:08,104:INFO:Importing untrained model
2025-05-13 15:13:08,105:INFO:Ridge Classifier Imported successfully
2025-05-13 15:13:08,107:INFO:Starting cross validation
2025-05-13 15:13:08,109:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:10,225:INFO:Calculating mean and std
2025-05-13 15:13:10,225:INFO:Creating metrics dataframe
2025-05-13 15:13:10,226:INFO:Uploading results into container
2025-05-13 15:13:10,227:INFO:Uploading model into container now
2025-05-13 15:13:10,227:INFO:_master_model_container: 6
2025-05-13 15:13:10,227:INFO:_display_container: 2
2025-05-13 15:13:10,227:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-13 15:13:10,227:INFO:create_model() successfully completed......................................
2025-05-13 15:13:10,302:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:10,302:INFO:Creating metrics dataframe
2025-05-13 15:13:10,305:INFO:Initializing Random Forest Classifier
2025-05-13 15:13:10,305:INFO:Total runtime is 0.3563728173573812 minutes
2025-05-13 15:13:10,306:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:10,306:INFO:Initializing create_model()
2025-05-13 15:13:10,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:10,306:INFO:Checking exceptions
2025-05-13 15:13:10,307:INFO:Importing libraries
2025-05-13 15:13:10,307:INFO:Copying training dataset
2025-05-13 15:13:10,316:INFO:Defining folds
2025-05-13 15:13:10,316:INFO:Declaring metric variables
2025-05-13 15:13:10,317:INFO:Importing untrained model
2025-05-13 15:13:10,318:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:13:10,320:INFO:Starting cross validation
2025-05-13 15:13:10,321:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:16,029:INFO:Calculating mean and std
2025-05-13 15:13:16,031:INFO:Creating metrics dataframe
2025-05-13 15:13:16,034:INFO:Uploading results into container
2025-05-13 15:13:16,034:INFO:Uploading model into container now
2025-05-13 15:13:16,035:INFO:_master_model_container: 7
2025-05-13 15:13:16,035:INFO:_display_container: 2
2025-05-13 15:13:16,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:13:16,035:INFO:create_model() successfully completed......................................
2025-05-13 15:13:16,135:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:16,135:INFO:Creating metrics dataframe
2025-05-13 15:13:16,138:INFO:Initializing Quadratic Discriminant Analysis
2025-05-13 15:13:16,138:INFO:Total runtime is 0.4535940527915955 minutes
2025-05-13 15:13:16,140:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:16,140:INFO:Initializing create_model()
2025-05-13 15:13:16,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:16,140:INFO:Checking exceptions
2025-05-13 15:13:16,140:INFO:Importing libraries
2025-05-13 15:13:16,140:INFO:Copying training dataset
2025-05-13 15:13:16,153:INFO:Defining folds
2025-05-13 15:13:16,153:INFO:Declaring metric variables
2025-05-13 15:13:16,155:INFO:Importing untrained model
2025-05-13 15:13:16,156:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-13 15:13:16,158:INFO:Starting cross validation
2025-05-13 15:13:16,160:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:17,138:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:17,152:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:17,156:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:17,162:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:17,212:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:17,226:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:17,229:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:17,238:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:18,305:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:13:18,368:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:18,383:INFO:Calculating mean and std
2025-05-13 15:13:18,384:INFO:Creating metrics dataframe
2025-05-13 15:13:18,385:INFO:Uploading results into container
2025-05-13 15:13:18,385:INFO:Uploading model into container now
2025-05-13 15:13:18,385:INFO:_master_model_container: 8
2025-05-13 15:13:18,385:INFO:_display_container: 2
2025-05-13 15:13:18,385:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-13 15:13:18,385:INFO:create_model() successfully completed......................................
2025-05-13 15:13:18,475:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:18,475:INFO:Creating metrics dataframe
2025-05-13 15:13:18,478:INFO:Initializing Ada Boost Classifier
2025-05-13 15:13:18,478:INFO:Total runtime is 0.4925962845484416 minutes
2025-05-13 15:13:18,480:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:18,480:INFO:Initializing create_model()
2025-05-13 15:13:18,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:18,480:INFO:Checking exceptions
2025-05-13 15:13:18,480:INFO:Importing libraries
2025-05-13 15:13:18,480:INFO:Copying training dataset
2025-05-13 15:13:18,491:INFO:Defining folds
2025-05-13 15:13:18,491:INFO:Declaring metric variables
2025-05-13 15:13:18,492:INFO:Importing untrained model
2025-05-13 15:13:18,493:INFO:Ada Boost Classifier Imported successfully
2025-05-13 15:13:18,496:INFO:Starting cross validation
2025-05-13 15:13:18,497:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:19,402:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:19,467:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:19,479:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:19,484:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:19,507:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:13:22,144:INFO:Calculating mean and std
2025-05-13 15:13:22,145:INFO:Creating metrics dataframe
2025-05-13 15:13:22,146:INFO:Uploading results into container
2025-05-13 15:13:22,146:INFO:Uploading model into container now
2025-05-13 15:13:22,146:INFO:_master_model_container: 9
2025-05-13 15:13:22,146:INFO:_display_container: 2
2025-05-13 15:13:22,146:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-13 15:13:22,146:INFO:create_model() successfully completed......................................
2025-05-13 15:13:22,220:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:22,220:INFO:Creating metrics dataframe
2025-05-13 15:13:22,224:INFO:Initializing Gradient Boosting Classifier
2025-05-13 15:13:22,224:INFO:Total runtime is 0.5550253868103028 minutes
2025-05-13 15:13:22,225:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:22,225:INFO:Initializing create_model()
2025-05-13 15:13:22,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:22,226:INFO:Checking exceptions
2025-05-13 15:13:22,226:INFO:Importing libraries
2025-05-13 15:13:22,226:INFO:Copying training dataset
2025-05-13 15:13:22,236:INFO:Defining folds
2025-05-13 15:13:22,236:INFO:Declaring metric variables
2025-05-13 15:13:22,238:INFO:Importing untrained model
2025-05-13 15:13:22,239:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:13:22,241:INFO:Starting cross validation
2025-05-13 15:13:22,242:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:35,548:INFO:Calculating mean and std
2025-05-13 15:13:35,550:INFO:Creating metrics dataframe
2025-05-13 15:13:35,551:INFO:Uploading results into container
2025-05-13 15:13:35,552:INFO:Uploading model into container now
2025-05-13 15:13:35,552:INFO:_master_model_container: 10
2025-05-13 15:13:35,552:INFO:_display_container: 2
2025-05-13 15:13:35,552:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:13:35,552:INFO:create_model() successfully completed......................................
2025-05-13 15:13:35,632:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:35,632:INFO:Creating metrics dataframe
2025-05-13 15:13:35,635:INFO:Initializing Linear Discriminant Analysis
2025-05-13 15:13:35,636:INFO:Total runtime is 0.7785467346509298 minutes
2025-05-13 15:13:35,637:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:35,637:INFO:Initializing create_model()
2025-05-13 15:13:35,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:35,637:INFO:Checking exceptions
2025-05-13 15:13:35,637:INFO:Importing libraries
2025-05-13 15:13:35,637:INFO:Copying training dataset
2025-05-13 15:13:35,648:INFO:Defining folds
2025-05-13 15:13:35,648:INFO:Declaring metric variables
2025-05-13 15:13:35,649:INFO:Importing untrained model
2025-05-13 15:13:35,650:INFO:Linear Discriminant Analysis Imported successfully
2025-05-13 15:13:35,653:INFO:Starting cross validation
2025-05-13 15:13:35,654:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:36,781:INFO:Calculating mean and std
2025-05-13 15:13:36,781:INFO:Creating metrics dataframe
2025-05-13 15:13:36,783:INFO:Uploading results into container
2025-05-13 15:13:36,783:INFO:Uploading model into container now
2025-05-13 15:13:36,783:INFO:_master_model_container: 11
2025-05-13 15:13:36,783:INFO:_display_container: 2
2025-05-13 15:13:36,784:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-13 15:13:36,784:INFO:create_model() successfully completed......................................
2025-05-13 15:13:36,862:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:36,862:INFO:Creating metrics dataframe
2025-05-13 15:13:36,866:INFO:Initializing Extra Trees Classifier
2025-05-13 15:13:36,866:INFO:Total runtime is 0.7990583856900534 minutes
2025-05-13 15:13:36,867:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:36,868:INFO:Initializing create_model()
2025-05-13 15:13:36,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:36,868:INFO:Checking exceptions
2025-05-13 15:13:36,868:INFO:Importing libraries
2025-05-13 15:13:36,868:INFO:Copying training dataset
2025-05-13 15:13:36,878:INFO:Defining folds
2025-05-13 15:13:36,878:INFO:Declaring metric variables
2025-05-13 15:13:36,879:INFO:Importing untrained model
2025-05-13 15:13:36,881:INFO:Extra Trees Classifier Imported successfully
2025-05-13 15:13:36,883:INFO:Starting cross validation
2025-05-13 15:13:36,884:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:41,817:INFO:Calculating mean and std
2025-05-13 15:13:41,820:INFO:Creating metrics dataframe
2025-05-13 15:13:41,826:INFO:Uploading results into container
2025-05-13 15:13:41,826:INFO:Uploading model into container now
2025-05-13 15:13:41,827:INFO:_master_model_container: 12
2025-05-13 15:13:41,827:INFO:_display_container: 2
2025-05-13 15:13:41,828:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-13 15:13:41,828:INFO:create_model() successfully completed......................................
2025-05-13 15:13:41,972:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:41,972:INFO:Creating metrics dataframe
2025-05-13 15:13:41,976:INFO:Initializing Light Gradient Boosting Machine
2025-05-13 15:13:41,976:INFO:Total runtime is 0.8842240532239279 minutes
2025-05-13 15:13:41,977:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:41,978:INFO:Initializing create_model()
2025-05-13 15:13:41,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:41,978:INFO:Checking exceptions
2025-05-13 15:13:41,978:INFO:Importing libraries
2025-05-13 15:13:41,978:INFO:Copying training dataset
2025-05-13 15:13:41,990:INFO:Defining folds
2025-05-13 15:13:41,991:INFO:Declaring metric variables
2025-05-13 15:13:41,992:INFO:Importing untrained model
2025-05-13 15:13:41,994:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:13:41,996:INFO:Starting cross validation
2025-05-13 15:13:41,998:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:45,903:INFO:Calculating mean and std
2025-05-13 15:13:45,904:INFO:Creating metrics dataframe
2025-05-13 15:13:45,905:INFO:Uploading results into container
2025-05-13 15:13:45,906:INFO:Uploading model into container now
2025-05-13 15:13:45,906:INFO:_master_model_container: 13
2025-05-13 15:13:45,906:INFO:_display_container: 2
2025-05-13 15:13:45,907:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:13:45,907:INFO:create_model() successfully completed......................................
2025-05-13 15:13:45,990:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:45,990:INFO:Creating metrics dataframe
2025-05-13 15:13:45,994:INFO:Initializing Dummy Classifier
2025-05-13 15:13:45,994:INFO:Total runtime is 0.9511892199516297 minutes
2025-05-13 15:13:45,995:INFO:SubProcess create_model() called ==================================
2025-05-13 15:13:45,995:INFO:Initializing create_model()
2025-05-13 15:13:45,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x327caa310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:45,995:INFO:Checking exceptions
2025-05-13 15:13:45,996:INFO:Importing libraries
2025-05-13 15:13:45,996:INFO:Copying training dataset
2025-05-13 15:13:46,006:INFO:Defining folds
2025-05-13 15:13:46,006:INFO:Declaring metric variables
2025-05-13 15:13:46,007:INFO:Importing untrained model
2025-05-13 15:13:46,009:INFO:Dummy Classifier Imported successfully
2025-05-13 15:13:46,011:INFO:Starting cross validation
2025-05-13 15:13:46,012:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:13:46,982:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,046:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,053:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,094:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,145:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:13:47,157:INFO:Calculating mean and std
2025-05-13 15:13:47,158:INFO:Creating metrics dataframe
2025-05-13 15:13:47,159:INFO:Uploading results into container
2025-05-13 15:13:47,159:INFO:Uploading model into container now
2025-05-13 15:13:47,159:INFO:_master_model_container: 14
2025-05-13 15:13:47,159:INFO:_display_container: 2
2025-05-13 15:13:47,159:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-13 15:13:47,159:INFO:create_model() successfully completed......................................
2025-05-13 15:13:47,234:INFO:SubProcess create_model() end ==================================
2025-05-13 15:13:47,234:INFO:Creating metrics dataframe
2025-05-13 15:13:47,238:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-13 15:13:47,241:INFO:Initializing create_model()
2025-05-13 15:13:47,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:13:47,241:INFO:Checking exceptions
2025-05-13 15:13:47,242:INFO:Importing libraries
2025-05-13 15:13:47,242:INFO:Copying training dataset
2025-05-13 15:13:47,252:INFO:Defining folds
2025-05-13 15:13:47,252:INFO:Declaring metric variables
2025-05-13 15:13:47,252:INFO:Importing untrained model
2025-05-13 15:13:47,252:INFO:Declaring custom model
2025-05-13 15:13:47,252:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:13:47,253:INFO:Cross validation set to False
2025-05-13 15:13:47,253:INFO:Fitting Model
2025-05-13 15:14:03,158:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:14:03,159:INFO:create_model() successfully completed......................................
2025-05-13 15:14:03,245:INFO:Initializing create_model()
2025-05-13 15:14:03,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:14:03,246:INFO:Checking exceptions
2025-05-13 15:14:03,246:INFO:Importing libraries
2025-05-13 15:14:03,246:INFO:Copying training dataset
2025-05-13 15:14:03,258:INFO:Defining folds
2025-05-13 15:14:03,258:INFO:Declaring metric variables
2025-05-13 15:14:03,258:INFO:Importing untrained model
2025-05-13 15:14:03,258:INFO:Declaring custom model
2025-05-13 15:14:03,259:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:14:03,260:INFO:Cross validation set to False
2025-05-13 15:14:03,260:INFO:Fitting Model
2025-05-13 15:14:04,294:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-13 15:14:04,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004644 seconds.
2025-05-13 15:14:04,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-13 15:14:04,305:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-13 15:14:04,305:INFO:[LightGBM] [Info] Total Bins 6885
2025-05-13 15:14:04,305:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 27
2025-05-13 15:14:04,305:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-13 15:14:05,066:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:14:05,066:INFO:create_model() successfully completed......................................
2025-05-13 15:14:05,141:INFO:Initializing create_model()
2025-05-13 15:14:05,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:14:05,141:INFO:Checking exceptions
2025-05-13 15:14:05,142:INFO:Importing libraries
2025-05-13 15:14:05,142:INFO:Copying training dataset
2025-05-13 15:14:05,151:INFO:Defining folds
2025-05-13 15:14:05,151:INFO:Declaring metric variables
2025-05-13 15:14:05,151:INFO:Importing untrained model
2025-05-13 15:14:05,151:INFO:Declaring custom model
2025-05-13 15:14:05,151:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:14:05,152:INFO:Cross validation set to False
2025-05-13 15:14:05,152:INFO:Fitting Model
2025-05-13 15:14:07,395:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:14:07,395:INFO:create_model() successfully completed......................................
2025-05-13 15:14:07,478:INFO:_master_model_container: 14
2025-05-13 15:14:07,478:INFO:_display_container: 2
2025-05-13 15:14:07,478:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-13 15:14:07,478:INFO:compare_models() successfully completed......................................
2025-05-13 15:14:07,479:INFO:Initializing evaluate_model()
2025-05-13 15:14:07,479:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:14:07,486:INFO:Initializing plot_model()
2025-05-13 15:14:07,486:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:14:07,486:INFO:Checking exceptions
2025-05-13 15:14:07,490:INFO:Preloading libraries
2025-05-13 15:14:07,494:INFO:Copying training dataset
2025-05-13 15:14:07,494:INFO:Plot type: pipeline
2025-05-13 15:14:07,556:INFO:Visual Rendered Successfully
2025-05-13 15:14:07,633:INFO:plot_model() successfully completed......................................
2025-05-13 15:14:07,635:INFO:Initializing tune_model()
2025-05-13 15:14:07,635:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-13 15:14:07,635:INFO:Checking exceptions
2025-05-13 15:14:07,644:INFO:Copying training dataset
2025-05-13 15:14:07,653:INFO:Checking base model
2025-05-13 15:14:07,653:INFO:Base model : Gradient Boosting Classifier
2025-05-13 15:14:07,654:INFO:Declaring metric variables
2025-05-13 15:14:07,656:INFO:Defining Hyperparameters
2025-05-13 15:14:07,736:INFO:Tuning with n_jobs=-1
2025-05-13 15:14:07,736:INFO:Initializing RandomizedSearchCV
2025-05-13 15:14:45,989:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-13 15:14:45,992:INFO:Hyperparameter search completed
2025-05-13 15:14:45,992:INFO:SubProcess create_model() called ==================================
2025-05-13 15:14:45,993:INFO:Initializing create_model()
2025-05-13 15:14:45,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x331be6f90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-13 15:14:45,993:INFO:Checking exceptions
2025-05-13 15:14:45,993:INFO:Importing libraries
2025-05-13 15:14:45,993:INFO:Copying training dataset
2025-05-13 15:14:46,009:INFO:Defining folds
2025-05-13 15:14:46,009:INFO:Declaring metric variables
2025-05-13 15:14:46,018:INFO:Importing untrained model
2025-05-13 15:14:46,018:INFO:Declaring custom model
2025-05-13 15:14:46,020:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:14:46,023:INFO:Starting cross validation
2025-05-13 15:14:46,026:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:14:56,051:INFO:Calculating mean and std
2025-05-13 15:14:56,052:INFO:Creating metrics dataframe
2025-05-13 15:14:56,055:INFO:Finalizing model
2025-05-13 15:15:07,296:INFO:Uploading results into container
2025-05-13 15:15:07,297:INFO:Uploading model into container now
2025-05-13 15:15:07,297:INFO:_master_model_container: 15
2025-05-13 15:15:07,297:INFO:_display_container: 3
2025-05-13 15:15:07,298:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:15:07,298:INFO:create_model() successfully completed......................................
2025-05-13 15:15:07,430:INFO:SubProcess create_model() end ==================================
2025-05-13 15:15:07,430:INFO:choose_better activated
2025-05-13 15:15:07,431:INFO:SubProcess create_model() called ==================================
2025-05-13 15:15:07,432:INFO:Initializing create_model()
2025-05-13 15:15:07,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:15:07,432:INFO:Checking exceptions
2025-05-13 15:15:07,433:INFO:Importing libraries
2025-05-13 15:15:07,433:INFO:Copying training dataset
2025-05-13 15:15:07,443:INFO:Defining folds
2025-05-13 15:15:07,443:INFO:Declaring metric variables
2025-05-13 15:15:07,443:INFO:Importing untrained model
2025-05-13 15:15:07,443:INFO:Declaring custom model
2025-05-13 15:15:07,443:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:15:07,443:INFO:Starting cross validation
2025-05-13 15:15:07,444:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:15:20,739:INFO:Calculating mean and std
2025-05-13 15:15:20,741:INFO:Creating metrics dataframe
2025-05-13 15:15:20,745:INFO:Finalizing model
2025-05-13 15:15:36,998:INFO:Uploading results into container
2025-05-13 15:15:36,999:INFO:Uploading model into container now
2025-05-13 15:15:36,999:INFO:_master_model_container: 16
2025-05-13 15:15:36,999:INFO:_display_container: 4
2025-05-13 15:15:37,000:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:15:37,000:INFO:create_model() successfully completed......................................
2025-05-13 15:15:37,130:INFO:SubProcess create_model() end ==================================
2025-05-13 15:15:37,130:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4745
2025-05-13 15:15:37,131:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4906
2025-05-13 15:15:37,131:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-13 15:15:37,131:INFO:choose_better completed
2025-05-13 15:15:37,135:INFO:_master_model_container: 16
2025-05-13 15:15:37,135:INFO:_display_container: 3
2025-05-13 15:15:37,135:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:15:37,135:INFO:tune_model() successfully completed......................................
2025-05-13 15:15:37,226:INFO:Initializing evaluate_model()
2025-05-13 15:15:37,226:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:15:37,235:INFO:Initializing plot_model()
2025-05-13 15:15:37,235:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:15:37,235:INFO:Checking exceptions
2025-05-13 15:15:37,241:INFO:Preloading libraries
2025-05-13 15:15:37,251:INFO:Copying training dataset
2025-05-13 15:15:37,251:INFO:Plot type: pipeline
2025-05-13 15:15:37,309:INFO:Visual Rendered Successfully
2025-05-13 15:15:37,396:INFO:plot_model() successfully completed......................................
2025-05-13 15:15:37,398:INFO:Initializing interpret_model()
2025-05-13 15:15:37,398:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-13 15:15:37,398:INFO:Checking exceptions
2025-05-13 15:15:37,398:INFO:Soft dependency imported: shap: 0.47.2
2025-05-13 15:15:37,568:INFO:Initializing finalize_model()
2025-05-13 15:15:37,568:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-13 15:15:37,569:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:15:37,573:INFO:Initializing create_model()
2025-05-13 15:15:37,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:15:37,573:INFO:Checking exceptions
2025-05-13 15:15:37,573:INFO:Importing libraries
2025-05-13 15:15:37,573:INFO:Copying training dataset
2025-05-13 15:15:37,574:INFO:Defining folds
2025-05-13 15:15:37,574:INFO:Declaring metric variables
2025-05-13 15:15:37,574:INFO:Importing untrained model
2025-05-13 15:15:37,574:INFO:Declaring custom model
2025-05-13 15:15:37,574:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:15:37,575:INFO:Cross validation set to False
2025-05-13 15:15:37,575:INFO:Fitting Model
2025-05-13 15:15:54,143:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:15:54,143:INFO:create_model() successfully completed......................................
2025-05-13 15:15:54,245:INFO:_master_model_container: 16
2025-05-13 15:15:54,245:INFO:_display_container: 3
2025-05-13 15:15:54,269:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:15:54,269:INFO:finalize_model() successfully completed......................................
2025-05-13 15:15:54,396:INFO:Initializing save_model()
2025-05-13 15:15:54,396:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-13 15:15:54,396:INFO:Adding model into prep_pipe
2025-05-13 15:15:54,396:WARNING:Only Model saved as it was a pipeline.
2025-05-13 15:15:54,422:INFO:final_cancer_model.pkl saved in current working directory
2025-05-13 15:15:54,440:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:15:54,440:INFO:save_model() successfully completed......................................
2025-05-13 15:15:54,541:INFO:Initializing predict_model()
2025-05-13 15:15:54,541:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x33692b9c0>)
2025-05-13 15:15:54,541:INFO:Checking exceptions
2025-05-13 15:15:54,541:INFO:Preloading libraries
2025-05-13 15:15:54,542:INFO:Set up data.
2025-05-13 15:15:54,559:INFO:Set up index.
2025-05-13 15:15:55,442:INFO:Initializing blend_models()
2025-05-13 15:15:55,442:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-13 15:15:55,442:INFO:Checking exceptions
2025-05-13 15:15:55,451:INFO:Importing libraries
2025-05-13 15:15:55,451:INFO:Copying training dataset
2025-05-13 15:15:55,452:INFO:Getting model names
2025-05-13 15:15:55,453:INFO:SubProcess create_model() called ==================================
2025-05-13 15:15:55,455:INFO:Initializing create_model()
2025-05-13 15:15:55,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x337385d50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:15:55,455:INFO:Checking exceptions
2025-05-13 15:15:55,455:INFO:Importing libraries
2025-05-13 15:15:55,456:INFO:Copying training dataset
2025-05-13 15:15:55,466:INFO:Defining folds
2025-05-13 15:15:55,466:INFO:Declaring metric variables
2025-05-13 15:15:55,467:INFO:Importing untrained model
2025-05-13 15:15:55,467:INFO:Declaring custom model
2025-05-13 15:15:55,469:INFO:Voting Classifier Imported successfully
2025-05-13 15:15:55,471:INFO:Starting cross validation
2025-05-13 15:15:55,472:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:16:11,942:INFO:Calculating mean and std
2025-05-13 15:16:11,945:INFO:Creating metrics dataframe
2025-05-13 15:16:11,954:INFO:Finalizing model
2025-05-13 15:16:28,349:INFO:Uploading results into container
2025-05-13 15:16:28,350:INFO:Uploading model into container now
2025-05-13 15:16:28,350:INFO:_master_model_container: 17
2025-05-13 15:16:28,351:INFO:_display_container: 4
2025-05-13 15:16:28,355:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-13 15:16:28,355:INFO:create_model() successfully completed......................................
2025-05-13 15:16:28,546:INFO:SubProcess create_model() end ==================================
2025-05-13 15:16:28,550:INFO:_master_model_container: 17
2025-05-13 15:16:28,550:INFO:_display_container: 4
2025-05-13 15:16:28,552:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-13 15:16:28,552:INFO:blend_models() successfully completed......................................
2025-05-13 15:16:28,642:INFO:Initializing evaluate_model()
2025-05-13 15:16:28,643:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:16:28,652:INFO:Initializing plot_model()
2025-05-13 15:16:28,653:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:16:28,653:INFO:Checking exceptions
2025-05-13 15:16:28,657:INFO:Preloading libraries
2025-05-13 15:16:28,782:INFO:Copying training dataset
2025-05-13 15:16:28,782:INFO:Plot type: pipeline
2025-05-13 15:16:28,843:INFO:Visual Rendered Successfully
2025-05-13 15:16:28,935:INFO:plot_model() successfully completed......................................
2025-05-13 15:16:28,943:INFO:Initializing predict_model()
2025-05-13 15:16:28,944:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x33f8c8fe0>)
2025-05-13 15:16:28,944:INFO:Checking exceptions
2025-05-13 15:16:28,944:INFO:Preloading libraries
2025-05-13 15:16:28,945:INFO:Set up data.
2025-05-13 15:16:28,967:INFO:Set up index.
2025-05-13 15:16:29,618:INFO:Initializing plot_model()
2025-05-13 15:16:29,618:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:16:29,618:INFO:Checking exceptions
2025-05-13 15:16:29,622:INFO:Preloading libraries
2025-05-13 15:16:29,626:INFO:Copying training dataset
2025-05-13 15:16:29,626:INFO:Plot type: confusion_matrix
2025-05-13 15:16:29,840:INFO:Fitting Model
2025-05-13 15:16:29,841:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:16:29,842:INFO:Scoring test/hold-out set
2025-05-13 15:16:29,921:INFO:Visual Rendered Successfully
2025-05-13 15:16:30,010:INFO:plot_model() successfully completed......................................
2025-05-13 15:16:30,011:INFO:Initializing plot_model()
2025-05-13 15:16:30,011:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:16:30,011:INFO:Checking exceptions
2025-05-13 15:16:30,015:INFO:Preloading libraries
2025-05-13 15:16:30,019:INFO:Copying training dataset
2025-05-13 15:16:30,019:INFO:Plot type: auc
2025-05-13 15:16:30,217:INFO:Fitting Model
2025-05-13 15:16:30,218:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:16:30,219:INFO:Scoring test/hold-out set
2025-05-13 15:16:30,338:INFO:Visual Rendered Successfully
2025-05-13 15:16:30,427:INFO:plot_model() successfully completed......................................
2025-05-13 15:16:30,428:INFO:Initializing plot_model()
2025-05-13 15:16:30,428:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3275b0190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:16:30,428:INFO:Checking exceptions
2025-05-13 15:16:30,432:INFO:Preloading libraries
2025-05-13 15:16:30,436:INFO:Copying training dataset
2025-05-13 15:16:30,436:INFO:Plot type: feature
2025-05-13 15:16:30,436:WARNING:No coef_ found. Trying feature_importances_
2025-05-13 15:16:30,509:INFO:Visual Rendered Successfully
2025-05-13 15:16:30,591:INFO:plot_model() successfully completed......................................
2025-05-13 15:38:44,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 15:38:44,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 15:38:44,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 15:38:44,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 15:38:45,012:INFO:PyCaret ClassificationExperiment
2025-05-13 15:38:45,012:INFO:Logging name: clf-default-name
2025-05-13 15:38:45,012:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-13 15:38:45,012:INFO:version 3.3.2
2025-05-13 15:38:45,012:INFO:Initializing setup()
2025-05-13 15:38:45,012:INFO:self.USI: 4919
2025-05-13 15:38:45,012:INFO:self._variable_keys: {'fold_groups_param', 'html_param', 'USI', 'fix_imbalance', 'log_plots_param', 'idx', 'fold_generator', 'exp_name_log', 'exp_id', 'y', 'is_multiclass', 'memory', 'gpu_param', 'y_test', 'pipeline', 'seed', '_ml_usecase', 'X_train', 'gpu_n_jobs_param', 'y_train', 'fold_shuffle_param', 'X', 'data', '_available_plots', 'X_test', 'target_param', 'n_jobs_param', 'logging_param'}
2025-05-13 15:38:45,012:INFO:Checking environment
2025-05-13 15:38:45,012:INFO:python_version: 3.11.0
2025-05-13 15:38:45,012:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-13 15:38:45,012:INFO:machine: arm64
2025-05-13 15:38:45,012:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:38:45,012:INFO:Memory: svmem(total=17179869184, available=3887300608, percent=77.4, used=6402818048, free=76447744, active=3830382592, inactive=3719823360, wired=2572435456)
2025-05-13 15:38:45,012:INFO:Physical Core: 12
2025-05-13 15:38:45,012:INFO:Logical Core: 12
2025-05-13 15:38:45,012:INFO:Checking libraries
2025-05-13 15:38:45,012:INFO:System:
2025-05-13 15:38:45,012:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-13 15:38:45,012:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-13 15:38:45,012:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:38:45,012:INFO:PyCaret required dependencies:
2025-05-13 15:38:45,037:INFO:                 pip: 22.3
2025-05-13 15:38:45,037:INFO:          setuptools: 65.5.0
2025-05-13 15:38:45,037:INFO:             pycaret: 3.3.2
2025-05-13 15:38:45,037:INFO:             IPython: 9.2.0
2025-05-13 15:38:45,037:INFO:          ipywidgets: 8.1.7
2025-05-13 15:38:45,037:INFO:                tqdm: 4.67.1
2025-05-13 15:38:45,037:INFO:               numpy: 1.26.4
2025-05-13 15:38:45,037:INFO:              pandas: 2.1.4
2025-05-13 15:38:45,037:INFO:              jinja2: 3.1.6
2025-05-13 15:38:45,037:INFO:               scipy: 1.11.4
2025-05-13 15:38:45,037:INFO:              joblib: 1.3.2
2025-05-13 15:38:45,037:INFO:             sklearn: 1.4.2
2025-05-13 15:38:45,037:INFO:                pyod: 2.0.5
2025-05-13 15:38:45,037:INFO:            imblearn: 0.13.0
2025-05-13 15:38:45,037:INFO:   category_encoders: 2.7.0
2025-05-13 15:38:45,037:INFO:            lightgbm: 4.6.0
2025-05-13 15:38:45,037:INFO:               numba: 0.61.2
2025-05-13 15:38:45,037:INFO:            requests: 2.32.3
2025-05-13 15:38:45,037:INFO:          matplotlib: 3.7.5
2025-05-13 15:38:45,038:INFO:          scikitplot: 0.3.7
2025-05-13 15:38:45,038:INFO:         yellowbrick: 1.5
2025-05-13 15:38:45,038:INFO:              plotly: 5.24.1
2025-05-13 15:38:45,038:INFO:    plotly-resampler: Not installed
2025-05-13 15:38:45,038:INFO:             kaleido: 0.2.1
2025-05-13 15:38:45,038:INFO:           schemdraw: 0.15
2025-05-13 15:38:45,038:INFO:         statsmodels: 0.14.4
2025-05-13 15:38:45,038:INFO:              sktime: 0.26.0
2025-05-13 15:38:45,038:INFO:               tbats: 1.1.3
2025-05-13 15:38:45,038:INFO:            pmdarima: 2.0.4
2025-05-13 15:38:45,038:INFO:              psutil: 7.0.0
2025-05-13 15:38:45,038:INFO:          markupsafe: 3.0.2
2025-05-13 15:38:45,038:INFO:             pickle5: Not installed
2025-05-13 15:38:45,038:INFO:         cloudpickle: 3.1.1
2025-05-13 15:38:45,038:INFO:         deprecation: 2.1.0
2025-05-13 15:38:45,038:INFO:              xxhash: 3.5.0
2025-05-13 15:38:45,038:INFO:           wurlitzer: 3.1.1
2025-05-13 15:38:45,038:INFO:PyCaret optional dependencies:
2025-05-13 15:38:45,043:INFO:                shap: 0.47.2
2025-05-13 15:38:45,043:INFO:           interpret: Not installed
2025-05-13 15:38:45,043:INFO:                umap: Not installed
2025-05-13 15:38:45,043:INFO:     ydata_profiling: Not installed
2025-05-13 15:38:45,043:INFO:  explainerdashboard: Not installed
2025-05-13 15:38:45,043:INFO:             autoviz: Not installed
2025-05-13 15:38:45,043:INFO:           fairlearn: Not installed
2025-05-13 15:38:45,043:INFO:          deepchecks: Not installed
2025-05-13 15:38:45,043:INFO:             xgboost: Not installed
2025-05-13 15:38:45,043:INFO:            catboost: Not installed
2025-05-13 15:38:45,043:INFO:              kmodes: Not installed
2025-05-13 15:38:45,043:INFO:             mlxtend: Not installed
2025-05-13 15:38:45,043:INFO:       statsforecast: Not installed
2025-05-13 15:38:45,043:INFO:        tune_sklearn: Not installed
2025-05-13 15:38:45,043:INFO:                 ray: Not installed
2025-05-13 15:38:45,043:INFO:            hyperopt: Not installed
2025-05-13 15:38:45,043:INFO:              optuna: 4.3.0
2025-05-13 15:38:45,043:INFO:               skopt: Not installed
2025-05-13 15:38:45,043:INFO:              mlflow: Not installed
2025-05-13 15:38:45,043:INFO:              gradio: Not installed
2025-05-13 15:38:45,043:INFO:             fastapi: Not installed
2025-05-13 15:38:45,043:INFO:             uvicorn: Not installed
2025-05-13 15:38:45,043:INFO:              m2cgen: Not installed
2025-05-13 15:38:45,043:INFO:           evidently: Not installed
2025-05-13 15:38:45,043:INFO:               fugue: Not installed
2025-05-13 15:38:45,043:INFO:           streamlit: Not installed
2025-05-13 15:38:45,043:INFO:             prophet: Not installed
2025-05-13 15:38:45,043:INFO:None
2025-05-13 15:38:45,043:INFO:Set up data.
2025-05-13 15:38:45,071:INFO:Set up folding strategy.
2025-05-13 15:38:45,071:INFO:Set up train/test split.
2025-05-13 15:38:45,091:INFO:Set up index.
2025-05-13 15:38:45,092:INFO:Assigning column types.
2025-05-13 15:38:45,095:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-13 15:38:45,113:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,115:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,146:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,157:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-13 15:38:45,175:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,204:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:38:45,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,215:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-13 15:38:45,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:45,276:INFO:Preparing preprocessing pipeline...
2025-05-13 15:38:45,277:INFO:Set up simple imputation.
2025-05-13 15:38:45,282:INFO:Set up encoding of ordinal features.
2025-05-13 15:38:45,290:INFO:Set up encoding of categorical features.
2025-05-13 15:38:45,290:INFO:Set up imbalanced handling.
2025-05-13 15:38:45,290:INFO:Set up column transformation.
2025-05-13 15:38:46,546:INFO:Finished creating preprocessing pipeline.
2025-05-13 15:38:46,561:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-13 15:38:46,561:INFO:Creating final display dataframe.
2025-05-13 15:38:47,001:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 14)
4        Transformed data shape      (106821, 27)
5   Transformed train set shape       (85902, 27)
6    Transformed test set shape       (20919, 27)
7              Numeric features                 6
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              4919
2025-05-13 15:38:47,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:47,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:47,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:47,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:38:47,068:INFO:setup() successfully completed in 2.06s...............
2025-05-13 15:38:47,068:INFO:Initializing compare_models()
2025-05-13 15:38:47,068:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-13 15:38:47,068:INFO:Checking exceptions
2025-05-13 15:38:47,076:INFO:Preparing display monitor
2025-05-13 15:38:47,108:INFO:Initializing Logistic Regression
2025-05-13 15:38:47,108:INFO:Total runtime is 2.9365221659342447e-06 minutes
2025-05-13 15:38:47,110:INFO:SubProcess create_model() called ==================================
2025-05-13 15:38:47,110:INFO:Initializing create_model()
2025-05-13 15:38:47,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:38:47,110:INFO:Checking exceptions
2025-05-13 15:38:47,110:INFO:Importing libraries
2025-05-13 15:38:47,110:INFO:Copying training dataset
2025-05-13 15:38:47,123:INFO:Defining folds
2025-05-13 15:38:47,123:INFO:Declaring metric variables
2025-05-13 15:38:47,124:INFO:Importing untrained model
2025-05-13 15:38:47,125:INFO:Logistic Regression Imported successfully
2025-05-13 15:38:47,128:INFO:Starting cross validation
2025-05-13 15:38:47,129:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:38:52,369:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,423:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,438:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,454:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,493:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:38:52,549:INFO:Calculating mean and std
2025-05-13 15:38:52,551:INFO:Creating metrics dataframe
2025-05-13 15:38:52,552:INFO:Uploading results into container
2025-05-13 15:38:52,553:INFO:Uploading model into container now
2025-05-13 15:38:52,553:INFO:_master_model_container: 1
2025-05-13 15:38:52,553:INFO:_display_container: 2
2025-05-13 15:38:52,554:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-13 15:38:52,554:INFO:create_model() successfully completed......................................
2025-05-13 15:38:52,612:INFO:SubProcess create_model() end ==================================
2025-05-13 15:38:52,613:INFO:Creating metrics dataframe
2025-05-13 15:38:52,615:INFO:Initializing K Neighbors Classifier
2025-05-13 15:38:52,615:INFO:Total runtime is 0.09178495407104492 minutes
2025-05-13 15:38:52,617:INFO:SubProcess create_model() called ==================================
2025-05-13 15:38:52,617:INFO:Initializing create_model()
2025-05-13 15:38:52,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:38:52,617:INFO:Checking exceptions
2025-05-13 15:38:52,617:INFO:Importing libraries
2025-05-13 15:38:52,617:INFO:Copying training dataset
2025-05-13 15:38:52,626:INFO:Defining folds
2025-05-13 15:38:52,626:INFO:Declaring metric variables
2025-05-13 15:38:52,627:INFO:Importing untrained model
2025-05-13 15:38:52,629:INFO:K Neighbors Classifier Imported successfully
2025-05-13 15:38:52,631:INFO:Starting cross validation
2025-05-13 15:38:52,632:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:38:58,431:INFO:Calculating mean and std
2025-05-13 15:38:58,433:INFO:Creating metrics dataframe
2025-05-13 15:38:58,438:INFO:Uploading results into container
2025-05-13 15:38:58,438:INFO:Uploading model into container now
2025-05-13 15:38:58,439:INFO:_master_model_container: 2
2025-05-13 15:38:58,439:INFO:_display_container: 2
2025-05-13 15:38:58,440:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-13 15:38:58,440:INFO:create_model() successfully completed......................................
2025-05-13 15:38:58,526:INFO:SubProcess create_model() end ==================================
2025-05-13 15:38:58,526:INFO:Creating metrics dataframe
2025-05-13 15:38:58,530:INFO:Initializing Naive Bayes
2025-05-13 15:38:58,530:INFO:Total runtime is 0.1903595010439555 minutes
2025-05-13 15:38:58,531:INFO:SubProcess create_model() called ==================================
2025-05-13 15:38:58,531:INFO:Initializing create_model()
2025-05-13 15:38:58,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:38:58,531:INFO:Checking exceptions
2025-05-13 15:38:58,532:INFO:Importing libraries
2025-05-13 15:38:58,532:INFO:Copying training dataset
2025-05-13 15:38:58,542:INFO:Defining folds
2025-05-13 15:38:58,542:INFO:Declaring metric variables
2025-05-13 15:38:58,543:INFO:Importing untrained model
2025-05-13 15:38:58,544:INFO:Naive Bayes Imported successfully
2025-05-13 15:38:58,547:INFO:Starting cross validation
2025-05-13 15:38:58,548:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:00,749:INFO:Calculating mean and std
2025-05-13 15:39:00,749:INFO:Creating metrics dataframe
2025-05-13 15:39:00,750:INFO:Uploading results into container
2025-05-13 15:39:00,751:INFO:Uploading model into container now
2025-05-13 15:39:00,751:INFO:_master_model_container: 3
2025-05-13 15:39:00,751:INFO:_display_container: 2
2025-05-13 15:39:00,751:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-13 15:39:00,751:INFO:create_model() successfully completed......................................
2025-05-13 15:39:00,821:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:00,821:INFO:Creating metrics dataframe
2025-05-13 15:39:00,825:INFO:Initializing Decision Tree Classifier
2025-05-13 15:39:00,825:INFO:Total runtime is 0.2286062002182007 minutes
2025-05-13 15:39:00,826:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:00,826:INFO:Initializing create_model()
2025-05-13 15:39:00,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:00,826:INFO:Checking exceptions
2025-05-13 15:39:00,826:INFO:Importing libraries
2025-05-13 15:39:00,826:INFO:Copying training dataset
2025-05-13 15:39:00,835:INFO:Defining folds
2025-05-13 15:39:00,835:INFO:Declaring metric variables
2025-05-13 15:39:00,836:INFO:Importing untrained model
2025-05-13 15:39:00,837:INFO:Decision Tree Classifier Imported successfully
2025-05-13 15:39:00,839:INFO:Starting cross validation
2025-05-13 15:39:00,841:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:02,424:INFO:Calculating mean and std
2025-05-13 15:39:02,425:INFO:Creating metrics dataframe
2025-05-13 15:39:02,426:INFO:Uploading results into container
2025-05-13 15:39:02,426:INFO:Uploading model into container now
2025-05-13 15:39:02,426:INFO:_master_model_container: 4
2025-05-13 15:39:02,427:INFO:_display_container: 2
2025-05-13 15:39:02,427:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-13 15:39:02,427:INFO:create_model() successfully completed......................................
2025-05-13 15:39:02,470:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:02,471:INFO:Creating metrics dataframe
2025-05-13 15:39:02,474:INFO:Initializing SVM - Linear Kernel
2025-05-13 15:39:02,474:INFO:Total runtime is 0.2560910701751709 minutes
2025-05-13 15:39:02,475:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:02,475:INFO:Initializing create_model()
2025-05-13 15:39:02,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:02,475:INFO:Checking exceptions
2025-05-13 15:39:02,475:INFO:Importing libraries
2025-05-13 15:39:02,475:INFO:Copying training dataset
2025-05-13 15:39:02,484:INFO:Defining folds
2025-05-13 15:39:02,484:INFO:Declaring metric variables
2025-05-13 15:39:02,485:INFO:Importing untrained model
2025-05-13 15:39:02,487:INFO:SVM - Linear Kernel Imported successfully
2025-05-13 15:39:02,489:INFO:Starting cross validation
2025-05-13 15:39:02,490:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:06,111:INFO:Calculating mean and std
2025-05-13 15:39:06,114:INFO:Creating metrics dataframe
2025-05-13 15:39:06,118:INFO:Uploading results into container
2025-05-13 15:39:06,119:INFO:Uploading model into container now
2025-05-13 15:39:06,119:INFO:_master_model_container: 5
2025-05-13 15:39:06,119:INFO:_display_container: 2
2025-05-13 15:39:06,120:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-13 15:39:06,120:INFO:create_model() successfully completed......................................
2025-05-13 15:39:06,209:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:06,209:INFO:Creating metrics dataframe
2025-05-13 15:39:06,213:INFO:Initializing Ridge Classifier
2025-05-13 15:39:06,213:INFO:Total runtime is 0.3184064189592997 minutes
2025-05-13 15:39:06,214:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:06,214:INFO:Initializing create_model()
2025-05-13 15:39:06,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:06,214:INFO:Checking exceptions
2025-05-13 15:39:06,214:INFO:Importing libraries
2025-05-13 15:39:06,215:INFO:Copying training dataset
2025-05-13 15:39:06,226:INFO:Defining folds
2025-05-13 15:39:06,226:INFO:Declaring metric variables
2025-05-13 15:39:06,227:INFO:Importing untrained model
2025-05-13 15:39:06,228:INFO:Ridge Classifier Imported successfully
2025-05-13 15:39:06,230:INFO:Starting cross validation
2025-05-13 15:39:06,231:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:07,261:INFO:Calculating mean and std
2025-05-13 15:39:07,261:INFO:Creating metrics dataframe
2025-05-13 15:39:07,263:INFO:Uploading results into container
2025-05-13 15:39:07,263:INFO:Uploading model into container now
2025-05-13 15:39:07,263:INFO:_master_model_container: 6
2025-05-13 15:39:07,263:INFO:_display_container: 2
2025-05-13 15:39:07,263:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-13 15:39:07,263:INFO:create_model() successfully completed......................................
2025-05-13 15:39:07,310:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:07,310:INFO:Creating metrics dataframe
2025-05-13 15:39:07,313:INFO:Initializing Random Forest Classifier
2025-05-13 15:39:07,313:INFO:Total runtime is 0.3367486516634623 minutes
2025-05-13 15:39:07,314:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:07,314:INFO:Initializing create_model()
2025-05-13 15:39:07,315:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:07,315:INFO:Checking exceptions
2025-05-13 15:39:07,315:INFO:Importing libraries
2025-05-13 15:39:07,315:INFO:Copying training dataset
2025-05-13 15:39:07,325:INFO:Defining folds
2025-05-13 15:39:07,325:INFO:Declaring metric variables
2025-05-13 15:39:07,326:INFO:Importing untrained model
2025-05-13 15:39:07,327:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:39:07,329:INFO:Starting cross validation
2025-05-13 15:39:07,330:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:13,517:INFO:Calculating mean and std
2025-05-13 15:39:13,524:INFO:Creating metrics dataframe
2025-05-13 15:39:13,529:INFO:Uploading results into container
2025-05-13 15:39:13,529:INFO:Uploading model into container now
2025-05-13 15:39:13,530:INFO:_master_model_container: 7
2025-05-13 15:39:13,530:INFO:_display_container: 2
2025-05-13 15:39:13,531:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:39:13,531:INFO:create_model() successfully completed......................................
2025-05-13 15:39:13,613:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:13,613:INFO:Creating metrics dataframe
2025-05-13 15:39:13,617:INFO:Initializing Quadratic Discriminant Analysis
2025-05-13 15:39:13,617:INFO:Total runtime is 0.4418077707290649 minutes
2025-05-13 15:39:13,618:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:13,618:INFO:Initializing create_model()
2025-05-13 15:39:13,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:13,618:INFO:Checking exceptions
2025-05-13 15:39:13,618:INFO:Importing libraries
2025-05-13 15:39:13,619:INFO:Copying training dataset
2025-05-13 15:39:13,635:INFO:Defining folds
2025-05-13 15:39:13,635:INFO:Declaring metric variables
2025-05-13 15:39:13,637:INFO:Importing untrained model
2025-05-13 15:39:13,639:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-13 15:39:13,641:INFO:Starting cross validation
2025-05-13 15:39:13,642:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:14,572:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:14,604:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:14,626:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:14,637:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:14,643:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:14,694:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:14,703:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:15,990:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:39:16,051:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:16,062:INFO:Calculating mean and std
2025-05-13 15:39:16,063:INFO:Creating metrics dataframe
2025-05-13 15:39:16,064:INFO:Uploading results into container
2025-05-13 15:39:16,064:INFO:Uploading model into container now
2025-05-13 15:39:16,064:INFO:_master_model_container: 8
2025-05-13 15:39:16,064:INFO:_display_container: 2
2025-05-13 15:39:16,064:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-13 15:39:16,064:INFO:create_model() successfully completed......................................
2025-05-13 15:39:16,109:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:16,109:INFO:Creating metrics dataframe
2025-05-13 15:39:16,112:INFO:Initializing Ada Boost Classifier
2025-05-13 15:39:16,112:INFO:Total runtime is 0.48340231974919634 minutes
2025-05-13 15:39:16,114:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:16,114:INFO:Initializing create_model()
2025-05-13 15:39:16,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:16,114:INFO:Checking exceptions
2025-05-13 15:39:16,114:INFO:Importing libraries
2025-05-13 15:39:16,114:INFO:Copying training dataset
2025-05-13 15:39:16,129:INFO:Defining folds
2025-05-13 15:39:16,129:INFO:Declaring metric variables
2025-05-13 15:39:16,130:INFO:Importing untrained model
2025-05-13 15:39:16,132:INFO:Ada Boost Classifier Imported successfully
2025-05-13 15:39:16,134:INFO:Starting cross validation
2025-05-13 15:39:16,135:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:17,048:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:17,069:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:17,089:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:17,096:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:17,097:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:39:19,884:INFO:Calculating mean and std
2025-05-13 15:39:19,888:INFO:Creating metrics dataframe
2025-05-13 15:39:19,894:INFO:Uploading results into container
2025-05-13 15:39:19,895:INFO:Uploading model into container now
2025-05-13 15:39:19,895:INFO:_master_model_container: 9
2025-05-13 15:39:19,896:INFO:_display_container: 2
2025-05-13 15:39:19,896:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-13 15:39:19,896:INFO:create_model() successfully completed......................................
2025-05-13 15:39:19,990:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:19,991:INFO:Creating metrics dataframe
2025-05-13 15:39:19,995:INFO:Initializing Gradient Boosting Classifier
2025-05-13 15:39:19,995:INFO:Total runtime is 0.5481151382128397 minutes
2025-05-13 15:39:19,997:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:19,997:INFO:Initializing create_model()
2025-05-13 15:39:19,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:19,997:INFO:Checking exceptions
2025-05-13 15:39:19,997:INFO:Importing libraries
2025-05-13 15:39:19,997:INFO:Copying training dataset
2025-05-13 15:39:20,012:INFO:Defining folds
2025-05-13 15:39:20,012:INFO:Declaring metric variables
2025-05-13 15:39:20,014:INFO:Importing untrained model
2025-05-13 15:39:20,016:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:39:20,018:INFO:Starting cross validation
2025-05-13 15:39:20,020:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:32,940:INFO:Calculating mean and std
2025-05-13 15:39:32,941:INFO:Creating metrics dataframe
2025-05-13 15:39:32,942:INFO:Uploading results into container
2025-05-13 15:39:32,942:INFO:Uploading model into container now
2025-05-13 15:39:32,943:INFO:_master_model_container: 10
2025-05-13 15:39:32,943:INFO:_display_container: 2
2025-05-13 15:39:32,943:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:39:32,943:INFO:create_model() successfully completed......................................
2025-05-13 15:39:32,990:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:32,990:INFO:Creating metrics dataframe
2025-05-13 15:39:32,994:INFO:Initializing Linear Discriminant Analysis
2025-05-13 15:39:32,994:INFO:Total runtime is 0.7647580186525981 minutes
2025-05-13 15:39:32,995:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:32,995:INFO:Initializing create_model()
2025-05-13 15:39:32,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:32,995:INFO:Checking exceptions
2025-05-13 15:39:32,995:INFO:Importing libraries
2025-05-13 15:39:32,995:INFO:Copying training dataset
2025-05-13 15:39:33,005:INFO:Defining folds
2025-05-13 15:39:33,005:INFO:Declaring metric variables
2025-05-13 15:39:33,007:INFO:Importing untrained model
2025-05-13 15:39:33,008:INFO:Linear Discriminant Analysis Imported successfully
2025-05-13 15:39:33,010:INFO:Starting cross validation
2025-05-13 15:39:33,011:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:34,122:INFO:Calculating mean and std
2025-05-13 15:39:34,123:INFO:Creating metrics dataframe
2025-05-13 15:39:34,124:INFO:Uploading results into container
2025-05-13 15:39:34,124:INFO:Uploading model into container now
2025-05-13 15:39:34,124:INFO:_master_model_container: 11
2025-05-13 15:39:34,124:INFO:_display_container: 2
2025-05-13 15:39:34,125:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-13 15:39:34,125:INFO:create_model() successfully completed......................................
2025-05-13 15:39:34,166:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:34,166:INFO:Creating metrics dataframe
2025-05-13 15:39:34,171:INFO:Initializing Extra Trees Classifier
2025-05-13 15:39:34,171:INFO:Total runtime is 0.7843758344650269 minutes
2025-05-13 15:39:34,172:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:34,172:INFO:Initializing create_model()
2025-05-13 15:39:34,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:34,172:INFO:Checking exceptions
2025-05-13 15:39:34,172:INFO:Importing libraries
2025-05-13 15:39:34,172:INFO:Copying training dataset
2025-05-13 15:39:34,182:INFO:Defining folds
2025-05-13 15:39:34,182:INFO:Declaring metric variables
2025-05-13 15:39:34,184:INFO:Importing untrained model
2025-05-13 15:39:34,185:INFO:Extra Trees Classifier Imported successfully
2025-05-13 15:39:34,187:INFO:Starting cross validation
2025-05-13 15:39:34,188:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:38,694:INFO:Calculating mean and std
2025-05-13 15:39:38,698:INFO:Creating metrics dataframe
2025-05-13 15:39:38,704:INFO:Uploading results into container
2025-05-13 15:39:38,705:INFO:Uploading model into container now
2025-05-13 15:39:38,706:INFO:_master_model_container: 12
2025-05-13 15:39:38,706:INFO:_display_container: 2
2025-05-13 15:39:38,707:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-13 15:39:38,708:INFO:create_model() successfully completed......................................
2025-05-13 15:39:38,816:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:38,816:INFO:Creating metrics dataframe
2025-05-13 15:39:38,820:INFO:Initializing Light Gradient Boosting Machine
2025-05-13 15:39:38,820:INFO:Total runtime is 0.8618667523066204 minutes
2025-05-13 15:39:38,822:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:38,822:INFO:Initializing create_model()
2025-05-13 15:39:38,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:38,822:INFO:Checking exceptions
2025-05-13 15:39:38,822:INFO:Importing libraries
2025-05-13 15:39:38,822:INFO:Copying training dataset
2025-05-13 15:39:38,838:INFO:Defining folds
2025-05-13 15:39:38,838:INFO:Declaring metric variables
2025-05-13 15:39:38,840:INFO:Importing untrained model
2025-05-13 15:39:38,841:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:39:38,844:INFO:Starting cross validation
2025-05-13 15:39:38,845:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:43,198:INFO:Calculating mean and std
2025-05-13 15:39:43,199:INFO:Creating metrics dataframe
2025-05-13 15:39:43,200:INFO:Uploading results into container
2025-05-13 15:39:43,201:INFO:Uploading model into container now
2025-05-13 15:39:43,201:INFO:_master_model_container: 13
2025-05-13 15:39:43,201:INFO:_display_container: 2
2025-05-13 15:39:43,202:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:39:43,202:INFO:create_model() successfully completed......................................
2025-05-13 15:39:43,256:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:43,256:INFO:Creating metrics dataframe
2025-05-13 15:39:43,260:INFO:Initializing Dummy Classifier
2025-05-13 15:39:43,260:INFO:Total runtime is 0.9358652194341024 minutes
2025-05-13 15:39:43,261:INFO:SubProcess create_model() called ==================================
2025-05-13 15:39:43,262:INFO:Initializing create_model()
2025-05-13 15:39:43,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325f3c910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:43,262:INFO:Checking exceptions
2025-05-13 15:39:43,262:INFO:Importing libraries
2025-05-13 15:39:43,262:INFO:Copying training dataset
2025-05-13 15:39:43,271:INFO:Defining folds
2025-05-13 15:39:43,271:INFO:Declaring metric variables
2025-05-13 15:39:43,273:INFO:Importing untrained model
2025-05-13 15:39:43,274:INFO:Dummy Classifier Imported successfully
2025-05-13 15:39:43,276:INFO:Starting cross validation
2025-05-13 15:39:43,277:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:39:44,246:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,246:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,257:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,268:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,343:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:39:44,362:INFO:Calculating mean and std
2025-05-13 15:39:44,363:INFO:Creating metrics dataframe
2025-05-13 15:39:44,365:INFO:Uploading results into container
2025-05-13 15:39:44,365:INFO:Uploading model into container now
2025-05-13 15:39:44,365:INFO:_master_model_container: 14
2025-05-13 15:39:44,365:INFO:_display_container: 2
2025-05-13 15:39:44,365:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-13 15:39:44,366:INFO:create_model() successfully completed......................................
2025-05-13 15:39:44,413:INFO:SubProcess create_model() end ==================================
2025-05-13 15:39:44,413:INFO:Creating metrics dataframe
2025-05-13 15:39:44,419:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-13 15:39:44,422:INFO:Initializing create_model()
2025-05-13 15:39:44,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:39:44,422:INFO:Checking exceptions
2025-05-13 15:39:44,423:INFO:Importing libraries
2025-05-13 15:39:44,423:INFO:Copying training dataset
2025-05-13 15:39:44,432:INFO:Defining folds
2025-05-13 15:39:44,432:INFO:Declaring metric variables
2025-05-13 15:39:44,432:INFO:Importing untrained model
2025-05-13 15:39:44,432:INFO:Declaring custom model
2025-05-13 15:39:44,432:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:39:44,433:INFO:Cross validation set to False
2025-05-13 15:39:44,433:INFO:Fitting Model
2025-05-13 15:40:00,069:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:40:00,070:INFO:create_model() successfully completed......................................
2025-05-13 15:40:00,121:INFO:Initializing create_model()
2025-05-13 15:40:00,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:40:00,121:INFO:Checking exceptions
2025-05-13 15:40:00,122:INFO:Importing libraries
2025-05-13 15:40:00,122:INFO:Copying training dataset
2025-05-13 15:40:00,131:INFO:Defining folds
2025-05-13 15:40:00,131:INFO:Declaring metric variables
2025-05-13 15:40:00,131:INFO:Importing untrained model
2025-05-13 15:40:00,131:INFO:Declaring custom model
2025-05-13 15:40:00,132:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:40:00,132:INFO:Cross validation set to False
2025-05-13 15:40:00,132:INFO:Fitting Model
2025-05-13 15:40:01,091:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-13 15:40:01,104:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008033 seconds.
2025-05-13 15:40:01,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-13 15:40:01,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-13 15:40:01,104:INFO:[LightGBM] [Info] Total Bins 6630
2025-05-13 15:40:01,104:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 26
2025-05-13 15:40:01,104:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-13 15:40:01,859:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:40:01,859:INFO:create_model() successfully completed......................................
2025-05-13 15:40:01,908:INFO:Initializing create_model()
2025-05-13 15:40:01,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:40:01,908:INFO:Checking exceptions
2025-05-13 15:40:01,909:INFO:Importing libraries
2025-05-13 15:40:01,909:INFO:Copying training dataset
2025-05-13 15:40:01,919:INFO:Defining folds
2025-05-13 15:40:01,919:INFO:Declaring metric variables
2025-05-13 15:40:01,919:INFO:Importing untrained model
2025-05-13 15:40:01,919:INFO:Declaring custom model
2025-05-13 15:40:01,919:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:40:01,920:INFO:Cross validation set to False
2025-05-13 15:40:01,920:INFO:Fitting Model
2025-05-13 15:40:04,311:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:40:04,311:INFO:create_model() successfully completed......................................
2025-05-13 15:40:04,360:INFO:_master_model_container: 14
2025-05-13 15:40:04,360:INFO:_display_container: 2
2025-05-13 15:40:04,360:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-13 15:40:04,361:INFO:compare_models() successfully completed......................................
2025-05-13 15:40:04,361:INFO:Initializing evaluate_model()
2025-05-13 15:40:04,361:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:40:04,367:INFO:Initializing plot_model()
2025-05-13 15:40:04,367:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:40:04,367:INFO:Checking exceptions
2025-05-13 15:40:04,371:INFO:Preloading libraries
2025-05-13 15:40:04,374:INFO:Copying training dataset
2025-05-13 15:40:04,374:INFO:Plot type: pipeline
2025-05-13 15:40:04,461:INFO:Visual Rendered Successfully
2025-05-13 15:40:04,506:INFO:plot_model() successfully completed......................................
2025-05-13 15:40:04,508:INFO:Initializing tune_model()
2025-05-13 15:40:04,508:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-13 15:40:04,508:INFO:Checking exceptions
2025-05-13 15:40:04,516:INFO:Copying training dataset
2025-05-13 15:40:04,523:INFO:Checking base model
2025-05-13 15:40:04,523:INFO:Base model : Gradient Boosting Classifier
2025-05-13 15:40:04,524:INFO:Declaring metric variables
2025-05-13 15:40:04,525:INFO:Defining Hyperparameters
2025-05-13 15:40:04,569:INFO:Tuning with n_jobs=-1
2025-05-13 15:40:04,569:INFO:Initializing RandomizedSearchCV
2025-05-13 15:40:45,144:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-13 15:40:45,149:INFO:Hyperparameter search completed
2025-05-13 15:40:45,149:INFO:SubProcess create_model() called ==================================
2025-05-13 15:40:45,150:INFO:Initializing create_model()
2025-05-13 15:40:45,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325fb0410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-13 15:40:45,150:INFO:Checking exceptions
2025-05-13 15:40:45,150:INFO:Importing libraries
2025-05-13 15:40:45,150:INFO:Copying training dataset
2025-05-13 15:40:45,163:INFO:Defining folds
2025-05-13 15:40:45,163:INFO:Declaring metric variables
2025-05-13 15:40:45,166:INFO:Importing untrained model
2025-05-13 15:40:45,166:INFO:Declaring custom model
2025-05-13 15:40:45,169:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:40:45,171:INFO:Starting cross validation
2025-05-13 15:40:45,174:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:40:54,838:INFO:Calculating mean and std
2025-05-13 15:40:54,839:INFO:Creating metrics dataframe
2025-05-13 15:40:54,842:INFO:Finalizing model
2025-05-13 15:41:05,382:INFO:Uploading results into container
2025-05-13 15:41:05,383:INFO:Uploading model into container now
2025-05-13 15:41:05,384:INFO:_master_model_container: 15
2025-05-13 15:41:05,384:INFO:_display_container: 3
2025-05-13 15:41:05,384:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:41:05,384:INFO:create_model() successfully completed......................................
2025-05-13 15:41:05,481:INFO:SubProcess create_model() end ==================================
2025-05-13 15:41:05,481:INFO:choose_better activated
2025-05-13 15:41:05,483:INFO:SubProcess create_model() called ==================================
2025-05-13 15:41:05,483:INFO:Initializing create_model()
2025-05-13 15:41:05,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:41:05,485:INFO:Checking exceptions
2025-05-13 15:41:05,486:INFO:Importing libraries
2025-05-13 15:41:05,486:INFO:Copying training dataset
2025-05-13 15:41:05,496:INFO:Defining folds
2025-05-13 15:41:05,496:INFO:Declaring metric variables
2025-05-13 15:41:05,496:INFO:Importing untrained model
2025-05-13 15:41:05,496:INFO:Declaring custom model
2025-05-13 15:41:05,496:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:41:05,496:INFO:Starting cross validation
2025-05-13 15:41:05,497:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:41:18,521:INFO:Calculating mean and std
2025-05-13 15:41:18,522:INFO:Creating metrics dataframe
2025-05-13 15:41:18,525:INFO:Finalizing model
2025-05-13 15:41:34,251:INFO:Uploading results into container
2025-05-13 15:41:34,251:INFO:Uploading model into container now
2025-05-13 15:41:34,252:INFO:_master_model_container: 16
2025-05-13 15:41:34,252:INFO:_display_container: 4
2025-05-13 15:41:34,252:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:41:34,252:INFO:create_model() successfully completed......................................
2025-05-13 15:41:34,332:INFO:SubProcess create_model() end ==================================
2025-05-13 15:41:34,333:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4809
2025-05-13 15:41:34,333:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4906
2025-05-13 15:41:34,333:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-13 15:41:34,333:INFO:choose_better completed
2025-05-13 15:41:34,337:INFO:_master_model_container: 16
2025-05-13 15:41:34,337:INFO:_display_container: 3
2025-05-13 15:41:34,337:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:41:34,337:INFO:tune_model() successfully completed......................................
2025-05-13 15:41:34,387:INFO:Initializing evaluate_model()
2025-05-13 15:41:34,387:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:41:34,395:INFO:Initializing plot_model()
2025-05-13 15:41:34,395:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:41:34,395:INFO:Checking exceptions
2025-05-13 15:41:34,401:INFO:Preloading libraries
2025-05-13 15:41:34,410:INFO:Copying training dataset
2025-05-13 15:41:34,410:INFO:Plot type: pipeline
2025-05-13 15:41:34,473:INFO:Visual Rendered Successfully
2025-05-13 15:41:34,517:INFO:plot_model() successfully completed......................................
2025-05-13 15:41:34,519:INFO:Initializing interpret_model()
2025-05-13 15:41:34,519:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-13 15:41:34,519:INFO:Checking exceptions
2025-05-13 15:41:34,519:INFO:Soft dependency imported: shap: 0.47.2
2025-05-13 15:41:34,802:INFO:Initializing finalize_model()
2025-05-13 15:41:34,802:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-13 15:41:34,802:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:41:34,806:INFO:Initializing create_model()
2025-05-13 15:41:34,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:41:34,806:INFO:Checking exceptions
2025-05-13 15:41:34,807:INFO:Importing libraries
2025-05-13 15:41:34,807:INFO:Copying training dataset
2025-05-13 15:41:34,807:INFO:Defining folds
2025-05-13 15:41:34,807:INFO:Declaring metric variables
2025-05-13 15:41:34,807:INFO:Importing untrained model
2025-05-13 15:41:34,807:INFO:Declaring custom model
2025-05-13 15:41:34,807:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:41:34,809:INFO:Cross validation set to False
2025-05-13 15:41:34,809:INFO:Fitting Model
2025-05-13 15:41:50,493:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:41:50,494:INFO:create_model() successfully completed......................................
2025-05-13 15:41:50,544:INFO:_master_model_container: 16
2025-05-13 15:41:50,544:INFO:_display_container: 3
2025-05-13 15:41:50,560:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:41:50,560:INFO:finalize_model() successfully completed......................................
2025-05-13 15:41:50,638:INFO:Initializing save_model()
2025-05-13 15:41:50,638:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-13 15:41:50,638:INFO:Adding model into prep_pipe
2025-05-13 15:41:50,638:WARNING:Only Model saved as it was a pipeline.
2025-05-13 15:41:50,661:INFO:final_cancer_model.pkl saved in current working directory
2025-05-13 15:41:50,677:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:41:50,677:INFO:save_model() successfully completed......................................
2025-05-13 15:41:50,739:INFO:Initializing predict_model()
2025-05-13 15:41:50,739:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x325f053a0>)
2025-05-13 15:41:50,739:INFO:Checking exceptions
2025-05-13 15:41:50,739:INFO:Preloading libraries
2025-05-13 15:41:50,740:INFO:Set up data.
2025-05-13 15:41:50,754:INFO:Set up index.
2025-05-13 15:41:51,535:INFO:Initializing blend_models()
2025-05-13 15:41:51,535:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-13 15:41:51,535:INFO:Checking exceptions
2025-05-13 15:41:51,544:INFO:Importing libraries
2025-05-13 15:41:51,544:INFO:Copying training dataset
2025-05-13 15:41:51,545:INFO:Getting model names
2025-05-13 15:41:51,546:INFO:SubProcess create_model() called ==================================
2025-05-13 15:41:51,548:INFO:Initializing create_model()
2025-05-13 15:41:51,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x325feed50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:41:51,548:INFO:Checking exceptions
2025-05-13 15:41:51,548:INFO:Importing libraries
2025-05-13 15:41:51,548:INFO:Copying training dataset
2025-05-13 15:41:51,557:INFO:Defining folds
2025-05-13 15:41:51,557:INFO:Declaring metric variables
2025-05-13 15:41:51,558:INFO:Importing untrained model
2025-05-13 15:41:51,558:INFO:Declaring custom model
2025-05-13 15:41:51,560:INFO:Voting Classifier Imported successfully
2025-05-13 15:41:51,562:INFO:Starting cross validation
2025-05-13 15:41:51,563:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:42:08,254:INFO:Calculating mean and std
2025-05-13 15:42:08,257:INFO:Creating metrics dataframe
2025-05-13 15:42:08,271:INFO:Finalizing model
2025-05-13 15:42:24,806:INFO:Uploading results into container
2025-05-13 15:42:24,810:INFO:Uploading model into container now
2025-05-13 15:42:24,810:INFO:_master_model_container: 17
2025-05-13 15:42:24,810:INFO:_display_container: 4
2025-05-13 15:42:24,814:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-13 15:42:24,814:INFO:create_model() successfully completed......................................
2025-05-13 15:42:24,927:INFO:SubProcess create_model() end ==================================
2025-05-13 15:42:24,931:INFO:_master_model_container: 17
2025-05-13 15:42:24,931:INFO:_display_container: 4
2025-05-13 15:42:24,933:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-13 15:42:24,933:INFO:blend_models() successfully completed......................................
2025-05-13 15:42:24,988:INFO:Initializing evaluate_model()
2025-05-13 15:42:24,988:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:42:25,000:INFO:Initializing plot_model()
2025-05-13 15:42:25,000:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:42:25,000:INFO:Checking exceptions
2025-05-13 15:42:25,005:INFO:Preloading libraries
2025-05-13 15:42:25,135:INFO:Copying training dataset
2025-05-13 15:42:25,135:INFO:Plot type: pipeline
2025-05-13 15:42:25,195:INFO:Visual Rendered Successfully
2025-05-13 15:42:25,244:INFO:plot_model() successfully completed......................................
2025-05-13 15:42:25,253:INFO:Initializing predict_model()
2025-05-13 15:42:25,253:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x32fb43600>)
2025-05-13 15:42:25,253:INFO:Checking exceptions
2025-05-13 15:42:25,253:INFO:Preloading libraries
2025-05-13 15:42:25,254:INFO:Set up data.
2025-05-13 15:42:25,269:INFO:Set up index.
2025-05-13 15:42:25,839:INFO:Initializing plot_model()
2025-05-13 15:42:25,839:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:42:25,839:INFO:Checking exceptions
2025-05-13 15:42:25,844:INFO:Preloading libraries
2025-05-13 15:42:25,847:INFO:Copying training dataset
2025-05-13 15:42:25,847:INFO:Plot type: confusion_matrix
2025-05-13 15:42:26,040:INFO:Fitting Model
2025-05-13 15:42:26,042:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:42:26,043:INFO:Scoring test/hold-out set
2025-05-13 15:42:26,117:INFO:Visual Rendered Successfully
2025-05-13 15:42:26,166:INFO:plot_model() successfully completed......................................
2025-05-13 15:42:26,167:INFO:Initializing plot_model()
2025-05-13 15:42:26,167:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:42:26,167:INFO:Checking exceptions
2025-05-13 15:42:26,171:INFO:Preloading libraries
2025-05-13 15:42:26,174:INFO:Copying training dataset
2025-05-13 15:42:26,175:INFO:Plot type: auc
2025-05-13 15:42:26,361:INFO:Fitting Model
2025-05-13 15:42:26,362:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:42:26,363:INFO:Scoring test/hold-out set
2025-05-13 15:42:26,474:INFO:Visual Rendered Successfully
2025-05-13 15:42:26,521:INFO:plot_model() successfully completed......................................
2025-05-13 15:42:26,521:INFO:Initializing plot_model()
2025-05-13 15:42:26,521:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3238db190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:42:26,521:INFO:Checking exceptions
2025-05-13 15:42:26,527:INFO:Preloading libraries
2025-05-13 15:42:26,530:INFO:Copying training dataset
2025-05-13 15:42:26,530:INFO:Plot type: feature
2025-05-13 15:42:26,531:WARNING:No coef_ found. Trying feature_importances_
2025-05-13 15:42:26,599:INFO:Visual Rendered Successfully
2025-05-13 15:42:26,648:INFO:plot_model() successfully completed......................................
2025-05-13 15:46:43,301:INFO:PyCaret ClassificationExperiment
2025-05-13 15:46:43,301:INFO:Logging name: clf-default-name
2025-05-13 15:46:43,301:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-13 15:46:43,301:INFO:version 3.3.2
2025-05-13 15:46:43,301:INFO:Initializing setup()
2025-05-13 15:46:43,301:INFO:self.USI: 6f06
2025-05-13 15:46:43,301:INFO:self._variable_keys: {'fold_groups_param', 'html_param', 'USI', 'fix_imbalance', 'log_plots_param', 'idx', 'fold_generator', 'exp_name_log', 'exp_id', 'y', 'is_multiclass', 'memory', 'gpu_param', 'y_test', 'pipeline', 'seed', '_ml_usecase', 'X_train', 'gpu_n_jobs_param', 'y_train', 'fold_shuffle_param', 'X', 'data', '_available_plots', 'X_test', 'target_param', 'n_jobs_param', 'logging_param'}
2025-05-13 15:46:43,301:INFO:Checking environment
2025-05-13 15:46:43,301:INFO:python_version: 3.11.0
2025-05-13 15:46:43,301:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-13 15:46:43,301:INFO:machine: arm64
2025-05-13 15:46:43,301:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:46:43,302:INFO:Memory: svmem(total=17179869184, available=3750920192, percent=78.2, used=6131138560, free=61603840, active=3702865920, inactive=3663511552, wired=2428272640)
2025-05-13 15:46:43,302:INFO:Physical Core: 12
2025-05-13 15:46:43,302:INFO:Logical Core: 12
2025-05-13 15:46:43,302:INFO:Checking libraries
2025-05-13 15:46:43,302:INFO:System:
2025-05-13 15:46:43,302:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-13 15:46:43,302:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-13 15:46:43,302:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:46:43,302:INFO:PyCaret required dependencies:
2025-05-13 15:46:43,302:INFO:                 pip: 22.3
2025-05-13 15:46:43,302:INFO:          setuptools: 65.5.0
2025-05-13 15:46:43,302:INFO:             pycaret: 3.3.2
2025-05-13 15:46:43,302:INFO:             IPython: 9.2.0
2025-05-13 15:46:43,302:INFO:          ipywidgets: 8.1.7
2025-05-13 15:46:43,302:INFO:                tqdm: 4.67.1
2025-05-13 15:46:43,302:INFO:               numpy: 1.26.4
2025-05-13 15:46:43,302:INFO:              pandas: 2.1.4
2025-05-13 15:46:43,302:INFO:              jinja2: 3.1.6
2025-05-13 15:46:43,302:INFO:               scipy: 1.11.4
2025-05-13 15:46:43,302:INFO:              joblib: 1.3.2
2025-05-13 15:46:43,302:INFO:             sklearn: 1.4.2
2025-05-13 15:46:43,302:INFO:                pyod: 2.0.5
2025-05-13 15:46:43,302:INFO:            imblearn: 0.13.0
2025-05-13 15:46:43,302:INFO:   category_encoders: 2.7.0
2025-05-13 15:46:43,302:INFO:            lightgbm: 4.6.0
2025-05-13 15:46:43,302:INFO:               numba: 0.61.2
2025-05-13 15:46:43,302:INFO:            requests: 2.32.3
2025-05-13 15:46:43,302:INFO:          matplotlib: 3.7.5
2025-05-13 15:46:43,302:INFO:          scikitplot: 0.3.7
2025-05-13 15:46:43,302:INFO:         yellowbrick: 1.5
2025-05-13 15:46:43,302:INFO:              plotly: 5.24.1
2025-05-13 15:46:43,302:INFO:    plotly-resampler: Not installed
2025-05-13 15:46:43,302:INFO:             kaleido: 0.2.1
2025-05-13 15:46:43,302:INFO:           schemdraw: 0.15
2025-05-13 15:46:43,302:INFO:         statsmodels: 0.14.4
2025-05-13 15:46:43,302:INFO:              sktime: 0.26.0
2025-05-13 15:46:43,302:INFO:               tbats: 1.1.3
2025-05-13 15:46:43,302:INFO:            pmdarima: 2.0.4
2025-05-13 15:46:43,302:INFO:              psutil: 7.0.0
2025-05-13 15:46:43,302:INFO:          markupsafe: 3.0.2
2025-05-13 15:46:43,302:INFO:             pickle5: Not installed
2025-05-13 15:46:43,302:INFO:         cloudpickle: 3.1.1
2025-05-13 15:46:43,302:INFO:         deprecation: 2.1.0
2025-05-13 15:46:43,302:INFO:              xxhash: 3.5.0
2025-05-13 15:46:43,302:INFO:           wurlitzer: 3.1.1
2025-05-13 15:46:43,302:INFO:PyCaret optional dependencies:
2025-05-13 15:46:43,302:INFO:                shap: 0.47.2
2025-05-13 15:46:43,302:INFO:           interpret: Not installed
2025-05-13 15:46:43,302:INFO:                umap: Not installed
2025-05-13 15:46:43,302:INFO:     ydata_profiling: Not installed
2025-05-13 15:46:43,302:INFO:  explainerdashboard: Not installed
2025-05-13 15:46:43,302:INFO:             autoviz: Not installed
2025-05-13 15:46:43,302:INFO:           fairlearn: Not installed
2025-05-13 15:46:43,302:INFO:          deepchecks: Not installed
2025-05-13 15:46:43,302:INFO:             xgboost: Not installed
2025-05-13 15:46:43,302:INFO:            catboost: Not installed
2025-05-13 15:46:43,302:INFO:              kmodes: Not installed
2025-05-13 15:46:43,302:INFO:             mlxtend: Not installed
2025-05-13 15:46:43,302:INFO:       statsforecast: Not installed
2025-05-13 15:46:43,302:INFO:        tune_sklearn: Not installed
2025-05-13 15:46:43,302:INFO:                 ray: Not installed
2025-05-13 15:46:43,302:INFO:            hyperopt: Not installed
2025-05-13 15:46:43,302:INFO:              optuna: 4.3.0
2025-05-13 15:46:43,302:INFO:               skopt: Not installed
2025-05-13 15:46:43,302:INFO:              mlflow: Not installed
2025-05-13 15:46:43,302:INFO:              gradio: Not installed
2025-05-13 15:46:43,302:INFO:             fastapi: Not installed
2025-05-13 15:46:43,302:INFO:             uvicorn: Not installed
2025-05-13 15:46:43,302:INFO:              m2cgen: Not installed
2025-05-13 15:46:43,302:INFO:           evidently: Not installed
2025-05-13 15:46:43,302:INFO:               fugue: Not installed
2025-05-13 15:46:43,302:INFO:           streamlit: Not installed
2025-05-13 15:46:43,302:INFO:             prophet: Not installed
2025-05-13 15:46:43,302:INFO:None
2025-05-13 15:46:43,303:INFO:Set up data.
2025-05-13 15:46:43,335:INFO:Set up folding strategy.
2025-05-13 15:46:43,335:INFO:Set up train/test split.
2025-05-13 15:46:43,348:INFO:Set up index.
2025-05-13 15:46:43,349:INFO:Assigning column types.
2025-05-13 15:46:43,352:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-13 15:46:43,370:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,371:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,403:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,404:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,415:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,415:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-13 15:46:43,433:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,462:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:46:43,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,473:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-13 15:46:43,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,504:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:43,534:INFO:Preparing preprocessing pipeline...
2025-05-13 15:46:43,536:INFO:Set up simple imputation.
2025-05-13 15:46:43,542:INFO:Set up encoding of ordinal features.
2025-05-13 15:46:43,553:INFO:Set up encoding of categorical features.
2025-05-13 15:46:43,553:INFO:Set up imbalanced handling.
2025-05-13 15:46:43,553:INFO:Set up column transformation.
2025-05-13 15:46:44,751:INFO:Finished creating preprocessing pipeline.
2025-05-13 15:46:44,770:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-13 15:46:44,770:INFO:Creating final display dataframe.
2025-05-13 15:46:45,311:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 17)
4        Transformed data shape      (106821, 35)
5   Transformed train set shape       (85902, 35)
6    Transformed test set shape       (20919, 35)
7              Numeric features                 6
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              6f06
2025-05-13 15:46:45,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:45,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:45,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:45,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:46:45,374:INFO:setup() successfully completed in 2.08s...............
2025-05-13 15:46:45,375:INFO:Initializing compare_models()
2025-05-13 15:46:45,375:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-13 15:46:45,375:INFO:Checking exceptions
2025-05-13 15:46:45,379:INFO:Preparing display monitor
2025-05-13 15:46:45,388:INFO:Initializing Logistic Regression
2025-05-13 15:46:45,388:INFO:Total runtime is 1.3192494710286458e-06 minutes
2025-05-13 15:46:45,389:INFO:SubProcess create_model() called ==================================
2025-05-13 15:46:45,389:INFO:Initializing create_model()
2025-05-13 15:46:45,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:46:45,389:INFO:Checking exceptions
2025-05-13 15:46:45,389:INFO:Importing libraries
2025-05-13 15:46:45,389:INFO:Copying training dataset
2025-05-13 15:46:45,400:INFO:Defining folds
2025-05-13 15:46:45,400:INFO:Declaring metric variables
2025-05-13 15:46:45,402:INFO:Importing untrained model
2025-05-13 15:46:45,403:INFO:Logistic Regression Imported successfully
2025-05-13 15:46:45,405:INFO:Starting cross validation
2025-05-13 15:46:45,406:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:46:49,918:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:50,095:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:50,115:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:50,134:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:51,151:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:46:51,219:INFO:Calculating mean and std
2025-05-13 15:46:51,220:INFO:Creating metrics dataframe
2025-05-13 15:46:51,222:INFO:Uploading results into container
2025-05-13 15:46:51,222:INFO:Uploading model into container now
2025-05-13 15:46:51,222:INFO:_master_model_container: 1
2025-05-13 15:46:51,222:INFO:_display_container: 2
2025-05-13 15:46:51,223:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-13 15:46:51,223:INFO:create_model() successfully completed......................................
2025-05-13 15:46:51,317:INFO:SubProcess create_model() end ==================================
2025-05-13 15:46:51,317:INFO:Creating metrics dataframe
2025-05-13 15:46:51,320:INFO:Initializing K Neighbors Classifier
2025-05-13 15:46:51,320:INFO:Total runtime is 0.0988743503888448 minutes
2025-05-13 15:46:51,322:INFO:SubProcess create_model() called ==================================
2025-05-13 15:46:51,322:INFO:Initializing create_model()
2025-05-13 15:46:51,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:46:51,322:INFO:Checking exceptions
2025-05-13 15:46:51,322:INFO:Importing libraries
2025-05-13 15:46:51,322:INFO:Copying training dataset
2025-05-13 15:46:51,333:INFO:Defining folds
2025-05-13 15:46:51,333:INFO:Declaring metric variables
2025-05-13 15:46:51,335:INFO:Importing untrained model
2025-05-13 15:46:51,336:INFO:K Neighbors Classifier Imported successfully
2025-05-13 15:46:51,338:INFO:Starting cross validation
2025-05-13 15:46:51,339:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:46:58,123:INFO:Calculating mean and std
2025-05-13 15:46:58,126:INFO:Creating metrics dataframe
2025-05-13 15:46:58,130:INFO:Uploading results into container
2025-05-13 15:46:58,131:INFO:Uploading model into container now
2025-05-13 15:46:58,131:INFO:_master_model_container: 2
2025-05-13 15:46:58,131:INFO:_display_container: 2
2025-05-13 15:46:58,132:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-13 15:46:58,132:INFO:create_model() successfully completed......................................
2025-05-13 15:46:58,193:INFO:SubProcess create_model() end ==================================
2025-05-13 15:46:58,193:INFO:Creating metrics dataframe
2025-05-13 15:46:58,196:INFO:Initializing Naive Bayes
2025-05-13 15:46:58,196:INFO:Total runtime is 0.21347267230351766 minutes
2025-05-13 15:46:58,197:INFO:SubProcess create_model() called ==================================
2025-05-13 15:46:58,197:INFO:Initializing create_model()
2025-05-13 15:46:58,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:46:58,197:INFO:Checking exceptions
2025-05-13 15:46:58,197:INFO:Importing libraries
2025-05-13 15:46:58,198:INFO:Copying training dataset
2025-05-13 15:46:58,209:INFO:Defining folds
2025-05-13 15:46:58,209:INFO:Declaring metric variables
2025-05-13 15:46:58,210:INFO:Importing untrained model
2025-05-13 15:46:58,212:INFO:Naive Bayes Imported successfully
2025-05-13 15:46:58,214:INFO:Starting cross validation
2025-05-13 15:46:58,216:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:00,598:INFO:Calculating mean and std
2025-05-13 15:47:00,599:INFO:Creating metrics dataframe
2025-05-13 15:47:00,601:INFO:Uploading results into container
2025-05-13 15:47:00,601:INFO:Uploading model into container now
2025-05-13 15:47:00,601:INFO:_master_model_container: 3
2025-05-13 15:47:00,601:INFO:_display_container: 2
2025-05-13 15:47:00,601:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-13 15:47:00,602:INFO:create_model() successfully completed......................................
2025-05-13 15:47:00,655:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:00,655:INFO:Creating metrics dataframe
2025-05-13 15:47:00,658:INFO:Initializing Decision Tree Classifier
2025-05-13 15:47:00,658:INFO:Total runtime is 0.2545124689737956 minutes
2025-05-13 15:47:00,660:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:00,660:INFO:Initializing create_model()
2025-05-13 15:47:00,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:00,660:INFO:Checking exceptions
2025-05-13 15:47:00,660:INFO:Importing libraries
2025-05-13 15:47:00,660:INFO:Copying training dataset
2025-05-13 15:47:00,670:INFO:Defining folds
2025-05-13 15:47:00,670:INFO:Declaring metric variables
2025-05-13 15:47:00,671:INFO:Importing untrained model
2025-05-13 15:47:00,673:INFO:Decision Tree Classifier Imported successfully
2025-05-13 15:47:00,675:INFO:Starting cross validation
2025-05-13 15:47:00,677:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:03,679:INFO:Calculating mean and std
2025-05-13 15:47:03,680:INFO:Creating metrics dataframe
2025-05-13 15:47:03,681:INFO:Uploading results into container
2025-05-13 15:47:03,681:INFO:Uploading model into container now
2025-05-13 15:47:03,682:INFO:_master_model_container: 4
2025-05-13 15:47:03,682:INFO:_display_container: 2
2025-05-13 15:47:03,682:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-13 15:47:03,682:INFO:create_model() successfully completed......................................
2025-05-13 15:47:03,771:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:03,771:INFO:Creating metrics dataframe
2025-05-13 15:47:03,774:INFO:Initializing SVM - Linear Kernel
2025-05-13 15:47:03,775:INFO:Total runtime is 0.3064471522967021 minutes
2025-05-13 15:47:03,776:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:03,776:INFO:Initializing create_model()
2025-05-13 15:47:03,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:03,776:INFO:Checking exceptions
2025-05-13 15:47:03,777:INFO:Importing libraries
2025-05-13 15:47:03,777:INFO:Copying training dataset
2025-05-13 15:47:03,786:INFO:Defining folds
2025-05-13 15:47:03,786:INFO:Declaring metric variables
2025-05-13 15:47:03,788:INFO:Importing untrained model
2025-05-13 15:47:03,789:INFO:SVM - Linear Kernel Imported successfully
2025-05-13 15:47:03,791:INFO:Starting cross validation
2025-05-13 15:47:03,793:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:08,285:INFO:Calculating mean and std
2025-05-13 15:47:08,286:INFO:Creating metrics dataframe
2025-05-13 15:47:08,288:INFO:Uploading results into container
2025-05-13 15:47:08,288:INFO:Uploading model into container now
2025-05-13 15:47:08,288:INFO:_master_model_container: 5
2025-05-13 15:47:08,288:INFO:_display_container: 2
2025-05-13 15:47:08,289:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-13 15:47:08,289:INFO:create_model() successfully completed......................................
2025-05-13 15:47:08,350:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:08,350:INFO:Creating metrics dataframe
2025-05-13 15:47:08,354:INFO:Initializing Ridge Classifier
2025-05-13 15:47:08,354:INFO:Total runtime is 0.3827689170837403 minutes
2025-05-13 15:47:08,355:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:08,356:INFO:Initializing create_model()
2025-05-13 15:47:08,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:08,356:INFO:Checking exceptions
2025-05-13 15:47:08,356:INFO:Importing libraries
2025-05-13 15:47:08,356:INFO:Copying training dataset
2025-05-13 15:47:08,365:INFO:Defining folds
2025-05-13 15:47:08,365:INFO:Declaring metric variables
2025-05-13 15:47:08,367:INFO:Importing untrained model
2025-05-13 15:47:08,368:INFO:Ridge Classifier Imported successfully
2025-05-13 15:47:08,371:INFO:Starting cross validation
2025-05-13 15:47:08,372:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:11,116:INFO:Calculating mean and std
2025-05-13 15:47:11,117:INFO:Creating metrics dataframe
2025-05-13 15:47:11,121:INFO:Uploading results into container
2025-05-13 15:47:11,121:INFO:Uploading model into container now
2025-05-13 15:47:11,122:INFO:_master_model_container: 6
2025-05-13 15:47:11,122:INFO:_display_container: 2
2025-05-13 15:47:11,122:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-13 15:47:11,122:INFO:create_model() successfully completed......................................
2025-05-13 15:47:11,217:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:11,217:INFO:Creating metrics dataframe
2025-05-13 15:47:11,220:INFO:Initializing Random Forest Classifier
2025-05-13 15:47:11,220:INFO:Total runtime is 0.4305449684460958 minutes
2025-05-13 15:47:11,222:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:11,222:INFO:Initializing create_model()
2025-05-13 15:47:11,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:11,222:INFO:Checking exceptions
2025-05-13 15:47:11,222:INFO:Importing libraries
2025-05-13 15:47:11,222:INFO:Copying training dataset
2025-05-13 15:47:11,235:INFO:Defining folds
2025-05-13 15:47:11,235:INFO:Declaring metric variables
2025-05-13 15:47:11,236:INFO:Importing untrained model
2025-05-13 15:47:11,238:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:47:11,240:INFO:Starting cross validation
2025-05-13 15:47:11,242:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:17,420:INFO:Calculating mean and std
2025-05-13 15:47:17,423:INFO:Creating metrics dataframe
2025-05-13 15:47:17,426:INFO:Uploading results into container
2025-05-13 15:47:17,427:INFO:Uploading model into container now
2025-05-13 15:47:17,427:INFO:_master_model_container: 7
2025-05-13 15:47:17,427:INFO:_display_container: 2
2025-05-13 15:47:17,428:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:47:17,428:INFO:create_model() successfully completed......................................
2025-05-13 15:47:17,541:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:17,541:INFO:Creating metrics dataframe
2025-05-13 15:47:17,545:INFO:Initializing Quadratic Discriminant Analysis
2025-05-13 15:47:17,545:INFO:Total runtime is 0.5359603842099507 minutes
2025-05-13 15:47:17,547:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:17,547:INFO:Initializing create_model()
2025-05-13 15:47:17,547:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:17,547:INFO:Checking exceptions
2025-05-13 15:47:17,547:INFO:Importing libraries
2025-05-13 15:47:17,547:INFO:Copying training dataset
2025-05-13 15:47:17,563:INFO:Defining folds
2025-05-13 15:47:17,563:INFO:Declaring metric variables
2025-05-13 15:47:17,565:INFO:Importing untrained model
2025-05-13 15:47:17,566:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-13 15:47:17,568:INFO:Starting cross validation
2025-05-13 15:47:17,570:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:18,910:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:18,918:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:18,944:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:18,969:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:18,984:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:47:19,055:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:19,093:INFO:Calculating mean and std
2025-05-13 15:47:19,094:INFO:Creating metrics dataframe
2025-05-13 15:47:19,095:INFO:Uploading results into container
2025-05-13 15:47:19,096:INFO:Uploading model into container now
2025-05-13 15:47:19,096:INFO:_master_model_container: 8
2025-05-13 15:47:19,096:INFO:_display_container: 2
2025-05-13 15:47:19,096:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-13 15:47:19,096:INFO:create_model() successfully completed......................................
2025-05-13 15:47:19,150:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:19,150:INFO:Creating metrics dataframe
2025-05-13 15:47:19,154:INFO:Initializing Ada Boost Classifier
2025-05-13 15:47:19,154:INFO:Total runtime is 0.5627730687459309 minutes
2025-05-13 15:47:19,155:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:19,156:INFO:Initializing create_model()
2025-05-13 15:47:19,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:19,156:INFO:Checking exceptions
2025-05-13 15:47:19,156:INFO:Importing libraries
2025-05-13 15:47:19,156:INFO:Copying training dataset
2025-05-13 15:47:19,167:INFO:Defining folds
2025-05-13 15:47:19,167:INFO:Declaring metric variables
2025-05-13 15:47:19,168:INFO:Importing untrained model
2025-05-13 15:47:19,170:INFO:Ada Boost Classifier Imported successfully
2025-05-13 15:47:19,172:INFO:Starting cross validation
2025-05-13 15:47:19,174:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:20,347:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:20,385:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:20,410:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:20,430:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:20,438:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:47:23,295:INFO:Calculating mean and std
2025-05-13 15:47:23,295:INFO:Creating metrics dataframe
2025-05-13 15:47:23,296:INFO:Uploading results into container
2025-05-13 15:47:23,296:INFO:Uploading model into container now
2025-05-13 15:47:23,296:INFO:_master_model_container: 9
2025-05-13 15:47:23,296:INFO:_display_container: 2
2025-05-13 15:47:23,297:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-13 15:47:23,297:INFO:create_model() successfully completed......................................
2025-05-13 15:47:23,344:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:23,345:INFO:Creating metrics dataframe
2025-05-13 15:47:23,348:INFO:Initializing Gradient Boosting Classifier
2025-05-13 15:47:23,348:INFO:Total runtime is 0.6326791882514953 minutes
2025-05-13 15:47:23,350:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:23,350:INFO:Initializing create_model()
2025-05-13 15:47:23,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:23,350:INFO:Checking exceptions
2025-05-13 15:47:23,350:INFO:Importing libraries
2025-05-13 15:47:23,350:INFO:Copying training dataset
2025-05-13 15:47:23,360:INFO:Defining folds
2025-05-13 15:47:23,360:INFO:Declaring metric variables
2025-05-13 15:47:23,361:INFO:Importing untrained model
2025-05-13 15:47:23,362:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:47:23,365:INFO:Starting cross validation
2025-05-13 15:47:23,366:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:38,117:INFO:Calculating mean and std
2025-05-13 15:47:38,119:INFO:Creating metrics dataframe
2025-05-13 15:47:38,123:INFO:Uploading results into container
2025-05-13 15:47:38,123:INFO:Uploading model into container now
2025-05-13 15:47:38,124:INFO:_master_model_container: 10
2025-05-13 15:47:38,124:INFO:_display_container: 2
2025-05-13 15:47:38,124:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:47:38,125:INFO:create_model() successfully completed......................................
2025-05-13 15:47:38,239:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:38,239:INFO:Creating metrics dataframe
2025-05-13 15:47:38,244:INFO:Initializing Linear Discriminant Analysis
2025-05-13 15:47:38,244:INFO:Total runtime is 0.8809373378753661 minutes
2025-05-13 15:47:38,245:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:38,245:INFO:Initializing create_model()
2025-05-13 15:47:38,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:38,245:INFO:Checking exceptions
2025-05-13 15:47:38,246:INFO:Importing libraries
2025-05-13 15:47:38,246:INFO:Copying training dataset
2025-05-13 15:47:38,263:INFO:Defining folds
2025-05-13 15:47:38,263:INFO:Declaring metric variables
2025-05-13 15:47:38,265:INFO:Importing untrained model
2025-05-13 15:47:38,266:INFO:Linear Discriminant Analysis Imported successfully
2025-05-13 15:47:38,268:INFO:Starting cross validation
2025-05-13 15:47:38,270:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:39,735:INFO:Calculating mean and std
2025-05-13 15:47:39,736:INFO:Creating metrics dataframe
2025-05-13 15:47:39,737:INFO:Uploading results into container
2025-05-13 15:47:39,737:INFO:Uploading model into container now
2025-05-13 15:47:39,738:INFO:_master_model_container: 11
2025-05-13 15:47:39,738:INFO:_display_container: 2
2025-05-13 15:47:39,738:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-13 15:47:39,738:INFO:create_model() successfully completed......................................
2025-05-13 15:47:39,787:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:39,787:INFO:Creating metrics dataframe
2025-05-13 15:47:39,791:INFO:Initializing Extra Trees Classifier
2025-05-13 15:47:39,791:INFO:Total runtime is 0.9067201852798461 minutes
2025-05-13 15:47:39,792:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:39,792:INFO:Initializing create_model()
2025-05-13 15:47:39,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:39,792:INFO:Checking exceptions
2025-05-13 15:47:39,792:INFO:Importing libraries
2025-05-13 15:47:39,792:INFO:Copying training dataset
2025-05-13 15:47:39,802:INFO:Defining folds
2025-05-13 15:47:39,802:INFO:Declaring metric variables
2025-05-13 15:47:39,803:INFO:Importing untrained model
2025-05-13 15:47:39,805:INFO:Extra Trees Classifier Imported successfully
2025-05-13 15:47:39,807:INFO:Starting cross validation
2025-05-13 15:47:39,808:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:44,921:INFO:Calculating mean and std
2025-05-13 15:47:44,925:INFO:Creating metrics dataframe
2025-05-13 15:47:44,931:INFO:Uploading results into container
2025-05-13 15:47:44,932:INFO:Uploading model into container now
2025-05-13 15:47:44,932:INFO:_master_model_container: 12
2025-05-13 15:47:44,933:INFO:_display_container: 2
2025-05-13 15:47:44,933:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-13 15:47:44,933:INFO:create_model() successfully completed......................................
2025-05-13 15:47:45,080:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:45,080:INFO:Creating metrics dataframe
2025-05-13 15:47:45,084:INFO:Initializing Light Gradient Boosting Machine
2025-05-13 15:47:45,084:INFO:Total runtime is 0.9949469526608784 minutes
2025-05-13 15:47:45,086:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:45,086:INFO:Initializing create_model()
2025-05-13 15:47:45,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:45,086:INFO:Checking exceptions
2025-05-13 15:47:45,086:INFO:Importing libraries
2025-05-13 15:47:45,086:INFO:Copying training dataset
2025-05-13 15:47:45,107:INFO:Defining folds
2025-05-13 15:47:45,108:INFO:Declaring metric variables
2025-05-13 15:47:45,109:INFO:Importing untrained model
2025-05-13 15:47:45,111:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:47:45,113:INFO:Starting cross validation
2025-05-13 15:47:45,115:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:49,600:INFO:Calculating mean and std
2025-05-13 15:47:49,601:INFO:Creating metrics dataframe
2025-05-13 15:47:49,602:INFO:Uploading results into container
2025-05-13 15:47:49,602:INFO:Uploading model into container now
2025-05-13 15:47:49,602:INFO:_master_model_container: 13
2025-05-13 15:47:49,602:INFO:_display_container: 2
2025-05-13 15:47:49,603:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:47:49,603:INFO:create_model() successfully completed......................................
2025-05-13 15:47:49,655:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:49,655:INFO:Creating metrics dataframe
2025-05-13 15:47:49,659:INFO:Initializing Dummy Classifier
2025-05-13 15:47:49,659:INFO:Total runtime is 1.0711941679318744 minutes
2025-05-13 15:47:49,661:INFO:SubProcess create_model() called ==================================
2025-05-13 15:47:49,661:INFO:Initializing create_model()
2025-05-13 15:47:49,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32fee6550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:49,661:INFO:Checking exceptions
2025-05-13 15:47:49,661:INFO:Importing libraries
2025-05-13 15:47:49,661:INFO:Copying training dataset
2025-05-13 15:47:49,671:INFO:Defining folds
2025-05-13 15:47:49,671:INFO:Declaring metric variables
2025-05-13 15:47:49,672:INFO:Importing untrained model
2025-05-13 15:47:49,673:INFO:Dummy Classifier Imported successfully
2025-05-13 15:47:49,675:INFO:Starting cross validation
2025-05-13 15:47:49,677:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:47:50,855:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:50,899:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:50,966:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:50,998:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:51,046:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:47:51,061:INFO:Calculating mean and std
2025-05-13 15:47:51,062:INFO:Creating metrics dataframe
2025-05-13 15:47:51,063:INFO:Uploading results into container
2025-05-13 15:47:51,063:INFO:Uploading model into container now
2025-05-13 15:47:51,064:INFO:_master_model_container: 14
2025-05-13 15:47:51,064:INFO:_display_container: 2
2025-05-13 15:47:51,064:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-13 15:47:51,064:INFO:create_model() successfully completed......................................
2025-05-13 15:47:51,112:INFO:SubProcess create_model() end ==================================
2025-05-13 15:47:51,112:INFO:Creating metrics dataframe
2025-05-13 15:47:51,116:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-13 15:47:51,119:INFO:Initializing create_model()
2025-05-13 15:47:51,119:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:47:51,119:INFO:Checking exceptions
2025-05-13 15:47:51,119:INFO:Importing libraries
2025-05-13 15:47:51,120:INFO:Copying training dataset
2025-05-13 15:47:51,130:INFO:Defining folds
2025-05-13 15:47:51,130:INFO:Declaring metric variables
2025-05-13 15:47:51,130:INFO:Importing untrained model
2025-05-13 15:47:51,130:INFO:Declaring custom model
2025-05-13 15:47:51,130:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:47:51,131:INFO:Cross validation set to False
2025-05-13 15:47:51,131:INFO:Fitting Model
2025-05-13 15:48:08,726:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:48:08,727:INFO:create_model() successfully completed......................................
2025-05-13 15:48:08,794:INFO:Initializing create_model()
2025-05-13 15:48:08,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:48:08,794:INFO:Checking exceptions
2025-05-13 15:48:08,795:INFO:Importing libraries
2025-05-13 15:48:08,795:INFO:Copying training dataset
2025-05-13 15:48:08,805:INFO:Defining folds
2025-05-13 15:48:08,805:INFO:Declaring metric variables
2025-05-13 15:48:08,805:INFO:Importing untrained model
2025-05-13 15:48:08,805:INFO:Declaring custom model
2025-05-13 15:48:08,805:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:48:08,806:INFO:Cross validation set to False
2025-05-13 15:48:08,806:INFO:Fitting Model
2025-05-13 15:48:10,058:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-05-13 15:48:10,059:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-13 15:48:10,069:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005456 seconds.
2025-05-13 15:48:10,069:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-13 15:48:10,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-13 15:48:10,069:INFO:[LightGBM] [Info] Total Bins 8670
2025-05-13 15:48:10,070:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 34
2025-05-13 15:48:10,070:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-13 15:48:10,853:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:48:10,853:INFO:create_model() successfully completed......................................
2025-05-13 15:48:10,907:INFO:Initializing create_model()
2025-05-13 15:48:10,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:48:10,908:INFO:Checking exceptions
2025-05-13 15:48:10,908:INFO:Importing libraries
2025-05-13 15:48:10,909:INFO:Copying training dataset
2025-05-13 15:48:10,919:INFO:Defining folds
2025-05-13 15:48:10,919:INFO:Declaring metric variables
2025-05-13 15:48:10,919:INFO:Importing untrained model
2025-05-13 15:48:10,919:INFO:Declaring custom model
2025-05-13 15:48:10,919:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:48:10,920:INFO:Cross validation set to False
2025-05-13 15:48:10,920:INFO:Fitting Model
2025-05-13 15:48:13,166:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:48:13,166:INFO:create_model() successfully completed......................................
2025-05-13 15:48:13,225:INFO:_master_model_container: 14
2025-05-13 15:48:13,225:INFO:_display_container: 2
2025-05-13 15:48:13,226:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-13 15:48:13,226:INFO:compare_models() successfully completed......................................
2025-05-13 15:48:13,237:INFO:Initializing evaluate_model()
2025-05-13 15:48:13,237:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:48:13,245:INFO:Initializing plot_model()
2025-05-13 15:48:13,245:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:48:13,245:INFO:Checking exceptions
2025-05-13 15:48:13,249:INFO:Preloading libraries
2025-05-13 15:48:13,252:INFO:Copying training dataset
2025-05-13 15:48:13,252:INFO:Plot type: pipeline
2025-05-13 15:48:13,312:INFO:Visual Rendered Successfully
2025-05-13 15:48:13,361:INFO:plot_model() successfully completed......................................
2025-05-13 15:48:13,363:INFO:Initializing tune_model()
2025-05-13 15:48:13,363:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-13 15:48:13,363:INFO:Checking exceptions
2025-05-13 15:48:13,372:INFO:Copying training dataset
2025-05-13 15:48:13,385:INFO:Checking base model
2025-05-13 15:48:13,385:INFO:Base model : Gradient Boosting Classifier
2025-05-13 15:48:13,386:INFO:Declaring metric variables
2025-05-13 15:48:13,388:INFO:Defining Hyperparameters
2025-05-13 15:48:13,444:INFO:Tuning with n_jobs=-1
2025-05-13 15:48:13,444:INFO:Initializing RandomizedSearchCV
2025-05-13 15:48:52,601:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-13 15:48:52,603:INFO:Hyperparameter search completed
2025-05-13 15:48:52,604:INFO:SubProcess create_model() called ==================================
2025-05-13 15:48:52,605:INFO:Initializing create_model()
2025-05-13 15:48:52,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32f04c490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-13 15:48:52,605:INFO:Checking exceptions
2025-05-13 15:48:52,605:INFO:Importing libraries
2025-05-13 15:48:52,605:INFO:Copying training dataset
2025-05-13 15:48:52,620:INFO:Defining folds
2025-05-13 15:48:52,620:INFO:Declaring metric variables
2025-05-13 15:48:52,623:INFO:Importing untrained model
2025-05-13 15:48:52,623:INFO:Declaring custom model
2025-05-13 15:48:52,625:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:48:52,628:INFO:Starting cross validation
2025-05-13 15:48:52,631:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:49:02,360:INFO:Calculating mean and std
2025-05-13 15:49:02,361:INFO:Creating metrics dataframe
2025-05-13 15:49:02,363:INFO:Finalizing model
2025-05-13 15:49:13,199:INFO:Uploading results into container
2025-05-13 15:49:13,200:INFO:Uploading model into container now
2025-05-13 15:49:13,201:INFO:_master_model_container: 15
2025-05-13 15:49:13,201:INFO:_display_container: 3
2025-05-13 15:49:13,201:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:49:13,202:INFO:create_model() successfully completed......................................
2025-05-13 15:49:13,289:INFO:SubProcess create_model() end ==================================
2025-05-13 15:49:13,289:INFO:choose_better activated
2025-05-13 15:49:13,292:INFO:SubProcess create_model() called ==================================
2025-05-13 15:49:13,292:INFO:Initializing create_model()
2025-05-13 15:49:13,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:49:13,292:INFO:Checking exceptions
2025-05-13 15:49:13,293:INFO:Importing libraries
2025-05-13 15:49:13,293:INFO:Copying training dataset
2025-05-13 15:49:13,304:INFO:Defining folds
2025-05-13 15:49:13,304:INFO:Declaring metric variables
2025-05-13 15:49:13,304:INFO:Importing untrained model
2025-05-13 15:49:13,304:INFO:Declaring custom model
2025-05-13 15:49:13,304:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:49:13,304:INFO:Starting cross validation
2025-05-13 15:49:13,306:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:49:28,290:INFO:Calculating mean and std
2025-05-13 15:49:28,292:INFO:Creating metrics dataframe
2025-05-13 15:49:28,293:INFO:Finalizing model
2025-05-13 15:49:45,538:INFO:Uploading results into container
2025-05-13 15:49:45,539:INFO:Uploading model into container now
2025-05-13 15:49:45,539:INFO:_master_model_container: 16
2025-05-13 15:49:45,539:INFO:_display_container: 4
2025-05-13 15:49:45,539:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:49:45,539:INFO:create_model() successfully completed......................................
2025-05-13 15:49:45,633:INFO:SubProcess create_model() end ==================================
2025-05-13 15:49:45,633:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4645
2025-05-13 15:49:45,634:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.489
2025-05-13 15:49:45,634:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-13 15:49:45,634:INFO:choose_better completed
2025-05-13 15:49:45,637:INFO:_master_model_container: 16
2025-05-13 15:49:45,637:INFO:_display_container: 3
2025-05-13 15:49:45,638:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:49:45,638:INFO:tune_model() successfully completed......................................
2025-05-13 15:49:45,693:INFO:Initializing evaluate_model()
2025-05-13 15:49:45,693:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:49:45,701:INFO:Initializing plot_model()
2025-05-13 15:49:45,701:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:49:45,701:INFO:Checking exceptions
2025-05-13 15:49:45,709:INFO:Preloading libraries
2025-05-13 15:49:45,717:INFO:Copying training dataset
2025-05-13 15:49:45,717:INFO:Plot type: pipeline
2025-05-13 15:49:45,776:INFO:Visual Rendered Successfully
2025-05-13 15:49:45,831:INFO:plot_model() successfully completed......................................
2025-05-13 15:49:45,833:INFO:Initializing interpret_model()
2025-05-13 15:49:45,833:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-13 15:49:45,833:INFO:Checking exceptions
2025-05-13 15:49:45,833:INFO:Soft dependency imported: shap: 0.47.2
2025-05-13 15:49:45,834:INFO:Initializing finalize_model()
2025-05-13 15:49:45,834:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-13 15:49:45,834:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:49:45,838:INFO:Initializing create_model()
2025-05-13 15:49:45,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:49:45,838:INFO:Checking exceptions
2025-05-13 15:49:45,838:INFO:Importing libraries
2025-05-13 15:49:45,838:INFO:Copying training dataset
2025-05-13 15:49:45,839:INFO:Defining folds
2025-05-13 15:49:45,839:INFO:Declaring metric variables
2025-05-13 15:49:45,839:INFO:Importing untrained model
2025-05-13 15:49:45,839:INFO:Declaring custom model
2025-05-13 15:49:45,840:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:49:45,841:INFO:Cross validation set to False
2025-05-13 15:49:45,841:INFO:Fitting Model
2025-05-13 15:50:00,667:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:50:00,668:INFO:create_model() successfully completed......................................
2025-05-13 15:50:00,713:INFO:_master_model_container: 16
2025-05-13 15:50:00,713:INFO:_display_container: 3
2025-05-13 15:50:00,733:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:50:00,733:INFO:finalize_model() successfully completed......................................
2025-05-13 15:50:00,813:INFO:Initializing save_model()
2025-05-13 15:50:00,813:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-13 15:50:00,813:INFO:Adding model into prep_pipe
2025-05-13 15:50:00,813:WARNING:Only Model saved as it was a pipeline.
2025-05-13 15:50:00,838:INFO:final_cancer_model.pkl saved in current working directory
2025-05-13 15:50:00,858:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:50:00,858:INFO:save_model() successfully completed......................................
2025-05-13 15:50:00,929:INFO:Initializing predict_model()
2025-05-13 15:50:00,929:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x32627cb80>)
2025-05-13 15:50:00,930:INFO:Checking exceptions
2025-05-13 15:50:00,930:INFO:Preloading libraries
2025-05-13 15:50:00,931:INFO:Set up data.
2025-05-13 15:50:00,955:INFO:Set up index.
2025-05-13 15:50:01,788:INFO:Initializing plot_model()
2025-05-13 15:50:01,788:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:50:01,788:INFO:Checking exceptions
2025-05-13 15:50:01,792:INFO:Preloading libraries
2025-05-13 15:50:01,796:INFO:Copying training dataset
2025-05-13 15:50:01,796:INFO:Plot type: confusion_matrix
2025-05-13 15:50:02,029:INFO:Fitting Model
2025-05-13 15:50:02,029:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:50:02,030:INFO:Scoring test/hold-out set
2025-05-13 15:50:02,102:INFO:Visual Rendered Successfully
2025-05-13 15:50:02,152:INFO:plot_model() successfully completed......................................
2025-05-13 15:50:02,152:INFO:Initializing plot_model()
2025-05-13 15:50:02,152:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:50:02,152:INFO:Checking exceptions
2025-05-13 15:50:02,156:INFO:Preloading libraries
2025-05-13 15:50:02,160:INFO:Copying training dataset
2025-05-13 15:50:02,160:INFO:Plot type: auc
2025-05-13 15:50:02,391:INFO:Fitting Model
2025-05-13 15:50:02,392:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:50:02,393:INFO:Scoring test/hold-out set
2025-05-13 15:50:02,507:INFO:Visual Rendered Successfully
2025-05-13 15:50:02,558:INFO:plot_model() successfully completed......................................
2025-05-13 15:50:02,558:INFO:Initializing plot_model()
2025-05-13 15:50:02,558:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x325c53b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:50:02,558:INFO:Checking exceptions
2025-05-13 15:50:02,563:INFO:Preloading libraries
2025-05-13 15:50:02,566:INFO:Copying training dataset
2025-05-13 15:50:02,566:INFO:Plot type: feature
2025-05-13 15:50:02,567:WARNING:No coef_ found. Trying feature_importances_
2025-05-13 15:50:02,641:INFO:Visual Rendered Successfully
2025-05-13 15:50:02,691:INFO:plot_model() successfully completed......................................
2025-05-13 15:50:02,691:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:189: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  age_cancer_ratio = train_df_processed.groupby('Age_Group')['Cancer'].mean() * 100

2025-05-13 15:50:02,713:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 45824 (\N{HANGUL SYLLABLE DAE}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,714:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 51060 (\N{HANGUL SYLLABLE I}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,714:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 49345 (\N{HANGUL SYLLABLE SANG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,714:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 50672 (\N{HANGUL SYLLABLE YEON}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,714:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 47161 (\N{HANGUL SYLLABLE RYEONG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 50516 (\N{HANGUL SYLLABLE AM}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 48156 (\N{HANGUL SYLLABLE BAL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 49373 (\N{HANGUL SYLLABLE SAENG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 48708 (\N{HANGUL SYLLABLE BI}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,716:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 50984 (\N{HANGUL SYLLABLE YUL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,718:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2905584972.py:196: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50516 (\N{HANGUL SYLLABLE AM}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48156 (\N{HANGUL SYLLABLE BAL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49373 (\N{HANGUL SYLLABLE SAENG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48708 (\N{HANGUL SYLLABLE BI}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50984 (\N{HANGUL SYLLABLE YUL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50672 (\N{HANGUL SYLLABLE YEON}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47161 (\N{HANGUL SYLLABLE RYEONG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 45824 (\N{HANGUL SYLLABLE DAE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,740:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,741:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51060 (\N{HANGUL SYLLABLE I}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:50:02,741:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49345 (\N{HANGUL SYLLABLE SANG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:51:31,254:INFO:PyCaret ClassificationExperiment
2025-05-13 15:51:31,254:INFO:Logging name: clf-default-name
2025-05-13 15:51:31,254:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-13 15:51:31,254:INFO:version 3.3.2
2025-05-13 15:51:31,255:INFO:Initializing setup()
2025-05-13 15:51:31,255:INFO:self.USI: eba9
2025-05-13 15:51:31,255:INFO:self._variable_keys: {'fold_groups_param', 'html_param', 'USI', 'fix_imbalance', 'log_plots_param', 'idx', 'fold_generator', 'exp_name_log', 'exp_id', 'y', 'is_multiclass', 'memory', 'gpu_param', 'y_test', 'pipeline', 'seed', '_ml_usecase', 'X_train', 'gpu_n_jobs_param', 'y_train', 'fold_shuffle_param', 'X', 'data', '_available_plots', 'X_test', 'target_param', 'n_jobs_param', 'logging_param'}
2025-05-13 15:51:31,255:INFO:Checking environment
2025-05-13 15:51:31,255:INFO:python_version: 3.11.0
2025-05-13 15:51:31,255:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-13 15:51:31,255:INFO:machine: arm64
2025-05-13 15:51:31,255:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:51:31,255:INFO:Memory: svmem(total=17179869184, available=3357442048, percent=80.5, used=5936070656, free=72073216, active=3300605952, inactive=3279241216, wired=2635464704)
2025-05-13 15:51:31,255:INFO:Physical Core: 12
2025-05-13 15:51:31,255:INFO:Logical Core: 12
2025-05-13 15:51:31,255:INFO:Checking libraries
2025-05-13 15:51:31,255:INFO:System:
2025-05-13 15:51:31,255:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-13 15:51:31,255:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-13 15:51:31,255:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-13 15:51:31,255:INFO:PyCaret required dependencies:
2025-05-13 15:51:31,255:INFO:                 pip: 22.3
2025-05-13 15:51:31,255:INFO:          setuptools: 65.5.0
2025-05-13 15:51:31,255:INFO:             pycaret: 3.3.2
2025-05-13 15:51:31,255:INFO:             IPython: 9.2.0
2025-05-13 15:51:31,255:INFO:          ipywidgets: 8.1.7
2025-05-13 15:51:31,255:INFO:                tqdm: 4.67.1
2025-05-13 15:51:31,255:INFO:               numpy: 1.26.4
2025-05-13 15:51:31,255:INFO:              pandas: 2.1.4
2025-05-13 15:51:31,255:INFO:              jinja2: 3.1.6
2025-05-13 15:51:31,255:INFO:               scipy: 1.11.4
2025-05-13 15:51:31,255:INFO:              joblib: 1.3.2
2025-05-13 15:51:31,255:INFO:             sklearn: 1.4.2
2025-05-13 15:51:31,255:INFO:                pyod: 2.0.5
2025-05-13 15:51:31,255:INFO:            imblearn: 0.13.0
2025-05-13 15:51:31,255:INFO:   category_encoders: 2.7.0
2025-05-13 15:51:31,255:INFO:            lightgbm: 4.6.0
2025-05-13 15:51:31,255:INFO:               numba: 0.61.2
2025-05-13 15:51:31,255:INFO:            requests: 2.32.3
2025-05-13 15:51:31,255:INFO:          matplotlib: 3.7.5
2025-05-13 15:51:31,255:INFO:          scikitplot: 0.3.7
2025-05-13 15:51:31,255:INFO:         yellowbrick: 1.5
2025-05-13 15:51:31,255:INFO:              plotly: 5.24.1
2025-05-13 15:51:31,255:INFO:    plotly-resampler: Not installed
2025-05-13 15:51:31,255:INFO:             kaleido: 0.2.1
2025-05-13 15:51:31,255:INFO:           schemdraw: 0.15
2025-05-13 15:51:31,255:INFO:         statsmodels: 0.14.4
2025-05-13 15:51:31,255:INFO:              sktime: 0.26.0
2025-05-13 15:51:31,255:INFO:               tbats: 1.1.3
2025-05-13 15:51:31,255:INFO:            pmdarima: 2.0.4
2025-05-13 15:51:31,255:INFO:              psutil: 7.0.0
2025-05-13 15:51:31,255:INFO:          markupsafe: 3.0.2
2025-05-13 15:51:31,255:INFO:             pickle5: Not installed
2025-05-13 15:51:31,255:INFO:         cloudpickle: 3.1.1
2025-05-13 15:51:31,255:INFO:         deprecation: 2.1.0
2025-05-13 15:51:31,255:INFO:              xxhash: 3.5.0
2025-05-13 15:51:31,255:INFO:           wurlitzer: 3.1.1
2025-05-13 15:51:31,255:INFO:PyCaret optional dependencies:
2025-05-13 15:51:31,255:INFO:                shap: 0.47.2
2025-05-13 15:51:31,255:INFO:           interpret: Not installed
2025-05-13 15:51:31,255:INFO:                umap: Not installed
2025-05-13 15:51:31,255:INFO:     ydata_profiling: Not installed
2025-05-13 15:51:31,255:INFO:  explainerdashboard: Not installed
2025-05-13 15:51:31,255:INFO:             autoviz: Not installed
2025-05-13 15:51:31,256:INFO:           fairlearn: Not installed
2025-05-13 15:51:31,256:INFO:          deepchecks: Not installed
2025-05-13 15:51:31,256:INFO:             xgboost: Not installed
2025-05-13 15:51:31,256:INFO:            catboost: Not installed
2025-05-13 15:51:31,256:INFO:              kmodes: Not installed
2025-05-13 15:51:31,256:INFO:             mlxtend: Not installed
2025-05-13 15:51:31,256:INFO:       statsforecast: Not installed
2025-05-13 15:51:31,256:INFO:        tune_sklearn: Not installed
2025-05-13 15:51:31,256:INFO:                 ray: Not installed
2025-05-13 15:51:31,256:INFO:            hyperopt: Not installed
2025-05-13 15:51:31,256:INFO:              optuna: 4.3.0
2025-05-13 15:51:31,256:INFO:               skopt: Not installed
2025-05-13 15:51:31,256:INFO:              mlflow: Not installed
2025-05-13 15:51:31,256:INFO:              gradio: Not installed
2025-05-13 15:51:31,256:INFO:             fastapi: Not installed
2025-05-13 15:51:31,256:INFO:             uvicorn: Not installed
2025-05-13 15:51:31,256:INFO:              m2cgen: Not installed
2025-05-13 15:51:31,256:INFO:           evidently: Not installed
2025-05-13 15:51:31,256:INFO:               fugue: Not installed
2025-05-13 15:51:31,256:INFO:           streamlit: Not installed
2025-05-13 15:51:31,256:INFO:             prophet: Not installed
2025-05-13 15:51:31,256:INFO:None
2025-05-13 15:51:31,256:INFO:Set up data.
2025-05-13 15:51:31,287:INFO:Set up folding strategy.
2025-05-13 15:51:31,287:INFO:Set up train/test split.
2025-05-13 15:51:31,301:INFO:Set up index.
2025-05-13 15:51:31,301:INFO:Assigning column types.
2025-05-13 15:51:31,305:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-13 15:51:31,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,324:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,354:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,366:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-13 15:51:31,385:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,397:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,415:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-13 15:51:31,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,426:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-13 15:51:31,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:31,490:INFO:Preparing preprocessing pipeline...
2025-05-13 15:51:31,491:INFO:Set up simple imputation.
2025-05-13 15:51:31,498:INFO:Set up encoding of ordinal features.
2025-05-13 15:51:31,507:INFO:Set up encoding of categorical features.
2025-05-13 15:51:31,508:INFO:Set up imbalanced handling.
2025-05-13 15:51:31,508:INFO:Set up column transformation.
2025-05-13 15:51:32,709:INFO:Finished creating preprocessing pipeline.
2025-05-13 15:51:32,728:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-13 15:51:32,728:INFO:Creating final display dataframe.
2025-05-13 15:51:33,263:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 17)
4        Transformed data shape      (106821, 37)
5   Transformed train set shape       (85902, 37)
6    Transformed test set shape       (20919, 37)
7              Numeric features                 6
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              eba9
2025-05-13 15:51:33,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:33,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:33,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:33,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 15:51:33,329:INFO:setup() successfully completed in 2.08s...............
2025-05-13 15:51:33,330:INFO:Initializing compare_models()
2025-05-13 15:51:33,330:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-13 15:51:33,330:INFO:Checking exceptions
2025-05-13 15:51:33,336:INFO:Preparing display monitor
2025-05-13 15:51:33,344:INFO:Initializing Logistic Regression
2025-05-13 15:51:33,345:INFO:Total runtime is 1.7682711283365886e-06 minutes
2025-05-13 15:51:33,346:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:33,346:INFO:Initializing create_model()
2025-05-13 15:51:33,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:33,346:INFO:Checking exceptions
2025-05-13 15:51:33,346:INFO:Importing libraries
2025-05-13 15:51:33,346:INFO:Copying training dataset
2025-05-13 15:51:33,358:INFO:Defining folds
2025-05-13 15:51:33,358:INFO:Declaring metric variables
2025-05-13 15:51:33,359:INFO:Importing untrained model
2025-05-13 15:51:33,361:INFO:Logistic Regression Imported successfully
2025-05-13 15:51:33,363:INFO:Starting cross validation
2025-05-13 15:51:33,364:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:37,456:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:37,607:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:38,921:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:39,010:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:42,459:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-13 15:51:42,526:INFO:Calculating mean and std
2025-05-13 15:51:42,528:INFO:Creating metrics dataframe
2025-05-13 15:51:42,531:INFO:Uploading results into container
2025-05-13 15:51:42,531:INFO:Uploading model into container now
2025-05-13 15:51:42,532:INFO:_master_model_container: 1
2025-05-13 15:51:42,532:INFO:_display_container: 2
2025-05-13 15:51:42,532:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-13 15:51:42,532:INFO:create_model() successfully completed......................................
2025-05-13 15:51:42,610:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:42,610:INFO:Creating metrics dataframe
2025-05-13 15:51:42,613:INFO:Initializing K Neighbors Classifier
2025-05-13 15:51:42,613:INFO:Total runtime is 0.15447012186050413 minutes
2025-05-13 15:51:42,614:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:42,614:INFO:Initializing create_model()
2025-05-13 15:51:42,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:42,614:INFO:Checking exceptions
2025-05-13 15:51:42,614:INFO:Importing libraries
2025-05-13 15:51:42,614:INFO:Copying training dataset
2025-05-13 15:51:42,626:INFO:Defining folds
2025-05-13 15:51:42,626:INFO:Declaring metric variables
2025-05-13 15:51:42,627:INFO:Importing untrained model
2025-05-13 15:51:42,628:INFO:K Neighbors Classifier Imported successfully
2025-05-13 15:51:42,631:INFO:Starting cross validation
2025-05-13 15:51:42,633:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:48,117:INFO:Calculating mean and std
2025-05-13 15:51:48,118:INFO:Creating metrics dataframe
2025-05-13 15:51:48,119:INFO:Uploading results into container
2025-05-13 15:51:48,119:INFO:Uploading model into container now
2025-05-13 15:51:48,120:INFO:_master_model_container: 2
2025-05-13 15:51:48,120:INFO:_display_container: 2
2025-05-13 15:51:48,120:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-13 15:51:48,120:INFO:create_model() successfully completed......................................
2025-05-13 15:51:48,178:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:48,178:INFO:Creating metrics dataframe
2025-05-13 15:51:48,182:INFO:Initializing Naive Bayes
2025-05-13 15:51:48,182:INFO:Total runtime is 0.24729955196380612 minutes
2025-05-13 15:51:48,184:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:48,184:INFO:Initializing create_model()
2025-05-13 15:51:48,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:48,184:INFO:Checking exceptions
2025-05-13 15:51:48,184:INFO:Importing libraries
2025-05-13 15:51:48,184:INFO:Copying training dataset
2025-05-13 15:51:48,202:INFO:Defining folds
2025-05-13 15:51:48,203:INFO:Declaring metric variables
2025-05-13 15:51:48,204:INFO:Importing untrained model
2025-05-13 15:51:48,205:INFO:Naive Bayes Imported successfully
2025-05-13 15:51:48,208:INFO:Starting cross validation
2025-05-13 15:51:48,209:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:49,622:INFO:Calculating mean and std
2025-05-13 15:51:49,624:INFO:Creating metrics dataframe
2025-05-13 15:51:49,628:INFO:Uploading results into container
2025-05-13 15:51:49,629:INFO:Uploading model into container now
2025-05-13 15:51:49,629:INFO:_master_model_container: 3
2025-05-13 15:51:49,629:INFO:_display_container: 2
2025-05-13 15:51:49,630:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-13 15:51:49,630:INFO:create_model() successfully completed......................................
2025-05-13 15:51:49,734:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:49,735:INFO:Creating metrics dataframe
2025-05-13 15:51:49,738:INFO:Initializing Decision Tree Classifier
2025-05-13 15:51:49,738:INFO:Total runtime is 0.27322769959767657 minutes
2025-05-13 15:51:49,739:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:49,740:INFO:Initializing create_model()
2025-05-13 15:51:49,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:49,740:INFO:Checking exceptions
2025-05-13 15:51:49,740:INFO:Importing libraries
2025-05-13 15:51:49,740:INFO:Copying training dataset
2025-05-13 15:51:49,760:INFO:Defining folds
2025-05-13 15:51:49,760:INFO:Declaring metric variables
2025-05-13 15:51:49,761:INFO:Importing untrained model
2025-05-13 15:51:49,763:INFO:Decision Tree Classifier Imported successfully
2025-05-13 15:51:49,766:INFO:Starting cross validation
2025-05-13 15:51:49,768:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:51,706:INFO:Calculating mean and std
2025-05-13 15:51:51,707:INFO:Creating metrics dataframe
2025-05-13 15:51:51,708:INFO:Uploading results into container
2025-05-13 15:51:51,708:INFO:Uploading model into container now
2025-05-13 15:51:51,709:INFO:_master_model_container: 4
2025-05-13 15:51:51,709:INFO:_display_container: 2
2025-05-13 15:51:51,709:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-13 15:51:51,709:INFO:create_model() successfully completed......................................
2025-05-13 15:51:51,805:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:51,805:INFO:Creating metrics dataframe
2025-05-13 15:51:51,809:INFO:Initializing SVM - Linear Kernel
2025-05-13 15:51:51,809:INFO:Total runtime is 0.30773888429005936 minutes
2025-05-13 15:51:51,811:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:51,811:INFO:Initializing create_model()
2025-05-13 15:51:51,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:51,811:INFO:Checking exceptions
2025-05-13 15:51:51,811:INFO:Importing libraries
2025-05-13 15:51:51,811:INFO:Copying training dataset
2025-05-13 15:51:51,830:INFO:Defining folds
2025-05-13 15:51:51,831:INFO:Declaring metric variables
2025-05-13 15:51:51,834:INFO:Importing untrained model
2025-05-13 15:51:51,838:INFO:SVM - Linear Kernel Imported successfully
2025-05-13 15:51:51,842:INFO:Starting cross validation
2025-05-13 15:51:51,853:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:56,188:INFO:Calculating mean and std
2025-05-13 15:51:56,190:INFO:Creating metrics dataframe
2025-05-13 15:51:56,192:INFO:Uploading results into container
2025-05-13 15:51:56,192:INFO:Uploading model into container now
2025-05-13 15:51:56,192:INFO:_master_model_container: 5
2025-05-13 15:51:56,192:INFO:_display_container: 2
2025-05-13 15:51:56,193:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-13 15:51:56,193:INFO:create_model() successfully completed......................................
2025-05-13 15:51:56,255:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:56,255:INFO:Creating metrics dataframe
2025-05-13 15:51:56,258:INFO:Initializing Ridge Classifier
2025-05-13 15:51:56,258:INFO:Total runtime is 0.3818989992141723 minutes
2025-05-13 15:51:56,260:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:56,260:INFO:Initializing create_model()
2025-05-13 15:51:56,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:56,260:INFO:Checking exceptions
2025-05-13 15:51:56,260:INFO:Importing libraries
2025-05-13 15:51:56,260:INFO:Copying training dataset
2025-05-13 15:51:56,270:INFO:Defining folds
2025-05-13 15:51:56,270:INFO:Declaring metric variables
2025-05-13 15:51:56,271:INFO:Importing untrained model
2025-05-13 15:51:56,272:INFO:Ridge Classifier Imported successfully
2025-05-13 15:51:56,275:INFO:Starting cross validation
2025-05-13 15:51:56,276:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:51:57,793:INFO:Calculating mean and std
2025-05-13 15:51:57,794:INFO:Creating metrics dataframe
2025-05-13 15:51:57,795:INFO:Uploading results into container
2025-05-13 15:51:57,795:INFO:Uploading model into container now
2025-05-13 15:51:57,795:INFO:_master_model_container: 6
2025-05-13 15:51:57,795:INFO:_display_container: 2
2025-05-13 15:51:57,796:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-13 15:51:57,796:INFO:create_model() successfully completed......................................
2025-05-13 15:51:57,852:INFO:SubProcess create_model() end ==================================
2025-05-13 15:51:57,852:INFO:Creating metrics dataframe
2025-05-13 15:51:57,856:INFO:Initializing Random Forest Classifier
2025-05-13 15:51:57,856:INFO:Total runtime is 0.4085217038790384 minutes
2025-05-13 15:51:57,857:INFO:SubProcess create_model() called ==================================
2025-05-13 15:51:57,857:INFO:Initializing create_model()
2025-05-13 15:51:57,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:51:57,857:INFO:Checking exceptions
2025-05-13 15:51:57,857:INFO:Importing libraries
2025-05-13 15:51:57,857:INFO:Copying training dataset
2025-05-13 15:51:57,868:INFO:Defining folds
2025-05-13 15:51:57,868:INFO:Declaring metric variables
2025-05-13 15:51:57,869:INFO:Importing untrained model
2025-05-13 15:51:57,870:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:51:57,873:INFO:Starting cross validation
2025-05-13 15:51:57,874:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:04,077:INFO:Calculating mean and std
2025-05-13 15:52:04,081:INFO:Creating metrics dataframe
2025-05-13 15:52:04,089:INFO:Uploading results into container
2025-05-13 15:52:04,089:INFO:Uploading model into container now
2025-05-13 15:52:04,090:INFO:_master_model_container: 7
2025-05-13 15:52:04,090:INFO:_display_container: 2
2025-05-13 15:52:04,091:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:52:04,092:INFO:create_model() successfully completed......................................
2025-05-13 15:52:04,203:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:04,203:INFO:Creating metrics dataframe
2025-05-13 15:52:04,207:INFO:Initializing Quadratic Discriminant Analysis
2025-05-13 15:52:04,208:INFO:Total runtime is 0.5143866697947184 minutes
2025-05-13 15:52:04,209:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:04,209:INFO:Initializing create_model()
2025-05-13 15:52:04,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:04,210:INFO:Checking exceptions
2025-05-13 15:52:04,210:INFO:Importing libraries
2025-05-13 15:52:04,210:INFO:Copying training dataset
2025-05-13 15:52:04,222:INFO:Defining folds
2025-05-13 15:52:04,222:INFO:Declaring metric variables
2025-05-13 15:52:04,224:INFO:Importing untrained model
2025-05-13 15:52:04,226:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-13 15:52:04,228:INFO:Starting cross validation
2025-05-13 15:52:04,232:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:05,555:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,573:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,586:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,639:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,680:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-13 15:52:05,689:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:05,733:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:05,770:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:05,782:INFO:Calculating mean and std
2025-05-13 15:52:05,783:INFO:Creating metrics dataframe
2025-05-13 15:52:05,784:INFO:Uploading results into container
2025-05-13 15:52:05,784:INFO:Uploading model into container now
2025-05-13 15:52:05,784:INFO:_master_model_container: 8
2025-05-13 15:52:05,784:INFO:_display_container: 2
2025-05-13 15:52:05,785:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-13 15:52:05,785:INFO:create_model() successfully completed......................................
2025-05-13 15:52:05,838:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:05,838:INFO:Creating metrics dataframe
2025-05-13 15:52:05,842:INFO:Initializing Ada Boost Classifier
2025-05-13 15:52:05,842:INFO:Total runtime is 0.5416210691134135 minutes
2025-05-13 15:52:05,843:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:05,843:INFO:Initializing create_model()
2025-05-13 15:52:05,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:05,843:INFO:Checking exceptions
2025-05-13 15:52:05,843:INFO:Importing libraries
2025-05-13 15:52:05,843:INFO:Copying training dataset
2025-05-13 15:52:05,852:INFO:Defining folds
2025-05-13 15:52:05,852:INFO:Declaring metric variables
2025-05-13 15:52:05,854:INFO:Importing untrained model
2025-05-13 15:52:05,855:INFO:Ada Boost Classifier Imported successfully
2025-05-13 15:52:05,857:INFO:Starting cross validation
2025-05-13 15:52:05,861:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:07,058:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:07,086:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:07,100:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:07,111:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:07,116:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-13 15:52:10,046:INFO:Calculating mean and std
2025-05-13 15:52:10,046:INFO:Creating metrics dataframe
2025-05-13 15:52:10,047:INFO:Uploading results into container
2025-05-13 15:52:10,047:INFO:Uploading model into container now
2025-05-13 15:52:10,048:INFO:_master_model_container: 9
2025-05-13 15:52:10,048:INFO:_display_container: 2
2025-05-13 15:52:10,048:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-13 15:52:10,048:INFO:create_model() successfully completed......................................
2025-05-13 15:52:10,100:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:10,100:INFO:Creating metrics dataframe
2025-05-13 15:52:10,104:INFO:Initializing Gradient Boosting Classifier
2025-05-13 15:52:10,104:INFO:Total runtime is 0.6126559217770894 minutes
2025-05-13 15:52:10,105:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:10,105:INFO:Initializing create_model()
2025-05-13 15:52:10,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:10,105:INFO:Checking exceptions
2025-05-13 15:52:10,105:INFO:Importing libraries
2025-05-13 15:52:10,106:INFO:Copying training dataset
2025-05-13 15:52:10,115:INFO:Defining folds
2025-05-13 15:52:10,116:INFO:Declaring metric variables
2025-05-13 15:52:10,117:INFO:Importing untrained model
2025-05-13 15:52:10,118:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:52:10,120:INFO:Starting cross validation
2025-05-13 15:52:10,122:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:25,448:INFO:Calculating mean and std
2025-05-13 15:52:25,451:INFO:Creating metrics dataframe
2025-05-13 15:52:25,454:INFO:Uploading results into container
2025-05-13 15:52:25,454:INFO:Uploading model into container now
2025-05-13 15:52:25,455:INFO:_master_model_container: 10
2025-05-13 15:52:25,455:INFO:_display_container: 2
2025-05-13 15:52:25,457:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:52:25,457:INFO:create_model() successfully completed......................................
2025-05-13 15:52:25,556:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:25,556:INFO:Creating metrics dataframe
2025-05-13 15:52:25,560:INFO:Initializing Linear Discriminant Analysis
2025-05-13 15:52:25,560:INFO:Total runtime is 0.8702641169230143 minutes
2025-05-13 15:52:25,562:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:25,562:INFO:Initializing create_model()
2025-05-13 15:52:25,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:25,562:INFO:Checking exceptions
2025-05-13 15:52:25,562:INFO:Importing libraries
2025-05-13 15:52:25,562:INFO:Copying training dataset
2025-05-13 15:52:25,580:INFO:Defining folds
2025-05-13 15:52:25,580:INFO:Declaring metric variables
2025-05-13 15:52:25,581:INFO:Importing untrained model
2025-05-13 15:52:25,583:INFO:Linear Discriminant Analysis Imported successfully
2025-05-13 15:52:25,585:INFO:Starting cross validation
2025-05-13 15:52:25,587:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:27,094:INFO:Calculating mean and std
2025-05-13 15:52:27,095:INFO:Creating metrics dataframe
2025-05-13 15:52:27,096:INFO:Uploading results into container
2025-05-13 15:52:27,096:INFO:Uploading model into container now
2025-05-13 15:52:27,096:INFO:_master_model_container: 11
2025-05-13 15:52:27,096:INFO:_display_container: 2
2025-05-13 15:52:27,096:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-13 15:52:27,096:INFO:create_model() successfully completed......................................
2025-05-13 15:52:27,143:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:27,144:INFO:Creating metrics dataframe
2025-05-13 15:52:27,148:INFO:Initializing Extra Trees Classifier
2025-05-13 15:52:27,148:INFO:Total runtime is 0.8967252651850383 minutes
2025-05-13 15:52:27,149:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:27,149:INFO:Initializing create_model()
2025-05-13 15:52:27,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:27,149:INFO:Checking exceptions
2025-05-13 15:52:27,149:INFO:Importing libraries
2025-05-13 15:52:27,149:INFO:Copying training dataset
2025-05-13 15:52:27,158:INFO:Defining folds
2025-05-13 15:52:27,158:INFO:Declaring metric variables
2025-05-13 15:52:27,159:INFO:Importing untrained model
2025-05-13 15:52:27,161:INFO:Extra Trees Classifier Imported successfully
2025-05-13 15:52:27,162:INFO:Starting cross validation
2025-05-13 15:52:27,164:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:32,596:INFO:Calculating mean and std
2025-05-13 15:52:32,600:INFO:Creating metrics dataframe
2025-05-13 15:52:32,604:INFO:Uploading results into container
2025-05-13 15:52:32,605:INFO:Uploading model into container now
2025-05-13 15:52:32,608:INFO:_master_model_container: 12
2025-05-13 15:52:32,608:INFO:_display_container: 2
2025-05-13 15:52:32,611:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-13 15:52:32,611:INFO:create_model() successfully completed......................................
2025-05-13 15:52:32,732:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:32,732:INFO:Creating metrics dataframe
2025-05-13 15:52:32,736:INFO:Initializing Light Gradient Boosting Machine
2025-05-13 15:52:32,737:INFO:Total runtime is 0.9898682355880737 minutes
2025-05-13 15:52:32,738:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:32,738:INFO:Initializing create_model()
2025-05-13 15:52:32,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:32,738:INFO:Checking exceptions
2025-05-13 15:52:32,738:INFO:Importing libraries
2025-05-13 15:52:32,738:INFO:Copying training dataset
2025-05-13 15:52:32,754:INFO:Defining folds
2025-05-13 15:52:32,754:INFO:Declaring metric variables
2025-05-13 15:52:32,756:INFO:Importing untrained model
2025-05-13 15:52:32,758:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:52:32,761:INFO:Starting cross validation
2025-05-13 15:52:32,763:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:37,434:INFO:Calculating mean and std
2025-05-13 15:52:37,435:INFO:Creating metrics dataframe
2025-05-13 15:52:37,435:INFO:Uploading results into container
2025-05-13 15:52:37,436:INFO:Uploading model into container now
2025-05-13 15:52:37,436:INFO:_master_model_container: 13
2025-05-13 15:52:37,436:INFO:_display_container: 2
2025-05-13 15:52:37,436:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:52:37,436:INFO:create_model() successfully completed......................................
2025-05-13 15:52:37,487:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:37,487:INFO:Creating metrics dataframe
2025-05-13 15:52:37,491:INFO:Initializing Dummy Classifier
2025-05-13 15:52:37,491:INFO:Total runtime is 1.0691153526306152 minutes
2025-05-13 15:52:37,493:INFO:SubProcess create_model() called ==================================
2025-05-13 15:52:37,493:INFO:Initializing create_model()
2025-05-13 15:52:37,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x323ddd810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:37,493:INFO:Checking exceptions
2025-05-13 15:52:37,493:INFO:Importing libraries
2025-05-13 15:52:37,493:INFO:Copying training dataset
2025-05-13 15:52:37,503:INFO:Defining folds
2025-05-13 15:52:37,503:INFO:Declaring metric variables
2025-05-13 15:52:37,504:INFO:Importing untrained model
2025-05-13 15:52:37,505:INFO:Dummy Classifier Imported successfully
2025-05-13 15:52:37,508:INFO:Starting cross validation
2025-05-13 15:52:37,509:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:52:38,748:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,813:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,824:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,851:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,854:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-13 15:52:38,870:INFO:Calculating mean and std
2025-05-13 15:52:38,871:INFO:Creating metrics dataframe
2025-05-13 15:52:38,873:INFO:Uploading results into container
2025-05-13 15:52:38,873:INFO:Uploading model into container now
2025-05-13 15:52:38,873:INFO:_master_model_container: 14
2025-05-13 15:52:38,873:INFO:_display_container: 2
2025-05-13 15:52:38,874:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-13 15:52:38,874:INFO:create_model() successfully completed......................................
2025-05-13 15:52:38,938:INFO:SubProcess create_model() end ==================================
2025-05-13 15:52:38,938:INFO:Creating metrics dataframe
2025-05-13 15:52:38,943:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-13 15:52:38,947:INFO:Initializing create_model()
2025-05-13 15:52:38,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:38,947:INFO:Checking exceptions
2025-05-13 15:52:38,948:INFO:Importing libraries
2025-05-13 15:52:38,948:INFO:Copying training dataset
2025-05-13 15:52:38,958:INFO:Defining folds
2025-05-13 15:52:38,958:INFO:Declaring metric variables
2025-05-13 15:52:38,958:INFO:Importing untrained model
2025-05-13 15:52:38,958:INFO:Declaring custom model
2025-05-13 15:52:38,958:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:52:38,960:INFO:Cross validation set to False
2025-05-13 15:52:38,960:INFO:Fitting Model
2025-05-13 15:52:56,429:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:52:56,430:INFO:create_model() successfully completed......................................
2025-05-13 15:52:56,502:INFO:Initializing create_model()
2025-05-13 15:52:56,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:56,502:INFO:Checking exceptions
2025-05-13 15:52:56,503:INFO:Importing libraries
2025-05-13 15:52:56,503:INFO:Copying training dataset
2025-05-13 15:52:56,513:INFO:Defining folds
2025-05-13 15:52:56,513:INFO:Declaring metric variables
2025-05-13 15:52:56,513:INFO:Importing untrained model
2025-05-13 15:52:56,514:INFO:Declaring custom model
2025-05-13 15:52:56,514:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 15:52:56,516:INFO:Cross validation set to False
2025-05-13 15:52:56,516:INFO:Fitting Model
2025-05-13 15:52:57,743:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-05-13 15:52:57,743:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-13 15:52:57,754:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005956 seconds.
2025-05-13 15:52:57,754:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-13 15:52:57,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-13 15:52:57,755:INFO:[LightGBM] [Info] Total Bins 9180
2025-05-13 15:52:57,755:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 36
2025-05-13 15:52:57,755:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-13 15:52:58,537:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-13 15:52:58,537:INFO:create_model() successfully completed......................................
2025-05-13 15:52:58,597:INFO:Initializing create_model()
2025-05-13 15:52:58,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:52:58,597:INFO:Checking exceptions
2025-05-13 15:52:58,598:INFO:Importing libraries
2025-05-13 15:52:58,598:INFO:Copying training dataset
2025-05-13 15:52:58,607:INFO:Defining folds
2025-05-13 15:52:58,607:INFO:Declaring metric variables
2025-05-13 15:52:58,607:INFO:Importing untrained model
2025-05-13 15:52:58,607:INFO:Declaring custom model
2025-05-13 15:52:58,608:INFO:Random Forest Classifier Imported successfully
2025-05-13 15:52:58,609:INFO:Cross validation set to False
2025-05-13 15:52:58,609:INFO:Fitting Model
2025-05-13 15:53:01,182:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-13 15:53:01,182:INFO:create_model() successfully completed......................................
2025-05-13 15:53:01,254:INFO:_master_model_container: 14
2025-05-13 15:53:01,254:INFO:_display_container: 2
2025-05-13 15:53:01,255:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-13 15:53:01,255:INFO:compare_models() successfully completed......................................
2025-05-13 15:53:01,274:INFO:Initializing evaluate_model()
2025-05-13 15:53:01,274:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:53:01,283:INFO:Initializing plot_model()
2025-05-13 15:53:01,283:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:53:01,283:INFO:Checking exceptions
2025-05-13 15:53:01,288:INFO:Preloading libraries
2025-05-13 15:53:01,291:INFO:Copying training dataset
2025-05-13 15:53:01,291:INFO:Plot type: pipeline
2025-05-13 15:53:01,362:INFO:Visual Rendered Successfully
2025-05-13 15:53:01,418:INFO:plot_model() successfully completed......................................
2025-05-13 15:53:01,419:INFO:Initializing tune_model()
2025-05-13 15:53:01,419:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-13 15:53:01,420:INFO:Checking exceptions
2025-05-13 15:53:01,429:INFO:Copying training dataset
2025-05-13 15:53:01,436:INFO:Checking base model
2025-05-13 15:53:01,436:INFO:Base model : Gradient Boosting Classifier
2025-05-13 15:53:01,438:INFO:Declaring metric variables
2025-05-13 15:53:01,439:INFO:Defining Hyperparameters
2025-05-13 15:53:01,494:INFO:Tuning with n_jobs=-1
2025-05-13 15:53:01,494:INFO:Initializing RandomizedSearchCV
2025-05-13 15:53:45,641:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.0001}
2025-05-13 15:53:45,644:INFO:Hyperparameter search completed
2025-05-13 15:53:45,646:INFO:SubProcess create_model() called ==================================
2025-05-13 15:53:45,647:INFO:Initializing create_model()
2025-05-13 15:53:45,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x32feeeed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 9, 'learning_rate': 0.0001})
2025-05-13 15:53:45,647:INFO:Checking exceptions
2025-05-13 15:53:45,647:INFO:Importing libraries
2025-05-13 15:53:45,648:INFO:Copying training dataset
2025-05-13 15:53:45,665:INFO:Defining folds
2025-05-13 15:53:45,665:INFO:Declaring metric variables
2025-05-13 15:53:45,671:INFO:Importing untrained model
2025-05-13 15:53:45,671:INFO:Declaring custom model
2025-05-13 15:53:45,674:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:53:45,677:INFO:Starting cross validation
2025-05-13 15:53:45,682:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:53:56,758:INFO:Calculating mean and std
2025-05-13 15:53:56,759:INFO:Creating metrics dataframe
2025-05-13 15:53:56,762:INFO:Finalizing model
2025-05-13 15:54:08,504:INFO:Uploading results into container
2025-05-13 15:54:08,506:INFO:Uploading model into container now
2025-05-13 15:54:08,507:INFO:_master_model_container: 15
2025-05-13 15:54:08,507:INFO:_display_container: 3
2025-05-13 15:54:08,508:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:54:08,508:INFO:create_model() successfully completed......................................
2025-05-13 15:54:08,596:INFO:SubProcess create_model() end ==================================
2025-05-13 15:54:08,596:INFO:choose_better activated
2025-05-13 15:54:08,598:INFO:SubProcess create_model() called ==================================
2025-05-13 15:54:08,598:INFO:Initializing create_model()
2025-05-13 15:54:08,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:54:08,598:INFO:Checking exceptions
2025-05-13 15:54:08,599:INFO:Importing libraries
2025-05-13 15:54:08,599:INFO:Copying training dataset
2025-05-13 15:54:08,608:INFO:Defining folds
2025-05-13 15:54:08,608:INFO:Declaring metric variables
2025-05-13 15:54:08,608:INFO:Importing untrained model
2025-05-13 15:54:08,609:INFO:Declaring custom model
2025-05-13 15:54:08,609:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:54:08,609:INFO:Starting cross validation
2025-05-13 15:54:08,610:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 15:54:24,304:INFO:Calculating mean and std
2025-05-13 15:54:24,305:INFO:Creating metrics dataframe
2025-05-13 15:54:24,309:INFO:Finalizing model
2025-05-13 15:54:42,775:INFO:Uploading results into container
2025-05-13 15:54:42,776:INFO:Uploading model into container now
2025-05-13 15:54:42,776:INFO:_master_model_container: 16
2025-05-13 15:54:42,776:INFO:_display_container: 4
2025-05-13 15:54:42,777:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:54:42,777:INFO:create_model() successfully completed......................................
2025-05-13 15:54:42,888:INFO:SubProcess create_model() end ==================================
2025-05-13 15:54:42,889:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4636
2025-05-13 15:54:42,889:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.4897
2025-05-13 15:54:42,889:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-05-13 15:54:42,889:INFO:choose_better completed
2025-05-13 15:54:42,894:INFO:_master_model_container: 16
2025-05-13 15:54:42,894:INFO:_display_container: 3
2025-05-13 15:54:42,894:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:54:42,894:INFO:tune_model() successfully completed......................................
2025-05-13 15:54:42,951:INFO:Initializing evaluate_model()
2025-05-13 15:54:42,951:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-13 15:54:42,964:INFO:Initializing plot_model()
2025-05-13 15:54:42,965:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-13 15:54:42,965:INFO:Checking exceptions
2025-05-13 15:54:42,971:INFO:Preloading libraries
2025-05-13 15:54:42,984:INFO:Copying training dataset
2025-05-13 15:54:42,984:INFO:Plot type: pipeline
2025-05-13 15:54:43,044:INFO:Visual Rendered Successfully
2025-05-13 15:54:43,096:INFO:plot_model() successfully completed......................................
2025-05-13 15:54:43,098:INFO:Initializing interpret_model()
2025-05-13 15:54:43,098:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-13 15:54:43,098:INFO:Checking exceptions
2025-05-13 15:54:43,099:INFO:Soft dependency imported: shap: 0.47.2
2025-05-13 15:54:43,099:INFO:Initializing finalize_model()
2025-05-13 15:54:43,099:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-13 15:54:43,099:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-13 15:54:43,103:INFO:Initializing create_model()
2025-05-13 15:54:43,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=9,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=260, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 15:54:43,103:INFO:Checking exceptions
2025-05-13 15:54:43,104:INFO:Importing libraries
2025-05-13 15:54:43,104:INFO:Copying training dataset
2025-05-13 15:54:43,104:INFO:Defining folds
2025-05-13 15:54:43,104:INFO:Declaring metric variables
2025-05-13 15:54:43,104:INFO:Importing untrained model
2025-05-13 15:54:43,104:INFO:Declaring custom model
2025-05-13 15:54:43,105:INFO:Gradient Boosting Classifier Imported successfully
2025-05-13 15:54:43,106:INFO:Cross validation set to False
2025-05-13 15:54:43,106:INFO:Fitting Model
2025-05-13 15:54:59,325:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:54:59,326:INFO:create_model() successfully completed......................................
2025-05-13 15:54:59,373:INFO:_master_model_container: 16
2025-05-13 15:54:59,373:INFO:_display_container: 3
2025-05-13 15:54:59,392:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:54:59,392:INFO:finalize_model() successfully completed......................................
2025-05-13 15:54:59,473:INFO:Initializing save_model()
2025-05-13 15:54:59,473:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-13 15:54:59,473:INFO:Adding model into prep_pipe
2025-05-13 15:54:59,473:WARNING:Only Model saved as it was a pipeline.
2025-05-13 15:54:59,497:INFO:final_cancer_model.pkl saved in current working directory
2025-05-13 15:54:59,516:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-13 15:54:59,516:INFO:save_model() successfully completed......................................
2025-05-13 15:54:59,584:INFO:Initializing predict_model()
2025-05-13 15:54:59,584:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.0001,
                                            loss='log_loss', max_depth=9,
                                            max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.3,
                                            min_samples_leaf=5,
                                            min_samples_split=5,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=260,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=0.35,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x32627cb80>)
2025-05-13 15:54:59,584:INFO:Checking exceptions
2025-05-13 15:54:59,584:INFO:Preloading libraries
2025-05-13 15:54:59,585:INFO:Set up data.
2025-05-13 15:54:59,602:INFO:Set up index.
2025-05-13 15:55:00,476:INFO:Initializing plot_model()
2025-05-13 15:55:00,476:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:55:00,476:INFO:Checking exceptions
2025-05-13 15:55:00,481:INFO:Preloading libraries
2025-05-13 15:55:00,485:INFO:Copying training dataset
2025-05-13 15:55:00,485:INFO:Plot type: confusion_matrix
2025-05-13 15:55:00,717:INFO:Fitting Model
2025-05-13 15:55:00,717:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:55:00,718:INFO:Scoring test/hold-out set
2025-05-13 15:55:00,791:INFO:Visual Rendered Successfully
2025-05-13 15:55:00,840:INFO:plot_model() successfully completed......................................
2025-05-13 15:55:00,840:INFO:Initializing plot_model()
2025-05-13 15:55:00,840:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:55:00,840:INFO:Checking exceptions
2025-05-13 15:55:00,844:INFO:Preloading libraries
2025-05-13 15:55:00,848:INFO:Copying training dataset
2025-05-13 15:55:00,848:INFO:Plot type: auc
2025-05-13 15:55:01,085:INFO:Fitting Model
2025-05-13 15:55:01,086:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-05-13 15:55:01,087:INFO:Scoring test/hold-out set
2025-05-13 15:55:01,202:INFO:Visual Rendered Successfully
2025-05-13 15:55:01,252:INFO:plot_model() successfully completed......................................
2025-05-13 15:55:01,252:INFO:Initializing plot_model()
2025-05-13 15:55:01,252:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3256fc410>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-13 15:55:01,252:INFO:Checking exceptions
2025-05-13 15:55:01,257:INFO:Preloading libraries
2025-05-13 15:55:01,260:INFO:Copying training dataset
2025-05-13 15:55:01,260:INFO:Plot type: feature
2025-05-13 15:55:01,261:WARNING:No coef_ found. Trying feature_importances_
2025-05-13 15:55:01,335:INFO:Visual Rendered Successfully
2025-05-13 15:55:01,394:INFO:plot_model() successfully completed......................................
2025-05-13 15:55:01,394:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:189: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  age_cancer_ratio = train_df_processed.groupby('Age_Group')['Cancer'].mean() * 100

2025-05-13 15:55:01,413:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 45824 (\N{HANGUL SYLLABLE DAE}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,414:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 51060 (\N{HANGUL SYLLABLE I}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,414:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 49345 (\N{HANGUL SYLLABLE SANG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,415:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 50672 (\N{HANGUL SYLLABLE YEON}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,415:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 47161 (\N{HANGUL SYLLABLE RYEONG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 50516 (\N{HANGUL SYLLABLE AM}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 48156 (\N{HANGUL SYLLABLE BAL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 49373 (\N{HANGUL SYLLABLE SAENG}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 48708 (\N{HANGUL SYLLABLE BI}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,417:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 50984 (\N{HANGUL SYLLABLE YUL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,419:WARNING:/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/ipykernel_45820/2587333989.py:196: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from current font.
  plt.tight_layout()

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50516 (\N{HANGUL SYLLABLE AM}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48156 (\N{HANGUL SYLLABLE BAL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49373 (\N{HANGUL SYLLABLE SAENG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48708 (\N{HANGUL SYLLABLE BI}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50984 (\N{HANGUL SYLLABLE YUL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50672 (\N{HANGUL SYLLABLE YEON}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47161 (\N{HANGUL SYLLABLE RYEONG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 45824 (\N{HANGUL SYLLABLE DAE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,442:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,443:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51060 (\N{HANGUL SYLLABLE I}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-13 15:55:01,443:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49345 (\N{HANGUL SYLLABLE SANG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2025-05-14 10:51:08,952:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 10:51:08,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 10:51:08,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 10:51:08,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 10:51:20,862:INFO:PyCaret ClassificationExperiment
2025-05-14 10:51:20,862:INFO:Logging name: clf-default-name
2025-05-14 10:51:20,862:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 10:51:20,862:INFO:version 3.3.2
2025-05-14 10:51:20,862:INFO:Initializing setup()
2025-05-14 10:51:20,862:INFO:self.USI: 5a61
2025-05-14 10:51:20,862:INFO:self._variable_keys: {'USI', 'exp_id', 'X', 'y_train', 'is_multiclass', 'memory', 'idx', 'data', 'y_test', 'n_jobs_param', 'pipeline', 'y', 'fold_generator', 'logging_param', 'fold_groups_param', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'html_param', 'X_test', 'gpu_param', 'X_train', '_available_plots', 'seed', 'exp_name_log', 'fold_shuffle_param', 'log_plots_param', 'target_param'}
2025-05-14 10:51:20,862:INFO:Checking environment
2025-05-14 10:51:20,862:INFO:python_version: 3.11.0
2025-05-14 10:51:20,862:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-14 10:51:20,862:INFO:machine: arm64
2025-05-14 10:51:20,862:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-14 10:51:20,862:INFO:Memory: svmem(total=17179869184, available=4668735488, percent=72.8, used=7316209664, free=78315520, active=4616912896, inactive=4583325696, wired=2699296768)
2025-05-14 10:51:20,862:INFO:Physical Core: 12
2025-05-14 10:51:20,862:INFO:Logical Core: 12
2025-05-14 10:51:20,862:INFO:Checking libraries
2025-05-14 10:51:20,862:INFO:System:
2025-05-14 10:51:20,862:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-14 10:51:20,862:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-14 10:51:20,862:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-14 10:51:20,862:INFO:PyCaret required dependencies:
2025-05-14 10:51:21,005:INFO:                 pip: 22.3
2025-05-14 10:51:21,005:INFO:          setuptools: 65.5.0
2025-05-14 10:51:21,005:INFO:             pycaret: 3.3.2
2025-05-14 10:51:21,005:INFO:             IPython: 9.2.0
2025-05-14 10:51:21,005:INFO:          ipywidgets: 8.1.7
2025-05-14 10:51:21,006:INFO:                tqdm: 4.67.1
2025-05-14 10:51:21,006:INFO:               numpy: 1.26.4
2025-05-14 10:51:21,006:INFO:              pandas: 2.1.4
2025-05-14 10:51:21,006:INFO:              jinja2: 3.1.6
2025-05-14 10:51:21,006:INFO:               scipy: 1.11.4
2025-05-14 10:51:21,006:INFO:              joblib: 1.3.2
2025-05-14 10:51:21,006:INFO:             sklearn: 1.4.2
2025-05-14 10:51:21,006:INFO:                pyod: 2.0.5
2025-05-14 10:51:21,006:INFO:            imblearn: 0.13.0
2025-05-14 10:51:21,006:INFO:   category_encoders: 2.7.0
2025-05-14 10:51:21,006:INFO:            lightgbm: 4.6.0
2025-05-14 10:51:21,006:INFO:               numba: 0.61.2
2025-05-14 10:51:21,006:INFO:            requests: 2.32.3
2025-05-14 10:51:21,006:INFO:          matplotlib: 3.7.5
2025-05-14 10:51:21,006:INFO:          scikitplot: 0.3.7
2025-05-14 10:51:21,006:INFO:         yellowbrick: 1.5
2025-05-14 10:51:21,006:INFO:              plotly: 5.24.1
2025-05-14 10:51:21,006:INFO:    plotly-resampler: Not installed
2025-05-14 10:51:21,006:INFO:             kaleido: 0.2.1
2025-05-14 10:51:21,006:INFO:           schemdraw: 0.15
2025-05-14 10:51:21,006:INFO:         statsmodels: 0.14.4
2025-05-14 10:51:21,006:INFO:              sktime: 0.26.0
2025-05-14 10:51:21,006:INFO:               tbats: 1.1.3
2025-05-14 10:51:21,006:INFO:            pmdarima: 2.0.4
2025-05-14 10:51:21,006:INFO:              psutil: 7.0.0
2025-05-14 10:51:21,006:INFO:          markupsafe: 3.0.2
2025-05-14 10:51:21,006:INFO:             pickle5: Not installed
2025-05-14 10:51:21,006:INFO:         cloudpickle: 3.1.1
2025-05-14 10:51:21,006:INFO:         deprecation: 2.1.0
2025-05-14 10:51:21,006:INFO:              xxhash: 3.5.0
2025-05-14 10:51:21,006:INFO:           wurlitzer: 3.1.1
2025-05-14 10:51:21,006:INFO:PyCaret optional dependencies:
2025-05-14 10:51:21,011:INFO:                shap: 0.47.2
2025-05-14 10:51:21,011:INFO:           interpret: Not installed
2025-05-14 10:51:21,011:INFO:                umap: Not installed
2025-05-14 10:51:21,011:INFO:     ydata_profiling: Not installed
2025-05-14 10:51:21,011:INFO:  explainerdashboard: Not installed
2025-05-14 10:51:21,011:INFO:             autoviz: Not installed
2025-05-14 10:51:21,011:INFO:           fairlearn: Not installed
2025-05-14 10:51:21,011:INFO:          deepchecks: Not installed
2025-05-14 10:51:21,011:INFO:             xgboost: Not installed
2025-05-14 10:51:21,011:INFO:            catboost: 1.2.8
2025-05-14 10:51:21,011:INFO:              kmodes: Not installed
2025-05-14 10:51:21,011:INFO:             mlxtend: Not installed
2025-05-14 10:51:21,011:INFO:       statsforecast: Not installed
2025-05-14 10:51:21,011:INFO:        tune_sklearn: Not installed
2025-05-14 10:51:21,011:INFO:                 ray: Not installed
2025-05-14 10:51:21,011:INFO:            hyperopt: Not installed
2025-05-14 10:51:21,011:INFO:              optuna: 4.3.0
2025-05-14 10:51:21,011:INFO:               skopt: Not installed
2025-05-14 10:51:21,011:INFO:              mlflow: Not installed
2025-05-14 10:51:21,011:INFO:              gradio: Not installed
2025-05-14 10:51:21,011:INFO:             fastapi: Not installed
2025-05-14 10:51:21,011:INFO:             uvicorn: Not installed
2025-05-14 10:51:21,011:INFO:              m2cgen: Not installed
2025-05-14 10:51:21,011:INFO:           evidently: Not installed
2025-05-14 10:51:21,011:INFO:               fugue: Not installed
2025-05-14 10:51:21,011:INFO:           streamlit: Not installed
2025-05-14 10:51:21,011:INFO:             prophet: Not installed
2025-05-14 10:51:21,011:INFO:None
2025-05-14 10:51:21,011:INFO:Set up data.
2025-05-14 10:51:21,049:INFO:Set up folding strategy.
2025-05-14 10:51:21,049:INFO:Set up train/test split.
2025-05-14 10:51:21,082:INFO:Set up index.
2025-05-14 10:51:21,082:INFO:Assigning column types.
2025-05-14 10:51:21,088:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 10:51:21,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 10:51:21,108:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:51:21,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:21,122:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:21,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 10:51:21,141:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:51:21,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:21,152:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:21,152:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 10:51:21,170:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:51:21,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:21,181:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:21,199:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:51:21,210:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:21,210:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:21,211:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 10:51:21,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:21,241:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:21,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:21,271:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:21,273:INFO:Preparing preprocessing pipeline...
2025-05-14 10:51:21,275:INFO:Set up simple imputation.
2025-05-14 10:51:21,283:INFO:Set up encoding of ordinal features.
2025-05-14 10:51:21,294:INFO:Set up encoding of categorical features.
2025-05-14 10:51:21,294:INFO:Set up imbalanced handling.
2025-05-14 10:51:21,294:INFO:Set up column transformation.
2025-05-14 10:51:22,754:INFO:Finished creating preprocessing pipeline.
2025-05-14 10:51:22,773:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-14 10:51:22,773:INFO:Creating final display dataframe.
2025-05-14 10:51:23,278:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              5a61
2025-05-14 10:51:23,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:23,315:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:23,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:51:23,346:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:51:23,347:INFO:setup() successfully completed in 2.49s...............
2025-05-14 10:51:23,347:INFO:Initializing compare_models()
2025-05-14 10:51:23,347:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 10:51:23,347:INFO:Checking exceptions
2025-05-14 10:51:23,357:INFO:Preparing display monitor
2025-05-14 10:51:23,368:INFO:Initializing Logistic Regression
2025-05-14 10:51:23,368:INFO:Total runtime is 1.7523765563964843e-06 minutes
2025-05-14 10:51:23,369:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:23,369:INFO:Initializing create_model()
2025-05-14 10:51:23,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:23,369:INFO:Checking exceptions
2025-05-14 10:51:23,370:INFO:Importing libraries
2025-05-14 10:51:23,370:INFO:Copying training dataset
2025-05-14 10:51:23,383:INFO:Defining folds
2025-05-14 10:51:23,383:INFO:Declaring metric variables
2025-05-14 10:51:23,385:INFO:Importing untrained model
2025-05-14 10:51:23,387:INFO:Logistic Regression Imported successfully
2025-05-14 10:51:23,389:INFO:Starting cross validation
2025-05-14 10:51:23,390:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:29,189:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 10:51:29,349:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 10:51:29,374:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 10:51:29,408:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 10:51:29,422:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 10:51:29,486:INFO:Calculating mean and std
2025-05-14 10:51:29,488:INFO:Creating metrics dataframe
2025-05-14 10:51:29,492:INFO:Uploading results into container
2025-05-14 10:51:29,493:INFO:Uploading model into container now
2025-05-14 10:51:29,494:INFO:_master_model_container: 1
2025-05-14 10:51:29,495:INFO:_display_container: 2
2025-05-14 10:51:29,497:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 10:51:29,497:INFO:create_model() successfully completed......................................
2025-05-14 10:51:29,632:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:29,632:INFO:Creating metrics dataframe
2025-05-14 10:51:29,635:INFO:Initializing K Neighbors Classifier
2025-05-14 10:51:29,635:INFO:Total runtime is 0.10445725123087564 minutes
2025-05-14 10:51:29,637:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:29,637:INFO:Initializing create_model()
2025-05-14 10:51:29,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:29,637:INFO:Checking exceptions
2025-05-14 10:51:29,637:INFO:Importing libraries
2025-05-14 10:51:29,637:INFO:Copying training dataset
2025-05-14 10:51:29,648:INFO:Defining folds
2025-05-14 10:51:29,648:INFO:Declaring metric variables
2025-05-14 10:51:29,649:INFO:Importing untrained model
2025-05-14 10:51:29,651:INFO:K Neighbors Classifier Imported successfully
2025-05-14 10:51:29,653:INFO:Starting cross validation
2025-05-14 10:51:29,654:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:35,685:INFO:Calculating mean and std
2025-05-14 10:51:35,686:INFO:Creating metrics dataframe
2025-05-14 10:51:35,692:INFO:Uploading results into container
2025-05-14 10:51:35,692:INFO:Uploading model into container now
2025-05-14 10:51:35,693:INFO:_master_model_container: 2
2025-05-14 10:51:35,693:INFO:_display_container: 2
2025-05-14 10:51:35,693:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 10:51:35,693:INFO:create_model() successfully completed......................................
2025-05-14 10:51:35,772:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:35,772:INFO:Creating metrics dataframe
2025-05-14 10:51:35,775:INFO:Initializing Naive Bayes
2025-05-14 10:51:35,775:INFO:Total runtime is 0.20678410132726033 minutes
2025-05-14 10:51:35,776:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:35,776:INFO:Initializing create_model()
2025-05-14 10:51:35,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:35,776:INFO:Checking exceptions
2025-05-14 10:51:35,776:INFO:Importing libraries
2025-05-14 10:51:35,776:INFO:Copying training dataset
2025-05-14 10:51:35,788:INFO:Defining folds
2025-05-14 10:51:35,788:INFO:Declaring metric variables
2025-05-14 10:51:35,790:INFO:Importing untrained model
2025-05-14 10:51:35,791:INFO:Naive Bayes Imported successfully
2025-05-14 10:51:35,793:INFO:Starting cross validation
2025-05-14 10:51:35,794:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:38,097:INFO:Calculating mean and std
2025-05-14 10:51:38,098:INFO:Creating metrics dataframe
2025-05-14 10:51:38,099:INFO:Uploading results into container
2025-05-14 10:51:38,099:INFO:Uploading model into container now
2025-05-14 10:51:38,099:INFO:_master_model_container: 3
2025-05-14 10:51:38,099:INFO:_display_container: 2
2025-05-14 10:51:38,099:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 10:51:38,099:INFO:create_model() successfully completed......................................
2025-05-14 10:51:38,167:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:38,167:INFO:Creating metrics dataframe
2025-05-14 10:51:38,170:INFO:Initializing Decision Tree Classifier
2025-05-14 10:51:38,170:INFO:Total runtime is 0.2467023173967997 minutes
2025-05-14 10:51:38,171:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:38,171:INFO:Initializing create_model()
2025-05-14 10:51:38,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:38,171:INFO:Checking exceptions
2025-05-14 10:51:38,172:INFO:Importing libraries
2025-05-14 10:51:38,172:INFO:Copying training dataset
2025-05-14 10:51:38,181:INFO:Defining folds
2025-05-14 10:51:38,181:INFO:Declaring metric variables
2025-05-14 10:51:38,182:INFO:Importing untrained model
2025-05-14 10:51:38,183:INFO:Decision Tree Classifier Imported successfully
2025-05-14 10:51:38,186:INFO:Starting cross validation
2025-05-14 10:51:38,187:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:39,861:INFO:Calculating mean and std
2025-05-14 10:51:39,861:INFO:Creating metrics dataframe
2025-05-14 10:51:39,862:INFO:Uploading results into container
2025-05-14 10:51:39,862:INFO:Uploading model into container now
2025-05-14 10:51:39,863:INFO:_master_model_container: 4
2025-05-14 10:51:39,863:INFO:_display_container: 2
2025-05-14 10:51:39,863:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-14 10:51:39,863:INFO:create_model() successfully completed......................................
2025-05-14 10:51:39,922:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:39,923:INFO:Creating metrics dataframe
2025-05-14 10:51:39,926:INFO:Initializing SVM - Linear Kernel
2025-05-14 10:51:39,926:INFO:Total runtime is 0.2759643832842509 minutes
2025-05-14 10:51:39,927:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:39,927:INFO:Initializing create_model()
2025-05-14 10:51:39,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:39,927:INFO:Checking exceptions
2025-05-14 10:51:39,927:INFO:Importing libraries
2025-05-14 10:51:39,927:INFO:Copying training dataset
2025-05-14 10:51:39,936:INFO:Defining folds
2025-05-14 10:51:39,936:INFO:Declaring metric variables
2025-05-14 10:51:39,938:INFO:Importing untrained model
2025-05-14 10:51:39,939:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 10:51:39,941:INFO:Starting cross validation
2025-05-14 10:51:39,942:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:43,401:INFO:Calculating mean and std
2025-05-14 10:51:43,406:INFO:Creating metrics dataframe
2025-05-14 10:51:43,409:INFO:Uploading results into container
2025-05-14 10:51:43,409:INFO:Uploading model into container now
2025-05-14 10:51:43,410:INFO:_master_model_container: 5
2025-05-14 10:51:43,410:INFO:_display_container: 2
2025-05-14 10:51:43,411:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 10:51:43,411:INFO:create_model() successfully completed......................................
2025-05-14 10:51:43,491:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:43,491:INFO:Creating metrics dataframe
2025-05-14 10:51:43,494:INFO:Initializing Ridge Classifier
2025-05-14 10:51:43,494:INFO:Total runtime is 0.3354432185490926 minutes
2025-05-14 10:51:43,496:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:43,496:INFO:Initializing create_model()
2025-05-14 10:51:43,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:43,496:INFO:Checking exceptions
2025-05-14 10:51:43,496:INFO:Importing libraries
2025-05-14 10:51:43,496:INFO:Copying training dataset
2025-05-14 10:51:43,507:INFO:Defining folds
2025-05-14 10:51:43,507:INFO:Declaring metric variables
2025-05-14 10:51:43,508:INFO:Importing untrained model
2025-05-14 10:51:43,509:INFO:Ridge Classifier Imported successfully
2025-05-14 10:51:43,511:INFO:Starting cross validation
2025-05-14 10:51:43,513:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:45,748:INFO:Calculating mean and std
2025-05-14 10:51:45,748:INFO:Creating metrics dataframe
2025-05-14 10:51:45,750:INFO:Uploading results into container
2025-05-14 10:51:45,750:INFO:Uploading model into container now
2025-05-14 10:51:45,750:INFO:_master_model_container: 6
2025-05-14 10:51:45,750:INFO:_display_container: 2
2025-05-14 10:51:45,750:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-14 10:51:45,751:INFO:create_model() successfully completed......................................
2025-05-14 10:51:45,815:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:45,815:INFO:Creating metrics dataframe
2025-05-14 10:51:45,818:INFO:Initializing Random Forest Classifier
2025-05-14 10:51:45,818:INFO:Total runtime is 0.37417763471603394 minutes
2025-05-14 10:51:45,820:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:45,820:INFO:Initializing create_model()
2025-05-14 10:51:45,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:45,820:INFO:Checking exceptions
2025-05-14 10:51:45,820:INFO:Importing libraries
2025-05-14 10:51:45,820:INFO:Copying training dataset
2025-05-14 10:51:45,830:INFO:Defining folds
2025-05-14 10:51:45,830:INFO:Declaring metric variables
2025-05-14 10:51:45,831:INFO:Importing untrained model
2025-05-14 10:51:45,833:INFO:Random Forest Classifier Imported successfully
2025-05-14 10:51:45,835:INFO:Starting cross validation
2025-05-14 10:51:45,836:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:51,899:INFO:Calculating mean and std
2025-05-14 10:51:51,900:INFO:Creating metrics dataframe
2025-05-14 10:51:51,901:INFO:Uploading results into container
2025-05-14 10:51:51,901:INFO:Uploading model into container now
2025-05-14 10:51:51,902:INFO:_master_model_container: 7
2025-05-14 10:51:51,902:INFO:_display_container: 2
2025-05-14 10:51:51,903:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 10:51:51,903:INFO:create_model() successfully completed......................................
2025-05-14 10:51:51,983:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:51,983:INFO:Creating metrics dataframe
2025-05-14 10:51:51,987:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 10:51:51,987:INFO:Total runtime is 0.4769856532414754 minutes
2025-05-14 10:51:51,988:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:51,989:INFO:Initializing create_model()
2025-05-14 10:51:51,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:51,989:INFO:Checking exceptions
2025-05-14 10:51:51,989:INFO:Importing libraries
2025-05-14 10:51:51,989:INFO:Copying training dataset
2025-05-14 10:51:52,005:INFO:Defining folds
2025-05-14 10:51:52,006:INFO:Declaring metric variables
2025-05-14 10:51:52,007:INFO:Importing untrained model
2025-05-14 10:51:52,008:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 10:51:52,011:INFO:Starting cross validation
2025-05-14 10:51:52,012:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:53,094:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 10:51:53,115:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 10:51:53,150:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 10:51:53,185:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 10:51:53,189:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:51:53,203:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:51:53,229:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 10:51:53,246:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:51:53,272:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:51:53,311:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:51:53,329:INFO:Calculating mean and std
2025-05-14 10:51:53,331:INFO:Creating metrics dataframe
2025-05-14 10:51:53,338:INFO:Uploading results into container
2025-05-14 10:51:53,339:INFO:Uploading model into container now
2025-05-14 10:51:53,339:INFO:_master_model_container: 8
2025-05-14 10:51:53,339:INFO:_display_container: 2
2025-05-14 10:51:53,339:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 10:51:53,339:INFO:create_model() successfully completed......................................
2025-05-14 10:51:53,442:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:53,442:INFO:Creating metrics dataframe
2025-05-14 10:51:53,446:INFO:Initializing Ada Boost Classifier
2025-05-14 10:51:53,446:INFO:Total runtime is 0.5013117671012878 minutes
2025-05-14 10:51:53,448:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:53,448:INFO:Initializing create_model()
2025-05-14 10:51:53,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:53,448:INFO:Checking exceptions
2025-05-14 10:51:53,448:INFO:Importing libraries
2025-05-14 10:51:53,448:INFO:Copying training dataset
2025-05-14 10:51:53,460:INFO:Defining folds
2025-05-14 10:51:53,460:INFO:Declaring metric variables
2025-05-14 10:51:53,461:INFO:Importing untrained model
2025-05-14 10:51:53,463:INFO:Ada Boost Classifier Imported successfully
2025-05-14 10:51:53,465:INFO:Starting cross validation
2025-05-14 10:51:53,466:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:51:54,498:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 10:51:54,527:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 10:51:54,529:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 10:51:54,614:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 10:51:56,147:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 10:51:58,813:INFO:Calculating mean and std
2025-05-14 10:51:58,814:INFO:Creating metrics dataframe
2025-05-14 10:51:58,816:INFO:Uploading results into container
2025-05-14 10:51:58,816:INFO:Uploading model into container now
2025-05-14 10:51:58,816:INFO:_master_model_container: 9
2025-05-14 10:51:58,816:INFO:_display_container: 2
2025-05-14 10:51:58,816:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-14 10:51:58,816:INFO:create_model() successfully completed......................................
2025-05-14 10:51:58,885:INFO:SubProcess create_model() end ==================================
2025-05-14 10:51:58,885:INFO:Creating metrics dataframe
2025-05-14 10:51:58,889:INFO:Initializing Gradient Boosting Classifier
2025-05-14 10:51:58,889:INFO:Total runtime is 0.5920176029205322 minutes
2025-05-14 10:51:58,890:INFO:SubProcess create_model() called ==================================
2025-05-14 10:51:58,890:INFO:Initializing create_model()
2025-05-14 10:51:58,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:51:58,890:INFO:Checking exceptions
2025-05-14 10:51:58,890:INFO:Importing libraries
2025-05-14 10:51:58,890:INFO:Copying training dataset
2025-05-14 10:51:58,902:INFO:Defining folds
2025-05-14 10:51:58,902:INFO:Declaring metric variables
2025-05-14 10:51:58,903:INFO:Importing untrained model
2025-05-14 10:51:58,905:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 10:51:58,907:INFO:Starting cross validation
2025-05-14 10:51:58,908:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:52:12,615:INFO:Calculating mean and std
2025-05-14 10:52:12,616:INFO:Creating metrics dataframe
2025-05-14 10:52:12,618:INFO:Uploading results into container
2025-05-14 10:52:12,618:INFO:Uploading model into container now
2025-05-14 10:52:12,618:INFO:_master_model_container: 10
2025-05-14 10:52:12,618:INFO:_display_container: 2
2025-05-14 10:52:12,619:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 10:52:12,619:INFO:create_model() successfully completed......................................
2025-05-14 10:52:12,694:INFO:SubProcess create_model() end ==================================
2025-05-14 10:52:12,694:INFO:Creating metrics dataframe
2025-05-14 10:52:12,698:INFO:Initializing Linear Discriminant Analysis
2025-05-14 10:52:12,698:INFO:Total runtime is 0.8221716483434041 minutes
2025-05-14 10:52:12,699:INFO:SubProcess create_model() called ==================================
2025-05-14 10:52:12,699:INFO:Initializing create_model()
2025-05-14 10:52:12,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:52:12,700:INFO:Checking exceptions
2025-05-14 10:52:12,700:INFO:Importing libraries
2025-05-14 10:52:12,700:INFO:Copying training dataset
2025-05-14 10:52:12,711:INFO:Defining folds
2025-05-14 10:52:12,711:INFO:Declaring metric variables
2025-05-14 10:52:12,712:INFO:Importing untrained model
2025-05-14 10:52:12,713:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 10:52:12,715:INFO:Starting cross validation
2025-05-14 10:52:12,717:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:52:14,014:INFO:Calculating mean and std
2025-05-14 10:52:14,015:INFO:Creating metrics dataframe
2025-05-14 10:52:14,016:INFO:Uploading results into container
2025-05-14 10:52:14,017:INFO:Uploading model into container now
2025-05-14 10:52:14,017:INFO:_master_model_container: 11
2025-05-14 10:52:14,017:INFO:_display_container: 2
2025-05-14 10:52:14,017:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 10:52:14,017:INFO:create_model() successfully completed......................................
2025-05-14 10:52:14,087:INFO:SubProcess create_model() end ==================================
2025-05-14 10:52:14,087:INFO:Creating metrics dataframe
2025-05-14 10:52:14,091:INFO:Initializing Extra Trees Classifier
2025-05-14 10:52:14,091:INFO:Total runtime is 0.8453885197639465 minutes
2025-05-14 10:52:14,092:INFO:SubProcess create_model() called ==================================
2025-05-14 10:52:14,093:INFO:Initializing create_model()
2025-05-14 10:52:14,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:52:14,093:INFO:Checking exceptions
2025-05-14 10:52:14,093:INFO:Importing libraries
2025-05-14 10:52:14,093:INFO:Copying training dataset
2025-05-14 10:52:14,105:INFO:Defining folds
2025-05-14 10:52:14,105:INFO:Declaring metric variables
2025-05-14 10:52:14,106:INFO:Importing untrained model
2025-05-14 10:52:14,108:INFO:Extra Trees Classifier Imported successfully
2025-05-14 10:52:14,110:INFO:Starting cross validation
2025-05-14 10:52:14,111:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:52:18,626:INFO:Calculating mean and std
2025-05-14 10:52:18,629:INFO:Creating metrics dataframe
2025-05-14 10:52:18,632:INFO:Uploading results into container
2025-05-14 10:52:18,633:INFO:Uploading model into container now
2025-05-14 10:52:18,633:INFO:_master_model_container: 12
2025-05-14 10:52:18,633:INFO:_display_container: 2
2025-05-14 10:52:18,634:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-14 10:52:18,634:INFO:create_model() successfully completed......................................
2025-05-14 10:52:18,787:INFO:SubProcess create_model() end ==================================
2025-05-14 10:52:18,787:INFO:Creating metrics dataframe
2025-05-14 10:52:18,792:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 10:52:18,792:INFO:Total runtime is 0.9237370332082112 minutes
2025-05-14 10:52:18,794:INFO:SubProcess create_model() called ==================================
2025-05-14 10:52:18,795:INFO:Initializing create_model()
2025-05-14 10:52:18,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:52:18,795:INFO:Checking exceptions
2025-05-14 10:52:18,795:INFO:Importing libraries
2025-05-14 10:52:18,795:INFO:Copying training dataset
2025-05-14 10:52:18,809:INFO:Defining folds
2025-05-14 10:52:18,809:INFO:Declaring metric variables
2025-05-14 10:52:18,811:INFO:Importing untrained model
2025-05-14 10:52:18,813:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 10:52:18,815:INFO:Starting cross validation
2025-05-14 10:52:18,816:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:52:23,127:INFO:Calculating mean and std
2025-05-14 10:52:23,127:INFO:Creating metrics dataframe
2025-05-14 10:52:23,128:INFO:Uploading results into container
2025-05-14 10:52:23,129:INFO:Uploading model into container now
2025-05-14 10:52:23,129:INFO:_master_model_container: 13
2025-05-14 10:52:23,129:INFO:_display_container: 2
2025-05-14 10:52:23,129:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 10:52:23,129:INFO:create_model() successfully completed......................................
2025-05-14 10:52:23,198:INFO:SubProcess create_model() end ==================================
2025-05-14 10:52:23,198:INFO:Creating metrics dataframe
2025-05-14 10:52:23,203:INFO:Initializing CatBoost Classifier
2025-05-14 10:52:23,203:INFO:Total runtime is 0.9972560683886209 minutes
2025-05-14 10:52:23,204:INFO:SubProcess create_model() called ==================================
2025-05-14 10:52:23,205:INFO:Initializing create_model()
2025-05-14 10:52:23,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:52:23,205:INFO:Checking exceptions
2025-05-14 10:52:23,205:INFO:Importing libraries
2025-05-14 10:52:23,205:INFO:Copying training dataset
2025-05-14 10:52:23,215:INFO:Defining folds
2025-05-14 10:52:23,215:INFO:Declaring metric variables
2025-05-14 10:52:23,216:INFO:Importing untrained model
2025-05-14 10:52:23,218:INFO:CatBoost Classifier Imported successfully
2025-05-14 10:52:23,220:INFO:Starting cross validation
2025-05-14 10:52:23,222:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:52:40,313:INFO:Calculating mean and std
2025-05-14 10:52:40,315:INFO:Creating metrics dataframe
2025-05-14 10:52:40,316:INFO:Uploading results into container
2025-05-14 10:52:40,317:INFO:Uploading model into container now
2025-05-14 10:52:40,317:INFO:_master_model_container: 14
2025-05-14 10:52:40,317:INFO:_display_container: 2
2025-05-14 10:52:40,317:INFO:<catboost.core.CatBoostClassifier object at 0x33ce16410>
2025-05-14 10:52:40,317:INFO:create_model() successfully completed......................................
2025-05-14 10:52:40,400:INFO:SubProcess create_model() end ==================================
2025-05-14 10:52:40,400:INFO:Creating metrics dataframe
2025-05-14 10:52:40,404:INFO:Initializing Dummy Classifier
2025-05-14 10:52:40,404:INFO:Total runtime is 1.2839414199193318 minutes
2025-05-14 10:52:40,406:INFO:SubProcess create_model() called ==================================
2025-05-14 10:52:40,406:INFO:Initializing create_model()
2025-05-14 10:52:40,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332607fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:52:40,406:INFO:Checking exceptions
2025-05-14 10:52:40,406:INFO:Importing libraries
2025-05-14 10:52:40,406:INFO:Copying training dataset
2025-05-14 10:52:40,418:INFO:Defining folds
2025-05-14 10:52:40,418:INFO:Declaring metric variables
2025-05-14 10:52:40,420:INFO:Importing untrained model
2025-05-14 10:52:40,421:INFO:Dummy Classifier Imported successfully
2025-05-14 10:52:40,424:INFO:Starting cross validation
2025-05-14 10:52:40,425:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:52:41,493:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:52:41,507:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:52:41,539:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:52:41,589:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:52:41,668:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 10:52:41,676:INFO:Calculating mean and std
2025-05-14 10:52:41,676:INFO:Creating metrics dataframe
2025-05-14 10:52:41,677:INFO:Uploading results into container
2025-05-14 10:52:41,677:INFO:Uploading model into container now
2025-05-14 10:52:41,677:INFO:_master_model_container: 15
2025-05-14 10:52:41,677:INFO:_display_container: 2
2025-05-14 10:52:41,677:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-14 10:52:41,678:INFO:create_model() successfully completed......................................
2025-05-14 10:52:41,741:INFO:SubProcess create_model() end ==================================
2025-05-14 10:52:41,741:INFO:Creating metrics dataframe
2025-05-14 10:52:41,746:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2025-05-14 10:52:41,749:INFO:Initializing create_model()
2025-05-14 10:52:41,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:52:41,749:INFO:Checking exceptions
2025-05-14 10:52:41,750:INFO:Importing libraries
2025-05-14 10:52:41,750:INFO:Copying training dataset
2025-05-14 10:52:41,760:INFO:Defining folds
2025-05-14 10:52:41,760:INFO:Declaring metric variables
2025-05-14 10:52:41,760:INFO:Importing untrained model
2025-05-14 10:52:41,760:INFO:Declaring custom model
2025-05-14 10:52:41,760:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 10:52:41,761:INFO:Cross validation set to False
2025-05-14 10:52:41,761:INFO:Fitting Model
2025-05-14 10:52:43,157:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 10:52:43,167:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004613 seconds.
2025-05-14 10:52:43,167:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 10:52:43,167:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 10:52:43,167:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 10:52:43,167:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 10:52:43,167:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 10:52:43,924:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 10:52:43,924:INFO:create_model() successfully completed......................................
2025-05-14 10:52:43,984:INFO:Initializing create_model()
2025-05-14 10:52:43,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:52:43,984:INFO:Checking exceptions
2025-05-14 10:52:43,985:INFO:Importing libraries
2025-05-14 10:52:43,985:INFO:Copying training dataset
2025-05-14 10:52:43,995:INFO:Defining folds
2025-05-14 10:52:43,995:INFO:Declaring metric variables
2025-05-14 10:52:43,995:INFO:Importing untrained model
2025-05-14 10:52:43,995:INFO:Declaring custom model
2025-05-14 10:52:43,996:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 10:52:43,996:INFO:Cross validation set to False
2025-05-14 10:52:43,996:INFO:Fitting Model
2025-05-14 10:53:00,176:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 10:53:00,176:INFO:create_model() successfully completed......................................
2025-05-14 10:53:00,278:INFO:Initializing create_model()
2025-05-14 10:53:00,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:53:00,278:INFO:Checking exceptions
2025-05-14 10:53:00,279:INFO:Importing libraries
2025-05-14 10:53:00,279:INFO:Copying training dataset
2025-05-14 10:53:00,290:INFO:Defining folds
2025-05-14 10:53:00,290:INFO:Declaring metric variables
2025-05-14 10:53:00,290:INFO:Importing untrained model
2025-05-14 10:53:00,290:INFO:Declaring custom model
2025-05-14 10:53:00,290:INFO:Random Forest Classifier Imported successfully
2025-05-14 10:53:00,291:INFO:Cross validation set to False
2025-05-14 10:53:00,291:INFO:Fitting Model
2025-05-14 10:53:02,663:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 10:53:02,663:INFO:create_model() successfully completed......................................
2025-05-14 10:53:02,729:INFO:_master_model_container: 15
2025-05-14 10:53:02,730:INFO:_display_container: 2
2025-05-14 10:53:02,730:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-14 10:53:02,730:INFO:compare_models() successfully completed......................................
2025-05-14 10:53:02,731:INFO:Initializing evaluate_model()
2025-05-14 10:53:02,731:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 10:53:02,737:INFO:Initializing plot_model()
2025-05-14 10:53:02,737:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 10:53:02,737:INFO:Checking exceptions
2025-05-14 10:53:02,741:INFO:Preloading libraries
2025-05-14 10:53:02,742:INFO:Copying training dataset
2025-05-14 10:53:02,742:INFO:Plot type: pipeline
2025-05-14 10:53:02,818:INFO:Visual Rendered Successfully
2025-05-14 10:53:02,881:INFO:plot_model() successfully completed......................................
2025-05-14 10:53:02,882:INFO:Initializing tune_model()
2025-05-14 10:53:02,882:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 10:53:02,882:INFO:Checking exceptions
2025-05-14 10:53:02,891:INFO:Copying training dataset
2025-05-14 10:53:02,898:INFO:Checking base model
2025-05-14 10:53:02,898:INFO:Base model : Light Gradient Boosting Machine
2025-05-14 10:53:02,899:INFO:Declaring metric variables
2025-05-14 10:53:02,900:INFO:Defining Hyperparameters
2025-05-14 10:53:02,961:INFO:Tuning with n_jobs=-1
2025-05-14 10:53:02,961:INFO:Initializing RandomizedSearchCV
2025-05-14 10:53:41,166:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-14 10:53:41,169:INFO:Hyperparameter search completed
2025-05-14 10:53:41,170:INFO:SubProcess create_model() called ==================================
2025-05-14 10:53:41,172:INFO:Initializing create_model()
2025-05-14 10:53:41,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336c18dd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-14 10:53:41,172:INFO:Checking exceptions
2025-05-14 10:53:41,172:INFO:Importing libraries
2025-05-14 10:53:41,172:INFO:Copying training dataset
2025-05-14 10:53:41,196:INFO:Defining folds
2025-05-14 10:53:41,196:INFO:Declaring metric variables
2025-05-14 10:53:41,201:INFO:Importing untrained model
2025-05-14 10:53:41,201:INFO:Declaring custom model
2025-05-14 10:53:41,204:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 10:53:41,210:INFO:Starting cross validation
2025-05-14 10:53:41,221:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:53:48,107:INFO:Calculating mean and std
2025-05-14 10:53:48,110:INFO:Creating metrics dataframe
2025-05-14 10:53:48,116:INFO:Finalizing model
2025-05-14 10:53:49,208:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 10:53:49,208:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 10:53:49,208:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 10:53:49,242:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 10:53:49,242:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 10:53:49,242:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 10:53:49,242:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 10:53:49,258:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009285 seconds.
2025-05-14 10:53:49,258:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 10:53:49,258:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 10:53:49,258:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 10:53:49,258:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 10:53:49,258:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 10:53:50,712:INFO:Uploading results into container
2025-05-14 10:53:50,713:INFO:Uploading model into container now
2025-05-14 10:53:50,713:INFO:_master_model_container: 16
2025-05-14 10:53:50,713:INFO:_display_container: 3
2025-05-14 10:53:50,714:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 10:53:50,714:INFO:create_model() successfully completed......................................
2025-05-14 10:53:50,819:INFO:SubProcess create_model() end ==================================
2025-05-14 10:53:50,819:INFO:choose_better activated
2025-05-14 10:53:50,820:INFO:SubProcess create_model() called ==================================
2025-05-14 10:53:50,821:INFO:Initializing create_model()
2025-05-14 10:53:50,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 10:53:50,821:INFO:Checking exceptions
2025-05-14 10:53:50,822:INFO:Importing libraries
2025-05-14 10:53:50,822:INFO:Copying training dataset
2025-05-14 10:53:50,831:INFO:Defining folds
2025-05-14 10:53:50,832:INFO:Declaring metric variables
2025-05-14 10:53:50,832:INFO:Importing untrained model
2025-05-14 10:53:50,832:INFO:Declaring custom model
2025-05-14 10:53:50,832:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 10:53:50,832:INFO:Starting cross validation
2025-05-14 10:53:50,833:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 10:53:54,673:INFO:Calculating mean and std
2025-05-14 10:53:54,673:INFO:Creating metrics dataframe
2025-05-14 10:53:54,674:INFO:Finalizing model
2025-05-14 10:53:55,728:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 10:53:55,740:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005132 seconds.
2025-05-14 10:53:55,740:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 10:53:55,740:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 10:53:55,740:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 10:53:55,740:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 10:53:55,740:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 10:53:56,505:INFO:Uploading results into container
2025-05-14 10:53:56,505:INFO:Uploading model into container now
2025-05-14 10:53:56,506:INFO:_master_model_container: 17
2025-05-14 10:53:56,506:INFO:_display_container: 4
2025-05-14 10:53:56,506:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 10:53:56,506:INFO:create_model() successfully completed......................................
2025-05-14 10:53:56,569:INFO:SubProcess create_model() end ==================================
2025-05-14 10:53:56,569:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-14 10:53:56,570:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-14 10:53:56,570:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-14 10:53:56,570:INFO:choose_better completed
2025-05-14 10:53:56,574:INFO:_master_model_container: 17
2025-05-14 10:53:56,574:INFO:_display_container: 3
2025-05-14 10:53:56,574:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 10:53:56,574:INFO:tune_model() successfully completed......................................
2025-05-14 10:53:56,639:INFO:Initializing evaluate_model()
2025-05-14 10:53:56,639:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 10:53:56,646:INFO:Initializing plot_model()
2025-05-14 10:53:56,646:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 10:53:56,646:INFO:Checking exceptions
2025-05-14 10:53:56,650:INFO:Preloading libraries
2025-05-14 10:53:56,652:INFO:Copying training dataset
2025-05-14 10:53:56,652:INFO:Plot type: pipeline
2025-05-14 10:53:56,709:INFO:Visual Rendered Successfully
2025-05-14 10:53:56,771:INFO:plot_model() successfully completed......................................
2025-05-14 10:53:56,773:INFO:Initializing interpret_model()
2025-05-14 10:53:56,773:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x332497f50>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 10:53:56,773:INFO:Checking exceptions
2025-05-14 10:53:56,773:INFO:Soft dependency imported: shap: 0.47.2
2025-05-14 10:53:57,857:INFO:plot type: summary
2025-05-14 10:53:57,857:INFO:Creating TreeExplainer
2025-05-14 10:53:57,934:INFO:Compiling shap values
2025-05-14 10:53:59,133:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning:

LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray


2025-05-14 10:53:59,133:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning:

The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.


2025-05-14 10:54:00,416:INFO:Visual Rendered Successfully
2025-05-14 10:54:00,416:INFO:interpret_model() successfully completed......................................
2025-05-14 10:54:00,490:INFO:PyCaret ClassificationExperiment
2025-05-14 10:54:00,490:INFO:Logging name: clf-default-name
2025-05-14 10:54:00,490:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 10:54:00,490:INFO:version 3.3.2
2025-05-14 10:54:00,490:INFO:Initializing setup()
2025-05-14 10:54:00,490:INFO:self.USI: 9474
2025-05-14 10:54:00,490:INFO:self._variable_keys: {'USI', 'exp_id', 'X', 'y_train', 'is_multiclass', 'memory', 'idx', 'data', 'y_test', 'n_jobs_param', 'pipeline', 'y', 'fold_generator', 'logging_param', 'fold_groups_param', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'html_param', 'X_test', 'gpu_param', 'X_train', '_available_plots', 'seed', 'exp_name_log', 'fold_shuffle_param', 'log_plots_param', 'target_param'}
2025-05-14 10:54:00,490:INFO:Checking environment
2025-05-14 10:54:00,490:INFO:python_version: 3.11.0
2025-05-14 10:54:00,490:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-14 10:54:00,490:INFO:machine: arm64
2025-05-14 10:54:00,490:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-14 10:54:00,490:INFO:Memory: svmem(total=17179869184, available=3576659968, percent=79.2, used=5830524928, free=57999360, active=3528589312, inactive=3503734784, wired=2301935616)
2025-05-14 10:54:00,490:INFO:Physical Core: 12
2025-05-14 10:54:00,490:INFO:Logical Core: 12
2025-05-14 10:54:00,491:INFO:Checking libraries
2025-05-14 10:54:00,491:INFO:System:
2025-05-14 10:54:00,491:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-14 10:54:00,491:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-14 10:54:00,491:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-14 10:54:00,491:INFO:PyCaret required dependencies:
2025-05-14 10:54:00,491:INFO:                 pip: 22.3
2025-05-14 10:54:00,491:INFO:          setuptools: 65.5.0
2025-05-14 10:54:00,491:INFO:             pycaret: 3.3.2
2025-05-14 10:54:00,491:INFO:             IPython: 9.2.0
2025-05-14 10:54:00,491:INFO:          ipywidgets: 8.1.7
2025-05-14 10:54:00,491:INFO:                tqdm: 4.67.1
2025-05-14 10:54:00,491:INFO:               numpy: 1.26.4
2025-05-14 10:54:00,491:INFO:              pandas: 2.1.4
2025-05-14 10:54:00,491:INFO:              jinja2: 3.1.6
2025-05-14 10:54:00,491:INFO:               scipy: 1.11.4
2025-05-14 10:54:00,491:INFO:              joblib: 1.3.2
2025-05-14 10:54:00,491:INFO:             sklearn: 1.4.2
2025-05-14 10:54:00,491:INFO:                pyod: 2.0.5
2025-05-14 10:54:00,491:INFO:            imblearn: 0.13.0
2025-05-14 10:54:00,491:INFO:   category_encoders: 2.7.0
2025-05-14 10:54:00,491:INFO:            lightgbm: 4.6.0
2025-05-14 10:54:00,491:INFO:               numba: 0.61.2
2025-05-14 10:54:00,491:INFO:            requests: 2.32.3
2025-05-14 10:54:00,491:INFO:          matplotlib: 3.7.5
2025-05-14 10:54:00,491:INFO:          scikitplot: 0.3.7
2025-05-14 10:54:00,491:INFO:         yellowbrick: 1.5
2025-05-14 10:54:00,491:INFO:              plotly: 5.24.1
2025-05-14 10:54:00,491:INFO:    plotly-resampler: Not installed
2025-05-14 10:54:00,491:INFO:             kaleido: 0.2.1
2025-05-14 10:54:00,491:INFO:           schemdraw: 0.15
2025-05-14 10:54:00,491:INFO:         statsmodels: 0.14.4
2025-05-14 10:54:00,491:INFO:              sktime: 0.26.0
2025-05-14 10:54:00,491:INFO:               tbats: 1.1.3
2025-05-14 10:54:00,491:INFO:            pmdarima: 2.0.4
2025-05-14 10:54:00,491:INFO:              psutil: 7.0.0
2025-05-14 10:54:00,491:INFO:          markupsafe: 3.0.2
2025-05-14 10:54:00,491:INFO:             pickle5: Not installed
2025-05-14 10:54:00,491:INFO:         cloudpickle: 3.1.1
2025-05-14 10:54:00,491:INFO:         deprecation: 2.1.0
2025-05-14 10:54:00,491:INFO:              xxhash: 3.5.0
2025-05-14 10:54:00,491:INFO:           wurlitzer: 3.1.1
2025-05-14 10:54:00,491:INFO:PyCaret optional dependencies:
2025-05-14 10:54:00,491:INFO:                shap: 0.47.2
2025-05-14 10:54:00,491:INFO:           interpret: Not installed
2025-05-14 10:54:00,491:INFO:                umap: Not installed
2025-05-14 10:54:00,491:INFO:     ydata_profiling: Not installed
2025-05-14 10:54:00,491:INFO:  explainerdashboard: Not installed
2025-05-14 10:54:00,491:INFO:             autoviz: Not installed
2025-05-14 10:54:00,491:INFO:           fairlearn: Not installed
2025-05-14 10:54:00,491:INFO:          deepchecks: Not installed
2025-05-14 10:54:00,491:INFO:             xgboost: Not installed
2025-05-14 10:54:00,491:INFO:            catboost: 1.2.8
2025-05-14 10:54:00,491:INFO:              kmodes: Not installed
2025-05-14 10:54:00,491:INFO:             mlxtend: Not installed
2025-05-14 10:54:00,491:INFO:       statsforecast: Not installed
2025-05-14 10:54:00,491:INFO:        tune_sklearn: Not installed
2025-05-14 10:54:00,491:INFO:                 ray: Not installed
2025-05-14 10:54:00,491:INFO:            hyperopt: Not installed
2025-05-14 10:54:00,491:INFO:              optuna: 4.3.0
2025-05-14 10:54:00,491:INFO:               skopt: Not installed
2025-05-14 10:54:00,491:INFO:              mlflow: Not installed
2025-05-14 10:54:00,491:INFO:              gradio: Not installed
2025-05-14 10:54:00,491:INFO:             fastapi: Not installed
2025-05-14 10:54:00,491:INFO:             uvicorn: Not installed
2025-05-14 10:54:00,491:INFO:              m2cgen: Not installed
2025-05-14 10:54:00,491:INFO:           evidently: Not installed
2025-05-14 10:54:00,491:INFO:               fugue: Not installed
2025-05-14 10:54:00,491:INFO:           streamlit: Not installed
2025-05-14 10:54:00,491:INFO:             prophet: Not installed
2025-05-14 10:54:00,491:INFO:None
2025-05-14 10:54:00,491:INFO:Set up data.
2025-05-14 10:54:00,542:INFO:Set up folding strategy.
2025-05-14 10:54:00,542:INFO:Set up train/test split.
2025-05-14 10:54:00,558:INFO:Set up index.
2025-05-14 10:54:00,559:INFO:Assigning column types.
2025-05-14 10:54:00,563:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 10:54:00,581:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 10:54:00,581:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:54:00,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:00,592:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:00,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 10:54:00,610:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:54:00,621:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:00,621:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:00,622:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 10:54:00,639:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:54:00,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:00,650:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:00,668:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 10:54:00,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:00,679:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:00,679:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 10:54:00,708:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:00,708:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:00,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:00,738:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:00,738:INFO:Preparing preprocessing pipeline...
2025-05-14 10:54:00,739:INFO:Set up simple imputation.
2025-05-14 10:54:00,746:INFO:Set up encoding of ordinal features.
2025-05-14 10:54:00,758:INFO:Set up encoding of categorical features.
2025-05-14 10:54:00,758:INFO:Set up imbalanced handling.
2025-05-14 10:54:00,758:INFO:Set up column transformation.
2025-05-14 10:54:02,096:INFO:Finished creating preprocessing pipeline.
2025-05-14 10:54:02,115:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-14 10:54:02,115:INFO:Creating final display dataframe.
2025-05-14 10:54:02,707:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (87159, 16)
4        Transformed data shape      (133528, 29)
5   Transformed train set shape      (107380, 29)
6    Transformed test set shape       (26148, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              9474
2025-05-14 10:54:02,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:02,738:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:02,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 10:54:02,768:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 10:54:02,768:INFO:setup() successfully completed in 2.28s...............
2025-05-14 10:54:02,768:INFO:Initializing get_config()
2025-05-14 10:54:02,768:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33e429d90>, variable=prep_pipe)
2025-05-14 11:00:07,141:INFO:PyCaret ClassificationExperiment
2025-05-14 11:00:07,141:INFO:Logging name: clf-default-name
2025-05-14 11:00:07,141:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 11:00:07,141:INFO:version 3.3.2
2025-05-14 11:00:07,141:INFO:Initializing setup()
2025-05-14 11:00:07,141:INFO:self.USI: cab3
2025-05-14 11:00:07,141:INFO:self._variable_keys: {'USI', 'exp_id', 'X', 'y_train', 'is_multiclass', 'memory', 'idx', 'data', 'y_test', 'n_jobs_param', 'pipeline', 'y', 'fold_generator', 'logging_param', 'fold_groups_param', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'html_param', 'X_test', 'gpu_param', 'X_train', '_available_plots', 'seed', 'exp_name_log', 'fold_shuffle_param', 'log_plots_param', 'target_param'}
2025-05-14 11:00:07,141:INFO:Checking environment
2025-05-14 11:00:07,141:INFO:python_version: 3.11.0
2025-05-14 11:00:07,141:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-14 11:00:07,141:INFO:machine: arm64
2025-05-14 11:00:07,141:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:00:07,142:INFO:Memory: svmem(total=17179869184, available=4533993472, percent=73.6, used=7127662592, free=59342848, active=4499062784, inactive=4463542272, wired=2628599808)
2025-05-14 11:00:07,142:INFO:Physical Core: 12
2025-05-14 11:00:07,142:INFO:Logical Core: 12
2025-05-14 11:00:07,142:INFO:Checking libraries
2025-05-14 11:00:07,142:INFO:System:
2025-05-14 11:00:07,142:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-14 11:00:07,142:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-14 11:00:07,142:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:00:07,142:INFO:PyCaret required dependencies:
2025-05-14 11:00:07,142:INFO:                 pip: 22.3
2025-05-14 11:00:07,142:INFO:          setuptools: 65.5.0
2025-05-14 11:00:07,142:INFO:             pycaret: 3.3.2
2025-05-14 11:00:07,142:INFO:             IPython: 9.2.0
2025-05-14 11:00:07,142:INFO:          ipywidgets: 8.1.7
2025-05-14 11:00:07,142:INFO:                tqdm: 4.67.1
2025-05-14 11:00:07,142:INFO:               numpy: 1.26.4
2025-05-14 11:00:07,142:INFO:              pandas: 2.1.4
2025-05-14 11:00:07,142:INFO:              jinja2: 3.1.6
2025-05-14 11:00:07,142:INFO:               scipy: 1.11.4
2025-05-14 11:00:07,142:INFO:              joblib: 1.3.2
2025-05-14 11:00:07,142:INFO:             sklearn: 1.4.2
2025-05-14 11:00:07,142:INFO:                pyod: 2.0.5
2025-05-14 11:00:07,142:INFO:            imblearn: 0.13.0
2025-05-14 11:00:07,142:INFO:   category_encoders: 2.7.0
2025-05-14 11:00:07,142:INFO:            lightgbm: 4.6.0
2025-05-14 11:00:07,142:INFO:               numba: 0.61.2
2025-05-14 11:00:07,142:INFO:            requests: 2.32.3
2025-05-14 11:00:07,142:INFO:          matplotlib: 3.7.5
2025-05-14 11:00:07,142:INFO:          scikitplot: 0.3.7
2025-05-14 11:00:07,142:INFO:         yellowbrick: 1.5
2025-05-14 11:00:07,142:INFO:              plotly: 5.24.1
2025-05-14 11:00:07,142:INFO:    plotly-resampler: Not installed
2025-05-14 11:00:07,142:INFO:             kaleido: 0.2.1
2025-05-14 11:00:07,142:INFO:           schemdraw: 0.15
2025-05-14 11:00:07,142:INFO:         statsmodels: 0.14.4
2025-05-14 11:00:07,142:INFO:              sktime: 0.26.0
2025-05-14 11:00:07,142:INFO:               tbats: 1.1.3
2025-05-14 11:00:07,142:INFO:            pmdarima: 2.0.4
2025-05-14 11:00:07,142:INFO:              psutil: 7.0.0
2025-05-14 11:00:07,142:INFO:          markupsafe: 3.0.2
2025-05-14 11:00:07,142:INFO:             pickle5: Not installed
2025-05-14 11:00:07,142:INFO:         cloudpickle: 3.1.1
2025-05-14 11:00:07,142:INFO:         deprecation: 2.1.0
2025-05-14 11:00:07,142:INFO:              xxhash: 3.5.0
2025-05-14 11:00:07,142:INFO:           wurlitzer: 3.1.1
2025-05-14 11:00:07,142:INFO:PyCaret optional dependencies:
2025-05-14 11:00:07,142:INFO:                shap: 0.47.2
2025-05-14 11:00:07,142:INFO:           interpret: Not installed
2025-05-14 11:00:07,142:INFO:                umap: Not installed
2025-05-14 11:00:07,142:INFO:     ydata_profiling: Not installed
2025-05-14 11:00:07,142:INFO:  explainerdashboard: Not installed
2025-05-14 11:00:07,142:INFO:             autoviz: Not installed
2025-05-14 11:00:07,142:INFO:           fairlearn: Not installed
2025-05-14 11:00:07,142:INFO:          deepchecks: Not installed
2025-05-14 11:00:07,142:INFO:             xgboost: Not installed
2025-05-14 11:00:07,142:INFO:            catboost: 1.2.8
2025-05-14 11:00:07,142:INFO:              kmodes: Not installed
2025-05-14 11:00:07,142:INFO:             mlxtend: Not installed
2025-05-14 11:00:07,142:INFO:       statsforecast: Not installed
2025-05-14 11:00:07,142:INFO:        tune_sklearn: Not installed
2025-05-14 11:00:07,142:INFO:                 ray: Not installed
2025-05-14 11:00:07,142:INFO:            hyperopt: Not installed
2025-05-14 11:00:07,142:INFO:              optuna: 4.3.0
2025-05-14 11:00:07,142:INFO:               skopt: Not installed
2025-05-14 11:00:07,142:INFO:              mlflow: Not installed
2025-05-14 11:00:07,142:INFO:              gradio: Not installed
2025-05-14 11:00:07,142:INFO:             fastapi: Not installed
2025-05-14 11:00:07,142:INFO:             uvicorn: Not installed
2025-05-14 11:00:07,142:INFO:              m2cgen: Not installed
2025-05-14 11:00:07,142:INFO:           evidently: Not installed
2025-05-14 11:00:07,142:INFO:               fugue: Not installed
2025-05-14 11:00:07,142:INFO:           streamlit: Not installed
2025-05-14 11:00:07,142:INFO:             prophet: Not installed
2025-05-14 11:00:07,142:INFO:None
2025-05-14 11:00:07,142:INFO:Set up data.
2025-05-14 11:00:07,174:INFO:Set up folding strategy.
2025-05-14 11:00:07,174:INFO:Set up train/test split.
2025-05-14 11:00:07,188:INFO:Set up index.
2025-05-14 11:00:07,188:INFO:Assigning column types.
2025-05-14 11:00:07,192:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 11:00:07,210:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:00:07,210:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:00:07,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:07,223:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:07,242:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:00:07,242:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:00:07,253:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:07,253:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:07,253:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 11:00:07,270:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:00:07,281:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:07,281:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:07,298:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:00:07,309:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:07,309:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:07,310:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 11:00:07,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:07,339:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:07,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:07,368:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:07,368:INFO:Preparing preprocessing pipeline...
2025-05-14 11:00:07,370:INFO:Set up simple imputation.
2025-05-14 11:00:07,376:INFO:Set up encoding of ordinal features.
2025-05-14 11:00:07,385:INFO:Set up encoding of categorical features.
2025-05-14 11:00:07,385:INFO:Set up imbalanced handling.
2025-05-14 11:00:07,385:INFO:Set up column transformation.
2025-05-14 11:00:07,739:INFO:Finished creating preprocessing pipeline.
2025-05-14 11:00:07,759:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-14 11:00:07,759:INFO:Creating final display dataframe.
2025-05-14 11:00:08,323:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              cab3
2025-05-14 11:00:08,355:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:08,356:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:08,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:00:08,388:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:00:08,389:INFO:setup() successfully completed in 1.25s...............
2025-05-14 11:00:08,389:INFO:Initializing compare_models()
2025-05-14 11:00:08,389:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 11:00:08,389:INFO:Checking exceptions
2025-05-14 11:00:08,395:INFO:Preparing display monitor
2025-05-14 11:00:08,404:INFO:Initializing Logistic Regression
2025-05-14 11:00:08,404:INFO:Total runtime is 1.8715858459472655e-06 minutes
2025-05-14 11:00:08,405:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:08,406:INFO:Initializing create_model()
2025-05-14 11:00:08,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:08,406:INFO:Checking exceptions
2025-05-14 11:00:08,406:INFO:Importing libraries
2025-05-14 11:00:08,406:INFO:Copying training dataset
2025-05-14 11:00:08,418:INFO:Defining folds
2025-05-14 11:00:08,418:INFO:Declaring metric variables
2025-05-14 11:00:08,419:INFO:Importing untrained model
2025-05-14 11:00:08,421:INFO:Logistic Regression Imported successfully
2025-05-14 11:00:08,423:INFO:Starting cross validation
2025-05-14 11:00:08,425:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:14,416:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:00:14,489:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:00:14,618:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:00:14,657:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:00:14,678:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:00:14,741:INFO:Calculating mean and std
2025-05-14 11:00:14,743:INFO:Creating metrics dataframe
2025-05-14 11:00:14,748:INFO:Uploading results into container
2025-05-14 11:00:14,748:INFO:Uploading model into container now
2025-05-14 11:00:14,750:INFO:_master_model_container: 1
2025-05-14 11:00:14,750:INFO:_display_container: 2
2025-05-14 11:00:14,750:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 11:00:14,751:INFO:create_model() successfully completed......................................
2025-05-14 11:00:14,880:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:14,880:INFO:Creating metrics dataframe
2025-05-14 11:00:14,883:INFO:Initializing K Neighbors Classifier
2025-05-14 11:00:14,883:INFO:Total runtime is 0.1079794685045878 minutes
2025-05-14 11:00:14,884:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:14,884:INFO:Initializing create_model()
2025-05-14 11:00:14,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:14,884:INFO:Checking exceptions
2025-05-14 11:00:14,885:INFO:Importing libraries
2025-05-14 11:00:14,885:INFO:Copying training dataset
2025-05-14 11:00:14,894:INFO:Defining folds
2025-05-14 11:00:14,895:INFO:Declaring metric variables
2025-05-14 11:00:14,896:INFO:Importing untrained model
2025-05-14 11:00:14,897:INFO:K Neighbors Classifier Imported successfully
2025-05-14 11:00:14,899:INFO:Starting cross validation
2025-05-14 11:00:14,900:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:21,174:INFO:Calculating mean and std
2025-05-14 11:00:21,175:INFO:Creating metrics dataframe
2025-05-14 11:00:21,177:INFO:Uploading results into container
2025-05-14 11:00:21,177:INFO:Uploading model into container now
2025-05-14 11:00:21,178:INFO:_master_model_container: 2
2025-05-14 11:00:21,178:INFO:_display_container: 2
2025-05-14 11:00:21,178:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 11:00:21,178:INFO:create_model() successfully completed......................................
2025-05-14 11:00:21,271:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:21,271:INFO:Creating metrics dataframe
2025-05-14 11:00:21,274:INFO:Initializing Naive Bayes
2025-05-14 11:00:21,274:INFO:Total runtime is 0.21450820366541545 minutes
2025-05-14 11:00:21,276:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:21,276:INFO:Initializing create_model()
2025-05-14 11:00:21,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:21,276:INFO:Checking exceptions
2025-05-14 11:00:21,276:INFO:Importing libraries
2025-05-14 11:00:21,276:INFO:Copying training dataset
2025-05-14 11:00:21,287:INFO:Defining folds
2025-05-14 11:00:21,287:INFO:Declaring metric variables
2025-05-14 11:00:21,288:INFO:Importing untrained model
2025-05-14 11:00:21,290:INFO:Naive Bayes Imported successfully
2025-05-14 11:00:21,292:INFO:Starting cross validation
2025-05-14 11:00:21,293:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:23,696:INFO:Calculating mean and std
2025-05-14 11:00:23,701:INFO:Creating metrics dataframe
2025-05-14 11:00:23,705:INFO:Uploading results into container
2025-05-14 11:00:23,705:INFO:Uploading model into container now
2025-05-14 11:00:23,705:INFO:_master_model_container: 3
2025-05-14 11:00:23,706:INFO:_display_container: 2
2025-05-14 11:00:23,706:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 11:00:23,706:INFO:create_model() successfully completed......................................
2025-05-14 11:00:23,816:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:23,817:INFO:Creating metrics dataframe
2025-05-14 11:00:23,820:INFO:Initializing Decision Tree Classifier
2025-05-14 11:00:23,820:INFO:Total runtime is 0.25692960023880007 minutes
2025-05-14 11:00:23,821:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:23,821:INFO:Initializing create_model()
2025-05-14 11:00:23,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:23,821:INFO:Checking exceptions
2025-05-14 11:00:23,821:INFO:Importing libraries
2025-05-14 11:00:23,821:INFO:Copying training dataset
2025-05-14 11:00:23,831:INFO:Defining folds
2025-05-14 11:00:23,831:INFO:Declaring metric variables
2025-05-14 11:00:23,832:INFO:Importing untrained model
2025-05-14 11:00:23,834:INFO:Decision Tree Classifier Imported successfully
2025-05-14 11:00:23,835:INFO:Starting cross validation
2025-05-14 11:00:23,837:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:25,527:INFO:Calculating mean and std
2025-05-14 11:00:25,528:INFO:Creating metrics dataframe
2025-05-14 11:00:25,529:INFO:Uploading results into container
2025-05-14 11:00:25,529:INFO:Uploading model into container now
2025-05-14 11:00:25,529:INFO:_master_model_container: 4
2025-05-14 11:00:25,529:INFO:_display_container: 2
2025-05-14 11:00:25,530:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-14 11:00:25,530:INFO:create_model() successfully completed......................................
2025-05-14 11:00:25,601:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:25,601:INFO:Creating metrics dataframe
2025-05-14 11:00:25,604:INFO:Initializing SVM - Linear Kernel
2025-05-14 11:00:25,604:INFO:Total runtime is 0.2866738001505534 minutes
2025-05-14 11:00:25,605:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:25,606:INFO:Initializing create_model()
2025-05-14 11:00:25,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:25,606:INFO:Checking exceptions
2025-05-14 11:00:25,606:INFO:Importing libraries
2025-05-14 11:00:25,606:INFO:Copying training dataset
2025-05-14 11:00:25,616:INFO:Defining folds
2025-05-14 11:00:25,616:INFO:Declaring metric variables
2025-05-14 11:00:25,617:INFO:Importing untrained model
2025-05-14 11:00:25,618:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 11:00:25,620:INFO:Starting cross validation
2025-05-14 11:00:25,621:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:29,616:INFO:Calculating mean and std
2025-05-14 11:00:29,617:INFO:Creating metrics dataframe
2025-05-14 11:00:29,618:INFO:Uploading results into container
2025-05-14 11:00:29,619:INFO:Uploading model into container now
2025-05-14 11:00:29,619:INFO:_master_model_container: 5
2025-05-14 11:00:29,619:INFO:_display_container: 2
2025-05-14 11:00:29,619:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 11:00:29,619:INFO:create_model() successfully completed......................................
2025-05-14 11:00:29,701:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:29,701:INFO:Creating metrics dataframe
2025-05-14 11:00:29,704:INFO:Initializing Ridge Classifier
2025-05-14 11:00:29,704:INFO:Total runtime is 0.35500620206197103 minutes
2025-05-14 11:00:29,706:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:29,706:INFO:Initializing create_model()
2025-05-14 11:00:29,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:29,706:INFO:Checking exceptions
2025-05-14 11:00:29,706:INFO:Importing libraries
2025-05-14 11:00:29,706:INFO:Copying training dataset
2025-05-14 11:00:29,715:INFO:Defining folds
2025-05-14 11:00:29,715:INFO:Declaring metric variables
2025-05-14 11:00:29,716:INFO:Importing untrained model
2025-05-14 11:00:29,717:INFO:Ridge Classifier Imported successfully
2025-05-14 11:00:29,720:INFO:Starting cross validation
2025-05-14 11:00:29,721:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:30,912:INFO:Calculating mean and std
2025-05-14 11:00:30,913:INFO:Creating metrics dataframe
2025-05-14 11:00:30,914:INFO:Uploading results into container
2025-05-14 11:00:30,915:INFO:Uploading model into container now
2025-05-14 11:00:30,915:INFO:_master_model_container: 6
2025-05-14 11:00:30,915:INFO:_display_container: 2
2025-05-14 11:00:30,915:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-14 11:00:30,915:INFO:create_model() successfully completed......................................
2025-05-14 11:00:31,001:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:31,002:INFO:Creating metrics dataframe
2025-05-14 11:00:31,005:INFO:Initializing Random Forest Classifier
2025-05-14 11:00:31,005:INFO:Total runtime is 0.376682968934377 minutes
2025-05-14 11:00:31,006:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:31,006:INFO:Initializing create_model()
2025-05-14 11:00:31,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:31,006:INFO:Checking exceptions
2025-05-14 11:00:31,006:INFO:Importing libraries
2025-05-14 11:00:31,006:INFO:Copying training dataset
2025-05-14 11:00:31,016:INFO:Defining folds
2025-05-14 11:00:31,016:INFO:Declaring metric variables
2025-05-14 11:00:31,018:INFO:Importing untrained model
2025-05-14 11:00:31,019:INFO:Random Forest Classifier Imported successfully
2025-05-14 11:00:31,021:INFO:Starting cross validation
2025-05-14 11:00:31,022:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:37,090:INFO:Calculating mean and std
2025-05-14 11:00:37,092:INFO:Creating metrics dataframe
2025-05-14 11:00:37,097:INFO:Uploading results into container
2025-05-14 11:00:37,098:INFO:Uploading model into container now
2025-05-14 11:00:37,098:INFO:_master_model_container: 7
2025-05-14 11:00:37,098:INFO:_display_container: 2
2025-05-14 11:00:37,099:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 11:00:37,099:INFO:create_model() successfully completed......................................
2025-05-14 11:00:37,193:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:37,193:INFO:Creating metrics dataframe
2025-05-14 11:00:37,196:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 11:00:37,197:INFO:Total runtime is 0.47987731695175173 minutes
2025-05-14 11:00:37,198:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:37,198:INFO:Initializing create_model()
2025-05-14 11:00:37,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:37,198:INFO:Checking exceptions
2025-05-14 11:00:37,198:INFO:Importing libraries
2025-05-14 11:00:37,199:INFO:Copying training dataset
2025-05-14 11:00:37,219:INFO:Defining folds
2025-05-14 11:00:37,219:INFO:Declaring metric variables
2025-05-14 11:00:37,220:INFO:Importing untrained model
2025-05-14 11:00:37,222:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 11:00:37,224:INFO:Starting cross validation
2025-05-14 11:00:37,225:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:38,298:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:00:38,306:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:00:38,381:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:00:38,381:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:00:38,393:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:00:38,393:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:00:38,456:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:00:38,471:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:00:39,899:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:00:39,975:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:00:39,986:INFO:Calculating mean and std
2025-05-14 11:00:39,989:INFO:Creating metrics dataframe
2025-05-14 11:00:39,992:INFO:Uploading results into container
2025-05-14 11:00:39,992:INFO:Uploading model into container now
2025-05-14 11:00:39,993:INFO:_master_model_container: 8
2025-05-14 11:00:39,993:INFO:_display_container: 2
2025-05-14 11:00:39,994:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 11:00:39,994:INFO:create_model() successfully completed......................................
2025-05-14 11:00:40,130:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:40,130:INFO:Creating metrics dataframe
2025-05-14 11:00:40,134:INFO:Initializing Ada Boost Classifier
2025-05-14 11:00:40,134:INFO:Total runtime is 0.5288336197535197 minutes
2025-05-14 11:00:40,135:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:40,135:INFO:Initializing create_model()
2025-05-14 11:00:40,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:40,136:INFO:Checking exceptions
2025-05-14 11:00:40,136:INFO:Importing libraries
2025-05-14 11:00:40,136:INFO:Copying training dataset
2025-05-14 11:00:40,150:INFO:Defining folds
2025-05-14 11:00:40,150:INFO:Declaring metric variables
2025-05-14 11:00:40,151:INFO:Importing untrained model
2025-05-14 11:00:40,153:INFO:Ada Boost Classifier Imported successfully
2025-05-14 11:00:40,155:INFO:Starting cross validation
2025-05-14 11:00:40,156:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:41,160:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:00:41,173:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:00:41,217:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:00:41,239:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:00:41,253:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:00:44,016:INFO:Calculating mean and std
2025-05-14 11:00:44,017:INFO:Creating metrics dataframe
2025-05-14 11:00:44,018:INFO:Uploading results into container
2025-05-14 11:00:44,018:INFO:Uploading model into container now
2025-05-14 11:00:44,019:INFO:_master_model_container: 9
2025-05-14 11:00:44,019:INFO:_display_container: 2
2025-05-14 11:00:44,019:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-14 11:00:44,019:INFO:create_model() successfully completed......................................
2025-05-14 11:00:44,090:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:44,090:INFO:Creating metrics dataframe
2025-05-14 11:00:44,094:INFO:Initializing Gradient Boosting Classifier
2025-05-14 11:00:44,094:INFO:Total runtime is 0.5948346853256226 minutes
2025-05-14 11:00:44,095:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:44,095:INFO:Initializing create_model()
2025-05-14 11:00:44,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:44,096:INFO:Checking exceptions
2025-05-14 11:00:44,096:INFO:Importing libraries
2025-05-14 11:00:44,096:INFO:Copying training dataset
2025-05-14 11:00:44,106:INFO:Defining folds
2025-05-14 11:00:44,106:INFO:Declaring metric variables
2025-05-14 11:00:44,107:INFO:Importing untrained model
2025-05-14 11:00:44,108:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 11:00:44,110:INFO:Starting cross validation
2025-05-14 11:00:44,111:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:57,930:INFO:Calculating mean and std
2025-05-14 11:00:57,931:INFO:Creating metrics dataframe
2025-05-14 11:00:57,931:INFO:Uploading results into container
2025-05-14 11:00:57,932:INFO:Uploading model into container now
2025-05-14 11:00:57,932:INFO:_master_model_container: 10
2025-05-14 11:00:57,932:INFO:_display_container: 2
2025-05-14 11:00:57,932:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 11:00:57,932:INFO:create_model() successfully completed......................................
2025-05-14 11:00:58,001:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:58,001:INFO:Creating metrics dataframe
2025-05-14 11:00:58,005:INFO:Initializing Linear Discriminant Analysis
2025-05-14 11:00:58,005:INFO:Total runtime is 0.8266853849093119 minutes
2025-05-14 11:00:58,006:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:58,006:INFO:Initializing create_model()
2025-05-14 11:00:58,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:58,007:INFO:Checking exceptions
2025-05-14 11:00:58,007:INFO:Importing libraries
2025-05-14 11:00:58,007:INFO:Copying training dataset
2025-05-14 11:00:58,017:INFO:Defining folds
2025-05-14 11:00:58,017:INFO:Declaring metric variables
2025-05-14 11:00:58,018:INFO:Importing untrained model
2025-05-14 11:00:58,019:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 11:00:58,022:INFO:Starting cross validation
2025-05-14 11:00:58,023:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:00:59,283:INFO:Calculating mean and std
2025-05-14 11:00:59,284:INFO:Creating metrics dataframe
2025-05-14 11:00:59,287:INFO:Uploading results into container
2025-05-14 11:00:59,287:INFO:Uploading model into container now
2025-05-14 11:00:59,288:INFO:_master_model_container: 11
2025-05-14 11:00:59,288:INFO:_display_container: 2
2025-05-14 11:00:59,288:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 11:00:59,288:INFO:create_model() successfully completed......................................
2025-05-14 11:00:59,464:INFO:SubProcess create_model() end ==================================
2025-05-14 11:00:59,464:INFO:Creating metrics dataframe
2025-05-14 11:00:59,468:INFO:Initializing Extra Trees Classifier
2025-05-14 11:00:59,468:INFO:Total runtime is 0.8510716358820597 minutes
2025-05-14 11:00:59,470:INFO:SubProcess create_model() called ==================================
2025-05-14 11:00:59,470:INFO:Initializing create_model()
2025-05-14 11:00:59,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:00:59,470:INFO:Checking exceptions
2025-05-14 11:00:59,470:INFO:Importing libraries
2025-05-14 11:00:59,470:INFO:Copying training dataset
2025-05-14 11:00:59,481:INFO:Defining folds
2025-05-14 11:00:59,482:INFO:Declaring metric variables
2025-05-14 11:00:59,483:INFO:Importing untrained model
2025-05-14 11:00:59,484:INFO:Extra Trees Classifier Imported successfully
2025-05-14 11:00:59,486:INFO:Starting cross validation
2025-05-14 11:00:59,487:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:01:04,566:INFO:Calculating mean and std
2025-05-14 11:01:04,569:INFO:Creating metrics dataframe
2025-05-14 11:01:04,572:INFO:Uploading results into container
2025-05-14 11:01:04,573:INFO:Uploading model into container now
2025-05-14 11:01:04,573:INFO:_master_model_container: 12
2025-05-14 11:01:04,573:INFO:_display_container: 2
2025-05-14 11:01:04,574:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-14 11:01:04,575:INFO:create_model() successfully completed......................................
2025-05-14 11:01:04,730:INFO:SubProcess create_model() end ==================================
2025-05-14 11:01:04,730:INFO:Creating metrics dataframe
2025-05-14 11:01:04,736:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 11:01:04,736:INFO:Total runtime is 0.9388732671737671 minutes
2025-05-14 11:01:04,738:INFO:SubProcess create_model() called ==================================
2025-05-14 11:01:04,738:INFO:Initializing create_model()
2025-05-14 11:01:04,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:01:04,738:INFO:Checking exceptions
2025-05-14 11:01:04,738:INFO:Importing libraries
2025-05-14 11:01:04,738:INFO:Copying training dataset
2025-05-14 11:01:04,751:INFO:Defining folds
2025-05-14 11:01:04,751:INFO:Declaring metric variables
2025-05-14 11:01:04,752:INFO:Importing untrained model
2025-05-14 11:01:04,754:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:01:04,756:INFO:Starting cross validation
2025-05-14 11:01:04,757:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:01:08,937:INFO:Calculating mean and std
2025-05-14 11:01:08,938:INFO:Creating metrics dataframe
2025-05-14 11:01:08,939:INFO:Uploading results into container
2025-05-14 11:01:08,939:INFO:Uploading model into container now
2025-05-14 11:01:08,939:INFO:_master_model_container: 13
2025-05-14 11:01:08,939:INFO:_display_container: 2
2025-05-14 11:01:08,940:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:01:08,940:INFO:create_model() successfully completed......................................
2025-05-14 11:01:09,024:INFO:SubProcess create_model() end ==================================
2025-05-14 11:01:09,024:INFO:Creating metrics dataframe
2025-05-14 11:01:09,029:INFO:Initializing CatBoost Classifier
2025-05-14 11:01:09,029:INFO:Total runtime is 1.010413901011149 minutes
2025-05-14 11:01:09,030:INFO:SubProcess create_model() called ==================================
2025-05-14 11:01:09,031:INFO:Initializing create_model()
2025-05-14 11:01:09,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:01:09,031:INFO:Checking exceptions
2025-05-14 11:01:09,031:INFO:Importing libraries
2025-05-14 11:01:09,031:INFO:Copying training dataset
2025-05-14 11:01:09,044:INFO:Defining folds
2025-05-14 11:01:09,044:INFO:Declaring metric variables
2025-05-14 11:01:09,046:INFO:Importing untrained model
2025-05-14 11:01:09,049:INFO:CatBoost Classifier Imported successfully
2025-05-14 11:01:09,051:INFO:Starting cross validation
2025-05-14 11:01:09,052:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:01:26,715:INFO:Calculating mean and std
2025-05-14 11:01:26,718:INFO:Creating metrics dataframe
2025-05-14 11:01:26,723:INFO:Uploading results into container
2025-05-14 11:01:26,724:INFO:Uploading model into container now
2025-05-14 11:01:26,724:INFO:_master_model_container: 14
2025-05-14 11:01:26,724:INFO:_display_container: 2
2025-05-14 11:01:26,724:INFO:<catboost.core.CatBoostClassifier object at 0x335bf9190>
2025-05-14 11:01:26,724:INFO:create_model() successfully completed......................................
2025-05-14 11:01:26,933:INFO:SubProcess create_model() end ==================================
2025-05-14 11:01:26,933:INFO:Creating metrics dataframe
2025-05-14 11:01:26,939:INFO:Initializing Dummy Classifier
2025-05-14 11:01:26,939:INFO:Total runtime is 1.3089109857877095 minutes
2025-05-14 11:01:26,940:INFO:SubProcess create_model() called ==================================
2025-05-14 11:01:26,940:INFO:Initializing create_model()
2025-05-14 11:01:26,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33edb9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:01:26,940:INFO:Checking exceptions
2025-05-14 11:01:26,940:INFO:Importing libraries
2025-05-14 11:01:26,940:INFO:Copying training dataset
2025-05-14 11:01:26,957:INFO:Defining folds
2025-05-14 11:01:26,957:INFO:Declaring metric variables
2025-05-14 11:01:26,958:INFO:Importing untrained model
2025-05-14 11:01:26,960:INFO:Dummy Classifier Imported successfully
2025-05-14 11:01:26,962:INFO:Starting cross validation
2025-05-14 11:01:26,963:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:01:28,065:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:01:28,099:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:01:28,124:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:01:28,154:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:01:28,214:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:01:28,223:INFO:Calculating mean and std
2025-05-14 11:01:28,225:INFO:Creating metrics dataframe
2025-05-14 11:01:28,226:INFO:Uploading results into container
2025-05-14 11:01:28,226:INFO:Uploading model into container now
2025-05-14 11:01:28,226:INFO:_master_model_container: 15
2025-05-14 11:01:28,226:INFO:_display_container: 2
2025-05-14 11:01:28,226:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-14 11:01:28,226:INFO:create_model() successfully completed......................................
2025-05-14 11:01:28,305:INFO:SubProcess create_model() end ==================================
2025-05-14 11:01:28,305:INFO:Creating metrics dataframe
2025-05-14 11:01:28,310:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2025-05-14 11:01:28,313:INFO:Initializing create_model()
2025-05-14 11:01:28,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:01:28,313:INFO:Checking exceptions
2025-05-14 11:01:28,314:INFO:Importing libraries
2025-05-14 11:01:28,314:INFO:Copying training dataset
2025-05-14 11:01:28,324:INFO:Defining folds
2025-05-14 11:01:28,324:INFO:Declaring metric variables
2025-05-14 11:01:28,324:INFO:Importing untrained model
2025-05-14 11:01:28,324:INFO:Declaring custom model
2025-05-14 11:01:28,325:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:01:28,325:INFO:Cross validation set to False
2025-05-14 11:01:28,325:INFO:Fitting Model
2025-05-14 11:01:29,674:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 11:01:29,684:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005028 seconds.
2025-05-14 11:01:29,684:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:01:29,684:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:01:29,684:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:01:29,684:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 11:01:29,685:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:01:30,451:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:01:30,451:INFO:create_model() successfully completed......................................
2025-05-14 11:01:30,545:INFO:Initializing create_model()
2025-05-14 11:01:30,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:01:30,545:INFO:Checking exceptions
2025-05-14 11:01:30,546:INFO:Importing libraries
2025-05-14 11:01:30,546:INFO:Copying training dataset
2025-05-14 11:01:30,556:INFO:Defining folds
2025-05-14 11:01:30,556:INFO:Declaring metric variables
2025-05-14 11:01:30,556:INFO:Importing untrained model
2025-05-14 11:01:30,556:INFO:Declaring custom model
2025-05-14 11:01:30,557:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 11:01:30,558:INFO:Cross validation set to False
2025-05-14 11:01:30,558:INFO:Fitting Model
2025-05-14 11:01:47,181:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 11:01:47,182:INFO:create_model() successfully completed......................................
2025-05-14 11:01:47,321:INFO:Initializing create_model()
2025-05-14 11:01:47,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:01:47,321:INFO:Checking exceptions
2025-05-14 11:01:47,322:INFO:Importing libraries
2025-05-14 11:01:47,322:INFO:Copying training dataset
2025-05-14 11:01:47,333:INFO:Defining folds
2025-05-14 11:01:47,333:INFO:Declaring metric variables
2025-05-14 11:01:47,333:INFO:Importing untrained model
2025-05-14 11:01:47,333:INFO:Declaring custom model
2025-05-14 11:01:47,333:INFO:Random Forest Classifier Imported successfully
2025-05-14 11:01:47,334:INFO:Cross validation set to False
2025-05-14 11:01:47,334:INFO:Fitting Model
2025-05-14 11:01:49,607:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 11:01:49,607:INFO:create_model() successfully completed......................................
2025-05-14 11:01:49,691:INFO:_master_model_container: 15
2025-05-14 11:01:49,691:INFO:_display_container: 2
2025-05-14 11:01:49,692:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-14 11:01:49,692:INFO:compare_models() successfully completed......................................
2025-05-14 11:01:49,699:INFO:Initializing evaluate_model()
2025-05-14 11:01:49,699:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 11:01:49,706:INFO:Initializing plot_model()
2025-05-14 11:01:49,706:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 11:01:49,706:INFO:Checking exceptions
2025-05-14 11:01:49,710:INFO:Preloading libraries
2025-05-14 11:01:49,712:INFO:Copying training dataset
2025-05-14 11:01:49,712:INFO:Plot type: pipeline
2025-05-14 11:01:49,779:INFO:Visual Rendered Successfully
2025-05-14 11:01:49,863:INFO:plot_model() successfully completed......................................
2025-05-14 11:01:49,865:INFO:Initializing tune_model()
2025-05-14 11:01:49,865:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 11:01:49,865:INFO:Checking exceptions
2025-05-14 11:01:49,875:INFO:Copying training dataset
2025-05-14 11:01:49,883:INFO:Checking base model
2025-05-14 11:01:49,883:INFO:Base model : Light Gradient Boosting Machine
2025-05-14 11:01:49,885:INFO:Declaring metric variables
2025-05-14 11:01:49,886:INFO:Defining Hyperparameters
2025-05-14 11:01:49,966:INFO:Tuning with n_jobs=-1
2025-05-14 11:01:49,967:INFO:Initializing RandomizedSearchCV
2025-05-14 11:02:28,587:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-14 11:02:28,589:INFO:Hyperparameter search completed
2025-05-14 11:02:28,589:INFO:SubProcess create_model() called ==================================
2025-05-14 11:02:28,590:INFO:Initializing create_model()
2025-05-14 11:02:28,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33fab9b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-14 11:02:28,590:INFO:Checking exceptions
2025-05-14 11:02:28,590:INFO:Importing libraries
2025-05-14 11:02:28,591:INFO:Copying training dataset
2025-05-14 11:02:28,604:INFO:Defining folds
2025-05-14 11:02:28,605:INFO:Declaring metric variables
2025-05-14 11:02:28,613:INFO:Importing untrained model
2025-05-14 11:02:28,613:INFO:Declaring custom model
2025-05-14 11:02:28,616:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:02:28,619:INFO:Starting cross validation
2025-05-14 11:02:28,621:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:02:35,416:INFO:Calculating mean and std
2025-05-14 11:02:35,417:INFO:Creating metrics dataframe
2025-05-14 11:02:35,421:INFO:Finalizing model
2025-05-14 11:02:36,442:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:02:36,442:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:02:36,442:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:02:36,473:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:02:36,473:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:02:36,473:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:02:36,474:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 11:02:36,483:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004784 seconds.
2025-05-14 11:02:36,483:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:02:36,483:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:02:36,483:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:02:36,484:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 11:02:36,484:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:02:37,927:INFO:Uploading results into container
2025-05-14 11:02:37,927:INFO:Uploading model into container now
2025-05-14 11:02:37,928:INFO:_master_model_container: 16
2025-05-14 11:02:37,928:INFO:_display_container: 3
2025-05-14 11:02:37,928:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:02:37,928:INFO:create_model() successfully completed......................................
2025-05-14 11:02:38,054:INFO:SubProcess create_model() end ==================================
2025-05-14 11:02:38,054:INFO:choose_better activated
2025-05-14 11:02:38,055:INFO:SubProcess create_model() called ==================================
2025-05-14 11:02:38,056:INFO:Initializing create_model()
2025-05-14 11:02:38,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:02:38,056:INFO:Checking exceptions
2025-05-14 11:02:38,057:INFO:Importing libraries
2025-05-14 11:02:38,057:INFO:Copying training dataset
2025-05-14 11:02:38,066:INFO:Defining folds
2025-05-14 11:02:38,066:INFO:Declaring metric variables
2025-05-14 11:02:38,066:INFO:Importing untrained model
2025-05-14 11:02:38,066:INFO:Declaring custom model
2025-05-14 11:02:38,066:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:02:38,066:INFO:Starting cross validation
2025-05-14 11:02:38,067:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:02:42,137:INFO:Calculating mean and std
2025-05-14 11:02:42,138:INFO:Creating metrics dataframe
2025-05-14 11:02:42,140:INFO:Finalizing model
2025-05-14 11:02:43,184:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 11:02:43,198:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004945 seconds.
2025-05-14 11:02:43,198:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:02:43,198:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:02:43,198:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:02:43,198:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 11:02:43,199:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:02:43,949:INFO:Uploading results into container
2025-05-14 11:02:43,949:INFO:Uploading model into container now
2025-05-14 11:02:43,949:INFO:_master_model_container: 17
2025-05-14 11:02:43,949:INFO:_display_container: 4
2025-05-14 11:02:43,950:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:02:43,950:INFO:create_model() successfully completed......................................
2025-05-14 11:02:44,029:INFO:SubProcess create_model() end ==================================
2025-05-14 11:02:44,030:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-14 11:02:44,030:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-14 11:02:44,030:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-14 11:02:44,030:INFO:choose_better completed
2025-05-14 11:02:44,035:INFO:_master_model_container: 17
2025-05-14 11:02:44,035:INFO:_display_container: 3
2025-05-14 11:02:44,035:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:02:44,035:INFO:tune_model() successfully completed......................................
2025-05-14 11:02:44,109:INFO:Initializing evaluate_model()
2025-05-14 11:02:44,109:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 11:02:44,116:INFO:Initializing plot_model()
2025-05-14 11:02:44,116:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 11:02:44,116:INFO:Checking exceptions
2025-05-14 11:02:44,120:INFO:Preloading libraries
2025-05-14 11:02:44,122:INFO:Copying training dataset
2025-05-14 11:02:44,123:INFO:Plot type: pipeline
2025-05-14 11:02:44,183:INFO:Visual Rendered Successfully
2025-05-14 11:02:44,271:INFO:plot_model() successfully completed......................................
2025-05-14 11:02:44,273:INFO:Initializing interpret_model()
2025-05-14 11:02:44,273:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3308708d0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 11:02:44,273:INFO:Checking exceptions
2025-05-14 11:02:44,273:INFO:Soft dependency imported: shap: 0.47.2
2025-05-14 11:02:44,363:INFO:plot type: summary
2025-05-14 11:02:44,363:INFO:Creating TreeExplainer
2025-05-14 11:02:44,440:INFO:Compiling shap values
2025-05-14 11:02:45,787:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning:

LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray


2025-05-14 11:02:45,787:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning:

The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.


2025-05-14 11:02:47,056:INFO:Visual Rendered Successfully
2025-05-14 11:02:47,057:INFO:interpret_model() successfully completed......................................
2025-05-14 11:02:47,132:INFO:PyCaret ClassificationExperiment
2025-05-14 11:02:47,132:INFO:Logging name: clf-default-name
2025-05-14 11:02:47,132:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 11:02:47,132:INFO:version 3.3.2
2025-05-14 11:02:47,132:INFO:Initializing setup()
2025-05-14 11:02:47,133:INFO:self.USI: d78a
2025-05-14 11:02:47,133:INFO:self._variable_keys: {'USI', 'exp_id', 'X', 'y_train', 'is_multiclass', 'memory', 'idx', 'data', 'y_test', 'n_jobs_param', 'pipeline', 'y', 'fold_generator', 'logging_param', 'fold_groups_param', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'html_param', 'X_test', 'gpu_param', 'X_train', '_available_plots', 'seed', 'exp_name_log', 'fold_shuffle_param', 'log_plots_param', 'target_param'}
2025-05-14 11:02:47,133:INFO:Checking environment
2025-05-14 11:02:47,133:INFO:python_version: 3.11.0
2025-05-14 11:02:47,133:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-14 11:02:47,133:INFO:machine: arm64
2025-05-14 11:02:47,133:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:02:47,133:INFO:Memory: svmem(total=17179869184, available=3373498368, percent=80.4, used=5730254848, free=93257728, active=3292807168, inactive=3248226304, wired=2437447680)
2025-05-14 11:02:47,133:INFO:Physical Core: 12
2025-05-14 11:02:47,133:INFO:Logical Core: 12
2025-05-14 11:02:47,133:INFO:Checking libraries
2025-05-14 11:02:47,133:INFO:System:
2025-05-14 11:02:47,133:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-14 11:02:47,133:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-14 11:02:47,133:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:02:47,133:INFO:PyCaret required dependencies:
2025-05-14 11:02:47,133:INFO:                 pip: 22.3
2025-05-14 11:02:47,133:INFO:          setuptools: 65.5.0
2025-05-14 11:02:47,133:INFO:             pycaret: 3.3.2
2025-05-14 11:02:47,133:INFO:             IPython: 9.2.0
2025-05-14 11:02:47,133:INFO:          ipywidgets: 8.1.7
2025-05-14 11:02:47,133:INFO:                tqdm: 4.67.1
2025-05-14 11:02:47,133:INFO:               numpy: 1.26.4
2025-05-14 11:02:47,133:INFO:              pandas: 2.1.4
2025-05-14 11:02:47,133:INFO:              jinja2: 3.1.6
2025-05-14 11:02:47,133:INFO:               scipy: 1.11.4
2025-05-14 11:02:47,133:INFO:              joblib: 1.3.2
2025-05-14 11:02:47,133:INFO:             sklearn: 1.4.2
2025-05-14 11:02:47,133:INFO:                pyod: 2.0.5
2025-05-14 11:02:47,133:INFO:            imblearn: 0.13.0
2025-05-14 11:02:47,133:INFO:   category_encoders: 2.7.0
2025-05-14 11:02:47,133:INFO:            lightgbm: 4.6.0
2025-05-14 11:02:47,133:INFO:               numba: 0.61.2
2025-05-14 11:02:47,133:INFO:            requests: 2.32.3
2025-05-14 11:02:47,133:INFO:          matplotlib: 3.7.5
2025-05-14 11:02:47,133:INFO:          scikitplot: 0.3.7
2025-05-14 11:02:47,133:INFO:         yellowbrick: 1.5
2025-05-14 11:02:47,133:INFO:              plotly: 5.24.1
2025-05-14 11:02:47,133:INFO:    plotly-resampler: Not installed
2025-05-14 11:02:47,133:INFO:             kaleido: 0.2.1
2025-05-14 11:02:47,133:INFO:           schemdraw: 0.15
2025-05-14 11:02:47,133:INFO:         statsmodels: 0.14.4
2025-05-14 11:02:47,133:INFO:              sktime: 0.26.0
2025-05-14 11:02:47,133:INFO:               tbats: 1.1.3
2025-05-14 11:02:47,133:INFO:            pmdarima: 2.0.4
2025-05-14 11:02:47,133:INFO:              psutil: 7.0.0
2025-05-14 11:02:47,133:INFO:          markupsafe: 3.0.2
2025-05-14 11:02:47,133:INFO:             pickle5: Not installed
2025-05-14 11:02:47,133:INFO:         cloudpickle: 3.1.1
2025-05-14 11:02:47,133:INFO:         deprecation: 2.1.0
2025-05-14 11:02:47,133:INFO:              xxhash: 3.5.0
2025-05-14 11:02:47,133:INFO:           wurlitzer: 3.1.1
2025-05-14 11:02:47,133:INFO:PyCaret optional dependencies:
2025-05-14 11:02:47,133:INFO:                shap: 0.47.2
2025-05-14 11:02:47,133:INFO:           interpret: Not installed
2025-05-14 11:02:47,133:INFO:                umap: Not installed
2025-05-14 11:02:47,133:INFO:     ydata_profiling: Not installed
2025-05-14 11:02:47,133:INFO:  explainerdashboard: Not installed
2025-05-14 11:02:47,133:INFO:             autoviz: Not installed
2025-05-14 11:02:47,133:INFO:           fairlearn: Not installed
2025-05-14 11:02:47,133:INFO:          deepchecks: Not installed
2025-05-14 11:02:47,133:INFO:             xgboost: Not installed
2025-05-14 11:02:47,133:INFO:            catboost: 1.2.8
2025-05-14 11:02:47,133:INFO:              kmodes: Not installed
2025-05-14 11:02:47,133:INFO:             mlxtend: Not installed
2025-05-14 11:02:47,133:INFO:       statsforecast: Not installed
2025-05-14 11:02:47,133:INFO:        tune_sklearn: Not installed
2025-05-14 11:02:47,133:INFO:                 ray: Not installed
2025-05-14 11:02:47,133:INFO:            hyperopt: Not installed
2025-05-14 11:02:47,133:INFO:              optuna: 4.3.0
2025-05-14 11:02:47,133:INFO:               skopt: Not installed
2025-05-14 11:02:47,133:INFO:              mlflow: Not installed
2025-05-14 11:02:47,133:INFO:              gradio: Not installed
2025-05-14 11:02:47,133:INFO:             fastapi: Not installed
2025-05-14 11:02:47,133:INFO:             uvicorn: Not installed
2025-05-14 11:02:47,133:INFO:              m2cgen: Not installed
2025-05-14 11:02:47,133:INFO:           evidently: Not installed
2025-05-14 11:02:47,133:INFO:               fugue: Not installed
2025-05-14 11:02:47,133:INFO:           streamlit: Not installed
2025-05-14 11:02:47,133:INFO:             prophet: Not installed
2025-05-14 11:02:47,133:INFO:None
2025-05-14 11:02:47,133:INFO:Set up data.
2025-05-14 11:02:47,176:INFO:Set up folding strategy.
2025-05-14 11:02:47,176:INFO:Set up train/test split.
2025-05-14 11:02:47,194:INFO:Set up index.
2025-05-14 11:02:47,195:INFO:Assigning column types.
2025-05-14 11:02:47,199:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 11:02:47,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:02:47,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:02:47,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:47,230:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:47,249:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:02:47,250:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:02:47,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:47,261:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:47,262:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 11:02:47,280:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:02:47,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:47,292:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:47,310:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:02:47,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:47,322:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:47,322:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 11:02:47,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:47,351:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:47,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:47,381:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:47,381:INFO:Preparing preprocessing pipeline...
2025-05-14 11:02:47,382:INFO:Set up simple imputation.
2025-05-14 11:02:47,390:INFO:Set up encoding of ordinal features.
2025-05-14 11:02:47,401:INFO:Set up encoding of categorical features.
2025-05-14 11:02:47,401:INFO:Set up imbalanced handling.
2025-05-14 11:02:47,401:INFO:Set up column transformation.
2025-05-14 11:02:47,726:INFO:Finished creating preprocessing pipeline.
2025-05-14 11:02:47,745:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-14 11:02:47,745:INFO:Creating final display dataframe.
2025-05-14 11:02:48,220:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (87159, 16)
4        Transformed data shape      (133528, 29)
5   Transformed train set shape      (107380, 29)
6    Transformed test set shape       (26148, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              d78a
2025-05-14 11:02:48,253:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:48,253:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:48,282:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:02:48,284:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:02:48,284:INFO:setup() successfully completed in 1.15s...............
2025-05-14 11:02:48,285:INFO:Initializing create_model()
2025-05-14 11:02:48,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3322edb90>, estimator=LGBMClassifier, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:02:48,285:INFO:Checking exceptions
2025-05-14 11:04:48,925:INFO:PyCaret ClassificationExperiment
2025-05-14 11:04:48,925:INFO:Logging name: clf-default-name
2025-05-14 11:04:48,925:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 11:04:48,925:INFO:version 3.3.2
2025-05-14 11:04:48,925:INFO:Initializing setup()
2025-05-14 11:04:48,925:INFO:self.USI: 2e14
2025-05-14 11:04:48,925:INFO:self._variable_keys: {'USI', 'exp_id', 'X', 'y_train', 'is_multiclass', 'memory', 'idx', 'data', 'y_test', 'n_jobs_param', 'pipeline', 'y', 'fold_generator', 'logging_param', 'fold_groups_param', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'html_param', 'X_test', 'gpu_param', 'X_train', '_available_plots', 'seed', 'exp_name_log', 'fold_shuffle_param', 'log_plots_param', 'target_param'}
2025-05-14 11:04:48,926:INFO:Checking environment
2025-05-14 11:04:48,926:INFO:python_version: 3.11.0
2025-05-14 11:04:48,926:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-14 11:04:48,926:INFO:machine: arm64
2025-05-14 11:04:48,926:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:04:48,926:INFO:Memory: svmem(total=17179869184, available=3378610176, percent=80.3, used=6051807232, free=59047936, active=3343253504, inactive=3309256704, wired=2708553728)
2025-05-14 11:04:48,926:INFO:Physical Core: 12
2025-05-14 11:04:48,926:INFO:Logical Core: 12
2025-05-14 11:04:48,926:INFO:Checking libraries
2025-05-14 11:04:48,926:INFO:System:
2025-05-14 11:04:48,926:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-14 11:04:48,926:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-14 11:04:48,926:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:04:48,926:INFO:PyCaret required dependencies:
2025-05-14 11:04:48,926:INFO:                 pip: 22.3
2025-05-14 11:04:48,926:INFO:          setuptools: 65.5.0
2025-05-14 11:04:48,926:INFO:             pycaret: 3.3.2
2025-05-14 11:04:48,926:INFO:             IPython: 9.2.0
2025-05-14 11:04:48,926:INFO:          ipywidgets: 8.1.7
2025-05-14 11:04:48,926:INFO:                tqdm: 4.67.1
2025-05-14 11:04:48,926:INFO:               numpy: 1.26.4
2025-05-14 11:04:48,926:INFO:              pandas: 2.1.4
2025-05-14 11:04:48,926:INFO:              jinja2: 3.1.6
2025-05-14 11:04:48,926:INFO:               scipy: 1.11.4
2025-05-14 11:04:48,926:INFO:              joblib: 1.3.2
2025-05-14 11:04:48,926:INFO:             sklearn: 1.4.2
2025-05-14 11:04:48,926:INFO:                pyod: 2.0.5
2025-05-14 11:04:48,926:INFO:            imblearn: 0.13.0
2025-05-14 11:04:48,926:INFO:   category_encoders: 2.7.0
2025-05-14 11:04:48,926:INFO:            lightgbm: 4.6.0
2025-05-14 11:04:48,926:INFO:               numba: 0.61.2
2025-05-14 11:04:48,926:INFO:            requests: 2.32.3
2025-05-14 11:04:48,926:INFO:          matplotlib: 3.7.5
2025-05-14 11:04:48,926:INFO:          scikitplot: 0.3.7
2025-05-14 11:04:48,926:INFO:         yellowbrick: 1.5
2025-05-14 11:04:48,926:INFO:              plotly: 5.24.1
2025-05-14 11:04:48,926:INFO:    plotly-resampler: Not installed
2025-05-14 11:04:48,926:INFO:             kaleido: 0.2.1
2025-05-14 11:04:48,926:INFO:           schemdraw: 0.15
2025-05-14 11:04:48,926:INFO:         statsmodels: 0.14.4
2025-05-14 11:04:48,926:INFO:              sktime: 0.26.0
2025-05-14 11:04:48,926:INFO:               tbats: 1.1.3
2025-05-14 11:04:48,926:INFO:            pmdarima: 2.0.4
2025-05-14 11:04:48,926:INFO:              psutil: 7.0.0
2025-05-14 11:04:48,926:INFO:          markupsafe: 3.0.2
2025-05-14 11:04:48,926:INFO:             pickle5: Not installed
2025-05-14 11:04:48,926:INFO:         cloudpickle: 3.1.1
2025-05-14 11:04:48,926:INFO:         deprecation: 2.1.0
2025-05-14 11:04:48,926:INFO:              xxhash: 3.5.0
2025-05-14 11:04:48,926:INFO:           wurlitzer: 3.1.1
2025-05-14 11:04:48,926:INFO:PyCaret optional dependencies:
2025-05-14 11:04:48,927:INFO:                shap: 0.47.2
2025-05-14 11:04:48,927:INFO:           interpret: Not installed
2025-05-14 11:04:48,927:INFO:                umap: Not installed
2025-05-14 11:04:48,927:INFO:     ydata_profiling: Not installed
2025-05-14 11:04:48,927:INFO:  explainerdashboard: Not installed
2025-05-14 11:04:48,927:INFO:             autoviz: Not installed
2025-05-14 11:04:48,927:INFO:           fairlearn: Not installed
2025-05-14 11:04:48,927:INFO:          deepchecks: Not installed
2025-05-14 11:04:48,927:INFO:             xgboost: Not installed
2025-05-14 11:04:48,927:INFO:            catboost: 1.2.8
2025-05-14 11:04:48,927:INFO:              kmodes: Not installed
2025-05-14 11:04:48,927:INFO:             mlxtend: Not installed
2025-05-14 11:04:48,927:INFO:       statsforecast: Not installed
2025-05-14 11:04:48,927:INFO:        tune_sklearn: Not installed
2025-05-14 11:04:48,927:INFO:                 ray: Not installed
2025-05-14 11:04:48,927:INFO:            hyperopt: Not installed
2025-05-14 11:04:48,927:INFO:              optuna: 4.3.0
2025-05-14 11:04:48,927:INFO:               skopt: Not installed
2025-05-14 11:04:48,927:INFO:              mlflow: Not installed
2025-05-14 11:04:48,927:INFO:              gradio: Not installed
2025-05-14 11:04:48,927:INFO:             fastapi: Not installed
2025-05-14 11:04:48,927:INFO:             uvicorn: Not installed
2025-05-14 11:04:48,927:INFO:              m2cgen: Not installed
2025-05-14 11:04:48,927:INFO:           evidently: Not installed
2025-05-14 11:04:48,927:INFO:               fugue: Not installed
2025-05-14 11:04:48,927:INFO:           streamlit: Not installed
2025-05-14 11:04:48,927:INFO:             prophet: Not installed
2025-05-14 11:04:48,927:INFO:None
2025-05-14 11:04:48,927:INFO:Set up data.
2025-05-14 11:04:48,965:INFO:Set up folding strategy.
2025-05-14 11:04:48,966:INFO:Set up train/test split.
2025-05-14 11:04:48,980:INFO:Set up index.
2025-05-14 11:04:48,981:INFO:Assigning column types.
2025-05-14 11:04:48,985:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 11:04:49,003:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:04:49,004:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:04:49,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,015:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,033:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:04:49,034:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:04:49,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,050:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,050:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 11:04:49,068:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:04:49,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,080:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,099:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:04:49,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,111:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,111:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 11:04:49,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,141:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,170:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,171:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,172:INFO:Preparing preprocessing pipeline...
2025-05-14 11:04:49,173:INFO:Set up simple imputation.
2025-05-14 11:04:49,181:INFO:Set up encoding of ordinal features.
2025-05-14 11:04:49,192:INFO:Set up encoding of categorical features.
2025-05-14 11:04:49,192:INFO:Set up imbalanced handling.
2025-05-14 11:04:49,192:INFO:Set up column transformation.
2025-05-14 11:04:49,483:INFO:Finished creating preprocessing pipeline.
2025-05-14 11:04:49,504:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-14 11:04:49,504:INFO:Creating final display dataframe.
2025-05-14 11:04:49,733:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (69727, 16)
4        Transformed data shape      (106821, 29)
5   Transformed train set shape       (85902, 29)
6    Transformed test set shape       (20919, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              2e14
2025-05-14 11:04:49,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,769:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:04:49,810:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:04:49,813:INFO:setup() successfully completed in 0.89s...............
2025-05-14 11:04:49,813:INFO:Initializing compare_models()
2025-05-14 11:04:49,813:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=f1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 11:04:49,813:INFO:Checking exceptions
2025-05-14 11:04:49,819:INFO:Preparing display monitor
2025-05-14 11:04:49,838:INFO:Initializing Logistic Regression
2025-05-14 11:04:49,838:INFO:Total runtime is 1.720587412516276e-06 minutes
2025-05-14 11:04:49,840:INFO:SubProcess create_model() called ==================================
2025-05-14 11:04:49,840:INFO:Initializing create_model()
2025-05-14 11:04:49,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:04:49,841:INFO:Checking exceptions
2025-05-14 11:04:49,841:INFO:Importing libraries
2025-05-14 11:04:49,841:INFO:Copying training dataset
2025-05-14 11:04:49,870:INFO:Defining folds
2025-05-14 11:04:49,870:INFO:Declaring metric variables
2025-05-14 11:04:49,871:INFO:Importing untrained model
2025-05-14 11:04:49,873:INFO:Logistic Regression Imported successfully
2025-05-14 11:04:49,876:INFO:Starting cross validation
2025-05-14 11:04:49,877:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:04:53,802:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:04:53,848:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:04:53,885:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:04:53,905:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:04:53,905:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 11:04:53,960:INFO:Calculating mean and std
2025-05-14 11:04:53,960:INFO:Creating metrics dataframe
2025-05-14 11:04:53,961:INFO:Uploading results into container
2025-05-14 11:04:53,962:INFO:Uploading model into container now
2025-05-14 11:04:53,962:INFO:_master_model_container: 1
2025-05-14 11:04:53,962:INFO:_display_container: 2
2025-05-14 11:04:53,962:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 11:04:53,962:INFO:create_model() successfully completed......................................
2025-05-14 11:04:54,105:INFO:SubProcess create_model() end ==================================
2025-05-14 11:04:54,105:INFO:Creating metrics dataframe
2025-05-14 11:04:54,107:INFO:Initializing K Neighbors Classifier
2025-05-14 11:04:54,107:INFO:Total runtime is 0.07115906476974487 minutes
2025-05-14 11:04:54,108:INFO:SubProcess create_model() called ==================================
2025-05-14 11:04:54,109:INFO:Initializing create_model()
2025-05-14 11:04:54,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:04:54,109:INFO:Checking exceptions
2025-05-14 11:04:54,109:INFO:Importing libraries
2025-05-14 11:04:54,109:INFO:Copying training dataset
2025-05-14 11:04:54,118:INFO:Defining folds
2025-05-14 11:04:54,118:INFO:Declaring metric variables
2025-05-14 11:04:54,119:INFO:Importing untrained model
2025-05-14 11:04:54,120:INFO:K Neighbors Classifier Imported successfully
2025-05-14 11:04:54,122:INFO:Starting cross validation
2025-05-14 11:04:54,123:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:04:58,983:INFO:Calculating mean and std
2025-05-14 11:04:58,985:INFO:Creating metrics dataframe
2025-05-14 11:04:58,989:INFO:Uploading results into container
2025-05-14 11:04:58,990:INFO:Uploading model into container now
2025-05-14 11:04:58,990:INFO:_master_model_container: 2
2025-05-14 11:04:58,990:INFO:_display_container: 2
2025-05-14 11:04:58,991:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 11:04:58,991:INFO:create_model() successfully completed......................................
2025-05-14 11:04:59,084:INFO:SubProcess create_model() end ==================================
2025-05-14 11:04:59,084:INFO:Creating metrics dataframe
2025-05-14 11:04:59,087:INFO:Initializing Naive Bayes
2025-05-14 11:04:59,087:INFO:Total runtime is 0.15415916840235394 minutes
2025-05-14 11:04:59,088:INFO:SubProcess create_model() called ==================================
2025-05-14 11:04:59,088:INFO:Initializing create_model()
2025-05-14 11:04:59,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:04:59,089:INFO:Checking exceptions
2025-05-14 11:04:59,089:INFO:Importing libraries
2025-05-14 11:04:59,089:INFO:Copying training dataset
2025-05-14 11:04:59,100:INFO:Defining folds
2025-05-14 11:04:59,100:INFO:Declaring metric variables
2025-05-14 11:04:59,101:INFO:Importing untrained model
2025-05-14 11:04:59,103:INFO:Naive Bayes Imported successfully
2025-05-14 11:04:59,105:INFO:Starting cross validation
2025-05-14 11:04:59,106:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:00,286:INFO:Calculating mean and std
2025-05-14 11:05:00,287:INFO:Creating metrics dataframe
2025-05-14 11:05:00,287:INFO:Uploading results into container
2025-05-14 11:05:00,288:INFO:Uploading model into container now
2025-05-14 11:05:00,288:INFO:_master_model_container: 3
2025-05-14 11:05:00,288:INFO:_display_container: 2
2025-05-14 11:05:00,288:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 11:05:00,288:INFO:create_model() successfully completed......................................
2025-05-14 11:05:00,372:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:00,372:INFO:Creating metrics dataframe
2025-05-14 11:05:00,375:INFO:Initializing Decision Tree Classifier
2025-05-14 11:05:00,376:INFO:Total runtime is 0.17563133239746095 minutes
2025-05-14 11:05:00,377:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:00,377:INFO:Initializing create_model()
2025-05-14 11:05:00,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:00,377:INFO:Checking exceptions
2025-05-14 11:05:00,377:INFO:Importing libraries
2025-05-14 11:05:00,377:INFO:Copying training dataset
2025-05-14 11:05:00,387:INFO:Defining folds
2025-05-14 11:05:00,388:INFO:Declaring metric variables
2025-05-14 11:05:00,389:INFO:Importing untrained model
2025-05-14 11:05:00,390:INFO:Decision Tree Classifier Imported successfully
2025-05-14 11:05:00,392:INFO:Starting cross validation
2025-05-14 11:05:00,393:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:02,072:INFO:Calculating mean and std
2025-05-14 11:05:02,073:INFO:Creating metrics dataframe
2025-05-14 11:05:02,074:INFO:Uploading results into container
2025-05-14 11:05:02,074:INFO:Uploading model into container now
2025-05-14 11:05:02,074:INFO:_master_model_container: 4
2025-05-14 11:05:02,074:INFO:_display_container: 2
2025-05-14 11:05:02,074:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-05-14 11:05:02,074:INFO:create_model() successfully completed......................................
2025-05-14 11:05:02,196:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:02,196:INFO:Creating metrics dataframe
2025-05-14 11:05:02,199:INFO:Initializing SVM - Linear Kernel
2025-05-14 11:05:02,199:INFO:Total runtime is 0.20602888663609825 minutes
2025-05-14 11:05:02,201:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:02,201:INFO:Initializing create_model()
2025-05-14 11:05:02,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:02,201:INFO:Checking exceptions
2025-05-14 11:05:02,201:INFO:Importing libraries
2025-05-14 11:05:02,201:INFO:Copying training dataset
2025-05-14 11:05:02,219:INFO:Defining folds
2025-05-14 11:05:02,219:INFO:Declaring metric variables
2025-05-14 11:05:02,221:INFO:Importing untrained model
2025-05-14 11:05:02,222:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 11:05:02,225:INFO:Starting cross validation
2025-05-14 11:05:02,226:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:05,469:INFO:Calculating mean and std
2025-05-14 11:05:05,469:INFO:Creating metrics dataframe
2025-05-14 11:05:05,470:INFO:Uploading results into container
2025-05-14 11:05:05,470:INFO:Uploading model into container now
2025-05-14 11:05:05,471:INFO:_master_model_container: 5
2025-05-14 11:05:05,471:INFO:_display_container: 2
2025-05-14 11:05:05,471:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 11:05:05,471:INFO:create_model() successfully completed......................................
2025-05-14 11:05:05,555:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:05,555:INFO:Creating metrics dataframe
2025-05-14 11:05:05,559:INFO:Initializing Ridge Classifier
2025-05-14 11:05:05,559:INFO:Total runtime is 0.262016499042511 minutes
2025-05-14 11:05:05,560:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:05,560:INFO:Initializing create_model()
2025-05-14 11:05:05,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:05,560:INFO:Checking exceptions
2025-05-14 11:05:05,560:INFO:Importing libraries
2025-05-14 11:05:05,560:INFO:Copying training dataset
2025-05-14 11:05:05,570:INFO:Defining folds
2025-05-14 11:05:05,570:INFO:Declaring metric variables
2025-05-14 11:05:05,571:INFO:Importing untrained model
2025-05-14 11:05:05,572:INFO:Ridge Classifier Imported successfully
2025-05-14 11:05:05,574:INFO:Starting cross validation
2025-05-14 11:05:05,575:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:06,741:INFO:Calculating mean and std
2025-05-14 11:05:06,742:INFO:Creating metrics dataframe
2025-05-14 11:05:06,744:INFO:Uploading results into container
2025-05-14 11:05:06,744:INFO:Uploading model into container now
2025-05-14 11:05:06,744:INFO:_master_model_container: 6
2025-05-14 11:05:06,744:INFO:_display_container: 2
2025-05-14 11:05:06,744:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-05-14 11:05:06,745:INFO:create_model() successfully completed......................................
2025-05-14 11:05:06,832:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:06,833:INFO:Creating metrics dataframe
2025-05-14 11:05:06,836:INFO:Initializing Random Forest Classifier
2025-05-14 11:05:06,836:INFO:Total runtime is 0.2833044846852621 minutes
2025-05-14 11:05:06,837:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:06,837:INFO:Initializing create_model()
2025-05-14 11:05:06,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:06,837:INFO:Checking exceptions
2025-05-14 11:05:06,838:INFO:Importing libraries
2025-05-14 11:05:06,838:INFO:Copying training dataset
2025-05-14 11:05:06,847:INFO:Defining folds
2025-05-14 11:05:06,847:INFO:Declaring metric variables
2025-05-14 11:05:06,848:INFO:Importing untrained model
2025-05-14 11:05:06,849:INFO:Random Forest Classifier Imported successfully
2025-05-14 11:05:06,851:INFO:Starting cross validation
2025-05-14 11:05:06,853:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:13,258:INFO:Calculating mean and std
2025-05-14 11:05:13,259:INFO:Creating metrics dataframe
2025-05-14 11:05:13,261:INFO:Uploading results into container
2025-05-14 11:05:13,262:INFO:Uploading model into container now
2025-05-14 11:05:13,262:INFO:_master_model_container: 7
2025-05-14 11:05:13,262:INFO:_display_container: 2
2025-05-14 11:05:13,262:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 11:05:13,263:INFO:create_model() successfully completed......................................
2025-05-14 11:05:13,432:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:13,432:INFO:Creating metrics dataframe
2025-05-14 11:05:13,437:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 11:05:13,437:INFO:Total runtime is 0.3933164517084758 minutes
2025-05-14 11:05:13,438:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:13,438:INFO:Initializing create_model()
2025-05-14 11:05:13,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:13,438:INFO:Checking exceptions
2025-05-14 11:05:13,438:INFO:Importing libraries
2025-05-14 11:05:13,439:INFO:Copying training dataset
2025-05-14 11:05:13,457:INFO:Defining folds
2025-05-14 11:05:13,457:INFO:Declaring metric variables
2025-05-14 11:05:13,459:INFO:Importing untrained model
2025-05-14 11:05:13,460:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 11:05:13,463:INFO:Starting cross validation
2025-05-14 11:05:13,464:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:14,535:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:05:14,580:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:05:14,618:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:05:14,625:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:05:14,648:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:05:14,659:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:05:14,671:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 11:05:14,702:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:05:14,729:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:05:14,744:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:05:14,756:INFO:Calculating mean and std
2025-05-14 11:05:14,757:INFO:Creating metrics dataframe
2025-05-14 11:05:14,757:INFO:Uploading results into container
2025-05-14 11:05:14,758:INFO:Uploading model into container now
2025-05-14 11:05:14,758:INFO:_master_model_container: 8
2025-05-14 11:05:14,758:INFO:_display_container: 2
2025-05-14 11:05:14,758:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 11:05:14,758:INFO:create_model() successfully completed......................................
2025-05-14 11:05:14,845:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:14,845:INFO:Creating metrics dataframe
2025-05-14 11:05:14,849:INFO:Initializing Ada Boost Classifier
2025-05-14 11:05:14,849:INFO:Total runtime is 0.4168615857760112 minutes
2025-05-14 11:05:14,850:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:14,851:INFO:Initializing create_model()
2025-05-14 11:05:14,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:14,851:INFO:Checking exceptions
2025-05-14 11:05:14,851:INFO:Importing libraries
2025-05-14 11:05:14,851:INFO:Copying training dataset
2025-05-14 11:05:14,861:INFO:Defining folds
2025-05-14 11:05:14,861:INFO:Declaring metric variables
2025-05-14 11:05:14,862:INFO:Importing untrained model
2025-05-14 11:05:14,863:INFO:Ada Boost Classifier Imported successfully
2025-05-14 11:05:14,865:INFO:Starting cross validation
2025-05-14 11:05:14,867:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:15,912:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:05:15,922:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:05:15,947:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:05:15,972:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:05:16,050:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 11:05:18,797:INFO:Calculating mean and std
2025-05-14 11:05:18,799:INFO:Creating metrics dataframe
2025-05-14 11:05:18,803:INFO:Uploading results into container
2025-05-14 11:05:18,803:INFO:Uploading model into container now
2025-05-14 11:05:18,803:INFO:_master_model_container: 9
2025-05-14 11:05:18,803:INFO:_display_container: 2
2025-05-14 11:05:18,804:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-05-14 11:05:18,804:INFO:create_model() successfully completed......................................
2025-05-14 11:05:18,929:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:18,929:INFO:Creating metrics dataframe
2025-05-14 11:05:18,933:INFO:Initializing Gradient Boosting Classifier
2025-05-14 11:05:18,933:INFO:Total runtime is 0.48493014971415205 minutes
2025-05-14 11:05:18,935:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:18,935:INFO:Initializing create_model()
2025-05-14 11:05:18,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:18,935:INFO:Checking exceptions
2025-05-14 11:05:18,935:INFO:Importing libraries
2025-05-14 11:05:18,935:INFO:Copying training dataset
2025-05-14 11:05:18,946:INFO:Defining folds
2025-05-14 11:05:18,946:INFO:Declaring metric variables
2025-05-14 11:05:18,947:INFO:Importing untrained model
2025-05-14 11:05:18,948:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 11:05:18,950:INFO:Starting cross validation
2025-05-14 11:05:18,951:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:32,764:INFO:Calculating mean and std
2025-05-14 11:05:32,768:INFO:Creating metrics dataframe
2025-05-14 11:05:32,772:INFO:Uploading results into container
2025-05-14 11:05:32,772:INFO:Uploading model into container now
2025-05-14 11:05:32,772:INFO:_master_model_container: 10
2025-05-14 11:05:32,773:INFO:_display_container: 2
2025-05-14 11:05:32,773:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 11:05:32,773:INFO:create_model() successfully completed......................................
2025-05-14 11:05:32,910:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:32,910:INFO:Creating metrics dataframe
2025-05-14 11:05:32,915:INFO:Initializing Linear Discriminant Analysis
2025-05-14 11:05:32,915:INFO:Total runtime is 0.7179495851198833 minutes
2025-05-14 11:05:32,916:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:32,916:INFO:Initializing create_model()
2025-05-14 11:05:32,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:32,916:INFO:Checking exceptions
2025-05-14 11:05:32,916:INFO:Importing libraries
2025-05-14 11:05:32,916:INFO:Copying training dataset
2025-05-14 11:05:32,931:INFO:Defining folds
2025-05-14 11:05:32,931:INFO:Declaring metric variables
2025-05-14 11:05:32,932:INFO:Importing untrained model
2025-05-14 11:05:32,934:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 11:05:32,936:INFO:Starting cross validation
2025-05-14 11:05:32,938:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:34,204:INFO:Calculating mean and std
2025-05-14 11:05:34,204:INFO:Creating metrics dataframe
2025-05-14 11:05:34,205:INFO:Uploading results into container
2025-05-14 11:05:34,205:INFO:Uploading model into container now
2025-05-14 11:05:34,206:INFO:_master_model_container: 11
2025-05-14 11:05:34,206:INFO:_display_container: 2
2025-05-14 11:05:34,206:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 11:05:34,206:INFO:create_model() successfully completed......................................
2025-05-14 11:05:34,292:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:34,292:INFO:Creating metrics dataframe
2025-05-14 11:05:34,296:INFO:Initializing Extra Trees Classifier
2025-05-14 11:05:34,296:INFO:Total runtime is 0.7409696499506633 minutes
2025-05-14 11:05:34,297:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:34,297:INFO:Initializing create_model()
2025-05-14 11:05:34,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:34,297:INFO:Checking exceptions
2025-05-14 11:05:34,297:INFO:Importing libraries
2025-05-14 11:05:34,297:INFO:Copying training dataset
2025-05-14 11:05:34,307:INFO:Defining folds
2025-05-14 11:05:34,307:INFO:Declaring metric variables
2025-05-14 11:05:34,308:INFO:Importing untrained model
2025-05-14 11:05:34,309:INFO:Extra Trees Classifier Imported successfully
2025-05-14 11:05:34,311:INFO:Starting cross validation
2025-05-14 11:05:34,312:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:39,553:INFO:Calculating mean and std
2025-05-14 11:05:39,564:INFO:Creating metrics dataframe
2025-05-14 11:05:39,571:INFO:Uploading results into container
2025-05-14 11:05:39,572:INFO:Uploading model into container now
2025-05-14 11:05:39,573:INFO:_master_model_container: 12
2025-05-14 11:05:39,573:INFO:_display_container: 2
2025-05-14 11:05:39,574:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-05-14 11:05:39,574:INFO:create_model() successfully completed......................................
2025-05-14 11:05:39,745:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:39,745:INFO:Creating metrics dataframe
2025-05-14 11:05:39,750:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 11:05:39,750:INFO:Total runtime is 0.8318687995274862 minutes
2025-05-14 11:05:39,751:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:39,751:INFO:Initializing create_model()
2025-05-14 11:05:39,751:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:39,751:INFO:Checking exceptions
2025-05-14 11:05:39,752:INFO:Importing libraries
2025-05-14 11:05:39,752:INFO:Copying training dataset
2025-05-14 11:05:39,774:INFO:Defining folds
2025-05-14 11:05:39,774:INFO:Declaring metric variables
2025-05-14 11:05:39,776:INFO:Importing untrained model
2025-05-14 11:05:39,778:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:05:39,781:INFO:Starting cross validation
2025-05-14 11:05:39,783:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:05:43,882:INFO:Calculating mean and std
2025-05-14 11:05:43,882:INFO:Creating metrics dataframe
2025-05-14 11:05:43,883:INFO:Uploading results into container
2025-05-14 11:05:43,883:INFO:Uploading model into container now
2025-05-14 11:05:43,884:INFO:_master_model_container: 13
2025-05-14 11:05:43,884:INFO:_display_container: 2
2025-05-14 11:05:43,884:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:05:43,884:INFO:create_model() successfully completed......................................
2025-05-14 11:05:43,969:INFO:SubProcess create_model() end ==================================
2025-05-14 11:05:43,970:INFO:Creating metrics dataframe
2025-05-14 11:05:43,974:INFO:Initializing CatBoost Classifier
2025-05-14 11:05:43,974:INFO:Total runtime is 0.9022688349088033 minutes
2025-05-14 11:05:43,975:INFO:SubProcess create_model() called ==================================
2025-05-14 11:05:43,975:INFO:Initializing create_model()
2025-05-14 11:05:43,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:05:43,975:INFO:Checking exceptions
2025-05-14 11:05:43,975:INFO:Importing libraries
2025-05-14 11:05:43,975:INFO:Copying training dataset
2025-05-14 11:05:43,985:INFO:Defining folds
2025-05-14 11:05:43,985:INFO:Declaring metric variables
2025-05-14 11:05:43,986:INFO:Importing untrained model
2025-05-14 11:05:43,987:INFO:CatBoost Classifier Imported successfully
2025-05-14 11:05:43,989:INFO:Starting cross validation
2025-05-14 11:05:43,990:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:06:00,969:INFO:Calculating mean and std
2025-05-14 11:06:00,972:INFO:Creating metrics dataframe
2025-05-14 11:06:00,975:INFO:Uploading results into container
2025-05-14 11:06:00,976:INFO:Uploading model into container now
2025-05-14 11:06:00,976:INFO:_master_model_container: 14
2025-05-14 11:06:00,976:INFO:_display_container: 2
2025-05-14 11:06:00,977:INFO:<catboost.core.CatBoostClassifier object at 0x33cd75150>
2025-05-14 11:06:00,977:INFO:create_model() successfully completed......................................
2025-05-14 11:06:01,115:INFO:SubProcess create_model() end ==================================
2025-05-14 11:06:01,115:INFO:Creating metrics dataframe
2025-05-14 11:06:01,120:INFO:Initializing Dummy Classifier
2025-05-14 11:06:01,120:INFO:Total runtime is 1.1880457003911336 minutes
2025-05-14 11:06:01,122:INFO:SubProcess create_model() called ==================================
2025-05-14 11:06:01,122:INFO:Initializing create_model()
2025-05-14 11:06:01,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336296a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:06:01,122:INFO:Checking exceptions
2025-05-14 11:06:01,122:INFO:Importing libraries
2025-05-14 11:06:01,122:INFO:Copying training dataset
2025-05-14 11:06:01,136:INFO:Defining folds
2025-05-14 11:06:01,136:INFO:Declaring metric variables
2025-05-14 11:06:01,137:INFO:Importing untrained model
2025-05-14 11:06:01,139:INFO:Dummy Classifier Imported successfully
2025-05-14 11:06:01,141:INFO:Starting cross validation
2025-05-14 11:06:01,143:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:06:02,216:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:06:02,287:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:06:02,288:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:06:02,317:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:06:02,340:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 11:06:02,351:INFO:Calculating mean and std
2025-05-14 11:06:02,351:INFO:Creating metrics dataframe
2025-05-14 11:06:02,352:INFO:Uploading results into container
2025-05-14 11:06:02,352:INFO:Uploading model into container now
2025-05-14 11:06:02,353:INFO:_master_model_container: 15
2025-05-14 11:06:02,353:INFO:_display_container: 2
2025-05-14 11:06:02,353:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-05-14 11:06:02,353:INFO:create_model() successfully completed......................................
2025-05-14 11:06:02,440:INFO:SubProcess create_model() end ==================================
2025-05-14 11:06:02,440:INFO:Creating metrics dataframe
2025-05-14 11:06:02,445:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2025-05-14 11:06:02,449:INFO:Initializing create_model()
2025-05-14 11:06:02,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:06:02,449:INFO:Checking exceptions
2025-05-14 11:06:02,450:INFO:Importing libraries
2025-05-14 11:06:02,450:INFO:Copying training dataset
2025-05-14 11:06:02,461:INFO:Defining folds
2025-05-14 11:06:02,461:INFO:Declaring metric variables
2025-05-14 11:06:02,461:INFO:Importing untrained model
2025-05-14 11:06:02,461:INFO:Declaring custom model
2025-05-14 11:06:02,462:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:06:02,462:INFO:Cross validation set to False
2025-05-14 11:06:02,462:INFO:Fitting Model
2025-05-14 11:06:03,494:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 11:06:03,512:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008441 seconds.
2025-05-14 11:06:03,512:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:06:03,512:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:06:03,512:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:06:03,512:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 11:06:03,512:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:06:04,267:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:06:04,267:INFO:create_model() successfully completed......................................
2025-05-14 11:06:04,353:INFO:Initializing create_model()
2025-05-14 11:06:04,353:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:06:04,354:INFO:Checking exceptions
2025-05-14 11:06:04,354:INFO:Importing libraries
2025-05-14 11:06:04,354:INFO:Copying training dataset
2025-05-14 11:06:04,363:INFO:Defining folds
2025-05-14 11:06:04,363:INFO:Declaring metric variables
2025-05-14 11:06:04,364:INFO:Importing untrained model
2025-05-14 11:06:04,364:INFO:Declaring custom model
2025-05-14 11:06:04,364:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 11:06:04,365:INFO:Cross validation set to False
2025-05-14 11:06:04,365:INFO:Fitting Model
2025-05-14 11:06:20,273:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 11:06:20,274:INFO:create_model() successfully completed......................................
2025-05-14 11:06:20,353:INFO:Initializing create_model()
2025-05-14 11:06:20,353:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:06:20,353:INFO:Checking exceptions
2025-05-14 11:06:20,354:INFO:Importing libraries
2025-05-14 11:06:20,354:INFO:Copying training dataset
2025-05-14 11:06:20,364:INFO:Defining folds
2025-05-14 11:06:20,364:INFO:Declaring metric variables
2025-05-14 11:06:20,364:INFO:Importing untrained model
2025-05-14 11:06:20,364:INFO:Declaring custom model
2025-05-14 11:06:20,364:INFO:Random Forest Classifier Imported successfully
2025-05-14 11:06:20,365:INFO:Cross validation set to False
2025-05-14 11:06:20,365:INFO:Fitting Model
2025-05-14 11:06:22,564:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 11:06:22,564:INFO:create_model() successfully completed......................................
2025-05-14 11:06:22,651:INFO:_master_model_container: 15
2025-05-14 11:06:22,651:INFO:_display_container: 2
2025-05-14 11:06:22,652:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2025-05-14 11:06:22,652:INFO:compare_models() successfully completed......................................
2025-05-14 11:06:22,667:INFO:Initializing evaluate_model()
2025-05-14 11:06:22,668:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 11:06:22,679:INFO:Initializing plot_model()
2025-05-14 11:06:22,679:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 11:06:22,679:INFO:Checking exceptions
2025-05-14 11:06:22,684:INFO:Preloading libraries
2025-05-14 11:06:22,686:INFO:Copying training dataset
2025-05-14 11:06:22,686:INFO:Plot type: pipeline
2025-05-14 11:06:22,746:INFO:Visual Rendered Successfully
2025-05-14 11:06:22,830:INFO:plot_model() successfully completed......................................
2025-05-14 11:06:22,832:INFO:Initializing tune_model()
2025-05-14 11:06:22,832:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 11:06:22,832:INFO:Checking exceptions
2025-05-14 11:06:22,843:INFO:Copying training dataset
2025-05-14 11:06:22,852:INFO:Checking base model
2025-05-14 11:06:22,852:INFO:Base model : Light Gradient Boosting Machine
2025-05-14 11:06:22,854:INFO:Declaring metric variables
2025-05-14 11:06:22,855:INFO:Defining Hyperparameters
2025-05-14 11:06:22,941:INFO:Tuning with n_jobs=-1
2025-05-14 11:06:22,941:INFO:Initializing RandomizedSearchCV
2025-05-14 11:06:58,123:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-14 11:06:58,126:INFO:Hyperparameter search completed
2025-05-14 11:06:58,126:INFO:SubProcess create_model() called ==================================
2025-05-14 11:06:58,128:INFO:Initializing create_model()
2025-05-14 11:06:58,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x346bb4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-14 11:06:58,128:INFO:Checking exceptions
2025-05-14 11:06:58,128:INFO:Importing libraries
2025-05-14 11:06:58,128:INFO:Copying training dataset
2025-05-14 11:06:58,143:INFO:Defining folds
2025-05-14 11:06:58,143:INFO:Declaring metric variables
2025-05-14 11:06:58,149:INFO:Importing untrained model
2025-05-14 11:06:58,149:INFO:Declaring custom model
2025-05-14 11:06:58,153:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:06:58,157:INFO:Starting cross validation
2025-05-14 11:06:58,161:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:07:04,908:INFO:Calculating mean and std
2025-05-14 11:07:04,909:INFO:Creating metrics dataframe
2025-05-14 11:07:04,911:INFO:Finalizing model
2025-05-14 11:07:05,937:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:07:05,937:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:07:05,937:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:07:05,968:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:07:05,968:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:07:05,968:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:07:05,968:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 11:07:05,983:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008904 seconds.
2025-05-14 11:07:05,983:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:07:05,983:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:07:05,983:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:07:05,983:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 11:07:05,983:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:07:07,447:INFO:Uploading results into container
2025-05-14 11:07:07,448:INFO:Uploading model into container now
2025-05-14 11:07:07,448:INFO:_master_model_container: 16
2025-05-14 11:07:07,448:INFO:_display_container: 3
2025-05-14 11:07:07,449:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:07:07,449:INFO:create_model() successfully completed......................................
2025-05-14 11:07:07,581:INFO:SubProcess create_model() end ==================================
2025-05-14 11:07:07,582:INFO:choose_better activated
2025-05-14 11:07:07,583:INFO:SubProcess create_model() called ==================================
2025-05-14 11:07:07,584:INFO:Initializing create_model()
2025-05-14 11:07:07,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:07:07,584:INFO:Checking exceptions
2025-05-14 11:07:07,584:INFO:Importing libraries
2025-05-14 11:07:07,584:INFO:Copying training dataset
2025-05-14 11:07:07,594:INFO:Defining folds
2025-05-14 11:07:07,594:INFO:Declaring metric variables
2025-05-14 11:07:07,594:INFO:Importing untrained model
2025-05-14 11:07:07,594:INFO:Declaring custom model
2025-05-14 11:07:07,594:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:07:07,594:INFO:Starting cross validation
2025-05-14 11:07:07,595:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:07:11,476:INFO:Calculating mean and std
2025-05-14 11:07:11,477:INFO:Creating metrics dataframe
2025-05-14 11:07:11,478:INFO:Finalizing model
2025-05-14 11:07:12,483:INFO:[LightGBM] [Info] Number of positive: 42951, number of negative: 42951
2025-05-14 11:07:12,493:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004739 seconds.
2025-05-14 11:07:12,493:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:07:12,493:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:07:12,493:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:07:12,493:INFO:[LightGBM] [Info] Number of data points in the train set: 85902, number of used features: 28
2025-05-14 11:07:12,493:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:07:13,247:INFO:Uploading results into container
2025-05-14 11:07:13,248:INFO:Uploading model into container now
2025-05-14 11:07:13,248:INFO:_master_model_container: 17
2025-05-14 11:07:13,248:INFO:_display_container: 4
2025-05-14 11:07:13,248:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:07:13,248:INFO:create_model() successfully completed......................................
2025-05-14 11:07:13,330:INFO:SubProcess create_model() end ==================================
2025-05-14 11:07:13,331:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4708
2025-05-14 11:07:13,331:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4906
2025-05-14 11:07:13,331:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-14 11:07:13,331:INFO:choose_better completed
2025-05-14 11:07:13,335:INFO:_master_model_container: 17
2025-05-14 11:07:13,335:INFO:_display_container: 3
2025-05-14 11:07:13,336:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:07:13,336:INFO:tune_model() successfully completed......................................
2025-05-14 11:07:13,425:INFO:Initializing evaluate_model()
2025-05-14 11:07:13,425:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 11:07:13,432:INFO:Initializing plot_model()
2025-05-14 11:07:13,433:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 11:07:13,433:INFO:Checking exceptions
2025-05-14 11:07:13,437:INFO:Preloading libraries
2025-05-14 11:07:13,440:INFO:Copying training dataset
2025-05-14 11:07:13,440:INFO:Plot type: pipeline
2025-05-14 11:07:13,499:INFO:Visual Rendered Successfully
2025-05-14 11:07:13,581:INFO:plot_model() successfully completed......................................
2025-05-14 11:07:13,583:INFO:Initializing interpret_model()
2025-05-14 11:07:13,583:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3360fa290>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 11:07:13,583:INFO:Checking exceptions
2025-05-14 11:07:13,583:INFO:Soft dependency imported: shap: 0.47.2
2025-05-14 11:07:13,669:INFO:plot type: summary
2025-05-14 11:07:13,669:INFO:Creating TreeExplainer
2025-05-14 11:07:13,746:INFO:Compiling shap values
2025-05-14 11:07:15,028:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning:

LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray


2025-05-14 11:07:15,028:WARNING:/Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4145: FutureWarning:

The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.


2025-05-14 11:07:16,301:INFO:Visual Rendered Successfully
2025-05-14 11:07:16,301:INFO:interpret_model() successfully completed......................................
2025-05-14 11:07:16,405:INFO:gpu_param set to False
2025-05-14 11:07:16,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,437:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,468:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,472:INFO:PyCaret ClassificationExperiment
2025-05-14 11:07:16,472:INFO:Logging name: clf-default-name
2025-05-14 11:07:16,473:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 11:07:16,473:INFO:version 3.3.2
2025-05-14 11:07:16,473:INFO:Initializing setup()
2025-05-14 11:07:16,473:INFO:self.USI: 237b
2025-05-14 11:07:16,473:INFO:self._variable_keys: {'USI', 'exp_id', 'X', 'y_train', 'is_multiclass', 'memory', 'idx', 'data', 'y_test', 'n_jobs_param', 'pipeline', 'y', 'fold_generator', 'logging_param', 'fold_groups_param', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'html_param', 'X_test', 'gpu_param', 'X_train', '_available_plots', 'seed', 'exp_name_log', 'fold_shuffle_param', 'log_plots_param', 'target_param'}
2025-05-14 11:07:16,473:INFO:Checking environment
2025-05-14 11:07:16,473:INFO:python_version: 3.11.0
2025-05-14 11:07:16,473:INFO:python_build: ('main', 'Mar 10 2025 10:54:30')
2025-05-14 11:07:16,473:INFO:machine: arm64
2025-05-14 11:07:16,473:INFO:platform: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:07:16,473:INFO:Memory: svmem(total=17179869184, available=3439935488, percent=80.0, used=5903941632, free=67928064, active=3393896448, inactive=3368665088, wired=2510045184)
2025-05-14 11:07:16,473:INFO:Physical Core: 12
2025-05-14 11:07:16,473:INFO:Logical Core: 12
2025-05-14 11:07:16,473:INFO:Checking libraries
2025-05-14 11:07:16,473:INFO:System:
2025-05-14 11:07:16,473:INFO:    python: 3.11.0 (main, Mar 10 2025, 10:54:30) [Clang 16.0.0 (clang-1600.0.26.6)]
2025-05-14 11:07:16,473:INFO:executable: /Users/junghwanryu/.pyenv/versions/3.11.0/envs/dacon-3.11/bin/python
2025-05-14 11:07:16,473:INFO:   machine: macOS-15.4.1-arm64-arm-64bit
2025-05-14 11:07:16,473:INFO:PyCaret required dependencies:
2025-05-14 11:07:16,473:INFO:                 pip: 22.3
2025-05-14 11:07:16,473:INFO:          setuptools: 65.5.0
2025-05-14 11:07:16,473:INFO:             pycaret: 3.3.2
2025-05-14 11:07:16,473:INFO:             IPython: 9.2.0
2025-05-14 11:07:16,473:INFO:          ipywidgets: 8.1.7
2025-05-14 11:07:16,473:INFO:                tqdm: 4.67.1
2025-05-14 11:07:16,473:INFO:               numpy: 1.26.4
2025-05-14 11:07:16,473:INFO:              pandas: 2.1.4
2025-05-14 11:07:16,473:INFO:              jinja2: 3.1.6
2025-05-14 11:07:16,473:INFO:               scipy: 1.11.4
2025-05-14 11:07:16,473:INFO:              joblib: 1.3.2
2025-05-14 11:07:16,473:INFO:             sklearn: 1.4.2
2025-05-14 11:07:16,473:INFO:                pyod: 2.0.5
2025-05-14 11:07:16,473:INFO:            imblearn: 0.13.0
2025-05-14 11:07:16,473:INFO:   category_encoders: 2.7.0
2025-05-14 11:07:16,473:INFO:            lightgbm: 4.6.0
2025-05-14 11:07:16,473:INFO:               numba: 0.61.2
2025-05-14 11:07:16,473:INFO:            requests: 2.32.3
2025-05-14 11:07:16,473:INFO:          matplotlib: 3.7.5
2025-05-14 11:07:16,473:INFO:          scikitplot: 0.3.7
2025-05-14 11:07:16,473:INFO:         yellowbrick: 1.5
2025-05-14 11:07:16,473:INFO:              plotly: 5.24.1
2025-05-14 11:07:16,473:INFO:    plotly-resampler: Not installed
2025-05-14 11:07:16,473:INFO:             kaleido: 0.2.1
2025-05-14 11:07:16,473:INFO:           schemdraw: 0.15
2025-05-14 11:07:16,473:INFO:         statsmodels: 0.14.4
2025-05-14 11:07:16,473:INFO:              sktime: 0.26.0
2025-05-14 11:07:16,473:INFO:               tbats: 1.1.3
2025-05-14 11:07:16,473:INFO:            pmdarima: 2.0.4
2025-05-14 11:07:16,473:INFO:              psutil: 7.0.0
2025-05-14 11:07:16,473:INFO:          markupsafe: 3.0.2
2025-05-14 11:07:16,473:INFO:             pickle5: Not installed
2025-05-14 11:07:16,473:INFO:         cloudpickle: 3.1.1
2025-05-14 11:07:16,473:INFO:         deprecation: 2.1.0
2025-05-14 11:07:16,474:INFO:              xxhash: 3.5.0
2025-05-14 11:07:16,474:INFO:           wurlitzer: 3.1.1
2025-05-14 11:07:16,474:INFO:PyCaret optional dependencies:
2025-05-14 11:07:16,474:INFO:                shap: 0.47.2
2025-05-14 11:07:16,474:INFO:           interpret: Not installed
2025-05-14 11:07:16,474:INFO:                umap: Not installed
2025-05-14 11:07:16,474:INFO:     ydata_profiling: Not installed
2025-05-14 11:07:16,474:INFO:  explainerdashboard: Not installed
2025-05-14 11:07:16,474:INFO:             autoviz: Not installed
2025-05-14 11:07:16,474:INFO:           fairlearn: Not installed
2025-05-14 11:07:16,474:INFO:          deepchecks: Not installed
2025-05-14 11:07:16,474:INFO:             xgboost: Not installed
2025-05-14 11:07:16,474:INFO:            catboost: 1.2.8
2025-05-14 11:07:16,474:INFO:              kmodes: Not installed
2025-05-14 11:07:16,474:INFO:             mlxtend: Not installed
2025-05-14 11:07:16,474:INFO:       statsforecast: Not installed
2025-05-14 11:07:16,474:INFO:        tune_sklearn: Not installed
2025-05-14 11:07:16,474:INFO:                 ray: Not installed
2025-05-14 11:07:16,474:INFO:            hyperopt: Not installed
2025-05-14 11:07:16,474:INFO:              optuna: 4.3.0
2025-05-14 11:07:16,474:INFO:               skopt: Not installed
2025-05-14 11:07:16,474:INFO:              mlflow: Not installed
2025-05-14 11:07:16,474:INFO:              gradio: Not installed
2025-05-14 11:07:16,474:INFO:             fastapi: Not installed
2025-05-14 11:07:16,474:INFO:             uvicorn: Not installed
2025-05-14 11:07:16,474:INFO:              m2cgen: Not installed
2025-05-14 11:07:16,474:INFO:           evidently: Not installed
2025-05-14 11:07:16,474:INFO:               fugue: Not installed
2025-05-14 11:07:16,474:INFO:           streamlit: Not installed
2025-05-14 11:07:16,474:INFO:             prophet: Not installed
2025-05-14 11:07:16,474:INFO:None
2025-05-14 11:07:16,474:INFO:Set up data.
2025-05-14 11:07:16,517:INFO:Set up folding strategy.
2025-05-14 11:07:16,517:INFO:Set up train/test split.
2025-05-14 11:07:16,535:INFO:Set up index.
2025-05-14 11:07:16,535:INFO:Assigning column types.
2025-05-14 11:07:16,539:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 11:07:16,558:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:07:16,558:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:07:16,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,570:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,588:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 11:07:16,589:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:07:16,600:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,600:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,600:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 11:07:16,619:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:07:16,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,631:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,649:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 11:07:16,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,661:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,661:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 11:07:16,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,691:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:16,720:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:16,721:INFO:Preparing preprocessing pipeline...
2025-05-14 11:07:16,722:INFO:Set up simple imputation.
2025-05-14 11:07:16,730:INFO:Set up encoding of ordinal features.
2025-05-14 11:07:16,741:INFO:Set up encoding of categorical features.
2025-05-14 11:07:16,741:INFO:Set up imbalanced handling.
2025-05-14 11:07:16,741:INFO:Set up column transformation.
2025-05-14 11:07:17,059:INFO:Finished creating preprocessing pipeline.
2025-05-14 11:07:17,078:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-14 11:07:17,078:INFO:Creating final display dataframe.
2025-05-14 11:07:17,319:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Cancer
2                   Target type            Binary
3           Original data shape       (87159, 16)
4        Transformed data shape      (133528, 29)
5   Transformed train set shape      (107380, 29)
6    Transformed test set shape       (26148, 29)
7              Numeric features                 6
8          Categorical features                 9
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                 5
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              237b
2025-05-14 11:07:17,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:17,352:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:17,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 11:07:17,384:INFO:Soft dependency imported: catboost: 1.2.8
2025-05-14 11:07:17,385:INFO:setup() successfully completed in 0.92s...............
2025-05-14 11:07:17,385:INFO:Initializing create_model()
2025-05-14 11:07:17,385:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:07:17,385:INFO:Checking exceptions
2025-05-14 11:07:17,391:INFO:Importing libraries
2025-05-14 11:07:17,391:INFO:Copying training dataset
2025-05-14 11:07:17,403:INFO:Defining folds
2025-05-14 11:07:17,403:INFO:Declaring metric variables
2025-05-14 11:07:17,404:INFO:Importing untrained model
2025-05-14 11:07:17,406:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:07:17,408:INFO:Starting cross validation
2025-05-14 11:07:17,410:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:07:21,836:INFO:Calculating mean and std
2025-05-14 11:07:21,837:INFO:Creating metrics dataframe
2025-05-14 11:07:21,839:INFO:Finalizing model
2025-05-14 11:07:23,134:INFO:[LightGBM] [Info] Number of positive: 53690, number of negative: 53690
2025-05-14 11:07:23,147:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005997 seconds.
2025-05-14 11:07:23,147:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:07:23,147:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:07:23,148:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:07:23,148:INFO:[LightGBM] [Info] Number of data points in the train set: 107380, number of used features: 28
2025-05-14 11:07:23,148:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:07:23,928:INFO:Uploading results into container
2025-05-14 11:07:23,929:INFO:Uploading model into container now
2025-05-14 11:07:23,932:INFO:_master_model_container: 1
2025-05-14 11:07:23,932:INFO:_display_container: 2
2025-05-14 11:07:23,933:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:07:23,933:INFO:create_model() successfully completed......................................
2025-05-14 11:07:24,033:INFO:Initializing tune_model()
2025-05-14 11:07:24,033:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 11:07:24,033:INFO:Checking exceptions
2025-05-14 11:07:24,045:INFO:Copying training dataset
2025-05-14 11:07:24,055:INFO:Checking base model
2025-05-14 11:07:24,055:INFO:Base model : Light Gradient Boosting Machine
2025-05-14 11:07:24,057:INFO:Declaring metric variables
2025-05-14 11:07:24,058:INFO:Defining Hyperparameters
2025-05-14 11:07:24,159:INFO:Tuning with n_jobs=-1
2025-05-14 11:07:24,159:INFO:Initializing RandomizedSearchCV
2025-05-14 11:08:03,873:INFO:best_params: {'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 76, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2025-05-14 11:08:03,877:INFO:Hyperparameter search completed
2025-05-14 11:08:03,878:INFO:SubProcess create_model() called ==================================
2025-05-14 11:08:03,879:INFO:Initializing create_model()
2025-05-14 11:08:03,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33289f3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.005, 'reg_alpha': 0.05, 'num_leaves': 30, 'n_estimators': 190, 'min_split_gain': 0.1, 'min_child_samples': 76, 'learning_rate': 0.001, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2025-05-14 11:08:03,879:INFO:Checking exceptions
2025-05-14 11:08:03,879:INFO:Importing libraries
2025-05-14 11:08:03,879:INFO:Copying training dataset
2025-05-14 11:08:03,902:INFO:Defining folds
2025-05-14 11:08:03,902:INFO:Declaring metric variables
2025-05-14 11:08:03,908:INFO:Importing untrained model
2025-05-14 11:08:03,908:INFO:Declaring custom model
2025-05-14 11:08:03,912:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:08:03,914:INFO:Starting cross validation
2025-05-14 11:08:03,916:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:08:11,300:INFO:Calculating mean and std
2025-05-14 11:08:11,301:INFO:Creating metrics dataframe
2025-05-14 11:08:11,305:INFO:Finalizing model
2025-05-14 11:08:12,576:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:08:12,576:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:08:12,576:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:08:12,615:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:08:12,615:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:08:12,615:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:08:12,616:INFO:[LightGBM] [Info] Number of positive: 53690, number of negative: 53690
2025-05-14 11:08:12,626:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005761 seconds.
2025-05-14 11:08:12,626:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:08:12,626:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:08:12,627:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:08:12,627:INFO:[LightGBM] [Info] Number of data points in the train set: 107380, number of used features: 28
2025-05-14 11:08:12,627:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:08:14,110:INFO:Uploading results into container
2025-05-14 11:08:14,110:INFO:Uploading model into container now
2025-05-14 11:08:14,110:INFO:_master_model_container: 2
2025-05-14 11:08:14,111:INFO:_display_container: 3
2025-05-14 11:08:14,111:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:08:14,111:INFO:create_model() successfully completed......................................
2025-05-14 11:08:14,248:INFO:SubProcess create_model() end ==================================
2025-05-14 11:08:14,248:INFO:choose_better activated
2025-05-14 11:08:14,250:INFO:SubProcess create_model() called ==================================
2025-05-14 11:08:14,250:INFO:Initializing create_model()
2025-05-14 11:08:14,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:08:14,250:INFO:Checking exceptions
2025-05-14 11:08:14,251:INFO:Importing libraries
2025-05-14 11:08:14,251:INFO:Copying training dataset
2025-05-14 11:08:14,262:INFO:Defining folds
2025-05-14 11:08:14,262:INFO:Declaring metric variables
2025-05-14 11:08:14,262:INFO:Importing untrained model
2025-05-14 11:08:14,262:INFO:Declaring custom model
2025-05-14 11:08:14,263:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:08:14,263:INFO:Starting cross validation
2025-05-14 11:08:14,264:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:08:18,602:INFO:Calculating mean and std
2025-05-14 11:08:18,602:INFO:Creating metrics dataframe
2025-05-14 11:08:18,603:INFO:Finalizing model
2025-05-14 11:08:19,889:INFO:[LightGBM] [Info] Number of positive: 53690, number of negative: 53690
2025-05-14 11:08:19,900:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005382 seconds.
2025-05-14 11:08:19,900:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:08:19,900:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:08:19,900:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:08:19,900:INFO:[LightGBM] [Info] Number of data points in the train set: 107380, number of used features: 28
2025-05-14 11:08:19,900:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:08:20,686:INFO:Uploading results into container
2025-05-14 11:08:20,686:INFO:Uploading model into container now
2025-05-14 11:08:20,686:INFO:_master_model_container: 3
2025-05-14 11:08:20,686:INFO:_display_container: 4
2025-05-14 11:08:20,686:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:08:20,686:INFO:create_model() successfully completed......................................
2025-05-14 11:08:20,776:INFO:SubProcess create_model() end ==================================
2025-05-14 11:08:20,776:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4728
2025-05-14 11:08:20,776:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.4908
2025-05-14 11:08:20,777:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-14 11:08:20,777:INFO:choose_better completed
2025-05-14 11:08:20,780:INFO:_master_model_container: 3
2025-05-14 11:08:20,780:INFO:_display_container: 3
2025-05-14 11:08:20,781:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:08:20,781:INFO:tune_model() successfully completed......................................
2025-05-14 11:08:20,873:INFO:Initializing finalize_model()
2025-05-14 11:08:20,873:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-14 11:08:20,874:INFO:Finalizing LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:08:20,878:INFO:Initializing create_model()
2025-05-14 11:08:20,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=76, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=190, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.05, reg_lambda=0.005, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:08:20,878:INFO:Checking exceptions
2025-05-14 11:08:20,879:INFO:Importing libraries
2025-05-14 11:08:20,879:INFO:Copying training dataset
2025-05-14 11:08:20,880:INFO:Defining folds
2025-05-14 11:08:20,880:INFO:Declaring metric variables
2025-05-14 11:08:20,880:INFO:Importing untrained model
2025-05-14 11:08:20,880:INFO:Declaring custom model
2025-05-14 11:08:20,881:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:08:20,881:INFO:Cross validation set to False
2025-05-14 11:08:20,881:INFO:Fitting Model
2025-05-14 11:08:22,750:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:08:22,750:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:08:22,750:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:08:22,814:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:08:22,814:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:08:22,814:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:08:22,814:INFO:[LightGBM] [Info] Number of positive: 76700, number of negative: 76700
2025-05-14 11:08:22,831:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007302 seconds.
2025-05-14 11:08:22,831:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:08:22,831:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:08:22,831:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:08:22,831:INFO:[LightGBM] [Info] Number of data points in the train set: 153400, number of used features: 28
2025-05-14 11:08:22,831:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:08:24,598:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-14 11:08:24,599:INFO:create_model() successfully completed......................................
2025-05-14 11:08:24,749:INFO:_master_model_container: 3
2025-05-14 11:08:24,749:INFO:_display_container: 3
2025-05-14 11:08:24,771:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-14 11:08:24,771:INFO:finalize_model() successfully completed......................................
2025-05-14 11:08:24,913:INFO:Initializing save_model()
2025-05-14 11:08:24,913:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=final_cancer_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bj/ljbr3v1s4vg1cjjtmtss7w3r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-14 11:08:24,913:INFO:Adding model into prep_pipe
2025-05-14 11:08:24,913:WARNING:Only Model saved as it was a pipeline.
2025-05-14 11:08:24,924:INFO:final_cancer_model.pkl saved in current working directory
2025-05-14 11:08:24,946:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-14 11:08:24,946:INFO:save_model() successfully completed......................................
2025-05-14 11:08:25,067:INFO:Initializing predict_model()
2025-05-14 11:08:25,067:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x33ed3bba0>)
2025-05-14 11:08:25,067:INFO:Checking exceptions
2025-05-14 11:08:25,067:INFO:Preloading libraries
2025-05-14 11:08:25,069:INFO:Set up data.
2025-05-14 11:08:25,089:INFO:Set up index.
2025-05-14 11:08:25,607:INFO:Initializing create_model()
2025-05-14 11:08:25,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:08:25,607:INFO:Checking exceptions
2025-05-14 11:08:25,612:INFO:Importing libraries
2025-05-14 11:08:25,612:INFO:Copying training dataset
2025-05-14 11:08:25,627:INFO:Defining folds
2025-05-14 11:08:25,627:INFO:Declaring metric variables
2025-05-14 11:08:25,628:INFO:Importing untrained model
2025-05-14 11:08:25,630:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 11:08:25,633:INFO:Starting cross validation
2025-05-14 11:08:25,634:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:08:30,296:INFO:Calculating mean and std
2025-05-14 11:08:30,297:INFO:Creating metrics dataframe
2025-05-14 11:08:30,299:INFO:Finalizing model
2025-05-14 11:08:31,564:INFO:[LightGBM] [Info] Number of positive: 53690, number of negative: 53690
2025-05-14 11:08:31,576:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005518 seconds.
2025-05-14 11:08:31,576:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 11:08:31,576:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 11:08:31,576:INFO:[LightGBM] [Info] Total Bins 7140
2025-05-14 11:08:31,576:INFO:[LightGBM] [Info] Number of data points in the train set: 107380, number of used features: 28
2025-05-14 11:08:31,577:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 11:08:32,360:INFO:Uploading results into container
2025-05-14 11:08:32,360:INFO:Uploading model into container now
2025-05-14 11:08:32,364:INFO:_master_model_container: 4
2025-05-14 11:08:32,364:INFO:_display_container: 4
2025-05-14 11:08:32,364:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 11:08:32,364:INFO:create_model() successfully completed......................................
2025-05-14 11:08:32,448:INFO:Initializing create_model()
2025-05-14 11:08:32,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:08:32,448:INFO:Checking exceptions
2025-05-14 11:08:32,454:INFO:Importing libraries
2025-05-14 11:08:32,454:INFO:Copying training dataset
2025-05-14 11:08:32,467:INFO:Defining folds
2025-05-14 11:08:32,467:INFO:Declaring metric variables
2025-05-14 11:08:32,468:INFO:Importing untrained model
2025-05-14 11:08:32,470:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 11:08:32,472:INFO:Starting cross validation
2025-05-14 11:08:32,474:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:08:49,630:INFO:Calculating mean and std
2025-05-14 11:08:49,634:INFO:Creating metrics dataframe
2025-05-14 11:08:49,645:INFO:Finalizing model
2025-05-14 11:09:10,589:INFO:Uploading results into container
2025-05-14 11:09:10,591:INFO:Uploading model into container now
2025-05-14 11:09:10,597:INFO:_master_model_container: 5
2025-05-14 11:09:10,597:INFO:_display_container: 5
2025-05-14 11:09:10,598:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 11:09:10,598:INFO:create_model() successfully completed......................................
2025-05-14 11:09:10,756:INFO:Initializing create_model()
2025-05-14 11:09:10,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:09:10,756:INFO:Checking exceptions
2025-05-14 11:09:10,762:INFO:Importing libraries
2025-05-14 11:09:10,762:INFO:Copying training dataset
2025-05-14 11:09:10,775:INFO:Defining folds
2025-05-14 11:09:10,775:INFO:Declaring metric variables
2025-05-14 11:09:10,777:INFO:Importing untrained model
2025-05-14 11:09:10,778:INFO:Random Forest Classifier Imported successfully
2025-05-14 11:09:10,781:INFO:Starting cross validation
2025-05-14 11:09:10,783:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:09:18,893:INFO:Calculating mean and std
2025-05-14 11:09:18,895:INFO:Creating metrics dataframe
2025-05-14 11:09:18,902:INFO:Finalizing model
2025-05-14 11:09:21,988:INFO:Uploading results into container
2025-05-14 11:09:21,988:INFO:Uploading model into container now
2025-05-14 11:09:21,993:INFO:_master_model_container: 6
2025-05-14 11:09:21,993:INFO:_display_container: 6
2025-05-14 11:09:21,993:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-05-14 11:09:21,993:INFO:create_model() successfully completed......................................
2025-05-14 11:09:22,134:INFO:Initializing blend_models()
2025-05-14 11:09:22,135:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-05-14 11:09:22,135:INFO:Checking exceptions
2025-05-14 11:09:22,147:INFO:Importing libraries
2025-05-14 11:09:22,147:INFO:Copying training dataset
2025-05-14 11:09:22,149:INFO:Getting model names
2025-05-14 11:09:22,151:INFO:SubProcess create_model() called ==================================
2025-05-14 11:09:22,153:INFO:Initializing create_model()
2025-05-14 11:09:22,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332814a50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 11:09:22,153:INFO:Checking exceptions
2025-05-14 11:09:22,153:INFO:Importing libraries
2025-05-14 11:09:22,153:INFO:Copying training dataset
2025-05-14 11:09:22,166:INFO:Defining folds
2025-05-14 11:09:22,166:INFO:Declaring metric variables
2025-05-14 11:09:22,167:INFO:Importing untrained model
2025-05-14 11:09:22,167:INFO:Declaring custom model
2025-05-14 11:09:22,170:INFO:Voting Classifier Imported successfully
2025-05-14 11:09:22,172:INFO:Starting cross validation
2025-05-14 11:09:22,173:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 11:09:43,763:INFO:Calculating mean and std
2025-05-14 11:09:43,766:INFO:Creating metrics dataframe
2025-05-14 11:09:43,779:INFO:Finalizing model
2025-05-14 11:10:05,337:INFO:Uploading results into container
2025-05-14 11:10:05,340:INFO:Uploading model into container now
2025-05-14 11:10:05,341:INFO:_master_model_container: 7
2025-05-14 11:10:05,342:INFO:_display_container: 7
2025-05-14 11:10:05,345:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-14 11:10:05,345:INFO:create_model() successfully completed......................................
2025-05-14 11:10:05,557:INFO:SubProcess create_model() end ==================================
2025-05-14 11:10:05,562:INFO:_master_model_container: 7
2025-05-14 11:10:05,562:INFO:_display_container: 7
2025-05-14 11:10:05,564:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-05-14 11:10:05,564:INFO:blend_models() successfully completed......................................
2025-05-14 11:10:05,655:INFO:Initializing predict_model()
2025-05-14 11:10:05,655:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda...
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x330b251c0>)
2025-05-14 11:10:05,655:INFO:Checking exceptions
2025-05-14 11:10:05,655:INFO:Preloading libraries
2025-05-14 11:10:05,656:INFO:Set up data.
2025-05-14 11:10:05,679:INFO:Set up index.
2025-05-14 11:10:06,443:INFO:Initializing plot_model()
2025-05-14 11:10:06,443:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 11:10:06,443:INFO:Checking exceptions
2025-05-14 11:10:06,450:INFO:Preloading libraries
2025-05-14 11:10:06,453:INFO:Copying training dataset
2025-05-14 11:10:06,453:INFO:Plot type: confusion_matrix
2025-05-14 11:10:06,713:INFO:Fitting Model
2025-05-14 11:10:06,716:INFO:Scoring test/hold-out set
2025-05-14 11:10:06,717:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:10:06,717:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:10:06,717:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:10:06,762:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:10:06,762:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:10:06,762:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:10:06,840:INFO:Visual Rendered Successfully
2025-05-14 11:10:06,927:INFO:plot_model() successfully completed......................................
2025-05-14 11:10:06,949:INFO:Initializing plot_model()
2025-05-14 11:10:06,949:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 11:10:06,949:INFO:Checking exceptions
2025-05-14 11:10:06,954:INFO:Preloading libraries
2025-05-14 11:10:06,957:INFO:Copying training dataset
2025-05-14 11:10:06,957:INFO:Plot type: auc
2025-05-14 11:10:07,210:INFO:Fitting Model
2025-05-14 11:10:07,212:INFO:Scoring test/hold-out set
2025-05-14 11:10:07,213:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:10:07,213:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:10:07,213:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:10:07,253:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-14 11:10:07,253:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-05-14 11:10:07,253:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-05-14 11:10:07,375:INFO:Visual Rendered Successfully
2025-05-14 11:10:07,468:INFO:plot_model() successfully completed......................................
2025-05-14 11:10:07,491:INFO:Initializing plot_model()
2025-05-14 11:10:07,491:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x33c9e8790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Nodule_Size', 'TSH_Result',
                                             'T4_Result', 'T3_Result',
                                             'Iodine_Country_Risk'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=76,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=190, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.05,
                                reg_lambda=0.005, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 11:10:07,491:INFO:Checking exceptions
2025-05-14 11:10:07,496:INFO:Preloading libraries
2025-05-14 11:10:07,500:INFO:Copying training dataset
2025-05-14 11:10:07,500:INFO:Plot type: feature
2025-05-14 11:10:07,500:WARNING:No coef_ found. Trying feature_importances_
2025-05-14 11:10:07,580:INFO:Visual Rendered Successfully
2025-05-14 11:10:07,674:INFO:plot_model() successfully completed......................................
